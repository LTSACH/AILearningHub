{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udd2c BBC News Pipeline Comparison\n",
        "\n",
        "**Compare feature extraction, dimensionality reduction, and classifier combinations**\n",
        "\n",
        "- **Dataset:** BBC News (2225 articles, 5 categories)\n",
        "- **Pipeline:** Feature Extractor \u2192 Dimensionality Reducer \u2192 Classifier\n",
        "- **Goal:** Find the optimal combination for text classification\n",
        "\n",
        "---\n",
        "\n",
        "**Source:** [AI Learning Hub](https://ltsach.github.io/AILearningHub/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q scikit-learn pandas numpy plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce5 Download Dataset\n",
        "\n",
        "We'll download the BBC News dataset from GitHub Pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_bbc_news():\n",
        "    \"\"\"Download BBC News dataset\"\"\"\n",
        "    base_url = 'https://ltsach.github.io/AILearningHub/datasets/bbcnews/data/'\n",
        "    files = ['train.csv', 'test.csv']\n",
        "    \n",
        "    data_dir = Path('bbc_data')\n",
        "    data_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    for filename in files:\n",
        "        filepath = data_dir / filename\n",
        "        if filepath.exists():\n",
        "            print(f\"\u2713 {filename} already exists\")\n",
        "        else:\n",
        "            print(f\"\u2b07\ufe0f  Downloading {filename}...\")\n",
        "            url = base_url + filename\n",
        "            urllib.request.urlretrieve(url, filepath)\n",
        "            print(f\"\u2705 Downloaded {filename}\")\n",
        "    \n",
        "    return data_dir\n",
        "\n",
        "# Download\n",
        "data_dir = download_bbc_news()\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(data_dir / 'train.csv')\n",
        "test_df = pd.read_csv(data_dir / 'test.csv')\n",
        "\n",
        "X_train = train_df['text'].values\n",
        "y_train = train_df['category'].values\n",
        "X_test = test_df['text'].values\n",
        "y_test = test_df['category'].values\n",
        "\n",
        "print(f\"\\n\ud83d\udcca Dataset Info:\")\n",
        "print(f\"   Train: {len(X_train)} samples\")\n",
        "print(f\"   Test: {len(X_test)} samples\")\n",
        "print(f\"   Classes: {sorted(set(y_train))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 Pipeline Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_pipeline(X_train, X_test, y_train, y_test, \n",
        "                   extractor, extractor_name,\n",
        "                   reducer, reducer_name,\n",
        "                   classifier, classifier_name):\n",
        "    \"\"\"Train a single pipeline and return results\"\"\"\n",
        "    \n",
        "    pipeline_name = f\"{extractor_name} \u2192 {reducer_name} \u2192 {classifier_name}\"\n",
        "    print(f\"\ud83d\udd2c {pipeline_name}\", end=\" \")\n",
        "    \n",
        "    try:\n",
        "        # Feature extraction\n",
        "        start = time.time()\n",
        "        X_train_vec = extractor.fit_transform(X_train)\n",
        "        X_test_vec = extractor.transform(X_test)\n",
        "        extract_time = time.time() - start\n",
        "        \n",
        "        features_before = X_train_vec.shape[1]\n",
        "        \n",
        "        # Dimensionality reduction\n",
        "        if reducer is not None:\n",
        "            start = time.time()\n",
        "            if reducer_name == 'Chi\u00b2':\n",
        "                X_train_vec = np.abs(X_train_vec.toarray())\n",
        "                X_test_vec = np.abs(X_test_vec.toarray())\n",
        "                X_train_vec = reducer.fit_transform(X_train_vec, y_train)\n",
        "                X_test_vec = reducer.transform(X_test_vec)\n",
        "            else:\n",
        "                X_train_vec = reducer.fit_transform(X_train_vec)\n",
        "                X_test_vec = reducer.transform(X_test_vec)\n",
        "            reduce_time = time.time() - start\n",
        "        else:\n",
        "            reduce_time = 0\n",
        "        \n",
        "        features_after = X_train_vec.shape[1]\n",
        "        \n",
        "        # Classification\n",
        "        start = time.time()\n",
        "        \n",
        "        if classifier_name == 'Naive Bayes':\n",
        "            if hasattr(X_train_vec, 'toarray'):\n",
        "                X_train_vec = X_train_vec.toarray()\n",
        "                X_test_vec = X_test_vec.toarray()\n",
        "            X_train_vec = np.abs(X_train_vec)\n",
        "            X_test_vec = np.abs(X_test_vec)\n",
        "        \n",
        "        classifier.fit(X_train_vec, y_train)\n",
        "        train_time = time.time() - start\n",
        "        \n",
        "        # Prediction\n",
        "        start = time.time()\n",
        "        y_pred = classifier.predict(X_test_vec)\n",
        "        infer_time = (time.time() - start) / len(y_test) * 1000\n",
        "        \n",
        "        # Metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        \n",
        "        print(f\"\u2192 \u2713 Accuracy: {accuracy*100:.2f}%\")\n",
        "        \n",
        "        return {\n",
        "            'pipeline': pipeline_name,\n",
        "            'extractor': extractor_name,\n",
        "            'reducer': reducer_name,\n",
        "            'classifier': classifier_name,\n",
        "            'accuracy': accuracy,\n",
        "            'train_time': extract_time + reduce_time + train_time,\n",
        "            'inference_ms': infer_time,\n",
        "            'features_before': features_before,\n",
        "            'features_after': features_after,\n",
        "            'confusion_matrix': cm,\n",
        "            'status': 'success'\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u2192 \u274c Error: {e}\")\n",
        "        return {'status': 'failed', 'pipeline': pipeline_name}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\ude80 Compare All Pipeline Combinations\n",
        "\n",
        "We'll test:\n",
        "- **2 Feature Extractors:** TF-IDF, Bag of Words\n",
        "- **3 Reducers:** None, PCA, Chi\u00b2\n",
        "- **4 Classifiers:** Logistic, SVM, Naive Bayes, Random Forest\n",
        "\n",
        "**Total: 24 pipelines**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define components\n",
        "extractors = [\n",
        "    (TfidfVectorizer(max_features=5000, ngram_range=(1,2), min_df=2, max_df=0.8), 'TF-IDF'),\n",
        "    (CountVectorizer(max_features=5000, ngram_range=(1,2), min_df=2), 'BoW'),\n",
        "]\n",
        "\n",
        "reducers = [\n",
        "    (None, 'None'),\n",
        "    (PCA(n_components=300), 'PCA'),\n",
        "    (SelectKBest(score_func=chi2, k=500), 'Chi\u00b2'),\n",
        "]\n",
        "\n",
        "classifiers = [\n",
        "    (LogisticRegression(max_iter=1000, random_state=42), 'Logistic'),\n",
        "    (LinearSVC(max_iter=1000, random_state=42), 'SVM'),\n",
        "    (MultinomialNB(), 'Naive Bayes'),\n",
        "    (RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1), 'Random Forest'),\n",
        "]\n",
        "\n",
        "# Train all combinations\n",
        "print(f\"Training {len(extractors) * len(reducers) * len(classifiers)} pipelines...\\n\")\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for extractor, ext_name in extractors:\n",
        "    for reducer, red_name in reducers:\n",
        "        for classifier, clf_name in classifiers:\n",
        "            from sklearn.base import clone\n",
        "            result = train_pipeline(\n",
        "                X_train, X_test, y_train, y_test,\n",
        "                clone(extractor), ext_name,\n",
        "                clone(reducer) if reducer else None, red_name,\n",
        "                clone(classifier), clf_name\n",
        "            )\n",
        "            all_results.append(result)\n",
        "\n",
        "# Filter successful\n",
        "results = [r for r in all_results if r.get('status') == 'success']\n",
        "print(f\"\\n\u2705 Successfully trained {len(results)} pipelines\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Visualization 1: Accuracy Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort by accuracy\n",
        "sorted_results = sorted(results, key=lambda x: -x['accuracy'])\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(\n",
        "    x=[r['pipeline'] for r in sorted_results],\n",
        "    y=[r['accuracy']*100 for r in sorted_results],\n",
        "    marker_color='#667eea',\n",
        "    text=[f\"{r['accuracy']*100:.2f}%\" for r in sorted_results],\n",
        "    textposition='outside'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Pipeline Accuracy Comparison',\n",
        "    xaxis_title='Pipeline',\n",
        "    yaxis_title='Accuracy (%)',\n",
        "    xaxis_tickangle=-45,\n",
        "    height=700,\n",
        "    yaxis_range=[75, 100],\n",
        "    margin=dict(b=200)\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Show top 5\n",
        "print(\"\\n\ud83c\udfc6 Top 5 Pipelines:\")\n",
        "for i, r in enumerate(sorted_results[:5], 1):\n",
        "    print(f\"{i}. {r['pipeline']}: {r['accuracy']*100:.2f}% (Train: {r['train_time']:.2f}s)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2696\ufe0f Visualization 2: Accuracy vs Speed Trade-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "for reducer in set(r['reducer'] for r in results):\n",
        "    filtered = [r for r in results if r['reducer'] == reducer]\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=[r['train_time'] for r in filtered],\n",
        "        y=[r['accuracy']*100 for r in filtered],\n",
        "        mode='markers+text',\n",
        "        name=reducer,\n",
        "        text=[r['classifier'] for r in filtered],\n",
        "        textposition='top center',\n",
        "        marker=dict(size=12)\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Trade-off: Accuracy vs Training Speed',\n",
        "    xaxis_title='Training Time (seconds, log scale)',\n",
        "    yaxis_title='Accuracy (%)',\n",
        "    height=600,\n",
        "    xaxis_type='log'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udf21\ufe0f Visualization 3: Accuracy Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create heatmap\n",
        "extractors_list = sorted(set(r['extractor'] for r in results))\n",
        "reducers_list = sorted(set(r['reducer'] for r in results))\n",
        "classifiers_list = sorted(set(r['classifier'] for r in results))\n",
        "\n",
        "x_labels = [f\"{e}+{r}\" for e in extractors_list for r in reducers_list]\n",
        "z_data = []\n",
        "\n",
        "for clf in classifiers_list:\n",
        "    row = []\n",
        "    for ext in extractors_list:\n",
        "        for red in reducers_list:\n",
        "            match = next((r for r in results \n",
        "                        if r['extractor']==ext and r['reducer']==red and r['classifier']==clf), None)\n",
        "            row.append(match['accuracy']*100 if match else None)\n",
        "    z_data.append(row)\n",
        "\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "    z=z_data,\n",
        "    x=x_labels,\n",
        "    y=classifiers_list,\n",
        "    colorscale='RdYlGn',\n",
        "    text=[[f\"{val:.1f}%\" if val else \"\" for val in row] for row in z_data],\n",
        "    texttemplate='%{text}',\n",
        "    colorbar=dict(title='Accuracy (%)')\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Accuracy Heatmap: Classifier vs Pipeline Configuration',\n",
        "    xaxis_title='Extractor + Reducer',\n",
        "    yaxis_title='Classifier',\n",
        "    height=500,\n",
        "    xaxis_tickangle=-45\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Visualization 4: Confusion Matrices (Top 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top3 = sorted(results, key=lambda x: -x['accuracy'])[:3]\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=3,\n",
        "    subplot_titles=[f\"{r['pipeline']}<br>Acc: {r['accuracy']*100:.1f}%\" for r in top3],\n",
        "    specs=[[{'type': 'heatmap'}]*3]\n",
        ")\n",
        "\n",
        "labels = sorted(set(y_test))\n",
        "\n",
        "for idx, r in enumerate(top3, 1):\n",
        "    fig.add_trace(\n",
        "        go.Heatmap(\n",
        "            z=r['confusion_matrix'],\n",
        "            x=labels,\n",
        "            y=labels,\n",
        "            colorscale='Blues',\n",
        "            showscale=(idx==3)\n",
        "        ),\n",
        "        row=1, col=idx\n",
        "    )\n",
        "\n",
        "fig.update_xaxes(title_text='Predicted')\n",
        "fig.update_yaxes(title_text='True')\n",
        "fig.update_layout(height=400, title_text='Top 3 Pipelines - Confusion Matrices')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udca1 Key Insights\n",
        "\n",
        "**General Findings:**\n",
        "- **TF-IDF** usually outperforms Bag of Words\n",
        "- **Dimensionality reduction** trades accuracy for speed and model size\n",
        "- **Logistic Regression**: Best balance of accuracy and speed\n",
        "- **Naive Bayes**: Fastest but slightly lower accuracy\n",
        "- **Random Forest**: Slowest with minimal accuracy benefit\n",
        "\n",
        "**Recommendations:**\n",
        "- \u2705 **Production**: TF-IDF \u2192 None \u2192 Logistic (best accuracy)\n",
        "- \u26a1 **Fast baseline**: TF-IDF \u2192 None \u2192 Naive Bayes (fastest)\n",
        "- \ud83d\udcbe **Small model**: TF-IDF \u2192 Chi\u00b2 \u2192 Naive Bayes (compact)\n",
        "- \u2696\ufe0f **Balanced**: TF-IDF \u2192 Chi\u00b2 \u2192 Logistic (good compromise)\n",
        "\n",
        "---\n",
        "\n",
        "**Source:** [AI Learning Hub - Pipeline Comparison](https://ltsach.github.io/AILearningHub/04_Natural_Language_Processing/text_classification/pages/pipeline_comparison/)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "name": "BBC_News_Pipeline_Comparison.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}