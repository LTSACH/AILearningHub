{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BBC News Classification with BERT Fine-tuning\n\nThis notebook fine-tunes BERT models (BERT-base, DistilBERT, TinyBERT) with different pooling strategies for text classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers torch pandas scikit-learn tqdm -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport json\nfrom datetime import datetime\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\nfrom transformers import (\n    AutoTokenizer, AutoModel, AutoConfig,\n    get_linear_schedule_with_warmup\n)\nfrom torch.optim import AdamW\n\n\n\nBERT_MODELS = {\n    'bert_base': {\n        'name': 'BERT-base',\n        'model_name': 'bert-base-uncased',\n        'params_millions': 110,\n        'has_pooler': True\n    },\n    'distilbert': {\n        'name': 'DistilBERT',\n        'model_name': 'distilbert-base-uncased',\n        'params_millions': 66,\n        'has_pooler': False\n    },\n    'tinybert': {\n        'name': 'TinyBERT',\n        'model_name': 'prajjwal1/bert-tiny',\n        'params_millions': 14,\n        'has_pooler': True\n    }\n}\n\nPOOLING_STRATEGIES = {\n    'cls_token': '[CLS] Token',\n    'mean_pooling': 'Mean Pooling',\n    'pooler_output': 'Pooler Output'\n}\n\nTRAINING_CONFIG = {\n    'max_length': 128,\n    'batch_size': 16,\n    'eval_batch_size': 32,\n    'learning_rate': 2e-5,\n    'num_epochs': 3,\n    'weight_decay': 0.01,\n    'warmup_ratio': 0.1,\n    'seed': 42\n}\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download BBC News dataset using the built-in function\ntrain_df, val_df, test_df = download_bbc_news()\n\n# Save to local files for Colab\ntrain_df.to_csv('data/train.csv', index=False)\nval_df.to_csv('data/val.csv', index=False)\ntest_df.to_csv('data/test.csv', index=False)\n\nprint(\"\u2705 Dataset downloaded and saved locally!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== Data Loading ==========\n\n\nclass BBCNewsDataset(Dataset):\n    \"\"\"PyTorch Dataset for BBC News\"\"\"\n    \n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        \n        encoding = self.tokenizer(\n            text,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'label': torch.tensor(label, dtype=torch.long)\n        }\n\n\ndef download_bbc_news():\n    \"\"\"Download BBC News dataset from GitHub Pages\"\"\"\n    print(\"=\"*70)\n    print(\"\ud83d\udce5 DOWNLOADING BBC NEWS DATASET\")\n    print(\"=\"*70)\n    \n    base_url = 'https://ltsach.github.io/AILearningHub/datasets/bbcnews/data/'\n    \n    try:\n        train_df = pd.read_csv(base_url + 'train.csv')\n        val_df = pd.read_csv(base_url + 'val.csv')\n        test_df = pd.read_csv(base_url + 'test.csv')\n        \n        print(f\"\u2713 Train: {len(train_df):,} samples\")\n        print(f\"\u2713 Val: {len(val_df):,} samples\")\n        print(f\"\u2713 Test: {len(test_df):,} samples\")\n        print(f\"\u2713 Categories: {sorted(train_df['category'].unique().tolist())}\")\n        print()\n        \n        return train_df, val_df, test_df\n    except Exception as e:\n        print(f\"\u274c Failed to download: {e}\")\n        return None, None, None\n\n\ndef load_bbc_news(data_dir='data'):\n    \"\"\"Load BBC News dataset\"\"\"\n    data_dir = Path(data_dir)\n    \n    # Check if data exists locally\n    if not (data_dir / 'train.csv').exists():\n        print(\"\ud83d\udce5 Dataset not found locally, downloading...\")\n        train_df, val_df, test_df = download_bbc_news()\n        if train_df is None:\n            raise FileNotFoundError(\"Failed to download dataset\")\n        \n        # Get label mapping for downloaded data\n        label_map = {label: idx for idx, label in enumerate(sorted(train_df['category'].unique()))}\n        \n        # Convert labels\n        train_df['label'] = train_df['category'].map(label_map)\n        val_df['label'] = val_df['category'].map(label_map)\n        test_df['label'] = test_df['category'].map(label_map)\n        \n        print(f\"\u2713 Loaded BBC News dataset\")\n        print(f\"  Train: {len(train_df)} samples\")\n        print(f\"  Val: {len(val_df)} samples\")\n        print(f\"  Test: {len(test_df)} samples\")\n        print(f\"  Classes: {list(label_map.keys())}\")\n        \n        return train_df, val_df, test_df, label_map\n    \n    # Load preprocessed data\n    train_df = pd.read_csv(data_dir / 'train.csv')\n    val_df = pd.read_csv(data_dir / 'val.csv')\n    test_df = pd.read_csv(data_dir / 'test.csv')\n    \n    # Get label mapping\n    label_map = {label: idx for idx, label in enumerate(sorted(train_df['category'].unique()))}\n    \n    # Convert labels\n    train_df['label'] = train_df['category'].map(label_map)\n    val_df['label'] = val_df['category'].map(label_map)\n    test_df['label'] = test_df['category'].map(label_map)\n    \n    print(f\"\u2713 Loaded BBC News dataset\")\n    print(f\"  Train: {len(train_df)} samples\")\n    print(f\"  Val: {len(val_df)} samples\")\n    print(f\"  Test: {len(test_df)} samples\")\n    print(f\"  Classes: {list(label_map.keys())}\")\n    \n    return train_df, val_df, test_df, label_map\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== Model Definition ==========\n\n\nclass BERTWithCustomPooling(nn.Module):\n    \"\"\"BERT model with custom pooling strategies\"\"\"\n    \n    def __init__(self, model_name, pooling_strategy='cls_token', num_labels=5, dropout=0.1):\n        super().__init__()\n        self.pooling_strategy = pooling_strategy\n        \n        # Load pre-trained BERT\n        config = AutoConfig.from_pretrained(model_name)\n        self.bert = AutoModel.from_pretrained(model_name, config=config)\n        hidden_size = config.hidden_size\n        \n        # Classification head\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Linear(hidden_size, num_labels)\n        \n        # Check if model has pooler\n        self.has_pooler = hasattr(self.bert, 'pooler') and self.bert.pooler is not None\n    \n    def forward(self, input_ids, attention_mask):\n        # Get BERT outputs\n        outputs = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            return_dict=True\n        )\n        \n        # Apply pooling strategy\n        if self.pooling_strategy == 'cls_token':\n            # Use [CLS] token (first token)\n            pooled = outputs.last_hidden_state[:, 0, :]\n        \n        elif self.pooling_strategy == 'mean_pooling':\n            # Average all tokens (excluding padding)\n            last_hidden = outputs.last_hidden_state\n            attention_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()\n            sum_hidden = torch.sum(last_hidden * attention_mask_expanded, dim=1)\n            sum_mask = torch.clamp(attention_mask_expanded.sum(dim=1), min=1e-9)\n            pooled = sum_hidden / sum_mask\n        \n        elif self.pooling_strategy == 'pooler_output':\n            # Use BERT's pooler output (if available)\n            if not self.has_pooler:\n                raise ValueError(f\"Model does not have pooler output\")\n            pooled = outputs.pooler_output\n        \n        else:\n            raise ValueError(f\"Unknown pooling strategy: {self.pooling_strategy}\")\n        \n        # Classification\n        pooled = self.dropout(pooled)\n        logits = self.classifier(pooled)\n        \n        return logits\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Trainer Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== Training ==========\n\n\nclass BERTTrainer:\n    \"\"\"Train and evaluate BERT models\"\"\"\n    \n    def __init__(self, data_dir='data', output_dir='results/bert'):\n        self.data_dir = Path(data_dir)\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Set device\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        print(f\"\\n\ud83d\udda5\ufe0f  Device: {self.device}\")\n        \n        # Set seed\n        torch.manual_seed(TRAINING_CONFIG['seed'])\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(TRAINING_CONFIG['seed'])\n    \n    def train_combination(self, model_key, pooling_key, train_df, val_df, test_df, label_map):\n        \"\"\"Train single model + pooling combination\"\"\"\n        \n        model_info = BERT_MODELS[model_key]\n        \n        # Skip if pooling requires pooler but model doesn't have it\n        if pooling_key == 'pooler_output' and not model_info['has_pooler']:\n            print(f\"\\n\u23ed\ufe0f  Skipping {model_key} + {pooling_key}: No pooler\")\n            return None\n        \n        combination_name = f\"{model_key}_{pooling_key}\"\n        display_name = f\"{model_info['name']} + {POOLING_STRATEGIES[pooling_key]}\"\n        \n        print(f\"\\n{'='*70}\")\n        print(f\"\ud83d\ude80 Training: {display_name}\")\n        print(f\"{'='*70}\")\n        \n        # Load tokenizer\n        tokenizer = AutoTokenizer.from_pretrained(model_info['model_name'])\n        \n        # Create datasets\n        train_dataset = BBCNewsDataset(\n            train_df['text'].values,\n            train_df['label'].values,\n            tokenizer,\n            TRAINING_CONFIG['max_length']\n        )\n        val_dataset = BBCNewsDataset(\n            val_df['text'].values,\n            val_df['label'].values,\n            tokenizer,\n            TRAINING_CONFIG['max_length']\n        )\n        test_dataset = BBCNewsDataset(\n            test_df['text'].values,\n            test_df['label'].values,\n            tokenizer,\n            TRAINING_CONFIG['max_length']\n        )\n        \n        # Create dataloaders\n        train_loader = DataLoader(\n            train_dataset,\n            batch_size=TRAINING_CONFIG['batch_size'],\n            shuffle=True\n        )\n        val_loader = DataLoader(\n            val_dataset,\n            batch_size=TRAINING_CONFIG['eval_batch_size']\n        )\n        test_loader = DataLoader(\n            test_dataset,\n            batch_size=TRAINING_CONFIG['eval_batch_size']\n        )\n        \n        # Initialize model\n        model = BERTWithCustomPooling(\n            model_info['model_name'],\n            pooling_strategy=pooling_key,\n            num_labels=len(label_map)\n        ).to(self.device)\n        \n        # Optimizer and scheduler\n        optimizer = AdamW(\n            model.parameters(),\n            lr=TRAINING_CONFIG['learning_rate'],\n            weight_decay=TRAINING_CONFIG['weight_decay']\n        )\n        \n        total_steps = len(train_loader) * TRAINING_CONFIG['num_epochs']\n        warmup_steps = int(total_steps * TRAINING_CONFIG['warmup_ratio'])\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=warmup_steps,\n            num_training_steps=total_steps\n        )\n        \n        loss_fn = nn.CrossEntropyLoss()\n        \n        # Training loop\n        best_val_acc = 0\n        train_start = datetime.now()\n        \n        for epoch in range(TRAINING_CONFIG['num_epochs']):\n            # Train\n            model.train()\n            train_loss = 0\n            train_preds = []\n            train_labels = []\n            \n            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{TRAINING_CONFIG['num_epochs']}\"):\n                input_ids = batch['input_ids'].to(self.device)\n                attention_mask = batch['attention_mask'].to(self.device)\n                labels = batch['label'].to(self.device)\n                \n                optimizer.zero_grad()\n                \n                logits = model(input_ids, attention_mask)\n                loss = loss_fn(logits, labels)\n                \n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n                \n                train_loss += loss.item()\n                preds = torch.argmax(logits, dim=1).cpu().numpy()\n                train_preds.extend(preds)\n                train_labels.extend(labels.cpu().numpy())\n            \n            train_acc = accuracy_score(train_labels, train_preds)\n            \n            # Validate\n            val_acc, val_loss = self.evaluate(model, val_loader, loss_fn)\n            \n            print(f\"Epoch {epoch+1}: Train Loss={train_loss/len(train_loader):.4f}, \"\n                  f\"Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}\")\n            \n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n        \n        train_time = (datetime.now() - train_start).total_seconds()\n        \n        # Final evaluation on test set\n        test_acc, test_loss, test_metrics = self.evaluate_detailed(model, test_loader, loss_fn, list(label_map.keys()))\n        \n        print(f\"\\n\u2705 Training completed!\")\n        print(f\"   Best Val Acc: {best_val_acc:.4f}\")\n        print(f\"   Test Acc: {test_acc:.4f}\")\n        print(f\"   Train Time: {train_time:.1f}s\")\n        \n        # Save results\n        results = {\n            'model_base': model_key,\n            'pooling_strategy': pooling_key,\n            'display_name': display_name,\n            'accuracy': test_acc * 100,\n            'precision': test_metrics['precision'] * 100,\n            'recall': test_metrics['recall'] * 100,\n            'f1_score': test_metrics['f1'] * 100,\n            'train_time_seconds': train_time,\n            'confusion_matrix': test_metrics['confusion_matrix'].tolist(),\n            'per_class_metrics': test_metrics['per_class_metrics']\n        }\n        \n        output_file = self.output_dir / f\"{combination_name}\" / \"results.json\"\n        output_file.parent.mkdir(exist_ok=True)\n        with open(output_file, 'w') as f:\n            json.dump(results, f, indent=2)\n        \n        return results\n    \n    def evaluate(self, model, dataloader, loss_fn):\n        \"\"\"Evaluate model\"\"\"\n        model.eval()\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        with torch.no_grad():\n            for batch in dataloader:\n                input_ids = batch['input_ids'].to(self.device)\n                attention_mask = batch['attention_mask'].to(self.device)\n                labels = batch['label'].to(self.device)\n                \n                logits = model(input_ids, attention_mask)\n                loss = loss_fn(logits, labels)\n                \n                total_loss += loss.item()\n                preds = torch.argmax(logits, dim=1).cpu().numpy()\n                all_preds.extend(preds)\n                all_labels.extend(labels.cpu().numpy())\n        \n        acc = accuracy_score(all_labels, all_preds)\n        avg_loss = total_loss / len(dataloader)\n        \n        return acc, avg_loss\n    \n    def evaluate_detailed(self, model, dataloader, loss_fn, class_names):\n        \"\"\"Detailed evaluation with metrics\"\"\"\n        acc, loss = self.evaluate(model, dataloader, loss_fn)\n        \n        # Get predictions\n        model.eval()\n        all_preds = []\n        all_labels = []\n        \n        with torch.no_grad():\n            for batch in dataloader:\n                input_ids = batch['input_ids'].to(self.device)\n                attention_mask = batch['attention_mask'].to(self.device)\n                labels = batch['label'].to(self.device)\n                \n                logits = model(input_ids, attention_mask)\n                preds = torch.argmax(logits, dim=1).cpu().numpy()\n                all_preds.extend(preds)\n                all_labels.extend(labels.cpu().numpy())\n        \n        # Calculate metrics\n        precision, recall, f1, _ = precision_recall_fscore_support(\n            all_labels, all_preds, average='weighted', zero_division=0\n        )\n        \n        # Per-class metrics\n        precision_per_class, recall_per_class, f1_per_class, _ = precision_recall_fscore_support(\n            all_labels, all_preds, average=None, zero_division=0\n        )\n        \n        per_class_metrics = [\n            {\n                'class': class_names[i],\n                'precision': float(precision_per_class[i]),\n                'recall': float(recall_per_class[i]),\n                'f1': float(f1_per_class[i])\n            }\n            for i in range(len(class_names))\n        ]\n        \n        # Confusion matrix\n        cm = confusion_matrix(all_labels, all_preds)\n        \n        metrics = {\n            'precision': precision,\n            'recall': recall,\n            'f1': f1,\n            'confusion_matrix': cm,\n            'per_class_metrics': per_class_metrics\n        }\n        \n        return acc, loss, metrics\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train All Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n\ndef main():\n    \"\"\"Train all 8 BERT configurations\"\"\"\n    \n    print(\"=\"*70)\n    print(\"BBC NEWS CLASSIFICATION - BERT FINE-TUNING\")\n    print(\"=\"*70)\n    \n    # Load data\n    trainer = BERTTrainer()\n    train_df, val_df, test_df, label_map = load_bbc_news()\n    \n    # Train all combinations\n    results = []\n    \n    for model_key in BERT_MODELS.keys():\n        for pooling_key in POOLING_STRATEGIES.keys():\n            result = trainer.train_combination(\n                model_key, pooling_key,\n                train_df, val_df, test_df, label_map\n            )\n            if result:\n                results.append(result)\n    \n    # Summary\n    print(f\"\\n{'='*70}\")\n    print(\"\ud83c\udf89 ALL TRAINING COMPLETED!\")\n    print(f\"{'='*70}\")\n    print(f\"\\nTrained {len(results)} configurations:\\n\")\n    \n    for r in sorted(results, key=lambda x: x['accuracy'], reverse=True):\n        print(f\"  {r['display_name']:<30} Acc: {r['accuracy']:.2f}%\")\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}