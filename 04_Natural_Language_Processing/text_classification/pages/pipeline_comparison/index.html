<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pipeline Comparison - BBC News Classification | AI Learning Hub</title>
    
    <!-- Plotly for interactive charts -->
    <script src="https://cdn.plot.ly/plotly-2.26.0.min.js"></script>
    
    <!-- KaTeX for math formulas -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <!-- Prism.js for code syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    
    <!-- Walkthrough CSS and JS -->
    <link rel="stylesheet" href="assets/css/walkthrough.css">
    
    <style>

/* ===== RESET & BASE ===== */
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
    line-height: 1.6;
    color: #333;
    background: #f5f7fa;
}

/* ===== NAVBAR ===== */
.navbar {
    background: white;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
    position: sticky;
    top: 0;
    z-index: 1000;
}

.nav-container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 1rem 2rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.brand {
    font-size: 1.5rem;
    font-weight: 700;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    text-decoration: none;
}

.nav-links a {
    color: #667eea;
    text-decoration: none;
    font-weight: 500;
    transition: opacity 0.3s;
}

.nav-links a:hover {
    opacity: 0.7;
}

/* ===== HERO ===== */
.hero {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 3rem 2rem;
    text-align: center;
}

.hero h1 {
    font-size: 2.5rem;
    margin-bottom: 0.5rem;
}

.hero p {
    font-size: 1.1rem;
    opacity: 0.9;
    margin-bottom: 2rem;
}

.hero-stats {
    display: flex;
    justify-content: center;
    gap: 3rem;
    flex-wrap: wrap;
}

.stat-item {
    text-align: center;
}

.stat-value {
    font-size: 2.5rem;
    font-weight: 700;
    margin-bottom: 0.25rem;
}

.stat-label {
    font-size: 0.9rem;
    opacity: 0.9;
    text-transform: uppercase;
    letter-spacing: 1px;
}

/* ===== CONTAINER ===== */
.container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 2rem;
}

.section-description {
    color: #666;
    font-size: 1.1rem;
    margin-bottom: 2rem;
    text-align: center;
}

/* ===== VIEW MODE TOGGLE ===== */
.view-mode-section {
    margin-bottom: 2rem;
}

.mode-toggle {
    display: flex;
    gap: 1rem;
    justify-content: center;
    background: white;
    padding: 1.5rem;
    border-radius: 12px;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
}

.mode-btn {
    padding: 1rem 2.5rem;
    font-size: 1.1rem;
    font-weight: 600;
    border: 2px solid #e0e7ff;
    background: white;
    color: #667eea;
    border-radius: 8px;
    cursor: pointer;
    transition: all 0.3s ease;
}

.mode-btn:hover {
    background: #f0f4ff;
    transform: translateY(-2px);
}

.mode-btn.active {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-color: #667eea;
}

/* ===== PIPELINE OVERVIEW TABS ===== */
.pipeline-overview-section {
    background: white;
    border-radius: 12px;
    padding: 2rem;
    margin-bottom: 2rem;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
}

.overview-tabs-section {
    width: 100%;
}

.overview-tabs {
    display: flex;
    gap: 0.5rem;
    border-bottom: 2px solid #e0e7ff;
    margin-bottom: 1.5rem;
}

.overview-tab-btn {
    padding: 0.75rem 1.5rem;
    background: none;
    border: none;
    border-bottom: 3px solid transparent;
    color: #666;
    font-size: 1.05rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.3s ease;
}

.overview-tab-btn:hover {
    color: #667eea;
    background: #f0f4ff;
}

.overview-tab-btn.active {
    color: #667eea;
    border-bottom-color: #667eea;
    font-weight: 600;
}

.overview-tab-content {
    display: none;
    padding: 1.5rem 0;
}

.overview-tab-content.active {
    display: block;
}

/* Pipeline Diagram */
.pipeline-diagram {
    padding: 1rem;
}

.diagram-flow {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 1rem;
    margin-bottom: 2rem;
    flex-wrap: wrap;
}

.flow-step {
    background: #f0f4ff;
    border: 2px solid #e0e7ff;
    border-radius: 12px;
    padding: 1.5rem 1rem;
    text-align: center;
    min-width: 120px;
}

.flow-step.flow-varied {
    background: linear-gradient(135deg, #fff5f5 0%, #f0f4ff 100%);
    border-color: #667eea;
}

.step-icon-large {
    font-size: 2.5rem;
    margin-bottom: 0.5rem;
}

.step-label {
    font-weight: 600;
    color: #333;
    font-size: 0.95rem;
}

.step-options {
    font-size: 0.8rem;
    color: #667eea;
    margin-top: 0.25rem;
}

.flow-arrow {
    font-size: 1.5rem;
    color: #667eea;
    font-weight: bold;
}

/* Pipeline Stats Highlight */
.pipeline-stats-highlight {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 1.5rem;
    margin: 1.5rem 0;
    padding: 1rem;
    background: linear-gradient(135deg, #f0f4ff 0%, #fff5f5 100%);
    border-radius: 12px;
    border: 2px solid #e0e7ff;
    flex-wrap: wrap;
}

.stats-highlight-item {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 0.25rem;
}

.stats-highlight-value {
    font-size: 1.8rem;
    font-weight: 700;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
}

.stats-highlight-label {
    font-size: 0.75rem;
    color: #666;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    font-weight: 600;
}

.stats-highlight-divider {
    font-size: 1.2rem;
    color: #667eea;
    opacity: 0.5;
}

.pipeline-info {
    text-align: center;
    background: #f9fafb;
    padding: 1rem;
    border-radius: 8px;
    margin-top: 1rem;
}

.pipeline-info p {
    margin: 0.5rem 0;
    color: #666;
    line-height: 1.6;
    font-size: 0.9rem;
}

.pipeline-info strong {
    color: #667eea;
    font-size: 1.1rem;
}

/* Tutorials Grid */
.tutorials-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 1.5rem;
}

.tutorial-card {
    background: #f9fafb;
    border-radius: 8px;
    padding: 1.5rem;
    border: 1px solid #e0e7ff;
}

.tutorial-card h3 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

.tutorial-item {
    margin-bottom: 1rem;
    padding-bottom: 1rem;
    border-bottom: 1px solid #e0e7ff;
}

.tutorial-item:last-child {
    border-bottom: none;
}

.tutorial-item h4 {
    color: #333;
    margin-bottom: 0.5rem;
    font-size: 1rem;
}

.tutorial-item p {
    color: #666;
    font-size: 0.9rem;
    margin-bottom: 0.5rem;
}

.tutorial-item a {
    color: #667eea;
    text-decoration: none;
    font-size: 0.9rem;
}

.tutorial-item a:hover {
    text-decoration: underline;
}

/* Code Tab (Y CHANG traditional_ml) */
.code-container {
    padding: 2rem;
    max-width: 1200px;
    margin: 0 auto;
}

.code-header h2 {
    font-size: 1.8rem;
    margin-bottom: 0.5rem;
    color: #2d3748;
}

.code-header p {
    color: #666;
    margin-bottom: 2rem;
}

.code-actions-top {
    display: flex;
    gap: 0.5rem;
    margin-bottom: 1rem;
    justify-content: flex-end;
}

.btn-copy-code-compact,
.btn-download-code-compact {
    padding: 0.5rem 1rem;
    border-radius: 6px;
    font-weight: 500;
    text-decoration: none;
    border: none;
    cursor: pointer;
    transition: all 0.2s;
    font-size: 0.9rem;
}

.btn-copy-code-compact {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
}

.btn-copy-code-compact:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 10px rgba(102, 126, 234, 0.3);
}

.btn-download-code-compact {
    background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
    color: white;
    display: inline-block;
}

.btn-download-code-compact:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 10px rgba(245, 87, 108, 0.3);
}

.code-block-container {
    background: #2d3748;
    border-radius: 10px;
    padding: 1.5rem;
    margin-bottom: 2rem;
    overflow-x: auto;
}

.code-loading {
    color: #a0aec0;
    text-align: center;
    padding: 2rem;
}

.code-features {
    background: #f8f9fa;
    padding: 1.5rem;
    border-radius: 10px;
    border-left: 4px solid #667eea;
}

.code-features h3 {
    margin-bottom: 1rem;
    color: #2d3748;
}

.code-features ul {
    list-style: none;
    padding: 0;
}

.code-features li {
    padding: 0.5rem 0;
    color: #666;
}

/* ===== HERO MODE: COMPARISON SECTION ===== */
.hero-mode-section {
    margin-bottom: 2rem;
}

.comparison-section {
    background: white;
    border-radius: 12px;
    padding: 2rem;
    margin-top: 2rem;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
}

.comparison-header {
    text-align: center;
    margin-bottom: 2rem;
}

.comparison-header h2 {
    color: #333;
    margin-bottom: 0.5rem;
}

.comparison-header p {
    color: #666;
    font-size: 1.05rem;
}

/* Comparison Tabs */
.comparison-tabs {
    display: flex;
    gap: 0.5rem;
    border-bottom: 2px solid #e0e7ff;
    margin-bottom: 2rem;
    justify-content: center;
}

.comparison-tab-btn {
    padding: 0.75rem 2rem;
    background: none;
    border: none;
    border-bottom: 3px solid transparent;
    color: #666;
    font-size: 1.05rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.3s ease;
}

.comparison-tab-btn:hover {
    color: #667eea;
    background: #f0f4ff;
}

.comparison-tab-btn.active {
    color: #667eea;
    border-bottom-color: #667eea;
    font-weight: 600;
}

.comparison-tab-content {
    display: none;
    padding: 1.5rem 0;
}

.comparison-tab-content.active {
    display: block;
}

/* Performance Table */
.performance-table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 1rem;
}

.performance-table thead {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
}

.performance-table th {
    padding: 1rem;
    text-align: left;
    font-weight: 600;
}

.performance-table td {
    padding: 0.75rem 1rem;
    border-bottom: 1px solid #e0e7ff;
}

.performance-table tbody tr:hover {
    background: #f0f4ff;
}

.pipeline-name-cell {
    font-weight: 500;
    color: #333;
}

.metric-best {
    background: #d4edda !important;
    color: #155724;
    font-weight: 700;
}

/* Config Grid */
.config-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 1.5rem;
}

.config-card {
    background: #f9fafb;
    border: 1px solid #e0e7ff;
    border-radius: 8px;
    padding: 1.5rem;
}

.config-card h4 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1rem;
}

.config-table-small {
    width: 100%;
    font-size: 0.9rem;
}

.config-table-small th {
    text-align: left;
    padding: 0.5rem;
    background: #e0e7ff;
    color: #333;
    font-weight: 600;
}

.config-table-small td {
    padding: 0.5rem;
    border-bottom: 1px solid #e0e7ff;
}

.config-details-small {
    font-size: 0.85rem;
    color: #666;
    font-family: monospace;
}

/* Formulas */
.formulas-container {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
    gap: 1.5rem;
}

.formula-section {
    background: #f9fafb;
    border-left: 4px solid #667eea;
    padding: 1.5rem;
    border-radius: 8px;
}

.formula-section h4 {
    color: #333;
    margin-bottom: 1rem;
}

.formula-box {
    background: white;
    padding: 1rem;
    border-radius: 6px;
    border: 1px solid #e0e7ff;
}

.formula-math {
    font-family: 'Courier New', monospace;
    background: #f0f4ff;
    padding: 0.5rem;
    margin: 0.5rem 0;
    border-radius: 4px;
    font-size: 0.95rem;
}

/* ===== CONFUSION MATRICES (Y CHANG traditional_ml) ===== */
.confusion-section {
    margin-top: 3rem;
    padding-top: 2rem;
    border-top: 2px solid #e0e7ff;
}

.confusion-section h3 {
    color: #333;
    margin-bottom: 1.5rem;
    text-align: center;
}

.confusion-matrix-card {
    background: white;
    border-radius: 12px;
    overflow: hidden;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    margin: 0.75rem 0;
}

.matrix-header {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 0.75rem 1rem;
}

.matrix-header h5 {
    margin: 0;
    font-size: 1.1rem;
}

.matrix-content {
    padding: 0.75rem;
}

/* Confusion matrix table */
.cm-table {
    width: 100%;
    border-collapse: separate;
    border-spacing: 6px;
    margin: 1rem 0;
}

.cm-table th,
.cm-table td {
    padding: 12px;
    text-align: center;
    font-weight: 600;
    border-radius: 8px;
    transition: all 0.3s ease;
}

.cm-table th {
    background: #667eea;
    color: white;
    font-size: 0.9rem;
}

.cm-table tbody th {
    background: #667eea;
    color: white;
    font-size: 0.9rem;
}

.cm-table td {
    background: #f3f4f6;
    color: #333;
    font-size: 1.1rem;
}

.cm-diagonal {
    background: linear-gradient(135deg, #10b981, #059669) !important;
    color: white !important;
    font-size: 1.2rem !important;
    box-shadow: 0 0 12px rgba(16, 185, 129, 0.4);
}

.cm-error-low {
    background: #fef3c7 !important;
    color: #92400e !important;
}

.cm-error-medium {
    background: #fed7aa !important;
    color: #9a3412 !important;
}

.cm-error-high {
    background: #fecaca !important;
    color: #991b1b !important;
    font-weight: 600 !important;
}

.cm-zero {
    background: #f9fafb !important;
    color: #d1d5db !important;
}

/* Per-class summary */
.per-class-summary {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
    gap: 0.75rem;
    margin: 0.75rem 0;
    padding: 0.75rem;
    background: #f9fafb;
    border-radius: 8px;
}

.per-class-item {
    text-align: center;
    padding: 0.75rem;
    background: white;
    border-radius: 6px;
    border: 1px solid #e5e7eb;
}

.per-class-label {
    font-weight: 600;
    color: #667eea;
    text-transform: capitalize;
    margin-bottom: 0.5rem;
}

.per-class-value {
    font-size: 1.5rem;
    font-weight: bold;
    color: #10b981;
}

/* Matrix view tabs */
.matrix-tabs {
    display: flex;
    gap: 0.5rem;
    margin-bottom: 1.5rem;
    border-bottom: 2px solid #e5e7eb;
}

.matrix-tab-btn {
    padding: 0.75rem 1.5rem;
    background: none;
    border: none;
    border-bottom: 3px solid transparent;
    cursor: pointer;
    font-size: 1rem;
    font-weight: 500;
    color: #666;
    transition: all 0.3s;
}

.matrix-tab-btn:hover {
    color: #667eea;
    background: #f8f9fa;
}

.matrix-tab-btn.active {
    color: #667eea;
    border-bottom-color: #667eea;
    font-weight: 600;
}

.matrix-view {
    display: none;
}

.matrix-view.active {
    display: block;
}

.top-tables-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
    gap: 2rem;
    margin-bottom: 2rem;
}

.top-table-card {
    background: white;
    border-radius: 12px;
    padding: 1.5rem;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
}

.top-table-card h3 {
    font-size: 1.3rem;
    margin-bottom: 1rem;
    color: #333;
    border-bottom: 3px solid #667eea;
    padding-bottom: 0.5rem;
}

/* ===== PIPELINE DETAILS (TABS) ===== */
.pipeline-details-section {
    background: white;
    border-radius: 12px;
    padding: 2rem;
    margin-top: 2rem;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
}

.pipeline-details-section h3 {
    font-size: 1.5rem;
    margin-bottom: 1.5rem;
    color: #333;
}

.pipeline-tabs-container {
    margin-top: 1rem;
}

.detail-tabs {
    display: flex;
    gap: 0.5rem;
    border-bottom: 2px solid #e0e7ff;
    margin-bottom: 1.5rem;
}

.detail-tab-btn {
    padding: 0.75rem 1.5rem;
    background: none;
    border: none;
    border-bottom: 3px solid transparent;
    color: #666;
    font-size: 1rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.3s ease;
}

.detail-tab-btn:hover {
    color: #667eea;
    background: #f0f4ff;
}

.detail-tab-btn.active {
    color: #667eea;
    border-bottom-color: #667eea;
    font-weight: 600;
}

.detail-tab-content {
    display: none;
    padding: 1.5rem;
    background: #f9fafb;
    border-radius: 8px;
    min-height: 300px;
}

.detail-tab-content.active {
    display: block;
}

/* Config Table */
.config-table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 1rem;
}

.config-table th {
    text-align: left;
    padding: 0.75rem;
    background: #667eea;
    color: white;
    font-weight: 600;
}

.config-table td {
    padding: 0.75rem;
    border-bottom: 1px solid #e0e7ff;
}

.config-table tr:hover {
    background: #f0f4ff;
}

/* Walkthrough Steps */
.walkthrough-steps {
    margin-top: 1rem;
}

.walkthrough-step {
    display: flex;
    gap: 1rem;
    margin-bottom: 1.5rem;
    align-items: flex-start;
}

.walkthrough-step .step-number {
    flex-shrink: 0;
    width: 40px;
    height: 40px;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: 700;
    font-size: 1.2rem;
}

.walkthrough-step .step-content {
    flex: 1;
}

.walkthrough-step .step-content h5 {
    margin-bottom: 0.5rem;
    color: #667eea;
}

.walkthrough-step .step-content p {
    color: #666;
    line-height: 1.6;
}

/* Button Styles */
.btn-view-details {
    padding: 0.5rem 1rem;
    background: #667eea;
    color: white;
    border: none;
    border-radius: 6px;
    cursor: pointer;
    font-size: 0.9rem;
    transition: all 0.3s ease;
}

.btn-view-details:hover {
    background: #5568d3;
    transform: scale(1.05);
}

/* ===== PIPELINE BUILDER ===== */
.pipeline-builder-section {
    background: white;
    border-radius: 12px;
    padding: 2rem;
    margin-bottom: 2rem;
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
}

.pipeline-builder-section h2 {
    color: #667eea;
    margin-bottom: 0.5rem;
    font-size: 2rem;
    text-align: center;
}

.pipeline-steps {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 1rem;
    margin: 2rem 0;
}

.step-item {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 0.5rem;
}

.step-number {
    width: 50px;
    height: 50px;
    border-radius: 50%;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 1.5rem;
    font-weight: 700;
}

.step-title {
    font-size: 0.9rem;
    font-weight: 600;
    color: #667eea;
}

.step-arrow {
    font-size: 2rem;
    color: #667eea;
    margin-top: -20px;
}

.builder-card {
    background: #f8f9fa;
    border-radius: 10px;
    padding: 1.5rem;
    margin-bottom: 1.5rem;
}

.builder-card h3 {
    color: #333;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

.option-group {
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.option-radio, .option-checkbox {
    display: flex;
    align-items: flex-start;
    gap: 0.75rem;
    padding: 1rem;
    background: white;
    border: 2px solid #e5e7eb;
    border-radius: 8px;
    cursor: pointer;
    transition: all 0.3s;
}

.option-radio:hover, .option-checkbox:hover {
    border-color: #667eea;
    box-shadow: 0 2px 8px rgba(102, 126, 234, 0.2);
}

.option-radio.checked, .option-checkbox.checked {
    border-color: #667eea;
    background: #f0f4ff;
}

.option-radio input, .option-checkbox input {
    margin-top: 0.2rem;
    cursor: pointer;
}

.option-content {
    display: flex;
    flex-direction: column;
    flex: 1;
}

.option-title {
    font-weight: 600;
    color: #333;
    margin-bottom: 0.25rem;
}

.option-desc {
    font-size: 0.9rem;
    color: #666;
}

.classifier-actions {
    display: flex;
    gap: 0.75rem;
    margin-top: 1rem;
    flex-wrap: wrap;
}

/* ===== PREVIEW & ACTIONS ===== */
.builder-preview {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 10px;
    padding: 1.5rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
    gap: 2rem;
    flex-wrap: wrap;
}

.preview-content {
    flex: 1;
}

.preview-content h4 {
    margin-bottom: 0.5rem;
    font-size: 1.1rem;
}

#pipeline-preview {
    font-size: 1rem;
}

#preview-list {
    margin: 0.75rem 0 0 1.5rem;
    list-style: none;
}

#preview-list li {
    padding: 0.25rem 0;
    opacity: 0.9;
}

#preview-list li::before {
    content: "‚ñ∏ ";
    margin-right: 0.5rem;
}

.preview-actions {
    display: flex;
    gap: 1rem;
    flex-wrap: wrap;
}

/* ===== BUTTONS ===== */
.btn-primary, .btn-secondary {
    padding: 0.75rem 1.5rem;
    border: none;
    border-radius: 8px;
    font-size: 1rem;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s;
    white-space: nowrap;
}

.btn-primary {
    background: white;
    color: #667eea;
}

.btn-primary:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
}

.btn-secondary {
    background: rgba(255, 255, 255, 0.2);
    color: white;
    border: 1px solid white;
}

.btn-secondary:hover {
    background: rgba(255, 255, 255, 0.3);
}

/* ===== RESULTS SECTION ===== */
.results-section {
    margin-top: 2rem;
}

.results-section h2 {
    color: #667eea;
    font-size: 2rem;
    margin-bottom: 2rem;
    text-align: center;
}

.best-cards {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
    gap: 1.5rem;
    margin-bottom: 2rem;
}

.best-card {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    border-top: 4px solid;
}

.best-card.accuracy {
    border-top-color: #10b981;
}

.best-card.speed {
    border-top-color: #f59e0b;
}

.best-card.size {
    border-top-color: #3b82f6;
}

.best-card h3 {
    font-size: 0.9rem;
    text-transform: uppercase;
    letter-spacing: 1px;
    color: #666;
    margin-bottom: 0.5rem;
}

.best-card .metric-value {
    font-size: 2rem;
    font-weight: 700;
    margin-bottom: 0.5rem;
}

.best-card .pipeline-name {
    font-size: 0.9rem;
    color: #666;
}

/* ===== TABLE ===== */
.table-container {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    margin-bottom: 2rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    overflow-x: auto;
}

.comparison-table {
    width: 100%;
    border-collapse: collapse;
    font-size: 0.9rem;
}

.comparison-table th {
    background: #667eea;
    color: white;
    padding: 0.75rem;
    text-align: left;
    font-weight: 600;
    white-space: nowrap;
}

.comparison-table td {
    padding: 0.75rem;
    border-bottom: 1px solid #e5e7eb;
}

.comparison-table tr:hover {
    background: #f8f9fa;
}

.metric-best {
    background: #d1fae5 !important;
    font-weight: 600;
    color: #065f46;
}

.pipeline-cell {
    font-family: 'Courier New', monospace;
    font-size: 0.85rem;
}

/* ===== VISUALIZATIONS ===== */
.viz-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
    gap: 2rem;
    margin-bottom: 2rem;
}

.viz-card {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
}

.viz-card h3 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

/* ===== CONFUSION MATRICES ===== */
.cm-section {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
}

.cm-section h3 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.3rem;
}

.cm-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(450px, 1fr));
    gap: 1.5rem;
    margin-top: 1.5rem;
}

/* ===== PIPELINE CALCULATION ===== */
/* Pipeline Calculation (now in tab) */
.calc-formula {
    text-align: center;
    margin-bottom: 2rem;
}

.calc-formula h3 {
    color: #667eea;
    margin-bottom: 1rem;
}

.formula-box {
    background: #f8f9fa;
    padding: 1.5rem;
    border-radius: 10px;
    border: 2px solid #667eea;
}

.formula-main {
    font-size: 1.3rem;
    margin-bottom: 0.75rem;
}

.formula-term {
    color: #667eea;
    font-weight: 700;
    padding: 0.25rem 0.5rem;
    background: rgba(102, 126, 234, 0.1);
    border-radius: 4px;
}

.formula-result {
    font-size: 1.5rem;
    color: #10b981;
    font-weight: 700;
    margin-top: 0.75rem;
}

.calc-breakdown {
    margin-top: 2rem;
}

.calc-section {
    margin-bottom: 2rem;
    padding: 1.5rem;
    background: #f8f9fa;
    border-radius: 10px;
}

.calc-section h4 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

.calc-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
    gap: 1rem;
}

.calc-grid-horizontal {
    display: flex;
    gap: 0.75rem;
    flex-wrap: wrap;
    justify-content: center;
}

.calc-item {
    background: white;
    padding: 1rem;
    border-radius: 8px;
    border-left: 4px solid #667eea;
}

.calc-item strong {
    color: #667eea;
    display: block;
    margin-bottom: 0.5rem;
}

.calc-item ul {
    margin: 0.5rem 0 0 1.25rem;
    font-size: 0.9rem;
    color: #666;
}

.calc-item ul li {
    margin: 0.25rem 0;
}

.calc-item-small {
    background: white;
    padding: 0.75rem 1rem;
    border-radius: 8px;
    border: 2px solid #667eea;
    color: #667eea;
    font-weight: 600;
    font-size: 0.9rem;
}

.calc-example {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 1.5rem;
    border-radius: 10px;
    margin-top: 2rem;
}

.calc-example h4 {
    margin-bottom: 1rem;
    text-align: center;
}

.pipeline-example {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 0.75rem;
    flex-wrap: wrap;
}

.pipeline-step {
    background: rgba(255, 255, 255, 0.2);
    padding: 0.75rem 1rem;
    border-radius: 8px;
    font-weight: 600;
    border: 2px solid white;
}

.pipeline-arrow {
    font-size: 1.5rem;
    font-weight: 700;
}

.pipeline-result {
    background: #10b981;
    padding: 0.75rem 1rem;
    border-radius: 8px;
    font-weight: 700;
    border: 2px solid white;
}

/* ===== RESPONSIVE ===== */
@media (max-width: 768px) {
    .hero h1 {
        font-size: 2rem;
    }
    
    .hero-stats {
        gap: 1.5rem;
    }
    
    .stat-value {
        font-size: 2rem;
    }
    
    .builder-preview {
        flex-direction: column;
        align-items: flex-start;
    }
    
    .preview-actions {
        width: 100%;
    }
    
    .preview-actions button {
        flex: 1;
    }
    
    .viz-grid {
        grid-template-columns: 1fr;
    }
    
    .cm-grid {
        grid-template-columns: 1fr;
    }
}

/* ===== LOADING ===== */
.loading {
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 3rem;
    font-size: 1.1rem;
    color: #667eea;
}

.loading::after {
    content: '...';
    animation: dots 1.5s infinite;
}

@keyframes dots {
    0%, 20% { content: '.'; }
    40% { content: '..'; }
    60%, 100% { content: '...'; }
}

    </style>
</head>
<body>
    <!-- Navbar -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="../../../../index.html" class="brand">ü§ñ AI Learning Hub</a>
            <div class="nav-links">
                <a href="../../index.html">‚Üê Back to Text Classification</a>
            </div>
        </div>
    </nav>

    <!-- Hero -->
    <div class="hero">
        <h1>üî¨ Pipeline Comparison</h1>
        <p>Compare feature extraction, dimensionality reduction, and classifier combinations</p>
    </div>

    <!-- Main content -->
    <div class="container">
        <!-- View Mode Toggle -->
        <section class="view-mode-section">
            <div class="mode-toggle">
                <button id="btn-hero-mode" class="mode-btn active" onclick="switchMode('hero')">
                    üèÜ Top Performers
                </button>
                <button id="btn-custom-mode" class="mode-btn" onclick="switchMode('custom')">
                    üîß Custom Filter
                </button>
            </div>
        </section>

        <!-- Hero Mode: Top Performers Comparison -->
        <section id="hero-mode-section" class="hero-mode-section">
            <!-- Pipeline Overview with Tabs -->
            <div class="pipeline-overview-section">
                
        <div class="overview-tabs-section">
            <!-- Tab buttons -->
            <div class="overview-tabs">
                <button class="overview-tab-btn active" onclick="switchOverviewTab('pipeline')">
                    üîÑ Pipeline
                </button>
                <button class="overview-tab-btn" onclick="switchOverviewTab('calculation')">
                    üßÆ Calculation
                </button>
                <button class="overview-tab-btn" onclick="switchOverviewTab('tutorials')">
                    üìö Tutorials
                </button>
                <button class="overview-tab-btn" onclick="switchOverviewTab('code')">
                    üíª Code
                </button>
                <button class="overview-tab-btn" onclick="switchOverviewTab('colab')">
                    üöÄ Colab
                </button>
            </div>
            
            <!-- Tab contents -->
            <div id="overview-pipeline-tab" class="overview-tab-content active">
                <div class="pipeline-diagram">
                    <div class="diagram-flow">
                        <div class="flow-step">
                            <div class="step-icon-large">üìù</div>
                            <div class="step-label">Text Input</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="flow-step flow-varied">
                            <div class="step-icon-large">üî¢</div>
                            <div class="step-label">Feature Extraction</div>
                            <div class="step-options">BoW or TF-IDF</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="flow-step flow-varied">
                            <div class="step-icon-large">üéØ</div>
                            <div class="step-label">Dim. Reduction</div>
                            <div class="step-options">None, Chi¬≤, or PCA</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="flow-step flow-varied">
                            <div class="step-icon-large">ü§ñ</div>
                            <div class="step-label">Classifier</div>
                            <div class="step-options">NB, LR, RF, DT, or KNN</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="flow-step">
                            <div class="step-icon-large">‚ú®</div>
                            <div class="step-label">Results</div>
                        </div>
                    </div>
                    
                    <!-- Stats Highlights below diagram -->
                    <div class="pipeline-stats-highlight">
                        <div class="stats-highlight-item">
                            <span class="stats-highlight-value">240</span>
                            <span class="stats-highlight-label">Total Pipelines</span>
                        </div>
                        <div class="stats-highlight-divider">‚Ä¢</div>
                        <div class="stats-highlight-item">
                            <span class="stats-highlight-value">99.4%</span>
                            <span class="stats-highlight-label">Best Accuracy</span>
                        </div>
                        <div class="stats-highlight-divider">‚Ä¢</div>
                        <div class="stats-highlight-item">
                            <span class="stats-highlight-value">0.46s</span>
                            <span class="stats-highlight-label">Fastest Training</span>
                        </div>
                    </div>
                </div>
            </div>
            
            <div id="overview-calculation-tab" class="overview-tab-content">
                
                <div class="calc-formula">
                    <h3>üßÆ Total Pipeline Combinations</h3>
                    <div class="formula-box">
                        <div class="formula-main">
                            Total = <span class="formula-term">Extractors</span> √ó 
                                   <span class="formula-term">Reducers</span> √ó 
                                   <span class="formula-term">Classifiers</span>
                        </div>
                        <div class="formula-result">
                            = <strong>6</strong> √ó <strong>4</strong> √ó <strong>10</strong> = <strong>240 pipelines</strong>
                        </div>
                    </div>
                </div>
                
                <div class="calc-breakdown">
                    <div class="calc-section">
                        <h4>1Ô∏è‚É£ Feature Extractors (6 configs)</h4>
                        <div class="calc-grid">
                            <div class="calc-item">
                                <strong>Bag of Words (BoW)</strong> - 3 configs
                                <ul>
                                    <li>10000 features, unigrams (1,1)</li>
                                    <li>5000 features, bigrams (1,2)</li>
                                    <li>10000 features, bigrams (1,2)</li>
                                </ul>
                            </div>
                            <div class="calc-item">
                                <strong>TF-IDF</strong> - 3 configs
                                <ul>
                                    <li>10000 features, unigrams (1,1)</li>
                                    <li>5000 features, bigrams (1,2)</li>
                                    <li>10000 features, bigrams (1,2)</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="calc-section">
                        <h4>2Ô∏è‚É£ Dimensionality Reducers (4 configs)</h4>
                        <div class="calc-grid">
                            <div class="calc-item">
                                <strong>None</strong> - 1 config
                                <ul><li>Use all features (no reduction)</li></ul>
                            </div>
                            <div class="calc-item">
                                <strong>Chi¬≤</strong> - 1 config
                                <ul><li>Select top 1000 features</li></ul>
                            </div>
                            <div class="calc-item">
                                <strong>PCA</strong> - 2 configs
                                <ul>
                                    <li>90% variance explained</li>
                                    <li>95% variance explained</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="calc-section">
                        <h4>3Ô∏è‚É£ Classifiers (10 configs across 5 models)</h4>
                        <div class="calc-grid">
                            <div class="calc-item">
                                <strong>Naive Bayes</strong> - 1 config
                                <ul><li>alpha=1.0</li></ul>
                            </div>
                            <div class="calc-item">
                                <strong>Logistic Regression</strong> - 2 configs
                                <ul><li>C=1.0, C=10.0</li></ul>
                            </div>
                            <div class="calc-item">
                                <strong>Random Forest</strong> - 2 configs
                                <ul><li>max_depth=10, 20</li></ul>
                            </div>
                            <div class="calc-item">
                                <strong>Decision Tree</strong> - 2 configs
                                <ul><li>max_depth=10, 20</li></ul>
                            </div>
                            <div class="calc-item">
                                <strong>K-Nearest Neighbors</strong> - 3 configs
                                <ul><li>n_neighbors=3, 5, 10</li></ul>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="calc-example">
                    <h4>üìù Example Pipeline</h4>
                    <div class="pipeline-example">
                        <div class="pipeline-step">TF-IDF (10000, unigrams)</div>
                        <div class="pipeline-arrow">‚Üí</div>
                        <div class="pipeline-step">PCA (90% variance)</div>
                        <div class="pipeline-arrow">‚Üí</div>
                        <div class="pipeline-step">Logistic Regression (C=1.0)</div>
                        <div class="pipeline-arrow">=</div>
                        <div class="pipeline-result">1 of 240 pipelines</div>
                    </div>
                </div>
    
            </div>
            
            <div id="overview-tutorials-tab" class="overview-tab-content">
                
        <div class="tutorials-grid">
            <div class="tutorial-card">
                <h3>üî¢ Feature Extraction</h3>
                <div class="tutorial-item">
                    <h4>Bag of Words (BoW)</h4>
                    <p>Counts word occurrences in documents. Simple but effective baseline.</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" target="_blank">üìö Docs</a>
                </div>
                <div class="tutorial-item">
                    <h4>TF-IDF</h4>
                    <p>Weighs words by importance (frequency √ó uniqueness).</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" target="_blank">üìö Docs</a>
                </div>
            </div>
            
            <div class="tutorial-card">
                <h3>üéØ Dimensionality Reduction</h3>
                <div class="tutorial-item">
                    <h4>Chi¬≤ (Chi-Square)</h4>
                    <p>Selects top K most relevant features for classification.</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html" target="_blank">üìö Docs</a>
                </div>
                <div class="tutorial-item">
                    <h4>PCA (Principal Component Analysis)</h4>
                    <p>Reduces dimensions while preserving variance (90% or 95%).</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" target="_blank">üìö Docs</a>
                </div>
            </div>
            
            <div class="tutorial-card">
                <h3>ü§ñ Classifiers</h3>
                <div class="tutorial-item">
                    <h4>Naive Bayes</h4>
                    <p>Probabilistic classifier based on Bayes' theorem. Fast and works well with text data.</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html" target="_blank">üìö Docs</a>
                </div>
                <div class="tutorial-item">
                    <h4>Logistic Regression</h4>
                    <p>Linear model for classification. Simple, interpretable, and often the best baseline.</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" target="_blank">üìö Docs</a>
                </div>
                <div class="tutorial-item">
                    <h4>Random Forest</h4>
                    <p>Ensemble of decision trees. Robust and handles non-linear patterns well.</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" target="_blank">üìö Docs</a>
                </div>
                <div class="tutorial-item">
                    <h4>Decision Tree</h4>
                    <p>Tree-based classifier. Simple and interpretable, but can overfit.</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" target="_blank">üìö Docs</a>
                </div>
                <div class="tutorial-item">
                    <h4>K-Nearest Neighbors (KNN)</h4>
                    <p>Instance-based learning. Classifies based on similarity to training examples.</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html" target="_blank">üìö Docs</a>
                </div>
            </div>
        </div>
    
            </div>
            
            <div id="overview-code-tab" class="overview-tab-content">
                
        <div class="code-container">
            <div class="code-header">
                <h2>üíª Full Implementation Code</h2>
                <p>Ready-to-run Python code with all 240 pipeline combinations. Includes dataset download, feature extraction, dimensionality reduction, classification, and evaluation.</p>
            </div>
            
            <div class="code-actions-top">
                <button onclick="copyPipelineCode()" class="btn-copy-code-compact">
                    üìã Copy
                </button>
                <a href="code/bbc_pipeline_comparison.py" download class="btn-download-code-compact">
                    ‚¨áÔ∏è Download
                </a>
            </div>
            
            <div id="pipeline-code-block" class="code-block-container">
                <div class="code-loading">‚è≥ Loading code...</div>
                <pre style="display:none;"><code id="pipeline-python-code" class="language-python"></code></pre>
            </div>
            
            <div class="code-features">
                <h3>Features:</h3>
                <ul>
                    <li>‚úÖ Automatic dataset download from GitHub Pages</li>
                    <li>‚úÖ 6 feature extractors (BoW + TF-IDF with different configs)</li>
                    <li>‚úÖ 4 dimensionality reducers (None, Chi¬≤, PCA 90%, PCA 95%)</li>
                    <li>‚úÖ 10 classifier configurations (NB, LR, RF, DT, KNN)</li>
                    <li>‚úÖ Training & inference time measurements</li>
                    <li>‚úÖ Performance comparison table with best highlighting</li>
                </ul>
            </div>
        </div>
    
            </div>
            
            <div id="overview-colab-tab" class="overview-tab-content">
                
        <div class="colab-container">
            <div class="colab-hero">
                <div class="colab-icon">üöÄ</div>
                <h3>Run Pipeline Comparison in Google Colab</h3>
                <p>Interactive notebook to explore and compare all 240 pipelines.</p>
            </div>
            <div class="colab-action">
                <a href="https://colab.research.google.com/github/LTSACH/AILearningHub/blob/main/04_Natural_Language_Processing/text_classification/notebooks/bbc_pipeline_comparison.ipynb" 
                   target="_blank" 
                   class="btn-colab-large">
                    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" style="height:40px;">
                    <span>Open Pipeline Comparison in Colab</span>
                </a>
            </div>
        </div>
    
            </div>
        </div>
    
            </div>
            
            <!-- Top Performers Comparison Section -->
            <div class="comparison-section">
                <div class="comparison-header">
                    <h2>üèÜ Top 9 Performers Comparison</h2>
                    <p>Top 3 by Accuracy, Training Speed, and Inference Speed</p>
                </div>
                
                <!-- Comparison Tabs -->
                <div class="comparison-tabs">
                    <button class="comparison-tab-btn active" onclick="switchComparisonTab('performance')">
                        üìä Performance
                    </button>
                    <button class="comparison-tab-btn" onclick="switchComparisonTab('configuration')">
                        ‚öôÔ∏è Configuration
                    </button>
                    <button class="comparison-tab-btn" onclick="switchComparisonTab('formulas')">
                        üìê Formulas
                    </button>
                </div>
                
                <!-- Tab Contents -->
                <div id="performance-tab" class="comparison-tab-content active">
                    <div id="performance-comparison-table"></div>
                </div>
                
                <div id="configuration-tab" class="comparison-tab-content">
                    <div id="configuration-details"></div>
                </div>
                
                <div id="formulas-tab" class="comparison-tab-content">
                    <div id="formulas-content"></div>
                </div>
                
                <!-- Confusion Matrices & Metrics -->
                <div class="confusion-section">
                    <h3>üéØ Confusion Matrices & Per-Class Metrics</h3>
                    <div id="confusion-matrices-grid"></div>
                </div>
            </div>
        </section>

        <!-- Custom Filter Mode -->
        <section id="custom-mode-section" class="custom-mode-section" style="display: none;">
            <h2>üî¨ Build Your Pipeline</h2>
            <p class="section-description">
                Select feature extraction, dimensionality reduction, and classifiers to compare
            </p>
            
            
        <div class="pipeline-builder">
            <!-- Step indicator -->
            <div class="pipeline-steps">
                <div class="step-item">
                    <div class="step-number">1</div>
                    <div class="step-title">üìù Extract</div>
                </div>
                <div class="step-arrow">‚Üí</div>
                <div class="step-item">
                    <div class="step-number">2</div>
                    <div class="step-title">üéØ Reduce</div>
                </div>
                <div class="step-arrow">‚Üí</div>
                <div class="step-item">
                    <div class="step-number">3</div>
                    <div class="step-title">ü§ñ Classify</div>
                </div>
            </div>
            
            <!-- Step 1: Feature Extraction -->
            <div class="builder-card">
                <h3>STEP 1: Feature Extraction</h3>
                <div class="option-group">
                    <label class="option-radio">
                        <input type="radio" name="extractor" value="bow" data-name="Bag of Words">
                        <span class="option-content">
                            <span class="option-title">Bag of Words (CountVectorizer)</span>
                            <span class="option-desc">Count word occurrences, simple and fast</span>
                        </span>
                    </label>
                    <label class="option-radio checked">
                        <input type="radio" name="extractor" value="tfidf" data-name="TF-IDF" checked>
                        <span class="option-content">
                            <span class="option-title">TF-IDF (TfidfVectorizer)</span>
                            <span class="option-desc">Weight words by importance, better for classification</span>
                        </span>
                    </label>
                </div>
            </div>
            
            <!-- Step 2: Dimensionality Reduction -->
            <div class="builder-card">
                <h3>STEP 2: Dimensionality Reduction (Optional)</h3>
                <div class="option-group">
                    <label class="option-radio checked">
                        <input type="radio" name="reducer" value="none" data-name="None" checked>
                        <span class="option-content">
                            <span class="option-title">None (Use all features)</span>
                            <span class="option-desc">Best accuracy, but slower and larger models</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="pca" data-name="PCA">
                        <span class="option-content">
                            <span class="option-title">PCA (Principal Component Analysis)</span>
                            <span class="option-desc">Reduce to uncorrelated components, good for variance</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="chi2" data-name="Chi¬≤">
                        <span class="option-content">
                            <span class="option-title">Chi¬≤ (SelectKBest)</span>
                            <span class="option-desc">Select most relevant features, good for text</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="svd" data-name="Truncated SVD">
                        <span class="option-content">
                            <span class="option-title">Truncated SVD</span>
                            <span class="option-desc">Like PCA but works with sparse matrices</span>
                        </span>
                    </label>
                </div>
            </div>
            
            <!-- Step 3: Classifiers -->
            <div class="builder-card">
                <h3>STEP 3: Classifiers (Select multiple)</h3>
                <div class="option-group">
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="logistic" data-name="Logistic Regression" checked>
                        <span class="option-content">
                            <span class="option-title">Logistic Regression</span>
                            <span class="option-desc">Fast, interpretable, great baseline (usually best)</span>
                        </span>
                    </label>
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="svm" data-name="SVM" checked>
                        <span class="option-content">
                            <span class="option-title">SVM (Support Vector Machine)</span>
                            <span class="option-desc">Strong for high-dimensional text data</span>
                        </span>
                    </label>
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="naive_bayes" data-name="Naive Bayes" checked>
                        <span class="option-content">
                            <span class="option-title">Naive Bayes</span>
                            <span class="option-desc">Extremely fast, good for large datasets</span>
                        </span>
                    </label>
                    <label class="option-checkbox">
                        <input type="checkbox" name="classifier" value="random_forest" data-name="Random Forest">
                        <span class="option-content">
                            <span class="option-title">Random Forest</span>
                            <span class="option-desc">Ensemble method, robust but slower</span>
                        </span>
                    </label>
                    <label class="option-checkbox">
                        <input type="checkbox" name="classifier" value="decision_tree" data-name="Decision Tree">
                        <span class="option-content">
                            <span class="option-title">Decision Tree</span>
                            <span class="option-desc">Simple, interpretable, usually lower accuracy</span>
                        </span>
                    </label>
                </div>
                <div class="classifier-actions">
                    <button onclick="selectAllClassifiers()" class="btn-secondary">Select All</button>
                    <button onclick="deselectAllClassifiers()" class="btn-secondary">Deselect All</button>
                    <button onclick="selectTopClassifiers()" class="btn-secondary">Top 3 Fastest</button>
                </div>
            </div>
            
            <!-- Preview & Action -->
            <div class="builder-preview">
                <div class="preview-content">
                    <h4>üìä Preview</h4>
                    <div id="pipeline-preview">
                        You will compare <strong id="preview-count">3</strong> pipeline(s):
                        <ul id="preview-list"></ul>
                    </div>
                </div>
                <div class="preview-actions">
                    <button onclick="comparePipelines()" class="btn-primary">
                        üîç Compare These Pipelines
                    </button>
                    <button onclick="resetBuilder()" class="btn-secondary">
                        üîÑ Reset to Defaults
                    </button>
                </div>
            </div>
        </div>
    
            
            <!-- Custom Results -->
            <div id="custom-results-section" class="results-section" style="display: none;">
                <h2>üìä Comparison Results</h2>
                
                <!-- Best pipeline cards -->
                <div id="custom-best-cards" class="best-cards"></div>
                
                <!-- Comparison table -->
                <div id="custom-comparison-table" class="table-container"></div>
                
                <!-- Visualizations -->
                <div class="viz-grid">
                    <div class="viz-card">
                        <h3>üìä Accuracy Heatmap</h3>
                        <div id="custom-heatmap-chart"></div>
                    </div>
                    <div class="viz-card">
                        <h3>‚öñÔ∏è Trade-off: Accuracy vs Speed</h3>
                        <div id="custom-tradeoff-chart"></div>
                    </div>
                </div>
                
                <!-- Pipeline Details (tabs) -->
                <div id="custom-pipeline-details" class="pipeline-details-section" style="display: none;">
                    <h3 id="custom-selected-title">Pipeline Details</h3>
                    
        <div class="pipeline-tabs-container">
            <!-- Tab buttons -->
            <div class="detail-tabs">
                <button class="detail-tab-btn active" onclick="switchDetailTab('custom', 'config')">
                    ‚öôÔ∏è Configuration
                </button>
                <button class="detail-tab-btn" onclick="switchDetailTab('custom', 'formula')">
                    üìê Formulas
                </button>
                <button class="detail-tab-btn" onclick="switchDetailTab('custom', 'confusion')">
                    üìä Confusion Matrix
                </button>
                <button class="detail-tab-btn" onclick="switchDetailTab('custom', 'walkthrough')">
                    üö∂ Walkthrough
                </button>
            </div>
            
            <!-- Tab contents -->
            <div id="custom-config-tab" class="detail-tab-content active">
                <div id="custom-config-content">Select a pipeline to view configuration</div>
            </div>
            
            <div id="custom-formula-tab" class="detail-tab-content">
                <div id="custom-formula-content">Select a pipeline to view formulas</div>
            </div>
            
            <div id="custom-confusion-tab" class="detail-tab-content">
                <div id="custom-confusion-content">Select a pipeline to view confusion matrix</div>
            </div>
            
            <div id="custom-walkthrough-tab" class="detail-tab-content">
                <div id="custom-walkthrough-content">Select a pipeline to view walkthrough</div>
            </div>
        </div>
    
                </div>
            </div>
        </section>
    </div>

    <!-- Data -->
    <script>
        const allPipelinesData = {'total_pipelines': 240, 'successful': 240, 'failed': 0, 'best_accuracy': {'pipeline_id': 'tfidf_m10000_n11_pca_n0.9_sfull_logistic_C1.0_m1000', 'accuracy': 0.9940119760479041, 'config': 'TF-IDF ‚Üí PCA ‚Üí Logistic Regression'}, 'fastest_training': {'pipeline_id': 'tfidf_m10000_n11_none_default_knn_n10_n-1', 'time': 0.46178412437438965, 'config': 'TF-IDF ‚Üí None ‚Üí K-Nearest Neighbors'}, 'fastest_inference': {'pipeline_id': 'bow_m5000_n12_pca_n0.9_sfull_logistic_C10.0_m1000', 'time': 0.0016403769304652416, 'config': 'Bag of Words ‚Üí PCA ‚Üí Logistic Regression'}, 'all_results': [{'pipeline_id': 'tfidf_m10000_n11_pca_n0.9_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:52:00.146736', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.45754075050354004, 'features_extracted': 10000, 'reduction_time': 5.005501747131348, 'features_after_reduction': 1010, 'metrics': {'accuracy': 0.6197604790419161, 'precision': 0.6833782288202396, 'recall': 0.6197604790419161, 'f1_score': 0.5602542926080505}, 'performance': {'train_time_seconds': 0.017238855361938477, 'total_time_seconds': 5.480281352996826, 'inference_time_ms_per_sample': 0.003131563791971721}, 'confusion_matrix': [[73, 0, 0, 2, 2], [28, 1, 0, 28, 1], [21, 0, 30, 9, 2], [2, 0, 0, 75, 0], [28, 1, 0, 3, 28]], 'per_class_metrics': [{'label': 'business', 'precision': 0.48026315789473684, 'recall': 0.948051948051948, 'f1': 0.6375545851528385, 'support': 77}, {'label': 'entertainment', 'precision': 0.5, 'recall': 0.017241379310344827, 'f1': 0.03333333333333333, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.4838709677419355, 'f1': 0.6521739130434783, 'support': 62}, {'label': 'sport', 'precision': 0.6410256410256411, 'recall': 0.974025974025974, 'f1': 0.7731958762886598, 'support': 77}, {'label': 'tech', 'precision': 0.8484848484848485, 'recall': 0.4666666666666667, 'f1': 0.6021505376344086, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:54:42.823440', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.59134840965271, 'features_extracted': 5000, 'reduction_time': 0.13574957847595215, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9762070722400643, 'recall': 0.9760479041916168, 'f1_score': 0.9760358804739142}, 'performance': {'train_time_seconds': 0.11746954917907715, 'total_time_seconds': 1.8445675373077393, 'inference_time_ms_per_sample': 0.0028510293560827563}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 57, 0, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9736842105263158, 'recall': 0.961038961038961, 'f1': 0.9673202614379085, 'support': 77}, {'label': 'entertainment', 'precision': 0.95, 'recall': 0.9827586206896551, 'f1': 0.9661016949152542, 'support': 58}, {'label': 'politics', 'precision': 0.9836065573770492, 'recall': 0.967741935483871, 'f1': 0.975609756097561, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.95_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:51:10.399278', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5657286643981934, 'features_extracted': 10000, 'reduction_time': 6.765340805053711, 'features_after_reduction': 789, 'metrics': {'accuracy': 0.6467065868263473, 'precision': 0.6480390530094139, 'recall': 0.6467065868263473, 'f1_score': 0.6456010381642493}, 'performance': {'train_time_seconds': 1.3794846534729004, 'total_time_seconds': 9.710554122924805, 'inference_time_ms_per_sample': 0.002571208748274935}, 'confusion_matrix': [[54, 11, 3, 2, 7], [7, 27, 5, 14, 5], [7, 8, 34, 5, 8], [2, 6, 5, 63, 1], [9, 10, 3, 0, 38]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6835443037974683, 'recall': 0.7012987012987013, 'f1': 0.6923076923076923, 'support': 77}, {'label': 'entertainment', 'precision': 0.43548387096774194, 'recall': 0.46551724137931033, 'f1': 0.45, 'support': 58}, {'label': 'politics', 'precision': 0.68, 'recall': 0.5483870967741935, 'f1': 0.6071428571428571, 'support': 62}, {'label': 'sport', 'precision': 0.75, 'recall': 0.8181818181818182, 'f1': 0.782608695652174, 'support': 77}, {'label': 'tech', 'precision': 0.6440677966101694, 'recall': 0.6333333333333333, 'f1': 0.6386554621848739, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:54:50.421846', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.520871877670288, 'features_extracted': 5000, 'reduction_time': 0.13292479515075684, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8173652694610778, 'precision': 0.8205447151034237, 'recall': 0.8173652694610778, 'f1_score': 0.8175800385716618}, 'performance': {'train_time_seconds': 0.14548349380493164, 'total_time_seconds': 1.7992801666259766, 'inference_time_ms_per_sample': 0.002404886805368755}, 'confusion_matrix': [[60, 5, 7, 1, 4], [8, 41, 4, 5, 0], [6, 2, 53, 1, 0], [3, 2, 3, 69, 0], [4, 2, 2, 2, 50]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7407407407407407, 'recall': 0.7792207792207793, 'f1': 0.759493670886076, 'support': 77}, {'label': 'entertainment', 'precision': 0.7884615384615384, 'recall': 0.7068965517241379, 'f1': 0.7454545454545455, 'support': 58}, {'label': 'politics', 'precision': 0.7681159420289855, 'recall': 0.8548387096774194, 'f1': 0.8091603053435115, 'support': 62}, {'label': 'sport', 'precision': 0.8846153846153846, 'recall': 0.8961038961038961, 'f1': 0.8903225806451613, 'support': 77}, {'label': 'tech', 'precision': 0.9259259259259259, 'recall': 0.8333333333333334, 'f1': 0.8771929824561403, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:48:12.995278', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.6158416271209717, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9763295154114302, 'recall': 0.9760479041916168, 'f1_score': 0.9760704058320477}, 'performance': {'train_time_seconds': 0.3076939582824707, 'total_time_seconds': 1.9235355854034424, 'inference_time_ms_per_sample': 0.019285493268224294}, 'confusion_matrix': [[75, 0, 1, 0, 1], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 1, 1, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.9_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:46:42.670824', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.612398386001587, 'features_extracted': 5000, 'reduction_time': 3.617318868637085, 'features_after_reduction': 420, 'metrics': {'accuracy': 0.844311377245509, 'precision': 0.8524863561811911, 'recall': 0.844311377245509, 'f1_score': 0.8432078531278774}, 'performance': {'train_time_seconds': 0.3137221336364746, 'total_time_seconds': 5.5434393882751465, 'inference_time_ms_per_sample': 0.12459226711067611}, 'confusion_matrix': [[71, 2, 4, 0, 0], [5, 45, 0, 8, 0], [5, 3, 48, 5, 1], [1, 2, 1, 73, 0], [9, 3, 3, 0, 45]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7802197802197802, 'recall': 0.922077922077922, 'f1': 0.8452380952380952, 'support': 77}, {'label': 'entertainment', 'precision': 0.8181818181818182, 'recall': 0.7758620689655172, 'f1': 0.7964601769911505, 'support': 58}, {'label': 'politics', 'precision': 0.8571428571428571, 'recall': 0.7741935483870968, 'f1': 0.8135593220338984, 'support': 62}, {'label': 'sport', 'precision': 0.8488372093023255, 'recall': 0.948051948051948, 'f1': 0.8957055214723927, 'support': 77}, {'label': 'tech', 'precision': 0.9782608695652174, 'recall': 0.75, 'f1': 0.8490566037735849, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.95_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:47:50.538484', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.564680814743042, 'features_extracted': 5000, 'reduction_time': 3.2493770122528076, 'features_after_reduction': 673, 'metrics': {'accuracy': 0.6287425149700598, 'precision': 0.6298017912996369, 'recall': 0.6287425149700598, 'f1_score': 0.6266130625227367}, 'performance': {'train_time_seconds': 1.1750915050506592, 'total_time_seconds': 5.989149332046509, 'inference_time_ms_per_sample': 0.002724681785720551}, 'confusion_matrix': [[51, 6, 6, 6, 8], [15, 26, 6, 8, 3], [12, 5, 35, 5, 5], [3, 9, 2, 62, 1], [11, 7, 4, 2, 36]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5543478260869565, 'recall': 0.6623376623376623, 'f1': 0.6035502958579881, 'support': 77}, {'label': 'entertainment', 'precision': 0.49056603773584906, 'recall': 0.4482758620689655, 'f1': 0.46846846846846846, 'support': 58}, {'label': 'politics', 'precision': 0.660377358490566, 'recall': 0.5645161290322581, 'f1': 0.6086956521739131, 'support': 62}, {'label': 'sport', 'precision': 0.7469879518072289, 'recall': 0.8051948051948052, 'f1': 0.775, 'support': 77}, {'label': 'tech', 'precision': 0.6792452830188679, 'recall': 0.6, 'f1': 0.6371681415929203, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.9_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:57:54.149950', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.8035697937011719, 'features_extracted': 10000, 'reduction_time': 6.38501763343811, 'features_after_reduction': 1020, 'metrics': {'accuracy': 0.9910179640718563, 'precision': 0.9911130120710959, 'recall': 0.9910179640718563, 'f1_score': 0.9910408747721947}, 'performance': {'train_time_seconds': 0.09459161758422852, 'total_time_seconds': 8.28317904472351, 'inference_time_ms_per_sample': 0.002722540301477124}, 'confusion_matrix': [[76, 0, 1, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:54:29.688088', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.5289838314056396, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7798037976435418, 'recall': 0.7694610778443114, 'f1_score': 0.7698911162806901}, 'performance': {'train_time_seconds': 0.47991394996643066, 'total_time_seconds': 2.0088977813720703, 'inference_time_ms_per_sample': 0.002102223698964376}, 'confusion_matrix': [[55, 3, 8, 4, 7], [6, 41, 4, 7, 0], [14, 0, 42, 3, 3], [5, 0, 0, 71, 1], [8, 0, 1, 3, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.625, 'recall': 0.7142857142857143, 'f1': 0.6666666666666666, 'support': 77}, {'label': 'entertainment', 'precision': 0.9318181818181818, 'recall': 0.7068965517241379, 'f1': 0.803921568627451, 'support': 58}, {'label': 'politics', 'precision': 0.7636363636363637, 'recall': 0.6774193548387096, 'f1': 0.717948717948718, 'support': 62}, {'label': 'sport', 'precision': 0.8068181818181818, 'recall': 0.922077922077922, 'f1': 0.8606060606060606, 'support': 77}, {'label': 'tech', 'precision': 0.8135593220338984, 'recall': 0.8, 'f1': 0.8067226890756303, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.9_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T15:52:49.428919', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.47382545471191406, 'features_extracted': 10000, 'reduction_time': 7.377352714538574, 'features_after_reduction': 1010, 'metrics': {'accuracy': 0.9251497005988024, 'precision': 0.9296160619427912, 'recall': 0.9251497005988024, 'f1_score': 0.9248626640761773}, 'performance': {'train_time_seconds': 0.015046834945678711, 'total_time_seconds': 7.866225004196167, 'inference_time_ms_per_sample': 0.3606459337794138}, 'confusion_matrix': [[64, 1, 10, 1, 1], [1, 51, 2, 1, 3], [1, 0, 60, 0, 1], [1, 0, 0, 75, 1], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9552238805970149, 'recall': 0.8311688311688312, 'f1': 0.8888888888888888, 'support': 77}, {'label': 'entertainment', 'precision': 0.9622641509433962, 'recall': 0.8793103448275862, 'f1': 0.918918918918919, 'support': 58}, {'label': 'politics', 'precision': 0.8333333333333334, 'recall': 0.967741935483871, 'f1': 0.8955223880597015, 'support': 62}, {'label': 'sport', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'tech', 'precision': 0.9076923076923077, 'recall': 0.9833333333333333, 'f1': 0.944, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.95_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T16:00:08.388133', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.816744089126587, 'features_extracted': 10000, 'reduction_time': 7.639346599578857, 'features_after_reduction': 1202, 'metrics': {'accuracy': 0.9101796407185628, 'precision': 0.9127366806882153, 'recall': 0.9101796407185628, 'f1_score': 0.9097678710643287}, 'performance': {'train_time_seconds': 0.01500082015991211, 'total_time_seconds': 9.471091508865356, 'inference_time_ms_per_sample': 0.3715667895928114}, 'confusion_matrix': [[65, 1, 8, 2, 1], [1, 49, 3, 1, 4], [1, 3, 56, 0, 2], [1, 0, 0, 75, 1], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9420289855072463, 'recall': 0.8441558441558441, 'f1': 0.8904109589041096, 'support': 77}, {'label': 'entertainment', 'precision': 0.9245283018867925, 'recall': 0.8448275862068966, 'f1': 0.8828828828828829, 'support': 58}, {'label': 'politics', 'precision': 0.835820895522388, 'recall': 0.9032258064516129, 'f1': 0.8682170542635659, 'support': 62}, {'label': 'sport', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'tech', 'precision': 0.8805970149253731, 'recall': 0.9833333333333333, 'f1': 0.9291338582677166, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.95_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:59:17.769743', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.809814691543579, 'features_extracted': 10000, 'reduction_time': 5.604454755783081, 'features_after_reduction': 1202, 'metrics': {'accuracy': 0.9910179640718563, 'precision': 0.9911130120710959, 'recall': 0.9910179640718563, 'f1_score': 0.9910408747721947}, 'performance': {'train_time_seconds': 0.133162260055542, 'total_time_seconds': 7.547431707382202, 'inference_time_ms_per_sample': 0.0031522648063248503}, 'confusion_matrix': [[76, 0, 1, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.95_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T16:00:18.009491', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.8304355144500732, 'features_extracted': 10000, 'reduction_time': 6.044954538345337, 'features_after_reduction': 1202, 'metrics': {'accuracy': 0.9341317365269461, 'precision': 0.9374342594389141, 'recall': 0.9341317365269461, 'f1_score': 0.9339649865883579}, 'performance': {'train_time_seconds': 0.020406484603881836, 'total_time_seconds': 7.895796537399292, 'inference_time_ms_per_sample': 0.33582398991384904}, 'confusion_matrix': [[68, 1, 7, 1, 0], [1, 50, 3, 1, 3], [1, 0, 60, 0, 1], [1, 0, 0, 75, 1], [0, 0, 0, 1, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9577464788732394, 'recall': 0.8831168831168831, 'f1': 0.918918918918919, 'support': 77}, {'label': 'entertainment', 'precision': 0.9803921568627451, 'recall': 0.8620689655172413, 'f1': 0.9174311926605505, 'support': 58}, {'label': 'politics', 'precision': 0.8571428571428571, 'recall': 0.967741935483871, 'f1': 0.9090909090909091, 'support': 62}, {'label': 'sport', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'tech', 'precision': 0.921875, 'recall': 0.9833333333333333, 'f1': 0.9516129032258065, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.9_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:48:59.574451', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.556572675704956, 'features_extracted': 10000, 'reduction_time': 6.877586364746094, 'features_after_reduction': 515, 'metrics': {'accuracy': 0.47604790419161674, 'precision': 0.4897631704440343, 'recall': 0.47604790419161674, 'f1_score': 0.46768046087139675}, 'performance': {'train_time_seconds': 0.011172056198120117, 'total_time_seconds': 8.44533109664917, 'inference_time_ms_per_sample': 0.0020722429195563948}, 'confusion_matrix': [[22, 19, 4, 13, 19], [4, 28, 1, 19, 6], [4, 12, 24, 10, 12], [2, 10, 10, 51, 4], [9, 8, 6, 3, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5365853658536586, 'recall': 0.2857142857142857, 'f1': 0.3728813559322034, 'support': 77}, {'label': 'entertainment', 'precision': 0.36363636363636365, 'recall': 0.4827586206896552, 'f1': 0.4148148148148148, 'support': 58}, {'label': 'politics', 'precision': 0.5333333333333333, 'recall': 0.3870967741935484, 'f1': 0.4485981308411215, 'support': 62}, {'label': 'sport', 'precision': 0.53125, 'recall': 0.6623376623376623, 'f1': 0.5895953757225434, 'support': 77}, {'label': 'tech', 'precision': 0.4533333333333333, 'recall': 0.5666666666666667, 'f1': 0.5037037037037037, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T15:42:54.629828', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5049114227294922, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9588148116452164, 'recall': 0.9580838323353293, 'f1_score': 0.9580231060694141}, 'performance': {'train_time_seconds': 0.2212364673614502, 'total_time_seconds': 0.7261478900909424, 'inference_time_ms_per_sample': 0.0984782944182436}, 'confusion_matrix': [[73, 0, 1, 1, 2], [1, 54, 1, 1, 1], [2, 0, 58, 2, 0], [0, 0, 0, 77, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9358974358974359, 'recall': 0.948051948051948, 'f1': 0.9419354838709677, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9310344827586207, 'f1': 0.9642857142857143, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1': 0.9508196721311475, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.9_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:55:14.969247', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.8662090301513672, 'features_extracted': 5000, 'reduction_time': 3.423366069793701, 'features_after_reduction': 906, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.9641790411850292, 'recall': 0.9640718562874252, 'f1_score': 0.9640664782489351}, 'performance': {'train_time_seconds': 0.3404831886291504, 'total_time_seconds': 5.630058288574219, 'inference_time_ms_per_sample': 0.10791153251054045}, 'confusion_matrix': [[73, 1, 3, 0, 0], [1, 55, 1, 1, 0], [1, 1, 59, 0, 1], [0, 1, 0, 76, 0], [0, 0, 0, 1, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9733333333333334, 'recall': 0.948051948051948, 'f1': 0.9605263157894737, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.95_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:47:44.607703', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.57755708694458, 'features_extracted': 5000, 'reduction_time': 3.2267611026763916, 'features_after_reduction': 673, 'metrics': {'accuracy': 0.6437125748502994, 'precision': 0.6472740455161452, 'recall': 0.6437125748502994, 'f1_score': 0.6405613571683563}, 'performance': {'train_time_seconds': 1.1097609996795654, 'total_time_seconds': 5.914079189300537, 'inference_time_ms_per_sample': 0.0021086481516946576}, 'confusion_matrix': [[53, 4, 7, 6, 7], [15, 27, 2, 11, 3], [9, 9, 35, 7, 2], [7, 3, 3, 63, 1], [10, 7, 4, 2, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5638297872340425, 'recall': 0.6883116883116883, 'f1': 0.6198830409356725, 'support': 77}, {'label': 'entertainment', 'precision': 0.54, 'recall': 0.46551724137931033, 'f1': 0.5, 'support': 58}, {'label': 'politics', 'precision': 0.6862745098039216, 'recall': 0.5645161290322581, 'f1': 0.6194690265486725, 'support': 62}, {'label': 'sport', 'precision': 0.7078651685393258, 'recall': 0.8181818181818182, 'f1': 0.7590361445783133, 'support': 77}, {'label': 'tech', 'precision': 0.74, 'recall': 0.6166666666666667, 'f1': 0.6727272727272727, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.9_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T15:44:01.522951', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.4733438491821289, 'features_extracted': 10000, 'reduction_time': 5.80204701423645, 'features_after_reduction': 446, 'metrics': {'accuracy': 0.7365269461077845, 'precision': 0.7808039655048423, 'recall': 0.7365269461077845, 'f1_score': 0.7339272086626227}, 'performance': {'train_time_seconds': 0.007726192474365234, 'total_time_seconds': 6.283117055892944, 'inference_time_ms_per_sample': 0.37269249647677305}, 'confusion_matrix': [[72, 1, 2, 1, 1], [11, 41, 0, 6, 0], [14, 13, 33, 2, 0], [5, 4, 2, 66, 0], [17, 6, 2, 1, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6050420168067226, 'recall': 0.935064935064935, 'f1': 0.7346938775510204, 'support': 77}, {'label': 'entertainment', 'precision': 0.6307692307692307, 'recall': 0.7068965517241379, 'f1': 0.6666666666666666, 'support': 58}, {'label': 'politics', 'precision': 0.8461538461538461, 'recall': 0.532258064516129, 'f1': 0.6534653465346535, 'support': 62}, {'label': 'sport', 'precision': 0.868421052631579, 'recall': 0.8571428571428571, 'f1': 0.8627450980392157, 'support': 77}, {'label': 'tech', 'precision': 0.9714285714285714, 'recall': 0.5666666666666667, 'f1': 0.7157894736842105, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:54:21.687973', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.574394941329956, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9850299401197605, 'precision': 0.985310628742515, 'recall': 0.9850299401197605, 'f1_score': 0.9850993907933737}, 'performance': {'train_time_seconds': 0.44528841972351074, 'total_time_seconds': 2.019683361053467, 'inference_time_ms_per_sample': 0.0034327992422138144}, 'confusion_matrix': [[75, 0, 2, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9833333333333333, 'f1': 0.9915966386554622, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.9_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:52:19.538076', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.570073127746582, 'features_extracted': 10000, 'reduction_time': 6.57193660736084, 'features_after_reduction': 1010, 'metrics': {'accuracy': 0.9730538922155688, 'precision': 0.9731639719257704, 'recall': 0.9730538922155688, 'f1_score': 0.9729438637061038}, 'performance': {'train_time_seconds': 0.33338499069213867, 'total_time_seconds': 7.4753947257995605, 'inference_time_ms_per_sample': 0.2788405218524133}, 'confusion_matrix': [[75, 1, 1, 0, 0], [0, 57, 1, 0, 0], [3, 1, 57, 1, 0], [0, 1, 0, 76, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'entertainment', 'precision': 0.95, 'recall': 0.9827586206896551, 'f1': 0.9661016949152542, 'support': 58}, {'label': 'politics', 'precision': 0.9661016949152542, 'recall': 0.9193548387096774, 'f1': 0.9421487603305785, 'support': 62}, {'label': 'sport', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.9_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T15:55:45.498804', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.786191463470459, 'features_extracted': 5000, 'reduction_time': 3.1790356636047363, 'features_after_reduction': 906, 'metrics': {'accuracy': 0.9251497005988024, 'precision': 0.9269036239129367, 'recall': 0.9251497005988024, 'f1_score': 0.9250155720098567}, 'performance': {'train_time_seconds': 0.015526056289672852, 'total_time_seconds': 4.980753183364868, 'inference_time_ms_per_sample': 0.3446911623378}, 'confusion_matrix': [[68, 1, 7, 1, 0], [2, 50, 2, 1, 3], [1, 1, 59, 0, 1], [1, 0, 0, 74, 2], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9315068493150684, 'recall': 0.8831168831168831, 'f1': 0.9066666666666666, 'support': 77}, {'label': 'entertainment', 'precision': 0.9433962264150944, 'recall': 0.8620689655172413, 'f1': 0.9009009009009009, 'support': 58}, {'label': 'politics', 'precision': 0.8676470588235294, 'recall': 0.9516129032258065, 'f1': 0.9076923076923077, 'support': 62}, {'label': 'sport', 'precision': 0.9736842105263158, 'recall': 0.961038961038961, 'f1': 0.9673202614379085, 'support': 77}, {'label': 'tech', 'precision': 0.90625, 'recall': 0.9666666666666667, 'f1': 0.9354838709677419, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T15:57:11.564231', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.8394110202789307, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9101796407185628, 'precision': 0.9119474280167817, 'recall': 0.9101796407185628, 'f1_score': 0.9097967985071983}, 'performance': {'train_time_seconds': 0.003237009048461914, 'total_time_seconds': 1.8426480293273926, 'inference_time_ms_per_sample': 0.29285725005372554}, 'confusion_matrix': [[66, 1, 5, 2, 3], [1, 49, 3, 2, 3], [1, 2, 57, 0, 2], [1, 1, 0, 74, 1], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9428571428571428, 'recall': 0.8571428571428571, 'f1': 0.8979591836734694, 'support': 77}, {'label': 'entertainment', 'precision': 0.9074074074074074, 'recall': 0.8448275862068966, 'f1': 0.875, 'support': 58}, {'label': 'politics', 'precision': 0.8769230769230769, 'recall': 0.9193548387096774, 'f1': 0.8976377952755905, 'support': 62}, {'label': 'sport', 'precision': 0.9487179487179487, 'recall': 0.961038961038961, 'f1': 0.9548387096774194, 'support': 77}, {'label': 'tech', 'precision': 0.8656716417910447, 'recall': 0.9666666666666667, 'f1': 0.9133858267716536, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.95_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:50:54.041202', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6369044780731201, 'features_extracted': 10000, 'reduction_time': 5.761640548706055, 'features_after_reduction': 789, 'metrics': {'accuracy': 0.7964071856287425, 'precision': 0.8181546049484085, 'recall': 0.7964071856287425, 'f1_score': 0.7922835180959238}, 'performance': {'train_time_seconds': 0.3649418354034424, 'total_time_seconds': 7.763486862182617, 'inference_time_ms_per_sample': 0.104350244213721}, 'confusion_matrix': [[73, 0, 3, 1, 0], [8, 40, 1, 9, 0], [12, 1, 42, 6, 1], [1, 1, 1, 73, 1], [11, 3, 5, 3, 38]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6952380952380952, 'recall': 0.948051948051948, 'f1': 0.8021978021978022, 'support': 77}, {'label': 'entertainment', 'precision': 0.8888888888888888, 'recall': 0.6896551724137931, 'f1': 0.7766990291262136, 'support': 58}, {'label': 'politics', 'precision': 0.8076923076923077, 'recall': 0.6774193548387096, 'f1': 0.7368421052631579, 'support': 62}, {'label': 'sport', 'precision': 0.7934782608695652, 'recall': 0.948051948051948, 'f1': 0.863905325443787, 'support': 77}, {'label': 'tech', 'precision': 0.95, 'recall': 0.6333333333333333, 'f1': 0.76, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:54:31.705274', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.67122483253479, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7844311377245509, 'precision': 0.7837046408805158, 'recall': 0.7844311377245509, 'f1_score': 0.78251185822289}, 'performance': {'train_time_seconds': 0.7504503726959229, 'total_time_seconds': 2.421675205230713, 'inference_time_ms_per_sample': 0.0029124185710610027}, 'confusion_matrix': [[51, 6, 8, 5, 7], [5, 41, 6, 4, 2], [7, 2, 49, 2, 2], [3, 0, 2, 70, 2], [5, 1, 2, 1, 51]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7183098591549296, 'recall': 0.6623376623376623, 'f1': 0.6891891891891891, 'support': 77}, {'label': 'entertainment', 'precision': 0.82, 'recall': 0.7068965517241379, 'f1': 0.7592592592592593, 'support': 58}, {'label': 'politics', 'precision': 0.7313432835820896, 'recall': 0.7903225806451613, 'f1': 0.7596899224806202, 'support': 62}, {'label': 'sport', 'precision': 0.8536585365853658, 'recall': 0.9090909090909091, 'f1': 0.8805031446540881, 'support': 77}, {'label': 'tech', 'precision': 0.796875, 'recall': 0.85, 'f1': 0.8225806451612904, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.95_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:59:09.593311', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.917926549911499, 'features_extracted': 10000, 'reduction_time': 6.1820597648620605, 'features_after_reduction': 1202, 'metrics': {'accuracy': 0.6197604790419161, 'precision': 0.7573203508868342, 'recall': 0.6197604790419161, 'f1_score': 0.5771917858442013}, 'performance': {'train_time_seconds': 0.034569501876831055, 'total_time_seconds': 8.13455581665039, 'inference_time_ms_per_sample': 0.007191104089428565}, 'confusion_matrix': [[71, 0, 1, 3, 2], [27, 7, 0, 24, 0], [21, 0, 31, 8, 2], [2, 0, 0, 74, 1], [27, 0, 0, 9, 24]], 'per_class_metrics': [{'label': 'business', 'precision': 0.4797297297297297, 'recall': 0.922077922077922, 'f1': 0.6311111111111111, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.1206896551724138, 'f1': 0.2153846153846154, 'support': 58}, {'label': 'politics', 'precision': 0.96875, 'recall': 0.5, 'f1': 0.6595744680851063, 'support': 62}, {'label': 'sport', 'precision': 0.6271186440677966, 'recall': 0.961038961038961, 'f1': 0.7589743589743589, 'support': 77}, {'label': 'tech', 'precision': 0.8275862068965517, 'recall': 0.4, 'f1': 0.5393258426966292, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.95_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:53:21.528981', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5243804454803467, 'features_extracted': 10000, 'reduction_time': 5.9704484939575195, 'features_after_reduction': 1191, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.979473277976272, 'recall': 0.9790419161676647, 'f1_score': 0.9790700186944252}, 'performance': {'train_time_seconds': 0.19452548027038574, 'total_time_seconds': 6.689354419708252, 'inference_time_ms_per_sample': 0.003028058720206072}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.95_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:53:28.249017', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5554232597351074, 'features_extracted': 10000, 'reduction_time': 6.18374228477478, 'features_after_reduction': 1191, 'metrics': {'accuracy': 0.9461077844311377, 'precision': 0.9488500123935136, 'recall': 0.9461077844311377, 'f1_score': 0.9453447046726348}, 'performance': {'train_time_seconds': 0.3548269271850586, 'total_time_seconds': 7.093992471694946, 'inference_time_ms_per_sample': 0.11404759869604054}, 'confusion_matrix': [[75, 0, 2, 0, 0], [3, 48, 2, 5, 0], [3, 0, 56, 3, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9259259259259259, 'recall': 0.974025974025974, 'f1': 0.9493670886075949, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.8275862068965517, 'f1': 0.9056603773584906, 'support': 58}, {'label': 'politics', 'precision': 0.9333333333333333, 'recall': 0.9032258064516129, 'f1': 0.9180327868852459, 'support': 62}, {'label': 'sport', 'precision': 0.9058823529411765, 'recall': 1.0, 'f1': 0.9506172839506173, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.9_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:57:40.119563', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.8428332805633545, 'features_extracted': 10000, 'reduction_time': 12.131406784057617, 'features_after_reduction': 1020, 'metrics': {'accuracy': 0.6287425149700598, 'precision': 0.763277039504826, 'recall': 0.6287425149700598, 'f1_score': 0.5868868906392976}, 'performance': {'train_time_seconds': 0.01526498794555664, 'total_time_seconds': 13.989505052566528, 'inference_time_ms_per_sample': 0.003029486376368357}, 'confusion_matrix': [[71, 0, 1, 3, 2], [27, 7, 0, 24, 0], [22, 0, 31, 7, 2], [1, 0, 0, 75, 1], [26, 0, 0, 8, 26]], 'per_class_metrics': [{'label': 'business', 'precision': 0.48299319727891155, 'recall': 0.922077922077922, 'f1': 0.6339285714285714, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.1206896551724138, 'f1': 0.2153846153846154, 'support': 58}, {'label': 'politics', 'precision': 0.96875, 'recall': 0.5, 'f1': 0.6595744680851063, 'support': 62}, {'label': 'sport', 'precision': 0.6410256410256411, 'recall': 0.974025974025974, 'f1': 0.7731958762886598, 'support': 77}, {'label': 'tech', 'precision': 0.8387096774193549, 'recall': 0.43333333333333335, 'f1': 0.5714285714285714, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.9_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:52:27.125554', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.4870615005493164, 'features_extracted': 10000, 'reduction_time': 6.061603546142578, 'features_after_reduction': 1010, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9820956022664864, 'recall': 0.9820359281437125, 'f1_score': 0.9820059075239251}, 'performance': {'train_time_seconds': 0.38700056076049805, 'total_time_seconds': 6.935665607452393, 'inference_time_ms_per_sample': 0.10516757736662906}, 'confusion_matrix': [[75, 1, 1, 0, 0], [0, 56, 1, 1, 0], [1, 0, 60, 1, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.967741935483871, 'recall': 0.967741935483871, 'f1': 0.967741935483871, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:48:38.637145', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.5518934726715088, 'features_extracted': 10000, 'reduction_time': 0.2730088233947754, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9730538922155688, 'precision': 0.9737496602766063, 'recall': 0.9730538922155688, 'f1_score': 0.9729928141568138}, 'performance': {'train_time_seconds': 0.015719175338745117, 'total_time_seconds': 1.8406214714050293, 'inference_time_ms_per_sample': 0.004885439387338604}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 54, 2, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.95_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:56:07.067500', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.9323115348815918, 'features_extracted': 5000, 'reduction_time': 3.868323564529419, 'features_after_reduction': 1105, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.979473277976272, 'recall': 0.9790419161676647, 'f1_score': 0.9790700186944252}, 'performance': {'train_time_seconds': 0.2848963737487793, 'total_time_seconds': 6.08553147315979, 'inference_time_ms_per_sample': 0.0032072295685728154}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.95_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:53:35.400933', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5057520866394043, 'features_extracted': 10000, 'reduction_time': 5.593707084655762, 'features_after_reduction': 1191, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9671499034897239, 'recall': 0.9670658682634731, 'f1_score': 0.9669179089094413}, 'performance': {'train_time_seconds': 0.3707897663116455, 'total_time_seconds': 6.4702489376068115, 'inference_time_ms_per_sample': 0.12634685653412414}, 'confusion_matrix': [[74, 1, 2, 0, 0], [2, 55, 1, 0, 0], [2, 0, 57, 3, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9487179487179487, 'recall': 0.961038961038961, 'f1': 0.9548387096774194, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.95, 'recall': 0.9193548387096774, 'f1': 0.9344262295081968, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.95_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:59:59.143117', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.7554287910461426, 'features_extracted': 10000, 'reduction_time': 5.70234227180481, 'features_after_reduction': 1202, 'metrics': {'accuracy': 0.9101796407185628, 'precision': 0.9125616530097699, 'recall': 0.9101796407185628, 'f1_score': 0.9107265663704737}, 'performance': {'train_time_seconds': 1.762542724609375, 'total_time_seconds': 9.220313787460327, 'inference_time_ms_per_sample': 0.00318795621038197}, 'confusion_matrix': [[69, 3, 4, 0, 1], [0, 54, 2, 0, 2], [3, 3, 55, 0, 1], [0, 1, 1, 74, 1], [3, 3, 2, 0, 52]], 'per_class_metrics': [{'label': 'business', 'precision': 0.92, 'recall': 0.8961038961038961, 'f1': 0.9078947368421053, 'support': 77}, {'label': 'entertainment', 'precision': 0.84375, 'recall': 0.9310344827586207, 'f1': 0.8852459016393442, 'support': 58}, {'label': 'politics', 'precision': 0.859375, 'recall': 0.8870967741935484, 'f1': 0.873015873015873, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 0.961038961038961, 'f1': 0.9801324503311258, 'support': 77}, {'label': 'tech', 'precision': 0.9122807017543859, 'recall': 0.8666666666666667, 'f1': 0.8888888888888888, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.95_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T15:47:56.546093', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.559973955154419, 'features_extracted': 5000, 'reduction_time': 3.303255796432495, 'features_after_reduction': 673, 'metrics': {'accuracy': 0.7574850299401198, 'precision': 0.7924972134988598, 'recall': 0.7574850299401198, 'f1_score': 0.7564121605479099}, 'performance': {'train_time_seconds': 0.010093927383422852, 'total_time_seconds': 4.873323678970337, 'inference_time_ms_per_sample': 0.35915046394942046}, 'confusion_matrix': [[70, 2, 1, 1, 3], [11, 42, 0, 5, 0], [10, 12, 36, 3, 1], [2, 4, 1, 69, 1], [13, 11, 0, 0, 36]], 'per_class_metrics': [{'label': 'business', 'precision': 0.660377358490566, 'recall': 0.9090909090909091, 'f1': 0.7650273224043715, 'support': 77}, {'label': 'entertainment', 'precision': 0.5915492957746479, 'recall': 0.7241379310344828, 'f1': 0.6511627906976745, 'support': 58}, {'label': 'politics', 'precision': 0.9473684210526315, 'recall': 0.5806451612903226, 'f1': 0.72, 'support': 62}, {'label': 'sport', 'precision': 0.8846153846153846, 'recall': 0.8961038961038961, 'f1': 0.8903225806451613, 'support': 77}, {'label': 'tech', 'precision': 0.8780487804878049, 'recall': 0.6, 'f1': 0.7128712871287128, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T15:51:46.001892', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5432207584381104, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9281437125748503, 'precision': 0.9327158066687695, 'recall': 0.9281437125748503, 'f1_score': 0.9281114296066986}, 'performance': {'train_time_seconds': 0.21058368682861328, 'total_time_seconds': 0.7538044452667236, 'inference_time_ms_per_sample': 0.0965373958656174}, 'confusion_matrix': [[74, 0, 1, 1, 1], [3, 50, 1, 4, 0], [5, 0, 56, 1, 0], [0, 0, 0, 77, 0], [5, 1, 1, 0, 53]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8505747126436781, 'recall': 0.961038961038961, 'f1': 0.9024390243902439, 'support': 77}, {'label': 'entertainment', 'precision': 0.9803921568627451, 'recall': 0.8620689655172413, 'f1': 0.9174311926605505, 'support': 58}, {'label': 'politics', 'precision': 0.9491525423728814, 'recall': 0.9032258064516129, 'f1': 0.9256198347107438, 'support': 62}, {'label': 'sport', 'precision': 0.927710843373494, 'recall': 1.0, 'f1': 0.9625, 'support': 77}, {'label': 'tech', 'precision': 0.9814814814814815, 'recall': 0.8833333333333333, 'f1': 0.9298245614035088, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.95_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:59:32.969653', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.8656330108642578, 'features_extracted': 10000, 'reduction_time': 5.390268802642822, 'features_after_reduction': 1202, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9584931361460957, 'recall': 0.9580838323353293, 'f1_score': 0.958080001805594}, 'performance': {'train_time_seconds': 0.3658919334411621, 'total_time_seconds': 7.621793746948242, 'inference_time_ms_per_sample': 0.11504909949388333}, 'confusion_matrix': [[74, 1, 2, 0, 0], [2, 53, 2, 1, 0], [1, 1, 59, 1, 0], [0, 0, 0, 77, 0], [0, 2, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.961038961038961, 'recall': 0.961038961038961, 'f1': 0.961038961038961, 'support': 77}, {'label': 'entertainment', 'precision': 0.9298245614035088, 'recall': 0.9137931034482759, 'f1': 0.9217391304347826, 'support': 58}, {'label': 'politics', 'precision': 0.921875, 'recall': 0.9516129032258065, 'f1': 0.9365079365079365, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.95, 'f1': 0.9743589743589743, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:42:59.134983', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.4787144660949707, 'features_extracted': 10000, 'reduction_time': 0.27202272415161133, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9797208779244705, 'recall': 0.9790419161676647, 'f1_score': 0.9789695970982052}, 'performance': {'train_time_seconds': 0.014728546142578125, 'total_time_seconds': 0.7654657363891602, 'inference_time_ms_per_sample': 0.005694920431354089}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 54, 2, 0, 2], [0, 0, 62, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 1.0, 'recall': 0.961038961038961, 'f1': 0.9801324503311258, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9538461538461539, 'recall': 1.0, 'f1': 0.9763779527559056, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.9_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:43:54.120364', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.49248456954956055, 'features_extracted': 10000, 'reduction_time': 6.003028154373169, 'features_after_reduction': 446, 'metrics': {'accuracy': 0.6467065868263473, 'precision': 0.6485749545326092, 'recall': 0.6467065868263473, 'f1_score': 0.6460993448845056}, 'performance': {'train_time_seconds': 0.8896536827087402, 'total_time_seconds': 7.38516640663147, 'inference_time_ms_per_sample': 0.0018181201226696998}, 'confusion_matrix': [[56, 4, 5, 2, 10], [8, 29, 7, 12, 2], [11, 8, 37, 5, 1], [2, 9, 4, 59, 3], [6, 12, 3, 4, 35]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6746987951807228, 'recall': 0.7272727272727273, 'f1': 0.7, 'support': 77}, {'label': 'entertainment', 'precision': 0.46774193548387094, 'recall': 0.5, 'f1': 0.48333333333333334, 'support': 58}, {'label': 'politics', 'precision': 0.6607142857142857, 'recall': 0.5967741935483871, 'f1': 0.6271186440677966, 'support': 62}, {'label': 'sport', 'precision': 0.7195121951219512, 'recall': 0.7662337662337663, 'f1': 0.7421383647798742, 'support': 77}, {'label': 'tech', 'precision': 0.6862745098039216, 'recall': 0.5833333333333334, 'f1': 0.6306306306306306, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.9_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:43:17.057500', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5300137996673584, 'features_extracted': 10000, 'reduction_time': 6.608157157897949, 'features_after_reduction': 446, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582447541728911, 'recall': 0.9580838323353293, 'f1_score': 0.9579974686617265}, 'performance': {'train_time_seconds': 0.2165207862854004, 'total_time_seconds': 7.354691743850708, 'inference_time_ms_per_sample': 0.0018309690281302629}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:57:31.204863', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.8041200637817383, 'features_extracted': 10000, 'reduction_time': 0.29224324226379395, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7964071856287425, 'precision': 0.801269900733833, 'recall': 0.7964071856287425, 'f1_score': 0.7975907203643189}, 'performance': {'train_time_seconds': 0.15465760231018066, 'total_time_seconds': 2.251020908355713, 'inference_time_ms_per_sample': 0.0029395440381444144}, 'confusion_matrix': [[55, 2, 11, 4, 5], [5, 45, 5, 3, 0], [9, 1, 50, 1, 1], [3, 2, 2, 68, 2], [5, 3, 4, 0, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7142857142857143, 'recall': 0.7142857142857143, 'f1': 0.7142857142857143, 'support': 77}, {'label': 'entertainment', 'precision': 0.8490566037735849, 'recall': 0.7758620689655172, 'f1': 0.8108108108108109, 'support': 58}, {'label': 'politics', 'precision': 0.6944444444444444, 'recall': 0.8064516129032258, 'f1': 0.746268656716418, 'support': 62}, {'label': 'sport', 'precision': 0.8947368421052632, 'recall': 0.8831168831168831, 'f1': 0.8888888888888888, 'support': 77}, {'label': 'tech', 'precision': 0.8571428571428571, 'recall': 0.8, 'f1': 0.8275862068965517, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T15:51:46.796721', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.4899914264678955, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.9643923345846616, 'recall': 0.9640718562874252, 'f1_score': 0.9640328039573028}, 'performance': {'train_time_seconds': 0.2249903678894043, 'total_time_seconds': 0.7149817943572998, 'inference_time_ms_per_sample': 0.09855681550716924}, 'confusion_matrix': [[74, 0, 1, 1, 1], [1, 56, 1, 0, 0], [2, 0, 59, 1, 0], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9367088607594937, 'recall': 0.961038961038961, 'f1': 0.9487179487179487, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T15:46:17.943349', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.5659348964691162, 'features_extracted': 5000, 'reduction_time': 0.14048218727111816, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7485029940119761, 'precision': 0.7805850298796609, 'recall': 0.7485029940119761, 'f1_score': 0.7439429735975069}, 'performance': {'train_time_seconds': 0.009404182434082031, 'total_time_seconds': 1.7158212661743164, 'inference_time_ms_per_sample': 0.29268307600192683}, 'confusion_matrix': [[72, 0, 4, 1, 0], [7, 42, 1, 7, 1], [12, 2, 40, 6, 2], [4, 6, 1, 66, 0], [23, 2, 4, 1, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6101694915254238, 'recall': 0.935064935064935, 'f1': 0.7384615384615385, 'support': 77}, {'label': 'entertainment', 'precision': 0.8076923076923077, 'recall': 0.7241379310344828, 'f1': 0.7636363636363637, 'support': 58}, {'label': 'politics', 'precision': 0.8, 'recall': 0.6451612903225806, 'f1': 0.7142857142857143, 'support': 62}, {'label': 'sport', 'precision': 0.8148148148148148, 'recall': 0.8571428571428571, 'f1': 0.8354430379746836, 'support': 77}, {'label': 'tech', 'precision': 0.9090909090909091, 'recall': 0.5, 'f1': 0.6451612903225806, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T15:46:16.110362', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.573364496231079, 'features_extracted': 5000, 'reduction_time': 0.1415853500366211, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7305389221556886, 'precision': 0.7512445908859735, 'recall': 0.7305389221556886, 'f1_score': 0.7261457736912116}, 'performance': {'train_time_seconds': 0.009287118911743164, 'total_time_seconds': 1.7242369651794434, 'inference_time_ms_per_sample': 0.287225146493512}, 'confusion_matrix': [[66, 3, 4, 2, 2], [5, 45, 1, 7, 0], [10, 8, 39, 3, 2], [4, 8, 1, 64, 0], [18, 3, 7, 2, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6407766990291263, 'recall': 0.8571428571428571, 'f1': 0.7333333333333333, 'support': 77}, {'label': 'entertainment', 'precision': 0.6716417910447762, 'recall': 0.7758620689655172, 'f1': 0.72, 'support': 58}, {'label': 'politics', 'precision': 0.75, 'recall': 0.6290322580645161, 'f1': 0.6842105263157895, 'support': 62}, {'label': 'sport', 'precision': 0.8205128205128205, 'recall': 0.8311688311688312, 'f1': 0.8258064516129032, 'support': 77}, {'label': 'tech', 'precision': 0.8823529411764706, 'recall': 0.5, 'f1': 0.6382978723404256, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.95_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:45:00.645254', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.49576497077941895, 'features_extracted': 10000, 'reduction_time': 6.354467391967773, 'features_after_reduction': 716, 'metrics': {'accuracy': 0.6317365269461078, 'precision': 0.6347567775703163, 'recall': 0.6317365269461078, 'f1_score': 0.6305377254928481}, 'performance': {'train_time_seconds': 1.177283763885498, 'total_time_seconds': 8.02751612663269, 'inference_time_ms_per_sample': 0.0022956711089539674}, 'confusion_matrix': [[50, 7, 10, 2, 8], [6, 28, 8, 14, 2], [13, 7, 37, 3, 2], [4, 5, 2, 64, 2], [5, 17, 3, 3, 32]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6410256410256411, 'recall': 0.6493506493506493, 'f1': 0.6451612903225806, 'support': 77}, {'label': 'entertainment', 'precision': 0.4375, 'recall': 0.4827586206896552, 'f1': 0.45901639344262296, 'support': 58}, {'label': 'politics', 'precision': 0.6166666666666667, 'recall': 0.5967741935483871, 'f1': 0.6065573770491803, 'support': 62}, {'label': 'sport', 'precision': 0.7441860465116279, 'recall': 0.8311688311688312, 'f1': 0.7852760736196319, 'support': 77}, {'label': 'tech', 'precision': 0.6956521739130435, 'recall': 0.5333333333333333, 'f1': 0.6037735849056604, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.95_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T16:00:26.052216', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.7539582252502441, 'features_extracted': 10000, 'reduction_time': 5.5168352127075195, 'features_after_reduction': 1202, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9593038202137489, 'recall': 0.9580838323353293, 'f1_score': 0.9580961862605307}, 'performance': {'train_time_seconds': 0.015369653701782227, 'total_time_seconds': 7.286163091659546, 'inference_time_ms_per_sample': 0.3352429338557991}, 'confusion_matrix': [[70, 1, 5, 1, 0], [1, 54, 2, 1, 0], [1, 0, 61, 0, 0], [1, 0, 0, 76, 0], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.958904109589041, 'recall': 0.9090909090909091, 'f1': 0.9333333333333333, 'support': 77}, {'label': 'entertainment', 'precision': 0.9642857142857143, 'recall': 0.9310344827586207, 'f1': 0.9473684210526315, 'support': 58}, {'label': 'politics', 'precision': 0.8970588235294118, 'recall': 0.9838709677419355, 'f1': 0.9384615384615385, 'support': 62}, {'label': 'sport', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9833333333333333, 'f1': 0.9915966386554622, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.9_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:55:33.089786', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.8322052955627441, 'features_extracted': 5000, 'reduction_time': 3.7887866497039795, 'features_after_reduction': 906, 'metrics': {'accuracy': 0.8982035928143712, 'precision': 0.8982625849994925, 'recall': 0.8982035928143712, 'f1_score': 0.8980992398163696}, 'performance': {'train_time_seconds': 1.3725099563598633, 'total_time_seconds': 6.993501901626587, 'inference_time_ms_per_sample': 0.0028810101354907374}, 'confusion_matrix': [[71, 1, 4, 0, 1], [3, 49, 4, 1, 1], [6, 1, 51, 2, 2], [0, 3, 0, 74, 0], [0, 2, 3, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8875, 'recall': 0.922077922077922, 'f1': 0.9044585987261147, 'support': 77}, {'label': 'entertainment', 'precision': 0.875, 'recall': 0.8448275862068966, 'f1': 0.8596491228070176, 'support': 58}, {'label': 'politics', 'precision': 0.8225806451612904, 'recall': 0.8225806451612904, 'f1': 0.8225806451612904, 'support': 62}, {'label': 'sport', 'precision': 0.961038961038961, 'recall': 0.961038961038961, 'f1': 0.961038961038961, 'support': 77}, {'label': 'tech', 'precision': 0.9322033898305084, 'recall': 0.9166666666666666, 'f1': 0.9243697478991597, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.9_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:46:54.190690', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5321264266967773, 'features_extracted': 5000, 'reduction_time': 3.5437777042388916, 'features_after_reduction': 420, 'metrics': {'accuracy': 0.6377245508982036, 'precision': 0.6400256303310493, 'recall': 0.6377245508982036, 'f1_score': 0.636615056330344}, 'performance': {'train_time_seconds': 0.7417206764221191, 'total_time_seconds': 5.817624807357788, 'inference_time_ms_per_sample': 0.001825972231562266}, 'confusion_matrix': [[47, 11, 7, 6, 6], [9, 31, 4, 9, 5], [8, 7, 35, 7, 5], [4, 7, 2, 63, 1], [11, 7, 3, 2, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5949367088607594, 'recall': 0.6103896103896104, 'f1': 0.6025641025641025, 'support': 77}, {'label': 'entertainment', 'precision': 0.49206349206349204, 'recall': 0.5344827586206896, 'f1': 0.512396694214876, 'support': 58}, {'label': 'politics', 'precision': 0.6862745098039216, 'recall': 0.5645161290322581, 'f1': 0.6194690265486725, 'support': 62}, {'label': 'sport', 'precision': 0.7241379310344828, 'recall': 0.8181818181818182, 'f1': 0.7682926829268293, 'support': 77}, {'label': 'tech', 'precision': 0.6851851851851852, 'recall': 0.6166666666666667, 'f1': 0.6491228070175439, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.9_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T15:50:05.015267', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.5575809478759766, 'features_extracted': 10000, 'reduction_time': 7.079388618469238, 'features_after_reduction': 515, 'metrics': {'accuracy': 0.7425149700598802, 'precision': 0.7929434552327687, 'recall': 0.7425149700598802, 'f1_score': 0.7360461403303727}, 'performance': {'train_time_seconds': 0.008530855178833008, 'total_time_seconds': 8.645500421524048, 'inference_time_ms_per_sample': 0.38230847455784234}, 'confusion_matrix': [[72, 3, 1, 1, 0], [8, 45, 0, 5, 0], [18, 10, 32, 2, 0], [3, 4, 0, 69, 1], [18, 7, 3, 2, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6050420168067226, 'recall': 0.935064935064935, 'f1': 0.7346938775510204, 'support': 77}, {'label': 'entertainment', 'precision': 0.6521739130434783, 'recall': 0.7758620689655172, 'f1': 0.7086614173228346, 'support': 58}, {'label': 'politics', 'precision': 0.8888888888888888, 'recall': 0.5161290322580645, 'f1': 0.6530612244897959, 'support': 62}, {'label': 'sport', 'precision': 0.8734177215189873, 'recall': 0.8961038961038961, 'f1': 0.8846153846153846, 'support': 77}, {'label': 'tech', 'precision': 0.967741935483871, 'recall': 0.5, 'f1': 0.6593406593406593, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.9_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:46:19.769662', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.577491044998169, 'features_extracted': 5000, 'reduction_time': 4.046832323074341, 'features_after_reduction': 420, 'metrics': {'accuracy': 0.49700598802395207, 'precision': 0.4986035974280682, 'recall': 0.49700598802395207, 'f1_score': 0.49115281562930657}, 'performance': {'train_time_seconds': 0.011347532272338867, 'total_time_seconds': 5.635670900344849, 'inference_time_ms_per_sample': 0.0022128670515414485}, 'confusion_matrix': [[26, 11, 6, 15, 19], [6, 29, 1, 15, 7], [6, 9, 27, 10, 10], [4, 7, 11, 50, 5], [12, 7, 4, 3, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.48148148148148145, 'recall': 0.33766233766233766, 'f1': 0.3969465648854962, 'support': 77}, {'label': 'entertainment', 'precision': 0.4603174603174603, 'recall': 0.5, 'f1': 0.4793388429752066, 'support': 58}, {'label': 'politics', 'precision': 0.5510204081632653, 'recall': 0.43548387096774194, 'f1': 0.4864864864864865, 'support': 62}, {'label': 'sport', 'precision': 0.5376344086021505, 'recall': 0.6493506493506493, 'f1': 0.5882352941176471, 'support': 77}, {'label': 'tech', 'precision': 0.4533333333333333, 'recall': 0.5666666666666667, 'f1': 0.5037037037037037, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T15:51:49.801647', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.49015212059020996, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9161676646706587, 'precision': 0.9220997922832007, 'recall': 0.9161676646706587, 'f1_score': 0.9161813881785702}, 'performance': {'train_time_seconds': 0.002463817596435547, 'total_time_seconds': 0.4926159381866455, 'inference_time_ms_per_sample': 0.28908038567640115}, 'confusion_matrix': [[64, 1, 8, 1, 3], [1, 50, 3, 1, 3], [1, 0, 60, 0, 1], [1, 0, 1, 74, 1], [0, 1, 1, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9552238805970149, 'recall': 0.8311688311688312, 'f1': 0.8888888888888888, 'support': 77}, {'label': 'entertainment', 'precision': 0.9615384615384616, 'recall': 0.8620689655172413, 'f1': 0.9090909090909091, 'support': 58}, {'label': 'politics', 'precision': 0.821917808219178, 'recall': 0.967741935483871, 'f1': 0.8888888888888888, 'support': 62}, {'label': 'sport', 'precision': 0.9736842105263158, 'recall': 0.961038961038961, 'f1': 0.9673202614379085, 'support': 77}, {'label': 'tech', 'precision': 0.8787878787878788, 'recall': 0.9666666666666667, 'f1': 0.9206349206349206, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.95_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:47:39.251792', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6349925994873047, 'features_extracted': 5000, 'reduction_time': 3.3258466720581055, 'features_after_reduction': 673, 'metrics': {'accuracy': 0.8083832335329342, 'precision': 0.8277166114712899, 'recall': 0.8083832335329342, 'f1_score': 0.8051142928858418}, 'performance': {'train_time_seconds': 0.3427138328552246, 'total_time_seconds': 5.303553104400635, 'inference_time_ms_per_sample': 0.1014092725194143}, 'confusion_matrix': [[73, 0, 2, 2, 0], [7, 38, 2, 11, 0], [9, 1, 44, 8, 0], [2, 1, 1, 73, 0], [9, 5, 4, 0, 42]], 'per_class_metrics': [{'label': 'business', 'precision': 0.73, 'recall': 0.948051948051948, 'f1': 0.8248587570621468, 'support': 77}, {'label': 'entertainment', 'precision': 0.8444444444444444, 'recall': 0.6551724137931034, 'f1': 0.7378640776699029, 'support': 58}, {'label': 'politics', 'precision': 0.8301886792452831, 'recall': 0.7096774193548387, 'f1': 0.7652173913043478, 'support': 62}, {'label': 'sport', 'precision': 0.776595744680851, 'recall': 0.948051948051948, 'f1': 0.8538011695906432, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.7, 'f1': 0.8235294117647058, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.95_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:59:40.654718', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.9659810066223145, 'features_extracted': 10000, 'reduction_time': 6.141005516052246, 'features_after_reduction': 1202, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.953804639645576, 'recall': 0.9520958083832335, 'f1_score': 0.9524340956593047}, 'performance': {'train_time_seconds': 0.3716397285461426, 'total_time_seconds': 8.478626251220703, 'inference_time_ms_per_sample': 0.11163771509410378}, 'confusion_matrix': [[73, 1, 3, 0, 0], [1, 53, 4, 0, 0], [1, 0, 60, 1, 0], [0, 1, 0, 76, 0], [0, 4, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9733333333333334, 'recall': 0.948051948051948, 'f1': 0.9605263157894737, 'support': 77}, {'label': 'entertainment', 'precision': 0.8983050847457628, 'recall': 0.9137931034482759, 'f1': 0.905982905982906, 'support': 58}, {'label': 'politics', 'precision': 0.8955223880597015, 'recall': 0.967741935483871, 'f1': 0.9302325581395349, 'support': 62}, {'label': 'sport', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9333333333333333, 'f1': 0.9655172413793104, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.95_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T15:45:29.939179', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.5139062404632568, 'features_extracted': 10000, 'reduction_time': 6.279380798339844, 'features_after_reduction': 716, 'metrics': {'accuracy': 0.7335329341317365, 'precision': 0.7723423468628201, 'recall': 0.7335329341317365, 'f1_score': 0.7267181744016658}, 'performance': {'train_time_seconds': 0.01076817512512207, 'total_time_seconds': 6.804055213928223, 'inference_time_ms_per_sample': 0.3502989957432547}, 'confusion_matrix': [[73, 0, 1, 2, 1], [11, 37, 0, 9, 1], [17, 1, 36, 7, 1], [0, 5, 2, 69, 1], [21, 8, 1, 0, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5983606557377049, 'recall': 0.948051948051948, 'f1': 0.7336683417085427, 'support': 77}, {'label': 'entertainment', 'precision': 0.7254901960784313, 'recall': 0.6379310344827587, 'f1': 0.6788990825688074, 'support': 58}, {'label': 'politics', 'precision': 0.9, 'recall': 0.5806451612903226, 'f1': 0.7058823529411765, 'support': 62}, {'label': 'sport', 'precision': 0.7931034482758621, 'recall': 0.8961038961038961, 'f1': 0.8414634146341463, 'support': 77}, {'label': 'tech', 'precision': 0.8823529411764706, 'recall': 0.5, 'f1': 0.6382978723404256, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T15:54:46.679512', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5482497215270996, 'features_extracted': 5000, 'reduction_time': 0.13704872131347656, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9687904435416547, 'recall': 0.9670658682634731, 'f1_score': 0.9672312816932294}, 'performance': {'train_time_seconds': 0.19587016105651855, 'total_time_seconds': 1.8811686038970947, 'inference_time_ms_per_sample': 0.09721838785502725}, 'confusion_matrix': [[76, 0, 0, 0, 1], [1, 56, 0, 1, 0], [4, 0, 58, 0, 0], [0, 0, 0, 77, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9047619047619048, 'recall': 0.987012987012987, 'f1': 0.9440993788819876, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9830508474576272, 'recall': 0.9354838709677419, 'f1': 0.9586776859504132, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.95_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:56:18.936556', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.7284619808197021, 'features_extracted': 5000, 'reduction_time': 3.267927408218384, 'features_after_reduction': 1105, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.9612414332797384, 'recall': 0.9610778443113772, 'f1_score': 0.9611380557136104}, 'performance': {'train_time_seconds': 0.3785841464996338, 'total_time_seconds': 5.37497353553772, 'inference_time_ms_per_sample': 0.1082812954565722}, 'confusion_matrix': [[75, 1, 1, 0, 0], [0, 55, 2, 0, 1], [2, 0, 58, 1, 1], [0, 2, 0, 75, 0], [0, 1, 1, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'entertainment', 'precision': 0.9322033898305084, 'recall': 0.9482758620689655, 'f1': 0.9401709401709402, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'tech', 'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1': 0.9666666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.9_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:58:13.427564', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.8975951671600342, 'features_extracted': 10000, 'reduction_time': 5.6216816902160645, 'features_after_reduction': 1020, 'metrics': {'accuracy': 0.9431137724550899, 'precision': 0.9447882827419284, 'recall': 0.9431137724550899, 'f1_score': 0.9428535872166877}, 'performance': {'train_time_seconds': 0.3719973564147949, 'total_time_seconds': 7.8912742137908936, 'inference_time_ms_per_sample': 0.11074257468035122}, 'confusion_matrix': [[74, 0, 3, 0, 0], [1, 50, 1, 5, 1], [3, 0, 58, 1, 0], [1, 0, 0, 76, 0], [1, 1, 0, 1, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.925, 'recall': 0.961038961038961, 'f1': 0.9426751592356688, 'support': 77}, {'label': 'entertainment', 'precision': 0.9803921568627451, 'recall': 0.8620689655172413, 'f1': 0.9174311926605505, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9156626506024096, 'recall': 0.987012987012987, 'f1': 0.95, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.9_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:58:21.381377', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.7755184173583984, 'features_extracted': 10000, 'reduction_time': 5.673251628875732, 'features_after_reduction': 1020, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.9642315162478743, 'recall': 0.9640718562874252, 'f1_score': 0.9640436596959722}, 'performance': {'train_time_seconds': 0.3574044704437256, 'total_time_seconds': 7.8061745166778564, 'inference_time_ms_per_sample': 0.10805072898636321}, 'confusion_matrix': [[74, 1, 2, 0, 0], [1, 55, 1, 0, 1], [1, 0, 59, 2, 0], [0, 0, 0, 77, 0], [0, 2, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9736842105263158, 'recall': 0.961038961038961, 'f1': 0.9673202614379085, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.95_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:55:55.893663', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.8173587322235107, 'features_extracted': 5000, 'reduction_time': 3.3366599082946777, 'features_after_reduction': 1105, 'metrics': {'accuracy': 0.5838323353293413, 'precision': 0.7509664107589522, 'recall': 0.5838323353293413, 'f1_score': 0.5335981583646355}, 'performance': {'train_time_seconds': 0.01983809471130371, 'total_time_seconds': 5.173856735229492, 'inference_time_ms_per_sample': 0.003130136135809436}, 'confusion_matrix': [[70, 0, 0, 7, 0], [24, 7, 0, 26, 1], [34, 0, 22, 6, 0], [1, 0, 0, 76, 0], [29, 1, 0, 10, 20]], 'per_class_metrics': [{'label': 'business', 'precision': 0.4430379746835443, 'recall': 0.9090909090909091, 'f1': 0.5957446808510638, 'support': 77}, {'label': 'entertainment', 'precision': 0.875, 'recall': 0.1206896551724138, 'f1': 0.21212121212121213, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.3548387096774194, 'f1': 0.5238095238095238, 'support': 62}, {'label': 'sport', 'precision': 0.608, 'recall': 0.987012987012987, 'f1': 0.7524752475247525, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 0.3333333333333333, 'f1': 0.49382716049382713, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.95_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:53:49.818181', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.4540681838989258, 'features_extracted': 10000, 'reduction_time': 5.786956071853638, 'features_after_reduction': 1191, 'metrics': {'accuracy': 0.9191616766467066, 'precision': 0.9216909685037854, 'recall': 0.9191616766467066, 'f1_score': 0.9198425371467157}, 'performance': {'train_time_seconds': 1.91404128074646, 'total_time_seconds': 8.155065536499023, 'inference_time_ms_per_sample': 0.003145126525513426}, 'confusion_matrix': [[72, 1, 3, 1, 0], [0, 53, 4, 0, 1], [4, 0, 54, 3, 1], [1, 0, 2, 74, 0], [0, 1, 4, 1, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.935064935064935, 'recall': 0.935064935064935, 'f1': 0.935064935064935, 'support': 77}, {'label': 'entertainment', 'precision': 0.9636363636363636, 'recall': 0.9137931034482759, 'f1': 0.9380530973451328, 'support': 58}, {'label': 'politics', 'precision': 0.8059701492537313, 'recall': 0.8709677419354839, 'f1': 0.8372093023255814, 'support': 62}, {'label': 'sport', 'precision': 0.9367088607594937, 'recall': 0.961038961038961, 'f1': 0.9487179487179487, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.9_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:43:45.082581', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.5133976936340332, 'features_extracted': 10000, 'reduction_time': 7.737345933914185, 'features_after_reduction': 446, 'metrics': {'accuracy': 0.6287425149700598, 'precision': 0.6329716048225517, 'recall': 0.6287425149700598, 'f1_score': 0.6287400406520003}, 'performance': {'train_time_seconds': 0.7689087390899658, 'total_time_seconds': 9.019652366638184, 'inference_time_ms_per_sample': 0.0018673742602685255}, 'confusion_matrix': [[53, 9, 6, 0, 9], [7, 30, 7, 10, 4], [15, 7, 34, 5, 1], [2, 8, 4, 60, 3], [5, 13, 3, 6, 33]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6463414634146342, 'recall': 0.6883116883116883, 'f1': 0.6666666666666666, 'support': 77}, {'label': 'entertainment', 'precision': 0.44776119402985076, 'recall': 0.5172413793103449, 'f1': 0.48, 'support': 58}, {'label': 'politics', 'precision': 0.6296296296296297, 'recall': 0.5483870967741935, 'f1': 0.5862068965517241, 'support': 62}, {'label': 'sport', 'precision': 0.7407407407407407, 'recall': 0.7792207792207793, 'f1': 0.759493670886076, 'support': 77}, {'label': 'tech', 'precision': 0.66, 'recall': 0.55, 'f1': 0.6, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.95_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:50:22.608830', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.5791239738464355, 'features_extracted': 10000, 'reduction_time': 5.682025194168091, 'features_after_reduction': 789, 'metrics': {'accuracy': 0.47005988023952094, 'precision': 0.4795296984648614, 'recall': 0.47005988023952094, 'f1_score': 0.46073287761474996}, 'performance': {'train_time_seconds': 0.013211965560913086, 'total_time_seconds': 7.2743611335754395, 'inference_time_ms_per_sample': 0.002634739447496608}, 'confusion_matrix': [[23, 21, 4, 15, 14], [5, 30, 1, 17, 5], [5, 11, 22, 15, 9], [0, 8, 12, 54, 3], [12, 13, 5, 2, 28]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5111111111111111, 'recall': 0.2987012987012987, 'f1': 0.3770491803278688, 'support': 77}, {'label': 'entertainment', 'precision': 0.3614457831325301, 'recall': 0.5172413793103449, 'f1': 0.425531914893617, 'support': 58}, {'label': 'politics', 'precision': 0.5, 'recall': 0.3548387096774194, 'f1': 0.41509433962264153, 'support': 62}, {'label': 'sport', 'precision': 0.5242718446601942, 'recall': 0.7012987012987013, 'f1': 0.6, 'support': 77}, {'label': 'tech', 'precision': 0.4745762711864407, 'recall': 0.4666666666666667, 'f1': 0.47058823529411764, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:57:06.176155', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.9354088306427002, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7811343773210655, 'recall': 0.7694610778443114, 'f1_score': 0.7718557041264855}, 'performance': {'train_time_seconds': 0.69461989402771, 'total_time_seconds': 2.63002872467041, 'inference_time_ms_per_sample': 0.003240065660305366}, 'confusion_matrix': [[57, 2, 8, 3, 7], [7, 43, 3, 5, 0], [17, 0, 41, 2, 2], [5, 2, 0, 69, 1], [9, 2, 2, 0, 47]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6, 'recall': 0.7402597402597403, 'f1': 0.6627906976744186, 'support': 77}, {'label': 'entertainment', 'precision': 0.8775510204081632, 'recall': 0.7413793103448276, 'f1': 0.8037383177570093, 'support': 58}, {'label': 'politics', 'precision': 0.7592592592592593, 'recall': 0.6612903225806451, 'f1': 0.7068965517241379, 'support': 62}, {'label': 'sport', 'precision': 0.8734177215189873, 'recall': 0.8961038961038961, 'f1': 0.8846153846153846, 'support': 77}, {'label': 'tech', 'precision': 0.8245614035087719, 'recall': 0.7833333333333333, 'f1': 0.8034188034188035, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T15:57:15.419698', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.8741118907928467, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9524141474184236, 'recall': 0.9520958083832335, 'f1_score': 0.9518580233666162}, 'performance': {'train_time_seconds': 0.00292205810546875, 'total_time_seconds': 1.8770339488983154, 'inference_time_ms_per_sample': 0.29339262111458236}, 'confusion_matrix': [[70, 1, 4, 1, 1], [1, 53, 1, 1, 2], [1, 0, 61, 0, 0], [1, 0, 0, 76, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.958904109589041, 'recall': 0.9090909090909091, 'f1': 0.9333333333333333, 'support': 77}, {'label': 'entertainment', 'precision': 0.9464285714285714, 'recall': 0.9137931034482759, 'f1': 0.9298245614035088, 'support': 58}, {'label': 'politics', 'precision': 0.9242424242424242, 'recall': 0.9838709677419355, 'f1': 0.953125, 'support': 62}, {'label': 'sport', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.9_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:43:08.939861', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.47957801818847656, 'features_extracted': 10000, 'reduction_time': 7.595116376876831, 'features_after_reduction': 446, 'metrics': {'accuracy': 0.4820359281437126, 'precision': 0.5012512777338658, 'recall': 0.4820359281437126, 'f1_score': 0.4761313633042694}, 'performance': {'train_time_seconds': 0.011024951934814453, 'total_time_seconds': 8.085719347000122, 'inference_time_ms_per_sample': 0.001836679652779402}, 'confusion_matrix': [[24, 9, 7, 20, 17], [4, 26, 4, 18, 6], [3, 5, 30, 14, 10], [3, 8, 12, 47, 7], [5, 3, 14, 4, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6153846153846154, 'recall': 0.3116883116883117, 'f1': 0.41379310344827586, 'support': 77}, {'label': 'entertainment', 'precision': 0.5098039215686274, 'recall': 0.4482758620689655, 'f1': 0.47706422018348627, 'support': 58}, {'label': 'politics', 'precision': 0.44776119402985076, 'recall': 0.4838709677419355, 'f1': 0.46511627906976744, 'support': 62}, {'label': 'sport', 'precision': 0.4563106796116505, 'recall': 0.6103896103896104, 'f1': 0.5222222222222223, 'support': 77}, {'label': 'tech', 'precision': 0.4594594594594595, 'recall': 0.5666666666666667, 'f1': 0.5074626865671642, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T15:51:57.852401', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.4518105983734131, 'features_extracted': 10000, 'reduction_time': 0.258486270904541, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8353293413173652, 'precision': 0.8601835863157405, 'recall': 0.8353293413173652, 'f1_score': 0.8373033595605403}, 'performance': {'train_time_seconds': 0.008976459503173828, 'total_time_seconds': 0.7192733287811279, 'inference_time_ms_per_sample': 0.09576075091333446}, 'confusion_matrix': [[68, 6, 2, 1, 0], [5, 51, 1, 1, 0], [10, 7, 45, 0, 0], [2, 1, 0, 73, 1], [11, 7, 0, 0, 42]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7083333333333334, 'recall': 0.8831168831168831, 'f1': 0.7861271676300579, 'support': 77}, {'label': 'entertainment', 'precision': 0.7083333333333334, 'recall': 0.8793103448275862, 'f1': 0.7846153846153846, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.7258064516129032, 'f1': 0.8181818181818182, 'support': 62}, {'label': 'sport', 'precision': 0.9733333333333334, 'recall': 0.948051948051948, 'f1': 0.9605263157894737, 'support': 77}, {'label': 'tech', 'precision': 0.9767441860465116, 'recall': 0.7, 'f1': 0.8155339805825242, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T15:48:53.346272', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5882134437561035, 'features_extracted': 10000, 'reduction_time': 0.2682075500488281, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.6976047904191617, 'precision': 0.7264321117560886, 'recall': 0.6976047904191617, 'f1_score': 0.6936704706528525}, 'performance': {'train_time_seconds': 0.007376909255981445, 'total_time_seconds': 1.863797903060913, 'inference_time_ms_per_sample': 0.33835879342998576}, 'confusion_matrix': [[65, 4, 1, 3, 4], [10, 40, 2, 5, 1], [14, 8, 37, 3, 0], [5, 6, 1, 64, 1], [20, 5, 6, 2, 27]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5701754385964912, 'recall': 0.8441558441558441, 'f1': 0.680628272251309, 'support': 77}, {'label': 'entertainment', 'precision': 0.6349206349206349, 'recall': 0.6896551724137931, 'f1': 0.6611570247933884, 'support': 58}, {'label': 'politics', 'precision': 0.7872340425531915, 'recall': 0.5967741935483871, 'f1': 0.6788990825688074, 'support': 62}, {'label': 'sport', 'precision': 0.8311688311688312, 'recall': 0.8311688311688312, 'f1': 0.8311688311688312, 'support': 77}, {'label': 'tech', 'precision': 0.8181818181818182, 'recall': 0.45, 'f1': 0.5806451612903226, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.95_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:56:13.177420', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.8359858989715576, 'features_extracted': 5000, 'reduction_time': 3.498627185821533, 'features_after_reduction': 1105, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.961667683613502, 'recall': 0.9610778443113772, 'f1_score': 0.9610764953349025}, 'performance': {'train_time_seconds': 0.35495495796203613, 'total_time_seconds': 5.689568042755127, 'inference_time_ms_per_sample': 0.13048134878010093}, 'confusion_matrix': [[72, 1, 4, 0, 0], [0, 55, 1, 2, 0], [1, 1, 59, 0, 1], [0, 0, 0, 77, 0], [0, 1, 0, 1, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9863013698630136, 'recall': 0.935064935064935, 'f1': 0.96, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.921875, 'recall': 0.9516129032258065, 'f1': 0.9365079365079365, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T15:43:08.089108', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.4697263240814209, 'features_extracted': 10000, 'reduction_time': 0.27086472511291504, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7485029940119761, 'precision': 0.7785201745968772, 'recall': 0.7485029940119761, 'f1_score': 0.7430762957129579}, 'performance': {'train_time_seconds': 0.007424831390380859, 'total_time_seconds': 0.7480158805847168, 'inference_time_ms_per_sample': 0.27484593991034045}, 'confusion_matrix': [[69, 1, 6, 1, 0], [3, 47, 0, 8, 0], [15, 2, 41, 3, 1], [4, 6, 1, 65, 1], [21, 3, 7, 1, 28]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6160714285714286, 'recall': 0.8961038961038961, 'f1': 0.7301587301587301, 'support': 77}, {'label': 'entertainment', 'precision': 0.7966101694915254, 'recall': 0.8103448275862069, 'f1': 0.8034188034188035, 'support': 58}, {'label': 'politics', 'precision': 0.7454545454545455, 'recall': 0.6612903225806451, 'f1': 0.7008547008547008, 'support': 62}, {'label': 'sport', 'precision': 0.8333333333333334, 'recall': 0.8441558441558441, 'f1': 0.8387096774193549, 'support': 77}, {'label': 'tech', 'precision': 0.9333333333333333, 'recall': 0.4666666666666667, 'f1': 0.6222222222222222, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T15:48:25.398630', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.612851858139038, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9431137724550899, 'precision': 0.9457408407115971, 'recall': 0.9431137724550899, 'f1_score': 0.9430828827706682}, 'performance': {'train_time_seconds': 0.20932459831237793, 'total_time_seconds': 1.822176456451416, 'inference_time_ms_per_sample': 0.10400760673477265}, 'confusion_matrix': [[74, 0, 2, 0, 1], [1, 52, 0, 4, 1], [4, 0, 56, 2, 0], [0, 0, 0, 77, 0], [4, 0, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.891566265060241, 'recall': 0.961038961038961, 'f1': 0.925, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.896551724137931, 'f1': 0.9454545454545454, 'support': 58}, {'label': 'politics', 'precision': 0.9655172413793104, 'recall': 0.9032258064516129, 'f1': 0.9333333333333333, 'support': 62}, {'label': 'sport', 'precision': 0.927710843373494, 'recall': 1.0, 'f1': 0.9625, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.9_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:58:02.472790', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.8017539978027344, 'features_extracted': 10000, 'reduction_time': 9.008931398391724, 'features_after_reduction': 1020, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9825088284968525, 'recall': 0.9820359281437125, 'f1_score': 0.9821213702034858}, 'performance': {'train_time_seconds': 0.11200618743896484, 'total_time_seconds': 10.922691583633423, 'inference_time_ms_per_sample': 0.00267685530428401}, 'confusion_matrix': [[74, 1, 2, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9866666666666667, 'recall': 0.961038961038961, 'f1': 0.9736842105263158, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9833333333333333, 'f1': 0.9915966386554622, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.9_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T15:53:03.899401', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.48438286781311035, 'features_extracted': 10000, 'reduction_time': 5.02301287651062, 'features_after_reduction': 1010, 'metrics': {'accuracy': 0.9311377245508982, 'precision': 0.9351784261964426, 'recall': 0.9311377245508982, 'f1_score': 0.9307895137318639}, 'performance': {'train_time_seconds': 0.015971660614013672, 'total_time_seconds': 5.523367404937744, 'inference_time_ms_per_sample': 0.3496986663270139}, 'confusion_matrix': [[67, 1, 8, 1, 0], [0, 49, 3, 4, 2], [1, 0, 60, 1, 0], [0, 0, 0, 77, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9852941176470589, 'recall': 0.8701298701298701, 'f1': 0.9241379310344827, 'support': 77}, {'label': 'entertainment', 'precision': 0.9423076923076923, 'recall': 0.8448275862068966, 'f1': 0.8909090909090909, 'support': 58}, {'label': 'politics', 'precision': 0.8450704225352113, 'recall': 0.967741935483871, 'f1': 0.9022556390977443, 'support': 62}, {'label': 'sport', 'precision': 0.927710843373494, 'recall': 1.0, 'f1': 0.9625, 'support': 77}, {'label': 'tech', 'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1': 0.9666666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.95_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T15:56:43.801569', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.796299934387207, 'features_extracted': 5000, 'reduction_time': 3.4128174781799316, 'features_after_reduction': 1105, 'metrics': {'accuracy': 0.9311377245508982, 'precision': 0.9327311763028565, 'recall': 0.9311377245508982, 'f1_score': 0.9310347206486259}, 'performance': {'train_time_seconds': 0.018602848052978516, 'total_time_seconds': 5.227720260620117, 'inference_time_ms_per_sample': 0.33627798457345565}, 'confusion_matrix': [[68, 1, 7, 1, 0], [1, 51, 2, 1, 3], [1, 1, 59, 0, 1], [1, 0, 0, 75, 1], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9444444444444444, 'recall': 0.8831168831168831, 'f1': 0.912751677852349, 'support': 77}, {'label': 'entertainment', 'precision': 0.9444444444444444, 'recall': 0.8793103448275862, 'f1': 0.9107142857142857, 'support': 58}, {'label': 'politics', 'precision': 0.8676470588235294, 'recall': 0.9516129032258065, 'f1': 0.9076923076923077, 'support': 62}, {'label': 'sport', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'tech', 'precision': 0.9206349206349206, 'recall': 0.9666666666666667, 'f1': 0.943089430894309, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.95_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T15:45:22.758254', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.5144863128662109, 'features_extracted': 10000, 'reduction_time': 6.511039972305298, 'features_after_reduction': 716, 'metrics': {'accuracy': 0.7455089820359282, 'precision': 0.7842066710172906, 'recall': 0.7455089820359282, 'f1_score': 0.7416523367685295}, 'performance': {'train_time_seconds': 0.012549877166748047, 'total_time_seconds': 7.038076162338257, 'inference_time_ms_per_sample': 0.35068374907899047}, 'confusion_matrix': [[72, 0, 4, 1, 0], [11, 39, 0, 8, 0], [17, 2, 37, 6, 0], [1, 5, 2, 68, 1], [18, 4, 2, 3, 33]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6050420168067226, 'recall': 0.935064935064935, 'f1': 0.7346938775510204, 'support': 77}, {'label': 'entertainment', 'precision': 0.78, 'recall': 0.6724137931034483, 'f1': 0.7222222222222222, 'support': 58}, {'label': 'politics', 'precision': 0.8222222222222222, 'recall': 0.5967741935483871, 'f1': 0.6915887850467289, 'support': 62}, {'label': 'sport', 'precision': 0.7906976744186046, 'recall': 0.8831168831168831, 'f1': 0.8343558282208589, 'support': 77}, {'label': 'tech', 'precision': 0.9705882352941176, 'recall': 0.55, 'f1': 0.7021276595744681, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T15:57:26.541491', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.9262056350708008, 'features_extracted': 10000, 'reduction_time': 0.2867307662963867, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9589054940965527, 'recall': 0.9580838323353293, 'f1_score': 0.9581549288074961}, 'performance': {'train_time_seconds': 0.20217680931091309, 'total_time_seconds': 2.4151132106781006, 'inference_time_ms_per_sample': 0.09830983099109399}, 'confusion_matrix': [[73, 0, 1, 1, 2], [1, 55, 1, 1, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [3, 0, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9125, 'recall': 0.948051948051948, 'f1': 0.9299363057324841, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1': 0.9508196721311475, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:56:54.532589', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.806915521621704, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9850299401197605, 'precision': 0.9852017576568474, 'recall': 0.9850299401197605, 'f1_score': 0.985042316047023}, 'performance': {'train_time_seconds': 0.20583105087280273, 'total_time_seconds': 2.012746572494507, 'inference_time_ms_per_sample': 0.016128231665331446}, 'confusion_matrix': [[76, 0, 1, 0, 0], [0, 56, 1, 0, 1], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.95_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T15:48:01.559797', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.5479397773742676, 'features_extracted': 5000, 'reduction_time': 4.236288070678711, 'features_after_reduction': 673, 'metrics': {'accuracy': 0.7485029940119761, 'precision': 0.7777277612606954, 'recall': 0.7485029940119761, 'f1_score': 0.7451386028110477}, 'performance': {'train_time_seconds': 0.009861469268798828, 'total_time_seconds': 5.794089317321777, 'inference_time_ms_per_sample': 0.36552280722977876}, 'confusion_matrix': [[70, 1, 1, 1, 4], [8, 41, 0, 8, 1], [13, 11, 36, 2, 0], [1, 6, 0, 69, 1], [16, 7, 2, 1, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6481481481481481, 'recall': 0.9090909090909091, 'f1': 0.7567567567567568, 'support': 77}, {'label': 'entertainment', 'precision': 0.6212121212121212, 'recall': 0.7068965517241379, 'f1': 0.6612903225806451, 'support': 58}, {'label': 'politics', 'precision': 0.9230769230769231, 'recall': 0.5806451612903226, 'f1': 0.7128712871287128, 'support': 62}, {'label': 'sport', 'precision': 0.8518518518518519, 'recall': 0.8961038961038961, 'f1': 0.8734177215189873, 'support': 77}, {'label': 'tech', 'precision': 0.85, 'recall': 0.5666666666666667, 'f1': 0.68, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T15:46:08.561273', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5781583786010742, 'features_extracted': 5000, 'reduction_time': 0.1433408260345459, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9681862206267825, 'recall': 0.9670658682634731, 'f1_score': 0.9672450988329659}, 'performance': {'train_time_seconds': 0.1998891830444336, 'total_time_seconds': 1.9213883876800537, 'inference_time_ms_per_sample': 0.09931989772591049}, 'confusion_matrix': [[75, 0, 1, 0, 1], [1, 56, 0, 1, 0], [2, 0, 60, 0, 0], [1, 0, 0, 76, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9146341463414634, 'recall': 0.974025974025974, 'f1': 0.9433962264150944, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.967741935483871, 'recall': 0.967741935483871, 'f1': 0.967741935483871, 'support': 62}, {'label': 'sport', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.9_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:52:12.523003', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5507762432098389, 'features_extracted': 10000, 'reduction_time': 6.314891338348389, 'features_after_reduction': 1010, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.979473277976272, 'recall': 0.9790419161676647, 'f1_score': 0.9790700186944252}, 'performance': {'train_time_seconds': 0.11931324005126953, 'total_time_seconds': 6.984980821609497, 'inference_time_ms_per_sample': 0.0027725082671570924}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.9_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:54:57.400648', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.5345213413238525, 'features_extracted': 5000, 'reduction_time': 4.703793048858643, 'features_after_reduction': 906, 'metrics': {'accuracy': 0.5718562874251497, 'precision': 0.7386805593881361, 'recall': 0.5718562874251497, 'f1_score': 0.5212883461379878}, 'performance': {'train_time_seconds': 0.037291526794433594, 'total_time_seconds': 6.275605916976929, 'inference_time_ms_per_sample': 0.0027389583473433994}, 'confusion_matrix': [[69, 0, 0, 8, 0], [25, 7, 0, 25, 1], [36, 0, 20, 6, 0], [1, 0, 1, 75, 0], [29, 1, 0, 10, 20]], 'per_class_metrics': [{'label': 'business', 'precision': 0.43125, 'recall': 0.8961038961038961, 'f1': 0.5822784810126582, 'support': 77}, {'label': 'entertainment', 'precision': 0.875, 'recall': 0.1206896551724138, 'f1': 0.21212121212121213, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.3225806451612903, 'f1': 0.4819277108433735, 'support': 62}, {'label': 'sport', 'precision': 0.6048387096774194, 'recall': 0.974025974025974, 'f1': 0.746268656716418, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 0.3333333333333333, 'f1': 0.49382716049382713, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:48:40.493240', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.594367265701294, 'features_extracted': 10000, 'reduction_time': 0.27124857902526855, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582480715261207, 'recall': 0.9580838323353293, 'f1_score': 0.9579495451843525}, 'performance': {'train_time_seconds': 0.5994288921356201, 'total_time_seconds': 2.4650447368621826, 'inference_time_ms_per_sample': 0.006238143601103457}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:51:51.534683', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.4602639675140381, 'features_extracted': 10000, 'reduction_time': 0.2644164562225342, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9791281994948433, 'recall': 0.9790419161676647, 'f1_score': 0.9790099071105288}, 'performance': {'train_time_seconds': 0.009838104248046875, 'total_time_seconds': 0.7345185279846191, 'inference_time_ms_per_sample': 0.002704694599448564}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 55, 2, 0, 1], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9672131147540983, 'recall': 0.9833333333333333, 'f1': 0.9752066115702479, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T15:43:03.537137', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.4814736843109131, 'features_extracted': 10000, 'reduction_time': 0.27402591705322266, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9597344991009152, 'recall': 0.9580838323353293, 'f1_score': 0.9582684020473764}, 'performance': {'train_time_seconds': 0.19667410850524902, 'total_time_seconds': 0.9521737098693848, 'inference_time_ms_per_sample': 0.09942768576616298}, 'confusion_matrix': [[75, 0, 1, 0, 1], [1, 54, 1, 2, 0], [3, 0, 59, 0, 0], [1, 0, 0, 76, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9036144578313253, 'recall': 0.974025974025974, 'f1': 0.9375, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9310344827586207, 'f1': 0.9642857142857143, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.9_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T15:55:50.614148', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.8161439895629883, 'features_extracted': 5000, 'reduction_time': 3.3142130374908447, 'features_after_reduction': 906, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.949961269979227, 'recall': 0.9491017964071856, 'f1_score': 0.9490092739012216}, 'performance': {'train_time_seconds': 0.015497207641601562, 'total_time_seconds': 5.145854234695435, 'inference_time_ms_per_sample': 0.34668916713691755}, 'confusion_matrix': [[69, 1, 6, 1, 0], [1, 54, 1, 1, 1], [1, 0, 60, 0, 1], [1, 0, 0, 76, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9583333333333334, 'recall': 0.8961038961038961, 'f1': 0.9261744966442953, 'support': 77}, {'label': 'entertainment', 'precision': 0.9473684210526315, 'recall': 0.9310344827586207, 'f1': 0.9391304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.8955223880597015, 'recall': 0.967741935483871, 'f1': 0.9302325581395349, 'support': 62}, {'label': 'sport', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'tech', 'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1': 0.9666666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:51:42.742506', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.4852914810180664, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9770319500858422, 'recall': 0.9760479041916168, 'f1_score': 0.9760204036130006}, 'performance': {'train_time_seconds': 0.19587087631225586, 'total_time_seconds': 0.6811623573303223, 'inference_time_ms_per_sample': 0.014295834981038898}, 'confusion_matrix': [[76, 0, 1, 0, 0], [1, 53, 3, 0, 1], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9137931034482759, 'f1': 0.954954954954955, 'support': 58}, {'label': 'politics', 'precision': 0.9242424242424242, 'recall': 0.9838709677419355, 'f1': 0.953125, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.9_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T15:52:57.437310', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.46520400047302246, 'features_extracted': 10000, 'reduction_time': 5.84168004989624, 'features_after_reduction': 1010, 'metrics': {'accuracy': 0.9341317365269461, 'precision': 0.9403307392104426, 'recall': 0.9341317365269461, 'f1_score': 0.9336362287068068}, 'performance': {'train_time_seconds': 0.016143083572387695, 'total_time_seconds': 6.32302713394165, 'inference_time_ms_per_sample': 0.3489755584808167}, 'confusion_matrix': [[65, 1, 10, 1, 0], [2, 49, 3, 1, 3], [0, 0, 62, 0, 0], [0, 0, 0, 76, 1], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9701492537313433, 'recall': 0.8441558441558441, 'f1': 0.9027777777777778, 'support': 77}, {'label': 'entertainment', 'precision': 0.98, 'recall': 0.8448275862068966, 'f1': 0.9074074074074074, 'support': 58}, {'label': 'politics', 'precision': 0.8266666666666667, 'recall': 1.0, 'f1': 0.9051094890510949, 'support': 62}, {'label': 'sport', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'tech', 'precision': 0.9375, 'recall': 1.0, 'f1': 0.967741935483871, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T15:45:56.770098', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.5537171363830566, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7395209580838323, 'precision': 0.7682079396085618, 'recall': 0.7395209580838323, 'f1_score': 0.7351170016814543}, 'performance': {'train_time_seconds': 0.0030584335327148438, 'total_time_seconds': 1.5567755699157715, 'inference_time_ms_per_sample': 0.42332146695987904}, 'confusion_matrix': [[68, 1, 1, 2, 5], [9, 40, 0, 8, 1], [13, 9, 34, 5, 1], [1, 5, 0, 70, 1], [17, 6, 1, 1, 35]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6296296296296297, 'recall': 0.8831168831168831, 'f1': 0.7351351351351352, 'support': 77}, {'label': 'entertainment', 'precision': 0.6557377049180327, 'recall': 0.6896551724137931, 'f1': 0.6722689075630253, 'support': 58}, {'label': 'politics', 'precision': 0.9444444444444444, 'recall': 0.5483870967741935, 'f1': 0.6938775510204082, 'support': 62}, {'label': 'sport', 'precision': 0.813953488372093, 'recall': 0.9090909090909091, 'f1': 0.8588957055214724, 'support': 77}, {'label': 'tech', 'precision': 0.813953488372093, 'recall': 0.5833333333333334, 'f1': 0.6796116504854369, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:48:29.099805', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.5588629245758057, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7395209580838323, 'precision': 0.7505434711606478, 'recall': 0.7395209580838323, 'f1_score': 0.7393322511368852}, 'performance': {'train_time_seconds': 0.4261479377746582, 'total_time_seconds': 1.9850108623504639, 'inference_time_ms_per_sample': 0.0027453828000736807}, 'confusion_matrix': [[59, 1, 6, 5, 6], [8, 37, 5, 8, 0], [15, 1, 40, 3, 3], [5, 4, 0, 67, 1], [9, 2, 2, 3, 44]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6145833333333334, 'recall': 0.7662337662337663, 'f1': 0.6820809248554913, 'support': 77}, {'label': 'entertainment', 'precision': 0.8222222222222222, 'recall': 0.6379310344827587, 'f1': 0.7184466019417476, 'support': 58}, {'label': 'politics', 'precision': 0.7547169811320755, 'recall': 0.6451612903225806, 'f1': 0.6956521739130435, 'support': 62}, {'label': 'sport', 'precision': 0.7790697674418605, 'recall': 0.8701298701298701, 'f1': 0.8220858895705522, 'support': 77}, {'label': 'tech', 'precision': 0.8148148148148148, 'recall': 0.7333333333333333, 'f1': 0.7719298245614035, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:51:47.553992', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.5132973194122314, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.781437125748503, 'precision': 0.793885561246416, 'recall': 0.781437125748503, 'f1_score': 0.7825399223164933}, 'performance': {'train_time_seconds': 0.49163389205932617, 'total_time_seconds': 1.0049312114715576, 'inference_time_ms_per_sample': 0.0027589455336153863}, 'confusion_matrix': [[60, 1, 7, 4, 5], [6, 40, 4, 8, 0], [13, 0, 44, 2, 3], [4, 1, 1, 69, 2], [10, 1, 1, 0, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6451612903225806, 'recall': 0.7792207792207793, 'f1': 0.7058823529411765, 'support': 77}, {'label': 'entertainment', 'precision': 0.9302325581395349, 'recall': 0.6896551724137931, 'f1': 0.7920792079207921, 'support': 58}, {'label': 'politics', 'precision': 0.7719298245614035, 'recall': 0.7096774193548387, 'f1': 0.7394957983193278, 'support': 62}, {'label': 'sport', 'precision': 0.8313253012048193, 'recall': 0.8961038961038961, 'f1': 0.8625, 'support': 77}, {'label': 'tech', 'precision': 0.8275862068965517, 'recall': 0.8, 'f1': 0.8135593220338984, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:51:44.682039', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5302519798278809, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.979473277976272, 'recall': 0.9790419161676647, 'f1_score': 0.9790700186944252}, 'performance': {'train_time_seconds': 0.7751121520996094, 'total_time_seconds': 1.3053641319274902, 'inference_time_ms_per_sample': 0.00489614680855574}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.9_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T15:47:06.316205', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.629096269607544, 'features_extracted': 5000, 'reduction_time': 3.9405698776245117, 'features_after_reduction': 420, 'metrics': {'accuracy': 0.7425149700598802, 'precision': 0.7704121072237, 'recall': 0.7425149700598802, 'f1_score': 0.7389130801377276}, 'performance': {'train_time_seconds': 0.005167961120605469, 'total_time_seconds': 5.574834108352661, 'inference_time_ms_per_sample': 0.36795196418990633}, 'confusion_matrix': [[69, 2, 1, 1, 4], [9, 44, 0, 5, 0], [13, 10, 34, 2, 3], [2, 6, 1, 67, 1], [16, 6, 2, 2, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6330275229357798, 'recall': 0.8961038961038961, 'f1': 0.7419354838709677, 'support': 77}, {'label': 'entertainment', 'precision': 0.6470588235294118, 'recall': 0.7586206896551724, 'f1': 0.6984126984126984, 'support': 58}, {'label': 'politics', 'precision': 0.8947368421052632, 'recall': 0.5483870967741935, 'f1': 0.68, 'support': 62}, {'label': 'sport', 'precision': 0.8701298701298701, 'recall': 0.8701298701298701, 'f1': 0.8701298701298701, 'support': 77}, {'label': 'tech', 'precision': 0.8095238095238095, 'recall': 0.5666666666666667, 'f1': 0.6666666666666666, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.9_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T15:58:47.670480', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.8372817039489746, 'features_extracted': 10000, 'reduction_time': 5.213464975357056, 'features_after_reduction': 1020, 'metrics': {'accuracy': 0.9221556886227545, 'precision': 0.9245571793010099, 'recall': 0.9221556886227545, 'f1_score': 0.9216693882045771}, 'performance': {'train_time_seconds': 0.01337122917175293, 'total_time_seconds': 7.064117908477783, 'inference_time_ms_per_sample': 0.28809958589291146}, 'confusion_matrix': [[65, 1, 8, 3, 0], [1, 50, 3, 1, 3], [1, 2, 59, 0, 0], [1, 0, 0, 75, 1], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9420289855072463, 'recall': 0.8441558441558441, 'f1': 0.8904109589041096, 'support': 77}, {'label': 'entertainment', 'precision': 0.9433962264150944, 'recall': 0.8620689655172413, 'f1': 0.9009009009009009, 'support': 58}, {'label': 'politics', 'precision': 0.8428571428571429, 'recall': 0.9516129032258065, 'f1': 0.8939393939393939, 'support': 62}, {'label': 'sport', 'precision': 0.9493670886075949, 'recall': 0.974025974025974, 'f1': 0.9615384615384616, 'support': 77}, {'label': 'tech', 'precision': 0.9365079365079365, 'recall': 0.9833333333333333, 'f1': 0.959349593495935, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.95_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:44:37.738499', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5562911033630371, 'features_extracted': 10000, 'reduction_time': 5.741917848587036, 'features_after_reduction': 716, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9550762995951328, 'recall': 0.9550898203592815, 'f1_score': 0.9549641472242703}, 'performance': {'train_time_seconds': 0.12614750862121582, 'total_time_seconds': 6.424356460571289, 'inference_time_ms_per_sample': 0.0023606294643379257}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 56, 1, 0, 0], [2, 0, 57, 2, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.935064935064935, 'recall': 0.935064935064935, 'f1': 0.935064935064935, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9344262295081968, 'recall': 0.9193548387096774, 'f1': 0.926829268292683, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.95_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:44:50.969291', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5440576076507568, 'features_extracted': 10000, 'reduction_time': 8.725452423095703, 'features_after_reduction': 716, 'metrics': {'accuracy': 0.8323353293413174, 'precision': 0.8529139361260383, 'recall': 0.8323353293413174, 'f1_score': 0.8297560785015341}, 'performance': {'train_time_seconds': 0.34883856773376465, 'total_time_seconds': 9.618348598480225, 'inference_time_ms_per_sample': 0.10294186140962704}, 'confusion_matrix': [[71, 1, 2, 2, 1], [5, 36, 1, 15, 1], [7, 1, 45, 9, 0], [1, 1, 0, 75, 0], [6, 1, 0, 2, 51]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7888888888888889, 'recall': 0.922077922077922, 'f1': 0.8502994011976048, 'support': 77}, {'label': 'entertainment', 'precision': 0.9, 'recall': 0.6206896551724138, 'f1': 0.7346938775510204, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.7258064516129032, 'f1': 0.8181818181818182, 'support': 62}, {'label': 'sport', 'precision': 0.7281553398058253, 'recall': 0.974025974025974, 'f1': 0.8333333333333334, 'support': 77}, {'label': 'tech', 'precision': 0.9622641509433962, 'recall': 0.85, 'f1': 0.9026548672566371, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.95_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:51:01.863760', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.569791555404663, 'features_extracted': 10000, 'reduction_time': 5.686948537826538, 'features_after_reduction': 789, 'metrics': {'accuracy': 0.6437125748502994, 'precision': 0.6454661510312708, 'recall': 0.6437125748502994, 'f1_score': 0.6418844737701822}, 'performance': {'train_time_seconds': 1.2568340301513672, 'total_time_seconds': 8.513574123382568, 'inference_time_ms_per_sample': 0.0021721788509163316}, 'confusion_matrix': [[51, 12, 4, 4, 6], [6, 29, 5, 14, 4], [8, 7, 34, 6, 7], [1, 5, 5, 65, 1], [9, 11, 3, 1, 36]], 'per_class_metrics': [{'label': 'business', 'precision': 0.68, 'recall': 0.6623376623376623, 'f1': 0.6710526315789473, 'support': 77}, {'label': 'entertainment', 'precision': 0.453125, 'recall': 0.5, 'f1': 0.47540983606557374, 'support': 58}, {'label': 'politics', 'precision': 0.6666666666666666, 'recall': 0.5483870967741935, 'f1': 0.6017699115044248, 'support': 62}, {'label': 'sport', 'precision': 0.7222222222222222, 'recall': 0.8441558441558441, 'f1': 0.7784431137724551, 'support': 77}, {'label': 'tech', 'precision': 0.6666666666666666, 'recall': 0.6, 'f1': 0.631578947368421, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.9_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:52:05.660382', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5032947063446045, 'features_extracted': 10000, 'reduction_time': 6.228400230407715, 'features_after_reduction': 1010, 'metrics': {'accuracy': 0.9940119760479041, 'precision': 0.9940503608168278, 'recall': 0.9940119760479041, 'f1_score': 0.9940086167076787}, 'performance': {'train_time_seconds': 0.0999903678894043, 'total_time_seconds': 6.831685304641724, 'inference_time_ms_per_sample': 0.0032893197979041917}, 'confusion_matrix': [[77, 0, 0, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9838709677419355, 'recall': 0.9838709677419355, 'f1': 0.9838709677419355, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:51:48.567890', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.48578643798828125, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7844311377245509, 'precision': 0.7859271045770384, 'recall': 0.7844311377245509, 'f1_score': 0.7841903691397354}, 'performance': {'train_time_seconds': 0.7401173114776611, 'total_time_seconds': 1.2259037494659424, 'inference_time_ms_per_sample': 0.0026154660893057636}, 'confusion_matrix': [[51, 4, 13, 3, 6], [5, 43, 5, 4, 1], [11, 0, 48, 0, 3], [1, 3, 1, 70, 2], [4, 3, 3, 0, 50]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7083333333333334, 'recall': 0.6623376623376623, 'f1': 0.6845637583892618, 'support': 77}, {'label': 'entertainment', 'precision': 0.8113207547169812, 'recall': 0.7413793103448276, 'f1': 0.7747747747747747, 'support': 58}, {'label': 'politics', 'precision': 0.6857142857142857, 'recall': 0.7741935483870968, 'f1': 0.7272727272727273, 'support': 62}, {'label': 'sport', 'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'support': 77}, {'label': 'tech', 'precision': 0.8064516129032258, 'recall': 0.8333333333333334, 'f1': 0.819672131147541, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:43:04.533366', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.4862980842590332, 'features_extracted': 10000, 'reduction_time': 0.27539753913879395, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7874251497005988, 'precision': 0.8054931066118158, 'recall': 0.7874251497005988, 'f1_score': 0.7878794541038044}, 'performance': {'train_time_seconds': 0.09162378311157227, 'total_time_seconds': 0.8533194065093994, 'inference_time_ms_per_sample': 0.00295025145936155}, 'confusion_matrix': [[64, 1, 5, 4, 3], [7, 40, 3, 7, 1], [17, 1, 40, 2, 2], [5, 1, 0, 71, 0], [8, 1, 1, 2, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6336633663366337, 'recall': 0.8311688311688312, 'f1': 0.7191011235955056, 'support': 77}, {'label': 'entertainment', 'precision': 0.9090909090909091, 'recall': 0.6896551724137931, 'f1': 0.7843137254901961, 'support': 58}, {'label': 'politics', 'precision': 0.8163265306122449, 'recall': 0.6451612903225806, 'f1': 0.7207207207207207, 'support': 62}, {'label': 'sport', 'precision': 0.8255813953488372, 'recall': 0.922077922077922, 'f1': 0.8711656441717791, 'support': 77}, {'label': 'tech', 'precision': 0.8888888888888888, 'recall': 0.8, 'f1': 0.8421052631578947, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.9_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T15:47:00.025913', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.6518433094024658, 'features_extracted': 5000, 'reduction_time': 4.492097616195679, 'features_after_reduction': 420, 'metrics': {'accuracy': 0.7634730538922155, 'precision': 0.7990535899314526, 'recall': 0.7634730538922155, 'f1_score': 0.7624889535614608}, 'performance': {'train_time_seconds': 0.007596015930175781, 'total_time_seconds': 6.15153694152832, 'inference_time_ms_per_sample': 0.35949381525644997}, 'confusion_matrix': [[71, 2, 1, 1, 2], [10, 42, 0, 6, 0], [9, 14, 36, 2, 1], [1, 5, 1, 69, 1], [15, 8, 0, 0, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6698113207547169, 'recall': 0.922077922077922, 'f1': 0.7759562841530054, 'support': 77}, {'label': 'entertainment', 'precision': 0.5915492957746479, 'recall': 0.7241379310344828, 'f1': 0.6511627906976745, 'support': 58}, {'label': 'politics', 'precision': 0.9473684210526315, 'recall': 0.5806451612903226, 'f1': 0.72, 'support': 62}, {'label': 'sport', 'precision': 0.8846153846153846, 'recall': 0.8961038961038961, 'f1': 0.8903225806451613, 'support': 77}, {'label': 'tech', 'precision': 0.9024390243902439, 'recall': 0.6166666666666667, 'f1': 0.7326732673267327, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T15:54:52.229937', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.513188123703003, 'features_extracted': 5000, 'reduction_time': 0.13334274291992188, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8862275449101796, 'precision': 0.893452275147433, 'recall': 0.8862275449101796, 'f1_score': 0.8859488148344287}, 'performance': {'train_time_seconds': 0.01088714599609375, 'total_time_seconds': 1.6574180126190186, 'inference_time_ms_per_sample': 0.09690644498356801}, 'confusion_matrix': [[70, 2, 2, 2, 1], [4, 52, 1, 1, 0], [4, 1, 56, 1, 0], [0, 2, 0, 74, 1], [10, 6, 0, 0, 44]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7954545454545454, 'recall': 0.9090909090909091, 'f1': 0.8484848484848485, 'support': 77}, {'label': 'entertainment', 'precision': 0.8253968253968254, 'recall': 0.896551724137931, 'f1': 0.859504132231405, 'support': 58}, {'label': 'politics', 'precision': 0.9491525423728814, 'recall': 0.9032258064516129, 'f1': 0.9256198347107438, 'support': 62}, {'label': 'sport', 'precision': 0.9487179487179487, 'recall': 0.961038961038961, 'f1': 0.9548387096774194, 'support': 77}, {'label': 'tech', 'precision': 0.9565217391304348, 'recall': 0.7333333333333333, 'f1': 0.8301886792452831, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.95_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:44:44.199282', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5585699081420898, 'features_extracted': 10000, 'reduction_time': 5.819912433624268, 'features_after_reduction': 716, 'metrics': {'accuracy': 0.8383233532934131, 'precision': 0.863258476512248, 'recall': 0.8383233532934131, 'f1_score': 0.8344623606609557}, 'performance': {'train_time_seconds': 0.3347442150115967, 'total_time_seconds': 6.713226556777954, 'inference_time_ms_per_sample': 0.10437094522807412}, 'confusion_matrix': [[75, 0, 1, 1, 0], [7, 37, 0, 14, 0], [7, 0, 44, 10, 1], [0, 0, 0, 77, 0], [7, 2, 3, 1, 47]], 'per_class_metrics': [{'label': 'business', 'precision': 0.78125, 'recall': 0.974025974025974, 'f1': 0.8670520231213873, 'support': 77}, {'label': 'entertainment', 'precision': 0.9487179487179487, 'recall': 0.6379310344827587, 'f1': 0.7628865979381443, 'support': 58}, {'label': 'politics', 'precision': 0.9166666666666666, 'recall': 0.7096774193548387, 'f1': 0.8, 'support': 62}, {'label': 'sport', 'precision': 0.7475728155339806, 'recall': 1.0, 'f1': 0.8555555555555555, 'support': 77}, {'label': 'tech', 'precision': 0.9791666666666666, 'recall': 0.7833333333333333, 'f1': 0.8703703703703703, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T15:57:33.471774', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.8906927108764648, 'features_extracted': 10000, 'reduction_time': 0.2924773693084717, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8473053892215568, 'precision': 0.8705461627049951, 'recall': 0.8473053892215568, 'f1_score': 0.8507001984865352}, 'performance': {'train_time_seconds': 0.009505748748779297, 'total_time_seconds': 2.192675828933716, 'inference_time_ms_per_sample': 0.09902151758799296}, 'confusion_matrix': [[71, 0, 2, 3, 1], [10, 46, 1, 1, 0], [9, 1, 52, 0, 0], [5, 1, 0, 70, 1], [11, 5, 0, 0, 44]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6698113207547169, 'recall': 0.922077922077922, 'f1': 0.7759562841530054, 'support': 77}, {'label': 'entertainment', 'precision': 0.8679245283018868, 'recall': 0.7931034482758621, 'f1': 0.8288288288288288, 'support': 58}, {'label': 'politics', 'precision': 0.9454545454545454, 'recall': 0.8387096774193549, 'f1': 0.8888888888888888, 'support': 62}, {'label': 'sport', 'precision': 0.9459459459459459, 'recall': 0.9090909090909091, 'f1': 0.9271523178807947, 'support': 77}, {'label': 'tech', 'precision': 0.9565217391304348, 'recall': 0.7333333333333333, 'f1': 0.8301886792452831, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:56:59.216533', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.8071157932281494, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9825088284968525, 'recall': 0.9820359281437125, 'f1_score': 0.9821213702034858}, 'performance': {'train_time_seconds': 0.8470609188079834, 'total_time_seconds': 2.654176712036133, 'inference_time_ms_per_sample': 0.0042958173923149795}, 'confusion_matrix': [[74, 1, 2, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9866666666666667, 'recall': 0.961038961038961, 'f1': 0.9736842105263158, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9833333333333333, 'f1': 0.9915966386554622, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.9_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:49:23.621161', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6221239566802979, 'features_extracted': 10000, 'reduction_time': 5.660853147506714, 'features_after_reduction': 515, 'metrics': {'accuracy': 0.8323353293413174, 'precision': 0.851656381366485, 'recall': 0.8323353293413174, 'f1_score': 0.8300175566407416}, 'performance': {'train_time_seconds': 0.32017087936401367, 'total_time_seconds': 7.603147983551025, 'inference_time_ms_per_sample': 0.10041205469005836}, 'confusion_matrix': [[73, 0, 4, 0, 0], [8, 39, 1, 10, 0], [8, 1, 46, 6, 1], [1, 1, 0, 75, 0], [10, 2, 1, 2, 45]], 'per_class_metrics': [{'label': 'business', 'precision': 0.73, 'recall': 0.948051948051948, 'f1': 0.8248587570621468, 'support': 77}, {'label': 'entertainment', 'precision': 0.9069767441860465, 'recall': 0.6724137931034483, 'f1': 0.7722772277227723, 'support': 58}, {'label': 'politics', 'precision': 0.8846153846153846, 'recall': 0.7419354838709677, 'f1': 0.8070175438596491, 'support': 62}, {'label': 'sport', 'precision': 0.8064516129032258, 'recall': 0.974025974025974, 'f1': 0.8823529411764706, 'support': 77}, {'label': 'tech', 'precision': 0.9782608695652174, 'recall': 0.75, 'f1': 0.8490566037735849, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T15:48:36.867273', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.6128571033477783, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7215568862275449, 'precision': 0.7716045760267021, 'recall': 0.7215568862275449, 'f1_score': 0.7185402591667486}, 'performance': {'train_time_seconds': 0.002665281295776367, 'total_time_seconds': 1.6155223846435547, 'inference_time_ms_per_sample': 0.43740672265698094}, 'confusion_matrix': [[69, 0, 1, 3, 4], [11, 38, 0, 9, 0], [19, 4, 32, 7, 0], [3, 4, 0, 68, 2], [21, 5, 0, 0, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5609756097560976, 'recall': 0.8961038961038961, 'f1': 0.69, 'support': 77}, {'label': 'entertainment', 'precision': 0.7450980392156863, 'recall': 0.6551724137931034, 'f1': 0.6972477064220184, 'support': 58}, {'label': 'politics', 'precision': 0.9696969696969697, 'recall': 0.5161290322580645, 'f1': 0.6736842105263158, 'support': 62}, {'label': 'sport', 'precision': 0.7816091954022989, 'recall': 0.8831168831168831, 'f1': 0.8292682926829268, 'support': 77}, {'label': 'tech', 'precision': 0.85, 'recall': 0.5666666666666667, 'f1': 0.68, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T15:43:06.318423', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.5036706924438477, 'features_extracted': 10000, 'reduction_time': 0.2740757465362549, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7005988023952096, 'precision': 0.7386074223726348, 'recall': 0.7005988023952096, 'f1_score': 0.6979053547915822}, 'performance': {'train_time_seconds': 0.007694721221923828, 'total_time_seconds': 0.7854411602020264, 'inference_time_ms_per_sample': 0.2995101277699727}, 'confusion_matrix': [[66, 5, 2, 2, 2], [12, 38, 1, 7, 0], [13, 6, 39, 3, 1], [4, 8, 0, 64, 1], [24, 2, 6, 1, 27]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5546218487394958, 'recall': 0.8571428571428571, 'f1': 0.673469387755102, 'support': 77}, {'label': 'entertainment', 'precision': 0.6440677966101694, 'recall': 0.6551724137931034, 'f1': 0.6495726495726496, 'support': 58}, {'label': 'politics', 'precision': 0.8125, 'recall': 0.6290322580645161, 'f1': 0.7090909090909091, 'support': 62}, {'label': 'sport', 'precision': 0.8311688311688312, 'recall': 0.8311688311688312, 'f1': 0.8311688311688312, 'support': 77}, {'label': 'tech', 'precision': 0.8709677419354839, 'recall': 0.45, 'f1': 0.5934065934065934, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T15:42:58.527564', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.4664425849914551, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7455089820359282, 'precision': 0.768395451029746, 'recall': 0.7455089820359282, 'f1_score': 0.7399041325889589}, 'performance': {'train_time_seconds': 0.002132415771484375, 'total_time_seconds': 0.46857500076293945, 'inference_time_ms_per_sample': 0.393570540194026}, 'confusion_matrix': [[70, 0, 1, 4, 2], [9, 35, 1, 12, 1], [11, 1, 39, 10, 1], [0, 4, 1, 70, 2], [15, 8, 1, 1, 35]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6666666666666666, 'recall': 0.9090909090909091, 'f1': 0.7692307692307693, 'support': 77}, {'label': 'entertainment', 'precision': 0.7291666666666666, 'recall': 0.603448275862069, 'f1': 0.660377358490566, 'support': 58}, {'label': 'politics', 'precision': 0.9069767441860465, 'recall': 0.6290322580645161, 'f1': 0.7428571428571429, 'support': 62}, {'label': 'sport', 'precision': 0.7216494845360825, 'recall': 0.9090909090909091, 'f1': 0.8045977011494253, 'support': 77}, {'label': 'tech', 'precision': 0.8536585365853658, 'recall': 0.5833333333333334, 'f1': 0.693069306930693, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.95_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:50:29.920512', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6100513935089111, 'features_extracted': 10000, 'reduction_time': 5.752367734909058, 'features_after_reduction': 789, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9552690671289003, 'recall': 0.9550898203592815, 'f1_score': 0.9549837121445497}, 'performance': {'train_time_seconds': 0.22480249404907227, 'total_time_seconds': 7.587221622467041, 'inference_time_ms_per_sample': 0.0021771756474843282}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.935064935064935, 'recall': 0.935064935064935, 'f1': 0.935064935064935, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.9_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:52:41.832985', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.46342897415161133, 'features_extracted': 10000, 'reduction_time': 5.46297812461853, 'features_after_reduction': 1010, 'metrics': {'accuracy': 0.937125748502994, 'precision': 0.9378919710380602, 'recall': 0.937125748502994, 'f1_score': 0.9373379985833395}, 'performance': {'train_time_seconds': 1.6510634422302246, 'total_time_seconds': 7.577470541000366, 'inference_time_ms_per_sample': 0.002811768811619924}, 'confusion_matrix': [[72, 1, 4, 0, 0], [0, 52, 4, 0, 2], [4, 0, 56, 1, 1], [0, 1, 1, 75, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9285714285714286, 'recall': 0.896551724137931, 'f1': 0.9122807017543859, 'support': 58}, {'label': 'politics', 'precision': 0.8615384615384616, 'recall': 0.9032258064516129, 'f1': 0.8818897637795275, 'support': 62}, {'label': 'sport', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T15:48:27.265770', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5663409233093262, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9587195757323855, 'recall': 0.9580838323353293, 'f1_score': 0.9581314365243281}, 'performance': {'train_time_seconds': 0.22585725784301758, 'total_time_seconds': 1.7921981811523438, 'inference_time_ms_per_sample': 0.09744681284099281}, 'confusion_matrix': [[73, 0, 2, 0, 2], [1, 54, 0, 1, 2], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9240506329113924, 'recall': 0.948051948051948, 'f1': 0.9358974358974359, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9310344827586207, 'f1': 0.9642857142857143, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9333333333333333, 'recall': 0.9333333333333333, 'f1': 0.9333333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.9_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T15:58:54.861072', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.775832176208496, 'features_extracted': 10000, 'reduction_time': 5.54566216468811, 'features_after_reduction': 1020, 'metrics': {'accuracy': 0.9251497005988024, 'precision': 0.9291078470325055, 'recall': 0.9251497005988024, 'f1_score': 0.9245237329785985}, 'performance': {'train_time_seconds': 0.013282299041748047, 'total_time_seconds': 7.3347766399383545, 'inference_time_ms_per_sample': 0.35129478591644836}, 'confusion_matrix': [[68, 1, 7, 1, 0], [2, 47, 4, 1, 4], [1, 0, 60, 1, 0], [1, 0, 0, 75, 1], [0, 0, 0, 1, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9444444444444444, 'recall': 0.8831168831168831, 'f1': 0.912751677852349, 'support': 77}, {'label': 'entertainment', 'precision': 0.9791666666666666, 'recall': 0.8103448275862069, 'f1': 0.8867924528301887, 'support': 58}, {'label': 'politics', 'precision': 0.8450704225352113, 'recall': 0.967741935483871, 'f1': 0.9022556390977443, 'support': 62}, {'label': 'sport', 'precision': 0.9493670886075949, 'recall': 0.974025974025974, 'f1': 0.9615384615384616, 'support': 77}, {'label': 'tech', 'precision': 0.921875, 'recall': 0.9833333333333333, 'f1': 0.9516129032258065, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T15:48:45.225707', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6169979572296143, 'features_extracted': 10000, 'reduction_time': 0.2584223747253418, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9311377245508982, 'precision': 0.9369378651603676, 'recall': 0.9311377245508982, 'f1_score': 0.9318616817611851}, 'performance': {'train_time_seconds': 0.19650530815124512, 'total_time_seconds': 2.071925640106201, 'inference_time_ms_per_sample': 0.09981458058614216}, 'confusion_matrix': [[75, 0, 1, 0, 1], [2, 52, 1, 3, 0], [7, 0, 55, 0, 0], [2, 0, 0, 74, 1], [4, 0, 0, 1, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8333333333333334, 'recall': 0.974025974025974, 'f1': 0.8982035928143712, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.896551724137931, 'f1': 0.9454545454545454, 'support': 58}, {'label': 'politics', 'precision': 0.9649122807017544, 'recall': 0.8870967741935484, 'f1': 0.9243697478991597, 'support': 62}, {'label': 'sport', 'precision': 0.9487179487179487, 'recall': 0.961038961038961, 'f1': 0.9548387096774194, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:57:19.569846', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.8998496532440186, 'features_extracted': 10000, 'reduction_time': 0.2899205684661865, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9822509602615772, 'recall': 0.9820359281437125, 'f1_score': 0.9820355339744099}, 'performance': {'train_time_seconds': 0.16819524765014648, 'total_time_seconds': 2.3579654693603516, 'inference_time_ms_per_sample': 0.007929916153410953}, 'confusion_matrix': [[76, 0, 0, 0, 1], [0, 57, 0, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:48:21.830047', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6435081958770752, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.961126032159464, 'recall': 0.9610778443113772, 'f1_score': 0.960942194123036}, 'performance': {'train_time_seconds': 1.9070830345153809, 'total_time_seconds': 3.550591230392456, 'inference_time_ms_per_sample': 0.004197309117117328}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 57, 1, 0, 0], [0, 0, 59, 1, 2], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.972972972972973, 'recall': 0.935064935064935, 'f1': 0.9536423841059603, 'support': 77}, {'label': 'entertainment', 'precision': 0.9661016949152542, 'recall': 0.9827586206896551, 'f1': 0.9743589743589743, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9491525423728814, 'recall': 0.9333333333333333, 'f1': 0.9411764705882353, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.9_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:55:26.515271', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.736421823501587, 'features_extracted': 5000, 'reduction_time': 3.4337446689605713, 'features_after_reduction': 906, 'metrics': {'accuracy': 0.8982035928143712, 'precision': 0.8982625849994925, 'recall': 0.8982035928143712, 'f1_score': 0.8980992398163696}, 'performance': {'train_time_seconds': 1.388756513595581, 'total_time_seconds': 6.558923006057739, 'inference_time_ms_per_sample': 0.0035691404057120136}, 'confusion_matrix': [[71, 1, 4, 0, 1], [3, 49, 4, 1, 1], [6, 1, 51, 2, 2], [0, 3, 0, 74, 0], [0, 2, 3, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8875, 'recall': 0.922077922077922, 'f1': 0.9044585987261147, 'support': 77}, {'label': 'entertainment', 'precision': 0.875, 'recall': 0.8448275862068966, 'f1': 0.8596491228070176, 'support': 58}, {'label': 'politics', 'precision': 0.8225806451612904, 'recall': 0.8225806451612904, 'f1': 0.8225806451612904, 'support': 62}, {'label': 'sport', 'precision': 0.961038961038961, 'recall': 0.961038961038961, 'f1': 0.961038961038961, 'support': 77}, {'label': 'tech', 'precision': 0.9322033898305084, 'recall': 0.9166666666666666, 'f1': 0.9243697478991597, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T15:57:24.214090', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.8171982765197754, 'features_extracted': 10000, 'reduction_time': 0.2682218551635742, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9431137724550899, 'precision': 0.9488539184198133, 'recall': 0.9431137724550899, 'f1_score': 0.9442170462220482}, 'performance': {'train_time_seconds': 0.19287610054016113, 'total_time_seconds': 2.2782962322235107, 'inference_time_ms_per_sample': 0.09866317589125947}, 'confusion_matrix': [[74, 0, 0, 1, 2], [2, 55, 0, 1, 0], [6, 0, 56, 0, 0], [2, 0, 0, 75, 0], [5, 0, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8314606741573034, 'recall': 0.961038961038961, 'f1': 0.891566265060241, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.9032258064516129, 'f1': 0.9491525423728814, 'support': 62}, {'label': 'sport', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T15:51:54.066584', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5492713451385498, 'features_extracted': 10000, 'reduction_time': 0.2663536071777344, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9341317365269461, 'precision': 0.9356036662425867, 'recall': 0.9341317365269461, 'f1_score': 0.9341157775392753}, 'performance': {'train_time_seconds': 0.19297528266906738, 'total_time_seconds': 1.0086002349853516, 'inference_time_ms_per_sample': 0.09740897995269228}, 'confusion_matrix': [[71, 0, 3, 1, 2], [0, 53, 0, 5, 0], [3, 0, 58, 1, 0], [1, 0, 0, 76, 0], [4, 1, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8987341772151899, 'recall': 0.922077922077922, 'f1': 0.9102564102564102, 'support': 77}, {'label': 'entertainment', 'precision': 0.9814814814814815, 'recall': 0.9137931034482759, 'f1': 0.9464285714285714, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9156626506024096, 'recall': 0.987012987012987, 'f1': 0.95, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.9_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:46:48.274688', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.5651936531066895, 'features_extracted': 5000, 'reduction_time': 3.568655490875244, 'features_after_reduction': 420, 'metrics': {'accuracy': 0.6407185628742516, 'precision': 0.6421572546217981, 'recall': 0.6407185628742516, 'f1_score': 0.6391007630167599}, 'performance': {'train_time_seconds': 0.7636914253234863, 'total_time_seconds': 5.89754056930542, 'inference_time_ms_per_sample': 0.002412025086180179}, 'confusion_matrix': [[52, 7, 8, 4, 6], [11, 31, 2, 9, 5], [10, 6, 33, 6, 7], [3, 10, 1, 61, 2], [11, 5, 5, 2, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5977011494252874, 'recall': 0.6753246753246753, 'f1': 0.6341463414634146, 'support': 77}, {'label': 'entertainment', 'precision': 0.5254237288135594, 'recall': 0.5344827586206896, 'f1': 0.5299145299145299, 'support': 58}, {'label': 'politics', 'precision': 0.673469387755102, 'recall': 0.532258064516129, 'f1': 0.5945945945945946, 'support': 62}, {'label': 'sport', 'precision': 0.7439024390243902, 'recall': 0.7922077922077922, 'f1': 0.7672955974842768, 'support': 77}, {'label': 'tech', 'precision': 0.6491228070175439, 'recall': 0.6166666666666667, 'f1': 0.6324786324786325, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.9_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:55:03.707652', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.9442307949066162, 'features_extracted': 5000, 'reduction_time': 3.5001282691955566, 'features_after_reduction': 906, 'metrics': {'accuracy': 0.9880239520958084, 'precision': 0.9881957696328952, 'recall': 0.9880239520958084, 'f1_score': 0.98806325722334}, 'performance': {'train_time_seconds': 0.06903266906738281, 'total_time_seconds': 5.513391733169556, 'inference_time_ms_per_sample': 0.0030230619236380754}, 'confusion_matrix': [[76, 0, 1, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9833333333333333, 'f1': 0.9915966386554622, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.95_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T15:51:20.132644', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5961124897003174, 'features_extracted': 10000, 'reduction_time': 6.359147310256958, 'features_after_reduction': 789, 'metrics': {'accuracy': 0.7305389221556886, 'precision': 0.7882278785674527, 'recall': 0.7305389221556886, 'f1_score': 0.7259601795386345}, 'performance': {'train_time_seconds': 0.01110219955444336, 'total_time_seconds': 7.966361999511719, 'inference_time_ms_per_sample': 0.34891987989048756}, 'confusion_matrix': [[73, 2, 1, 0, 1], [14, 38, 0, 6, 0], [23, 6, 29, 3, 1], [2, 4, 0, 70, 1], [18, 7, 1, 0, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5615384615384615, 'recall': 0.948051948051948, 'f1': 0.7053140096618358, 'support': 77}, {'label': 'entertainment', 'precision': 0.6666666666666666, 'recall': 0.6551724137931034, 'f1': 0.6608695652173913, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.46774193548387094, 'f1': 0.6236559139784946, 'support': 62}, {'label': 'sport', 'precision': 0.8860759493670886, 'recall': 0.9090909090909091, 'f1': 0.8974358974358975, 'support': 77}, {'label': 'tech', 'precision': 0.918918918918919, 'recall': 0.5666666666666667, 'f1': 0.7010309278350515, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.95_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:47:22.229617', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6105082035064697, 'features_extracted': 5000, 'reduction_time': 3.294459581375122, 'features_after_reduction': 673, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.9612620039068005, 'recall': 0.9610778443113772, 'f1_score': 0.9609884207675151}, 'performance': {'train_time_seconds': 0.23985981941223145, 'total_time_seconds': 5.144827604293823, 'inference_time_ms_per_sample': 0.0021978766618374578}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [1, 1, 59, 1, 0], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.96, 'recall': 0.935064935064935, 'f1': 0.9473684210526315, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.95_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:59:25.356984', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.8632140159606934, 'features_extracted': 10000, 'reduction_time': 5.591154336929321, 'features_after_reduction': 1202, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9825088284968525, 'recall': 0.9820359281437125, 'f1_score': 0.9821213702034858}, 'performance': {'train_time_seconds': 0.12495851516723633, 'total_time_seconds': 7.579326868057251, 'inference_time_ms_per_sample': 0.003041621453747778}, 'confusion_matrix': [[74, 1, 2, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9866666666666667, 'recall': 0.961038961038961, 'f1': 0.9736842105263158, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9833333333333333, 'f1': 0.9915966386554622, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.95_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T15:54:14.050461', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.45937275886535645, 'features_extracted': 10000, 'reduction_time': 5.360806941986084, 'features_after_reduction': 1191, 'metrics': {'accuracy': 0.9341317365269461, 'precision': 0.9389145774119612, 'recall': 0.9341317365269461, 'f1_score': 0.9338886550496961}, 'performance': {'train_time_seconds': 0.0182647705078125, 'total_time_seconds': 5.838444471359253, 'inference_time_ms_per_sample': 0.3572673854713668}, 'confusion_matrix': [[67, 1, 8, 1, 0], [1, 49, 4, 3, 1], [0, 0, 60, 1, 1], [0, 0, 0, 77, 0], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9852941176470589, 'recall': 0.8701298701298701, 'f1': 0.9241379310344827, 'support': 77}, {'label': 'entertainment', 'precision': 0.9607843137254902, 'recall': 0.8448275862068966, 'f1': 0.8990825688073395, 'support': 58}, {'label': 'politics', 'precision': 0.8333333333333334, 'recall': 0.967741935483871, 'f1': 0.8955223880597015, 'support': 62}, {'label': 'sport', 'precision': 0.9390243902439024, 'recall': 1.0, 'f1': 0.9685534591194969, 'support': 77}, {'label': 'tech', 'precision': 0.9672131147540983, 'recall': 0.9833333333333333, 'f1': 0.9752066115702479, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:42:55.397019', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.488781213760376, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7634730538922155, 'precision': 0.7787728905313933, 'recall': 0.7634730538922155, 'f1_score': 0.7643344269165264}, 'performance': {'train_time_seconds': 0.33113718032836914, 'total_time_seconds': 0.8199183940887451, 'inference_time_ms_per_sample': 0.0024006038368819}, 'confusion_matrix': [[61, 1, 5, 4, 6], [7, 39, 3, 8, 1], [16, 0, 41, 2, 3], [5, 4, 0, 67, 1], [9, 1, 0, 3, 47]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6224489795918368, 'recall': 0.7922077922077922, 'f1': 0.6971428571428572, 'support': 77}, {'label': 'entertainment', 'precision': 0.8666666666666667, 'recall': 0.6724137931034483, 'f1': 0.7572815533980582, 'support': 58}, {'label': 'politics', 'precision': 0.8367346938775511, 'recall': 0.6612903225806451, 'f1': 0.7387387387387387, 'support': 62}, {'label': 'sport', 'precision': 0.7976190476190477, 'recall': 0.8701298701298701, 'f1': 0.8322981366459627, 'support': 77}, {'label': 'tech', 'precision': 0.8103448275862069, 'recall': 0.7833333333333333, 'f1': 0.7966101694915254, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T15:45:49.156377', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5844426155090332, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9700598802395209, 'precision': 0.9708488305720072, 'recall': 0.9700598802395209, 'f1_score': 0.9702399065449924}, 'performance': {'train_time_seconds': 0.22995686531066895, 'total_time_seconds': 1.8143994808197021, 'inference_time_ms_per_sample': 0.09827699489936143}, 'confusion_matrix': [[75, 0, 1, 0, 1], [1, 56, 1, 0, 0], [3, 0, 59, 0, 0], [0, 0, 0, 76, 1], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9259259259259259, 'recall': 0.974025974025974, 'f1': 0.9493670886075949, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9672131147540983, 'recall': 0.9516129032258065, 'f1': 0.959349593495935, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 0.987012987012987, 'f1': 0.9934640522875817, 'support': 77}, {'label': 'tech', 'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1': 0.9666666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.95_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:45:08.694632', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.49919915199279785, 'features_extracted': 10000, 'reduction_time': 5.7079854011535645, 'features_after_reduction': 716, 'metrics': {'accuracy': 0.6616766467065869, 'precision': 0.6596399120717928, 'recall': 0.6616766467065869, 'f1_score': 0.6599580404962745}, 'performance': {'train_time_seconds': 1.4812262058258057, 'total_time_seconds': 7.688410758972168, 'inference_time_ms_per_sample': 0.0023456390746339354}, 'confusion_matrix': [[51, 7, 9, 2, 8], [5, 29, 9, 11, 4], [11, 5, 39, 4, 3], [2, 4, 2, 65, 4], [4, 13, 3, 3, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6986301369863014, 'recall': 0.6623376623376623, 'f1': 0.68, 'support': 77}, {'label': 'entertainment', 'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'support': 58}, {'label': 'politics', 'precision': 0.6290322580645161, 'recall': 0.6290322580645161, 'f1': 0.6290322580645161, 'support': 62}, {'label': 'sport', 'precision': 0.7647058823529411, 'recall': 0.8441558441558441, 'f1': 0.8024691358024691, 'support': 77}, {'label': 'tech', 'precision': 0.6607142857142857, 'recall': 0.6166666666666667, 'f1': 0.6379310344827587, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:45:52.929670', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5881338119506836, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7604790419161677, 'precision': 0.7639773036243528, 'recall': 0.7604790419161677, 'f1_score': 0.7604377994759974}, 'performance': {'train_time_seconds': 0.508629322052002, 'total_time_seconds': 2.0967631340026855, 'inference_time_ms_per_sample': 0.0072653422098673745}, 'confusion_matrix': [[53, 4, 11, 3, 6], [5, 39, 7, 6, 1], [8, 2, 47, 2, 3], [3, 3, 2, 67, 2], [7, 0, 4, 1, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6973684210526315, 'recall': 0.6883116883116883, 'f1': 0.6928104575163399, 'support': 77}, {'label': 'entertainment', 'precision': 0.8125, 'recall': 0.6724137931034483, 'f1': 0.7358490566037735, 'support': 58}, {'label': 'politics', 'precision': 0.6619718309859155, 'recall': 0.7580645161290323, 'f1': 0.706766917293233, 'support': 62}, {'label': 'sport', 'precision': 0.8481012658227848, 'recall': 0.8701298701298701, 'f1': 0.8589743589743589, 'support': 77}, {'label': 'tech', 'precision': 0.8, 'recall': 0.8, 'f1': 0.8, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T15:51:50.972060', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.45944809913635254, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9461077844311377, 'precision': 0.948370618660284, 'recall': 0.9461077844311377, 'f1_score': 0.9456643145263546}, 'performance': {'train_time_seconds': 0.0023360252380371094, 'total_time_seconds': 0.46178412437438965, 'inference_time_ms_per_sample': 0.27788970284833164}, 'confusion_matrix': [[68, 1, 6, 1, 1], [1, 51, 2, 1, 3], [0, 0, 62, 0, 0], [0, 0, 0, 77, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9855072463768116, 'recall': 0.8831168831168831, 'f1': 0.9315068493150684, 'support': 77}, {'label': 'entertainment', 'precision': 0.9444444444444444, 'recall': 0.8793103448275862, 'f1': 0.9107142857142857, 'support': 58}, {'label': 'politics', 'precision': 0.8857142857142857, 'recall': 1.0, 'f1': 0.9393939393939394, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9354838709677419, 'recall': 0.9666666666666667, 'f1': 0.9508196721311475, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:51:56.109261', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.485154390335083, 'features_extracted': 10000, 'reduction_time': 0.26043009757995605, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7994011976047904, 'precision': 0.8081974062999767, 'recall': 0.7994011976047904, 'f1_score': 0.7992305099343296}, 'performance': {'train_time_seconds': 0.11973428726196289, 'total_time_seconds': 0.865318775177002, 'inference_time_ms_per_sample': 0.002460565395697862}, 'confusion_matrix': [[64, 1, 6, 2, 4], [4, 42, 4, 8, 0], [14, 1, 43, 2, 2], [3, 1, 0, 72, 1], [9, 2, 3, 0, 46]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6808510638297872, 'recall': 0.8311688311688312, 'f1': 0.7485380116959064, 'support': 77}, {'label': 'entertainment', 'precision': 0.8936170212765957, 'recall': 0.7241379310344828, 'f1': 0.8, 'support': 58}, {'label': 'politics', 'precision': 0.7678571428571429, 'recall': 0.6935483870967742, 'f1': 0.7288135593220338, 'support': 62}, {'label': 'sport', 'precision': 0.8571428571428571, 'recall': 0.935064935064935, 'f1': 0.8944099378881988, 'support': 77}, {'label': 'tech', 'precision': 0.8679245283018868, 'recall': 0.7666666666666667, 'f1': 0.8141592920353983, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:46:00.389871', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.6543464660644531, 'features_extracted': 5000, 'reduction_time': 0.14199113845825195, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9730538922155688, 'precision': 0.9737496602766063, 'recall': 0.9730538922155688, 'f1_score': 0.9729928141568138}, 'performance': {'train_time_seconds': 0.015855789184570312, 'total_time_seconds': 1.8121933937072754, 'inference_time_ms_per_sample': 0.004771940722436962}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 54, 2, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:45:38.679864', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6007359027862549, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9581598373126704, 'recall': 0.9580838323353293, 'f1_score': 0.9579800968580585}, 'performance': {'train_time_seconds': 3.7161035537719727, 'total_time_seconds': 5.3168394565582275, 'inference_time_ms_per_sample': 0.003930337414770069}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [2, 1, 58, 1, 0], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:51:52.280418', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.4765920639038086, 'features_extracted': 10000, 'reduction_time': 0.2624015808105469, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9700598802395209, 'precision': 0.9703506518002348, 'recall': 0.9700598802395209, 'f1_score': 0.9700490110058383}, 'performance': {'train_time_seconds': 0.09631848335266113, 'total_time_seconds': 0.8353121280670166, 'inference_time_ms_per_sample': 0.003347139872476726}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 56, 1, 1, 0], [3, 0, 59, 0, 0], [0, 0, 0, 77, 0], [1, 2, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9493670886075949, 'recall': 0.974025974025974, 'f1': 0.9615384615384616, 'support': 77}, {'label': 'entertainment', 'precision': 0.9491525423728814, 'recall': 0.9655172413793104, 'f1': 0.9572649572649573, 'support': 58}, {'label': 'politics', 'precision': 0.9833333333333333, 'recall': 0.9516129032258065, 'f1': 0.9672131147540983, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.9_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T15:50:13.814216', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.659123420715332, 'features_extracted': 10000, 'reduction_time': 6.984294176101685, 'features_after_reduction': 515, 'metrics': {'accuracy': 0.7365269461077845, 'precision': 0.7829289964177526, 'recall': 0.7365269461077845, 'f1_score': 0.7296070121403734}, 'performance': {'train_time_seconds': 0.008600950241088867, 'total_time_seconds': 8.652018547058105, 'inference_time_ms_per_sample': 0.35725382273782513}, 'confusion_matrix': [[74, 1, 1, 1, 0], [9, 42, 0, 7, 0], [17, 7, 33, 5, 0], [2, 6, 0, 67, 2], [21, 5, 3, 1, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6016260162601627, 'recall': 0.961038961038961, 'f1': 0.74, 'support': 77}, {'label': 'entertainment', 'precision': 0.6885245901639344, 'recall': 0.7241379310344828, 'f1': 0.7058823529411765, 'support': 58}, {'label': 'politics', 'precision': 0.8918918918918919, 'recall': 0.532258064516129, 'f1': 0.6666666666666666, 'support': 62}, {'label': 'sport', 'precision': 0.8271604938271605, 'recall': 0.8701298701298701, 'f1': 0.8481012658227848, 'support': 77}, {'label': 'tech', 'precision': 0.9375, 'recall': 0.5, 'f1': 0.6521739130434783, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T15:46:06.593558', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5933754444122314, 'features_extracted': 5000, 'reduction_time': 0.13423371315002441, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9431137724550899, 'precision': 0.9448907419043473, 'recall': 0.9431137724550899, 'f1_score': 0.9434858979971915}, 'performance': {'train_time_seconds': 0.19385743141174316, 'total_time_seconds': 1.921466588973999, 'inference_time_ms_per_sample': 0.09705349356828336}, 'confusion_matrix': [[72, 0, 2, 1, 2], [1, 54, 0, 3, 0], [4, 0, 58, 0, 0], [1, 0, 0, 75, 1], [4, 0, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8780487804878049, 'recall': 0.935064935064935, 'f1': 0.9056603773584906, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9310344827586207, 'f1': 0.9642857142857143, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1': 0.9508196721311475, 'support': 62}, {'label': 'sport', 'precision': 0.9493670886075949, 'recall': 0.974025974025974, 'f1': 0.9615384615384616, 'support': 77}, {'label': 'tech', 'precision': 0.9491525423728814, 'recall': 0.9333333333333333, 'f1': 0.9411764705882353, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T15:57:13.514263', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.7950642108917236, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9251497005988024, 'precision': 0.9268188527710549, 'recall': 0.9251497005988024, 'f1_score': 0.9249608971665426}, 'performance': {'train_time_seconds': 0.0030274391174316406, 'total_time_seconds': 1.7980916500091553, 'inference_time_ms_per_sample': 0.292042058385061}, 'confusion_matrix': [[68, 1, 6, 1, 1], [1, 50, 3, 1, 3], [1, 1, 59, 0, 1], [1, 0, 0, 75, 1], [1, 1, 0, 1, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9444444444444444, 'recall': 0.8831168831168831, 'f1': 0.912751677852349, 'support': 77}, {'label': 'entertainment', 'precision': 0.9433962264150944, 'recall': 0.8620689655172413, 'f1': 0.9009009009009009, 'support': 58}, {'label': 'politics', 'precision': 0.8676470588235294, 'recall': 0.9516129032258065, 'f1': 0.9076923076923077, 'support': 62}, {'label': 'sport', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'tech', 'precision': 0.9047619047619048, 'recall': 0.95, 'f1': 0.926829268292683, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.9_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:49:15.981662', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.625519037246704, 'features_extracted': 10000, 'reduction_time': 5.872258901596069, 'features_after_reduction': 515, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9553152296241051, 'recall': 0.9550898203592815, 'f1_score': 0.9549854042635536}, 'performance': {'train_time_seconds': 0.10385441780090332, 'total_time_seconds': 7.601632356643677, 'inference_time_ms_per_sample': 0.0017467373145554593}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [1, 0, 58, 2, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T15:48:57.583013', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.5710289478302002, 'features_extracted': 10000, 'reduction_time': 0.26886820793151855, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7485029940119761, 'precision': 0.7805850298796609, 'recall': 0.7485029940119761, 'f1_score': 0.7439429735975069}, 'performance': {'train_time_seconds': 0.0072307586669921875, 'total_time_seconds': 1.847127914428711, 'inference_time_ms_per_sample': 0.36639010834836677}, 'confusion_matrix': [[72, 0, 4, 1, 0], [7, 42, 1, 7, 1], [12, 2, 40, 6, 2], [4, 6, 1, 66, 0], [23, 2, 4, 1, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6101694915254238, 'recall': 0.935064935064935, 'f1': 0.7384615384615385, 'support': 77}, {'label': 'entertainment', 'precision': 0.8076923076923077, 'recall': 0.7241379310344828, 'f1': 0.7636363636363637, 'support': 58}, {'label': 'politics', 'precision': 0.8, 'recall': 0.6451612903225806, 'f1': 0.7142857142857143, 'support': 62}, {'label': 'sport', 'precision': 0.8148148148148148, 'recall': 0.8571428571428571, 'f1': 0.8354430379746836, 'support': 77}, {'label': 'tech', 'precision': 0.9090909090909091, 'recall': 0.5, 'f1': 0.6451612903225806, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:42:51.383975', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5477383136749268, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9553975430261775, 'recall': 0.9550898203592815, 'f1_score': 0.9549256583867716}, 'performance': {'train_time_seconds': 1.8153302669525146, 'total_time_seconds': 2.3630685806274414, 'inference_time_ms_per_sample': 0.003821835546436424}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [1, 1, 59, 1, 0], [0, 0, 0, 77, 0], [3, 1, 1, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9491525423728814, 'recall': 0.9655172413793104, 'f1': 0.9572649572649573, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9821428571428571, 'recall': 0.9166666666666666, 'f1': 0.9482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:48:51.391634', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5587959289550781, 'features_extracted': 10000, 'reduction_time': 0.2672691345214844, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7784431137724551, 'precision': 0.7820767640639236, 'recall': 0.7784431137724551, 'f1_score': 0.7787006522958154}, 'performance': {'train_time_seconds': 0.11471414566040039, 'total_time_seconds': 1.940779209136963, 'inference_time_ms_per_sample': 0.0025733502325183616}, 'confusion_matrix': [[59, 2, 9, 4, 3], [5, 42, 4, 5, 2], [12, 3, 42, 2, 3], [3, 2, 3, 68, 1], [8, 1, 1, 1, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6781609195402298, 'recall': 0.7662337662337663, 'f1': 0.7195121951219512, 'support': 77}, {'label': 'entertainment', 'precision': 0.84, 'recall': 0.7241379310344828, 'f1': 0.7777777777777778, 'support': 58}, {'label': 'politics', 'precision': 0.711864406779661, 'recall': 0.6774193548387096, 'f1': 0.6942148760330579, 'support': 62}, {'label': 'sport', 'precision': 0.85, 'recall': 0.8831168831168831, 'f1': 0.8662420382165605, 'support': 77}, {'label': 'tech', 'precision': 0.8448275862068966, 'recall': 0.8166666666666667, 'f1': 0.8305084745762712, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.95_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T15:51:35.601301', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.5510907173156738, 'features_extracted': 10000, 'reduction_time': 5.4390459060668945, 'features_after_reduction': 789, 'metrics': {'accuracy': 0.7155688622754491, 'precision': 0.7669748524341691, 'recall': 0.7155688622754491, 'f1_score': 0.7092507278636212}, 'performance': {'train_time_seconds': 0.011045455932617188, 'total_time_seconds': 7.0011820793151855, 'inference_time_ms_per_sample': 0.348947005357571}, 'confusion_matrix': [[71, 1, 1, 1, 3], [12, 38, 0, 8, 0], [20, 5, 31, 6, 0], [1, 6, 0, 69, 1], [21, 8, 1, 0, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.568, 'recall': 0.922077922077922, 'f1': 0.7029702970297029, 'support': 77}, {'label': 'entertainment', 'precision': 0.6551724137931034, 'recall': 0.6551724137931034, 'f1': 0.6551724137931034, 'support': 58}, {'label': 'politics', 'precision': 0.9393939393939394, 'recall': 0.5, 'f1': 0.6526315789473685, 'support': 62}, {'label': 'sport', 'precision': 0.8214285714285714, 'recall': 0.8961038961038961, 'f1': 0.8571428571428571, 'support': 77}, {'label': 'tech', 'precision': 0.8823529411764706, 'recall': 0.5, 'f1': 0.6382978723404256, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:54:20.031107', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.5409772396087646, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9795946568401658, 'recall': 0.9790419161676647, 'f1_score': 0.9790994973331157}, 'performance': {'train_time_seconds': 0.09863066673278809, 'total_time_seconds': 1.6396079063415527, 'inference_time_ms_per_sample': 0.008139067781185677}, 'confusion_matrix': [[75, 0, 2, 0, 0], [0, 55, 2, 0, 1], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T15:57:01.887095', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.9253756999969482, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.937125748502994, 'precision': 0.9436572233683893, 'recall': 0.937125748502994, 'f1_score': 0.9371907722035053}, 'performance': {'train_time_seconds': 0.21497535705566406, 'total_time_seconds': 2.1403510570526123, 'inference_time_ms_per_sample': 0.09724765480635408}, 'confusion_matrix': [[76, 0, 0, 0, 1], [2, 50, 0, 6, 0], [5, 0, 55, 2, 0], [0, 0, 0, 77, 0], [5, 0, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8636363636363636, 'recall': 0.987012987012987, 'f1': 0.9212121212121213, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.8620689655172413, 'f1': 0.9259259259259259, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.8870967741935484, 'f1': 0.9401709401709402, 'support': 62}, {'label': 'sport', 'precision': 0.9058823529411765, 'recall': 1.0, 'f1': 0.9506172839506173, 'support': 77}, {'label': 'tech', 'precision': 0.9821428571428571, 'recall': 0.9166666666666666, 'f1': 0.9482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.95_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T15:56:37.966421', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.9412593841552734, 'features_extracted': 5000, 'reduction_time': 3.745074510574341, 'features_after_reduction': 1105, 'metrics': {'accuracy': 0.9191616766467066, 'precision': 0.9199950332435363, 'recall': 0.9191616766467066, 'f1_score': 0.9189570043940202}, 'performance': {'train_time_seconds': 0.01829838752746582, 'total_time_seconds': 5.70463228225708, 'inference_time_ms_per_sample': 0.3376221228502468}, 'confusion_matrix': [[68, 1, 7, 1, 0], [1, 50, 2, 2, 3], [1, 3, 56, 0, 2], [1, 0, 0, 75, 1], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9444444444444444, 'recall': 0.8831168831168831, 'f1': 0.912751677852349, 'support': 77}, {'label': 'entertainment', 'precision': 0.9090909090909091, 'recall': 0.8620689655172413, 'f1': 0.8849557522123894, 'support': 58}, {'label': 'politics', 'precision': 0.8615384615384616, 'recall': 0.9032258064516129, 'f1': 0.8818897637795275, 'support': 62}, {'label': 'sport', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'tech', 'precision': 0.90625, 'recall': 0.9666666666666667, 'f1': 0.9354838709677419, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.95_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T15:56:49.159910', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.762744665145874, 'features_extracted': 5000, 'reduction_time': 3.4610397815704346, 'features_after_reduction': 1105, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9505945914441823, 'recall': 0.9491017964071856, 'f1_score': 0.9488035231747476}, 'performance': {'train_time_seconds': 0.019063711166381836, 'total_time_seconds': 5.24284815788269, 'inference_time_ms_per_sample': 0.33509160230259694}, 'confusion_matrix': [[67, 1, 7, 1, 1], [1, 54, 1, 1, 1], [1, 0, 61, 0, 0], [1, 0, 0, 76, 0], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9571428571428572, 'recall': 0.8701298701298701, 'f1': 0.9115646258503401, 'support': 77}, {'label': 'entertainment', 'precision': 0.9642857142857143, 'recall': 0.9310344827586207, 'f1': 0.9473684210526315, 'support': 58}, {'label': 'politics', 'precision': 0.8840579710144928, 'recall': 0.9838709677419355, 'f1': 0.9312977099236641, 'support': 62}, {'label': 'sport', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'tech', 'precision': 0.9672131147540983, 'recall': 0.9833333333333333, 'f1': 0.9752066115702479, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:51:56.982991', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.4540257453918457, 'features_extracted': 10000, 'reduction_time': 0.26244306564331055, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7964071856287425, 'precision': 0.7977692216735719, 'recall': 0.7964071856287425, 'f1_score': 0.7955903885621982}, 'performance': {'train_time_seconds': 0.14448332786560059, 'total_time_seconds': 0.8609521389007568, 'inference_time_ms_per_sample': 0.002481980238132134}, 'confusion_matrix': [[52, 3, 10, 5, 7], [3, 44, 6, 5, 0], [6, 1, 51, 1, 3], [4, 1, 2, 68, 2], [6, 2, 1, 0, 51]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7323943661971831, 'recall': 0.6753246753246753, 'f1': 0.7027027027027027, 'support': 77}, {'label': 'entertainment', 'precision': 0.8627450980392157, 'recall': 0.7586206896551724, 'f1': 0.8073394495412844, 'support': 58}, {'label': 'politics', 'precision': 0.7285714285714285, 'recall': 0.8225806451612904, 'f1': 0.7727272727272727, 'support': 62}, {'label': 'sport', 'precision': 0.8607594936708861, 'recall': 0.8831168831168831, 'f1': 0.8717948717948718, 'support': 77}, {'label': 'tech', 'precision': 0.8095238095238095, 'recall': 0.85, 'f1': 0.8292682926829268, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T15:57:35.712026', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.9146316051483154, 'features_extracted': 10000, 'reduction_time': 0.28830409049987793, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.844311377245509, 'precision': 0.8635998206095044, 'recall': 0.844311377245509, 'f1_score': 0.845284563498897}, 'performance': {'train_time_seconds': 0.009315013885498047, 'total_time_seconds': 2.2122507095336914, 'inference_time_ms_per_sample': 0.09659664359635221}, 'confusion_matrix': [[72, 1, 2, 2, 0], [8, 45, 4, 1, 0], [10, 1, 51, 0, 0], [1, 1, 3, 72, 0], [11, 6, 1, 0, 42]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7058823529411765, 'recall': 0.935064935064935, 'f1': 0.8044692737430168, 'support': 77}, {'label': 'entertainment', 'precision': 0.8333333333333334, 'recall': 0.7758620689655172, 'f1': 0.8035714285714286, 'support': 58}, {'label': 'politics', 'precision': 0.8360655737704918, 'recall': 0.8225806451612904, 'f1': 0.8292682926829268, 'support': 62}, {'label': 'sport', 'precision': 0.96, 'recall': 0.935064935064935, 'f1': 0.9473684210526315, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.7, 'f1': 0.8235294117647058, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.9_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T15:49:57.490655', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5360424518585205, 'features_extracted': 10000, 'reduction_time': 5.823808431625366, 'features_after_reduction': 515, 'metrics': {'accuracy': 0.7455089820359282, 'precision': 0.7941499778655189, 'recall': 0.7455089820359282, 'f1_score': 0.7439972779036919}, 'performance': {'train_time_seconds': 0.008301496505737305, 'total_time_seconds': 7.368152379989624, 'inference_time_ms_per_sample': 0.3896616176216902}, 'confusion_matrix': [[71, 3, 1, 1, 1], [12, 41, 0, 5, 0], [15, 11, 33, 2, 1], [3, 4, 0, 69, 1], [18, 6, 1, 0, 35]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5966386554621849, 'recall': 0.922077922077922, 'f1': 0.7244897959183674, 'support': 77}, {'label': 'entertainment', 'precision': 0.6307692307692307, 'recall': 0.7068965517241379, 'f1': 0.6666666666666666, 'support': 58}, {'label': 'politics', 'precision': 0.9428571428571428, 'recall': 0.532258064516129, 'f1': 0.6804123711340206, 'support': 62}, {'label': 'sport', 'precision': 0.8961038961038961, 'recall': 0.8961038961038961, 'f1': 0.8961038961038961, 'support': 77}, {'label': 'tech', 'precision': 0.9210526315789473, 'recall': 0.5833333333333334, 'f1': 0.7142857142857143, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.95_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T15:48:07.495105', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.670698642730713, 'features_extracted': 5000, 'reduction_time': 3.6802732944488525, 'features_after_reduction': 673, 'metrics': {'accuracy': 0.7485029940119761, 'precision': 0.7809760892956218, 'recall': 0.7485029940119761, 'f1_score': 0.7429394123870761}, 'performance': {'train_time_seconds': 0.010200262069702148, 'total_time_seconds': 5.361172199249268, 'inference_time_ms_per_sample': 0.3602197784149718}, 'confusion_matrix': [[68, 2, 1, 2, 4], [5, 45, 0, 8, 0], [13, 7, 35, 7, 0], [1, 5, 0, 70, 1], [19, 8, 1, 0, 32]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6415094339622641, 'recall': 0.8831168831168831, 'f1': 0.7431693989071039, 'support': 77}, {'label': 'entertainment', 'precision': 0.6716417910447762, 'recall': 0.7758620689655172, 'f1': 0.72, 'support': 58}, {'label': 'politics', 'precision': 0.9459459459459459, 'recall': 0.5645161290322581, 'f1': 0.7070707070707071, 'support': 62}, {'label': 'sport', 'precision': 0.8045977011494253, 'recall': 0.9090909090909091, 'f1': 0.8536585365853658, 'support': 77}, {'label': 'tech', 'precision': 0.8648648648648649, 'recall': 0.5333333333333333, 'f1': 0.6597938144329897, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T15:54:27.866295', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5608508586883545, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.9616706689908869, 'recall': 0.9610778443113772, 'f1_score': 0.9611459439487486}, 'performance': {'train_time_seconds': 0.21920418739318848, 'total_time_seconds': 1.780055046081543, 'inference_time_ms_per_sample': 0.09740469698420542}, 'confusion_matrix': [[74, 0, 1, 0, 2], [1, 55, 0, 2, 0], [2, 0, 59, 1, 0], [1, 0, 0, 76, 0], [2, 1, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.925, 'recall': 0.961038961038961, 'f1': 0.9426751592356688, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9833333333333333, 'recall': 0.9516129032258065, 'f1': 0.9672131147540983, 'support': 62}, {'label': 'sport', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:48:42.976702', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6329808235168457, 'features_extracted': 10000, 'reduction_time': 0.25663185119628906, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.958013936715038, 'recall': 0.9580838323353293, 'f1_score': 0.9579418002709207}, 'performance': {'train_time_seconds': 0.3416748046875, 'total_time_seconds': 2.2312874794006348, 'inference_time_ms_per_sample': 0.006131069388932097}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 0, 1], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T15:45:55.040808', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5680832862854004, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7005988023952096, 'precision': 0.7392125438118978, 'recall': 0.7005988023952096, 'f1_score': 0.6968495383954719}, 'performance': {'train_time_seconds': 0.0027167797088623047, 'total_time_seconds': 1.5708000659942627, 'inference_time_ms_per_sample': 0.4488993547633736}, 'confusion_matrix': [[67, 2, 1, 2, 5], [16, 35, 0, 6, 1], [15, 8, 31, 3, 5], [2, 4, 1, 69, 1], [20, 8, 0, 0, 32]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5583333333333333, 'recall': 0.8701298701298701, 'f1': 0.6802030456852792, 'support': 77}, {'label': 'entertainment', 'precision': 0.6140350877192983, 'recall': 0.603448275862069, 'f1': 0.6086956521739131, 'support': 58}, {'label': 'politics', 'precision': 0.9393939393939394, 'recall': 0.5, 'f1': 0.6526315789473685, 'support': 62}, {'label': 'sport', 'precision': 0.8625, 'recall': 0.8961038961038961, 'f1': 0.8789808917197452, 'support': 77}, {'label': 'tech', 'precision': 0.7272727272727273, 'recall': 0.5333333333333333, 'f1': 0.6153846153846154, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.9_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:58:38.474626', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.8900635242462158, 'features_extracted': 10000, 'reduction_time': 5.722158193588257, 'features_after_reduction': 1020, 'metrics': {'accuracy': 0.8952095808383234, 'precision': 0.899626418977544, 'recall': 0.8952095808383234, 'f1_score': 0.8962460511473116}, 'performance': {'train_time_seconds': 1.558765172958374, 'total_time_seconds': 9.170986890792847, 'inference_time_ms_per_sample': 0.002853884668407326}, 'confusion_matrix': [[69, 3, 4, 0, 1], [0, 53, 3, 0, 2], [3, 6, 52, 1, 0], [1, 2, 1, 73, 0], [3, 3, 2, 0, 52]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9078947368421053, 'recall': 0.8961038961038961, 'f1': 0.9019607843137255, 'support': 77}, {'label': 'entertainment', 'precision': 0.7910447761194029, 'recall': 0.9137931034482759, 'f1': 0.848, 'support': 58}, {'label': 'politics', 'precision': 0.8387096774193549, 'recall': 0.8387096774193549, 'f1': 0.8387096774193549, 'support': 62}, {'label': 'sport', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'tech', 'precision': 0.9454545454545454, 'recall': 0.8666666666666667, 'f1': 0.9043478260869565, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.95_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:56:24.364310', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.8565583229064941, 'features_extracted': 5000, 'reduction_time': 3.2437186241149902, 'features_after_reduction': 1105, 'metrics': {'accuracy': 0.907185628742515, 'precision': 0.9076164806482937, 'recall': 0.907185628742515, 'f1_score': 0.906852405325547}, 'performance': {'train_time_seconds': 1.614004135131836, 'total_time_seconds': 6.71428108215332, 'inference_time_ms_per_sample': 0.003341429247827587}, 'confusion_matrix': [[72, 1, 2, 0, 2], [2, 48, 3, 3, 2], [3, 1, 54, 1, 3], [0, 1, 1, 75, 0], [1, 1, 4, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9230769230769231, 'recall': 0.935064935064935, 'f1': 0.9290322580645162, 'support': 77}, {'label': 'entertainment', 'precision': 0.9230769230769231, 'recall': 0.8275862068965517, 'f1': 0.8727272727272727, 'support': 58}, {'label': 'politics', 'precision': 0.84375, 'recall': 0.8709677419354839, 'f1': 0.8571428571428571, 'support': 62}, {'label': 'sport', 'precision': 0.9493670886075949, 'recall': 0.974025974025974, 'f1': 0.9615384615384616, 'support': 77}, {'label': 'tech', 'precision': 0.8852459016393442, 'recall': 0.9, 'f1': 0.8925619834710744, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T15:51:55.117621', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.4912276268005371, 'features_extracted': 10000, 'reduction_time': 0.2580835819244385, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9539892802626376, 'recall': 0.9520958083832335, 'f1_score': 0.9522534682228914}, 'performance': {'train_time_seconds': 0.20061969757080078, 'total_time_seconds': 0.9499309062957764, 'inference_time_ms_per_sample': 0.09753604135113562}, 'confusion_matrix': [[74, 0, 0, 1, 2], [2, 53, 0, 3, 0], [2, 0, 59, 1, 0], [1, 0, 0, 76, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9024390243902439, 'recall': 0.961038961038961, 'f1': 0.9308176100628931, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9137931034482759, 'f1': 0.954954954954955, 'support': 58}, {'label': 'politics', 'precision': 0.9833333333333333, 'recall': 0.9516129032258065, 'f1': 0.9672131147540983, 'support': 62}, {'label': 'sport', 'precision': 0.9382716049382716, 'recall': 0.987012987012987, 'f1': 0.9620253164556962, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.95_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T15:51:28.238754', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.590538501739502, 'features_extracted': 10000, 'reduction_time': 5.624318838119507, 'features_after_reduction': 789, 'metrics': {'accuracy': 0.7365269461077845, 'precision': 0.7933703002697484, 'recall': 0.7365269461077845, 'f1_score': 0.7294144419177057}, 'performance': {'train_time_seconds': 0.007956743240356445, 'total_time_seconds': 7.222814083099365, 'inference_time_ms_per_sample': 0.35204501922972903}, 'confusion_matrix': [[73, 1, 1, 1, 1], [10, 41, 0, 7, 0], [19, 10, 29, 4, 0], [3, 3, 0, 70, 1], [19, 6, 0, 2, 33]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5887096774193549, 'recall': 0.948051948051948, 'f1': 0.7263681592039801, 'support': 77}, {'label': 'entertainment', 'precision': 0.6721311475409836, 'recall': 0.7068965517241379, 'f1': 0.6890756302521008, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.46774193548387094, 'f1': 0.6304347826086957, 'support': 62}, {'label': 'sport', 'precision': 0.8333333333333334, 'recall': 0.9090909090909091, 'f1': 0.8695652173913043, 'support': 77}, {'label': 'tech', 'precision': 0.9428571428571428, 'recall': 0.55, 'f1': 0.6947368421052632, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:54:48.602922', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.5653061866760254, 'features_extracted': 5000, 'reduction_time': 0.13403797149658203, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7754491017964071, 'precision': 0.80293509290231, 'recall': 0.7754491017964071, 'f1_score': 0.7803227950230056}, 'performance': {'train_time_seconds': 0.11061239242553711, 'total_time_seconds': 1.8099565505981445, 'inference_time_ms_per_sample': 0.002439864381344732}, 'confusion_matrix': [[63, 2, 6, 1, 5], [11, 38, 4, 5, 0], [16, 1, 43, 1, 1], [9, 1, 0, 67, 0], [10, 1, 1, 0, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5779816513761468, 'recall': 0.8181818181818182, 'f1': 0.6774193548387096, 'support': 77}, {'label': 'entertainment', 'precision': 0.8837209302325582, 'recall': 0.6551724137931034, 'f1': 0.7524752475247525, 'support': 58}, {'label': 'politics', 'precision': 0.7962962962962963, 'recall': 0.6935483870967742, 'f1': 0.7413793103448276, 'support': 62}, {'label': 'sport', 'precision': 0.9054054054054054, 'recall': 0.8701298701298701, 'f1': 0.8874172185430463, 'support': 77}, {'label': 'tech', 'precision': 0.8888888888888888, 'recall': 0.8, 'f1': 0.8421052631578947, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.95_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T15:45:16.404474', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.49268674850463867, 'features_extracted': 10000, 'reduction_time': 5.705710172653198, 'features_after_reduction': 716, 'metrics': {'accuracy': 0.7215568862275449, 'precision': 0.7679710696583111, 'recall': 0.7215568862275449, 'f1_score': 0.7185830980037243}, 'performance': {'train_time_seconds': 0.010819673538208008, 'total_time_seconds': 6.209216594696045, 'inference_time_ms_per_sample': 0.3630072770718329}, 'confusion_matrix': [[72, 2, 2, 1, 0], [13, 37, 0, 8, 0], [19, 8, 33, 2, 0], [3, 5, 3, 66, 0], [16, 7, 3, 1, 33]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5853658536585366, 'recall': 0.935064935064935, 'f1': 0.72, 'support': 77}, {'label': 'entertainment', 'precision': 0.6271186440677966, 'recall': 0.6379310344827587, 'f1': 0.6324786324786325, 'support': 58}, {'label': 'politics', 'precision': 0.8048780487804879, 'recall': 0.532258064516129, 'f1': 0.6407766990291263, 'support': 62}, {'label': 'sport', 'precision': 0.8461538461538461, 'recall': 0.8571428571428571, 'f1': 0.8516129032258064, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.55, 'f1': 0.7096774193548387, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.95_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:50:45.998727', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.703526496887207, 'features_extracted': 10000, 'reduction_time': 5.930224418640137, 'features_after_reduction': 789, 'metrics': {'accuracy': 0.7844311377245509, 'precision': 0.8106885810966022, 'recall': 0.7844311377245509, 'f1_score': 0.7797714633615306}, 'performance': {'train_time_seconds': 0.34963536262512207, 'total_time_seconds': 7.983386278152466, 'inference_time_ms_per_sample': 0.10388768361714072}, 'confusion_matrix': [[71, 0, 3, 3, 0], [7, 34, 0, 16, 1], [9, 2, 42, 8, 1], [2, 1, 0, 74, 0], [10, 3, 3, 3, 41]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7171717171717171, 'recall': 0.922077922077922, 'f1': 0.8068181818181818, 'support': 77}, {'label': 'entertainment', 'precision': 0.85, 'recall': 0.5862068965517241, 'f1': 0.6938775510204082, 'support': 58}, {'label': 'politics', 'precision': 0.875, 'recall': 0.6774193548387096, 'f1': 0.7636363636363637, 'support': 62}, {'label': 'sport', 'precision': 0.7115384615384616, 'recall': 0.961038961038961, 'f1': 0.8176795580110497, 'support': 77}, {'label': 'tech', 'precision': 0.9534883720930233, 'recall': 0.6833333333333333, 'f1': 0.7961165048543689, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.9_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T15:59:02.338083', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.7279367446899414, 'features_extracted': 10000, 'reduction_time': 5.355876445770264, 'features_after_reduction': 1020, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.950506886258197, 'recall': 0.9491017964071856, 'f1_score': 0.9490425741922748}, 'performance': {'train_time_seconds': 0.0249481201171875, 'total_time_seconds': 7.108761310577393, 'inference_time_ms_per_sample': 0.36467192415705696}, 'confusion_matrix': [[70, 1, 5, 1, 0], [1, 52, 3, 1, 1], [1, 0, 60, 1, 0], [1, 0, 0, 76, 0], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.958904109589041, 'recall': 0.9090909090909091, 'f1': 0.9333333333333333, 'support': 77}, {'label': 'entertainment', 'precision': 0.9629629629629629, 'recall': 0.896551724137931, 'f1': 0.9285714285714286, 'support': 58}, {'label': 'politics', 'precision': 0.8823529411764706, 'recall': 0.967741935483871, 'f1': 0.9230769230769231, 'support': 62}, {'label': 'sport', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T15:42:57.251389', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.489307165145874, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7245508982035929, 'precision': 0.7609437560397708, 'recall': 0.7245508982035929, 'f1_score': 0.7208932968669342}, 'performance': {'train_time_seconds': 0.002279996871948242, 'total_time_seconds': 0.49158716201782227, 'inference_time_ms_per_sample': 0.43834326509943977}, 'confusion_matrix': [[70, 1, 1, 2, 3], [17, 33, 0, 8, 0], [14, 5, 38, 5, 0], [1, 5, 3, 68, 0], [15, 8, 0, 4, 33]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5982905982905983, 'recall': 0.9090909090909091, 'f1': 0.7216494845360825, 'support': 77}, {'label': 'entertainment', 'precision': 0.6346153846153846, 'recall': 0.5689655172413793, 'f1': 0.6, 'support': 58}, {'label': 'politics', 'precision': 0.9047619047619048, 'recall': 0.6129032258064516, 'f1': 0.7307692307692307, 'support': 62}, {'label': 'sport', 'precision': 0.7816091954022989, 'recall': 0.8831168831168831, 'f1': 0.8292682926829268, 'support': 77}, {'label': 'tech', 'precision': 0.9166666666666666, 'recall': 0.55, 'f1': 0.6875, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.9_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:49:08.057893', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.668715000152588, 'features_extracted': 10000, 'reduction_time': 5.981519460678101, 'features_after_reduction': 515, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582447541728911, 'recall': 0.9580838323353293, 'f1_score': 0.9579974686617265}, 'performance': {'train_time_seconds': 0.23607945442199707, 'total_time_seconds': 7.8863139152526855, 'inference_time_ms_per_sample': 0.0018545253548079622}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T15:45:58.476615', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.7478103637695312, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7425149700598802, 'precision': 0.7638039943989258, 'recall': 0.7425149700598802, 'f1_score': 0.7381551353808873}, 'performance': {'train_time_seconds': 0.0027217864990234375, 'total_time_seconds': 1.7505321502685547, 'inference_time_ms_per_sample': 0.4601878320385596}, 'confusion_matrix': [[68, 1, 1, 2, 5], [5, 43, 0, 10, 0], [11, 9, 35, 6, 1], [1, 6, 0, 67, 3], [15, 8, 2, 0, 35]], 'per_class_metrics': [{'label': 'business', 'precision': 0.68, 'recall': 0.8831168831168831, 'f1': 0.768361581920904, 'support': 77}, {'label': 'entertainment', 'precision': 0.6417910447761194, 'recall': 0.7413793103448276, 'f1': 0.688, 'support': 58}, {'label': 'politics', 'precision': 0.9210526315789473, 'recall': 0.5645161290322581, 'f1': 0.7, 'support': 62}, {'label': 'sport', 'precision': 0.788235294117647, 'recall': 0.8701298701298701, 'f1': 0.8271604938271605, 'support': 77}, {'label': 'tech', 'precision': 0.7954545454545454, 'recall': 0.5833333333333334, 'f1': 0.6730769230769231, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.95_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:44:31.106431', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5465126037597656, 'features_extracted': 10000, 'reduction_time': 5.770796298980713, 'features_after_reduction': 716, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.9609703683453901, 'recall': 0.9610778443113772, 'f1_score': 0.9609652704932733}, 'performance': {'train_time_seconds': 0.27828168869018555, 'total_time_seconds': 6.595590591430664, 'inference_time_ms_per_sample': 0.0022314265816511508}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 57, 1, 0, 0], [2, 0, 58, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T15:48:35.039723', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.6692156791687012, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7365269461077845, 'precision': 0.7875542750976036, 'recall': 0.7365269461077845, 'f1_score': 0.7337345942676484}, 'performance': {'train_time_seconds': 0.0029692649841308594, 'total_time_seconds': 1.672184944152832, 'inference_time_ms_per_sample': 0.43858168367854133}, 'confusion_matrix': [[71, 1, 1, 2, 2], [12, 38, 0, 8, 0], [17, 7, 34, 4, 0], [4, 2, 0, 70, 1], [21, 5, 1, 0, 33]], 'per_class_metrics': [{'label': 'business', 'precision': 0.568, 'recall': 0.922077922077922, 'f1': 0.7029702970297029, 'support': 77}, {'label': 'entertainment', 'precision': 0.7169811320754716, 'recall': 0.6551724137931034, 'f1': 0.6846846846846847, 'support': 58}, {'label': 'politics', 'precision': 0.9444444444444444, 'recall': 0.5483870967741935, 'f1': 0.6938775510204082, 'support': 62}, {'label': 'sport', 'precision': 0.8333333333333334, 'recall': 0.9090909090909091, 'f1': 0.8695652173913043, 'support': 77}, {'label': 'tech', 'precision': 0.9166666666666666, 'recall': 0.55, 'f1': 0.6875, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:54:23.722489', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.5865721702575684, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.979473277976272, 'recall': 0.9790419161676647, 'f1_score': 0.9790700186944252}, 'performance': {'train_time_seconds': 0.6956045627593994, 'total_time_seconds': 2.2821767330169678, 'inference_time_ms_per_sample': 0.003036624657179781}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.9_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:46:25.433398', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6021318435668945, 'features_extracted': 5000, 'reduction_time': 4.3184428215026855, 'features_after_reduction': 420, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.9640676528130293, 'recall': 0.9640718562874252, 'f1_score': 0.9640074141927214}, 'performance': {'train_time_seconds': 0.3014211654663086, 'total_time_seconds': 6.221995830535889, 'inference_time_ms_per_sample': 0.005863383858503696}, 'confusion_matrix': [[73, 1, 2, 0, 1], [1, 55, 1, 1, 0], [1, 1, 59, 1, 0], [0, 0, 0, 77, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.948051948051948, 'recall': 0.948051948051948, 'f1': 0.948051948051948, 'support': 77}, {'label': 'entertainment', 'precision': 0.9649122807017544, 'recall': 0.9482758620689655, 'f1': 0.9565217391304348, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.9_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:46:37.012466', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5795366764068604, 'features_extracted': 5000, 'reduction_time': 3.636641502380371, 'features_after_reduction': 420, 'metrics': {'accuracy': 0.8293413173652695, 'precision': 0.847537012169918, 'recall': 0.8293413173652695, 'f1_score': 0.8277167500640277}, 'performance': {'train_time_seconds': 0.3823509216308594, 'total_time_seconds': 5.598529100418091, 'inference_time_ms_per_sample': 0.1154274283768888}, 'confusion_matrix': [[72, 1, 2, 2, 0], [6, 38, 0, 14, 0], [5, 0, 49, 7, 1], [2, 1, 1, 73, 0], [8, 4, 1, 2, 45]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7741935483870968, 'recall': 0.935064935064935, 'f1': 0.8470588235294118, 'support': 77}, {'label': 'entertainment', 'precision': 0.8636363636363636, 'recall': 0.6551724137931034, 'f1': 0.7450980392156863, 'support': 58}, {'label': 'politics', 'precision': 0.9245283018867925, 'recall': 0.7903225806451613, 'f1': 0.8521739130434782, 'support': 62}, {'label': 'sport', 'precision': 0.7448979591836735, 'recall': 0.948051948051948, 'f1': 0.8342857142857143, 'support': 77}, {'label': 'tech', 'precision': 0.9782608695652174, 'recall': 0.75, 'f1': 0.8490566037735849, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.9_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:43:24.445913', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5307941436767578, 'features_extracted': 10000, 'reduction_time': 5.5305376052856445, 'features_after_reduction': 446, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9553666788698633, 'recall': 0.9550898203592815, 'f1_score': 0.9550008050524863}, 'performance': {'train_time_seconds': 0.12079048156738281, 'total_time_seconds': 6.182122230529785, 'inference_time_ms_per_sample': 0.0019080624608936423}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 55, 1, 1, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.921875, 'recall': 0.9516129032258065, 'f1': 0.9365079365079365, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.95_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:53:41.932620', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.4872701168060303, 'features_extracted': 10000, 'reduction_time': 5.454740285873413, 'features_after_reduction': 1191, 'metrics': {'accuracy': 0.9191616766467066, 'precision': 0.9216909685037854, 'recall': 0.9191616766467066, 'f1_score': 0.9198425371467157}, 'performance': {'train_time_seconds': 1.9254834651947021, 'total_time_seconds': 7.8674938678741455, 'inference_time_ms_per_sample': 0.003200805115842534}, 'confusion_matrix': [[72, 1, 3, 1, 0], [0, 53, 4, 0, 1], [4, 0, 54, 3, 1], [1, 0, 2, 74, 0], [0, 1, 4, 1, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.935064935064935, 'recall': 0.935064935064935, 'f1': 0.935064935064935, 'support': 77}, {'label': 'entertainment', 'precision': 0.9636363636363636, 'recall': 0.9137931034482759, 'f1': 0.9380530973451328, 'support': 58}, {'label': 'politics', 'precision': 0.8059701492537313, 'recall': 0.8709677419354839, 'f1': 0.8372093023255814, 'support': 62}, {'label': 'sport', 'precision': 0.9367088607594937, 'recall': 0.961038961038961, 'f1': 0.9487179487179487, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:42:56.225018', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.4839131832122803, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7745991635492975, 'recall': 0.7694610778443114, 'f1_score': 0.7704612545590968}, 'performance': {'train_time_seconds': 0.5342180728912354, 'total_time_seconds': 1.0181312561035156, 'inference_time_ms_per_sample': 0.0027560902212908165}, 'confusion_matrix': [[56, 1, 11, 3, 6], [4, 42, 4, 7, 1], [9, 2, 45, 3, 3], [3, 3, 5, 65, 1], [7, 0, 3, 1, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7088607594936709, 'recall': 0.7272727272727273, 'f1': 0.717948717948718, 'support': 77}, {'label': 'entertainment', 'precision': 0.875, 'recall': 0.7241379310344828, 'f1': 0.7924528301886793, 'support': 58}, {'label': 'politics', 'precision': 0.6617647058823529, 'recall': 0.7258064516129032, 'f1': 0.6923076923076923, 'support': 62}, {'label': 'sport', 'precision': 0.8227848101265823, 'recall': 0.8441558441558441, 'f1': 0.8333333333333334, 'support': 77}, {'label': 'tech', 'precision': 0.8166666666666667, 'recall': 0.8166666666666667, 'f1': 0.8166666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:57:29.005085', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.769670009613037, 'features_extracted': 10000, 'reduction_time': 0.2945125102996826, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7874251497005988, 'precision': 0.8050414215989689, 'recall': 0.7874251497005988, 'f1_score': 0.7906945506324907}, 'performance': {'train_time_seconds': 0.1202387809753418, 'total_time_seconds': 2.1844213008880615, 'inference_time_ms_per_sample': 0.0029324057573329905}, 'confusion_matrix': [[63, 1, 7, 2, 4], [7, 42, 3, 5, 1], [16, 1, 43, 1, 1], [7, 2, 0, 68, 0], [9, 2, 2, 0, 47]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6176470588235294, 'recall': 0.8181818181818182, 'f1': 0.7039106145251397, 'support': 77}, {'label': 'entertainment', 'precision': 0.875, 'recall': 0.7241379310344828, 'f1': 0.7924528301886793, 'support': 58}, {'label': 'politics', 'precision': 0.7818181818181819, 'recall': 0.6935483870967742, 'f1': 0.7350427350427351, 'support': 62}, {'label': 'sport', 'precision': 0.8947368421052632, 'recall': 0.8831168831168831, 'f1': 0.8888888888888888, 'support': 77}, {'label': 'tech', 'precision': 0.8867924528301887, 'recall': 0.7833333333333333, 'f1': 0.831858407079646, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T15:42:57.897341', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.47392868995666504, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7395209580838323, 'precision': 0.7783247856731887, 'recall': 0.7395209580838323, 'f1_score': 0.7330287924859743}, 'performance': {'train_time_seconds': 0.0024597644805908203, 'total_time_seconds': 0.47638845443725586, 'inference_time_ms_per_sample': 0.43837181822268545}, 'confusion_matrix': [[72, 0, 1, 2, 2], [19, 31, 1, 7, 0], [14, 4, 35, 9, 0], [2, 0, 2, 72, 1], [14, 4, 2, 3, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5950413223140496, 'recall': 0.935064935064935, 'f1': 0.7272727272727273, 'support': 77}, {'label': 'entertainment', 'precision': 0.7948717948717948, 'recall': 0.5344827586206896, 'f1': 0.6391752577319587, 'support': 58}, {'label': 'politics', 'precision': 0.8536585365853658, 'recall': 0.5645161290322581, 'f1': 0.6796116504854369, 'support': 62}, {'label': 'sport', 'precision': 0.7741935483870968, 'recall': 0.935064935064935, 'f1': 0.8470588235294118, 'support': 77}, {'label': 'tech', 'precision': 0.925, 'recall': 0.6166666666666667, 'f1': 0.74, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:48:31.093922', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5343542098999023, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7729690257820706, 'recall': 0.7694610778443114, 'f1_score': 0.7695580602879214}, 'performance': {'train_time_seconds': 0.6842622756958008, 'total_time_seconds': 2.218616485595703, 'inference_time_ms_per_sample': 0.002998077940798091}, 'confusion_matrix': [[56, 3, 11, 2, 5], [5, 39, 6, 7, 1], [8, 2, 46, 2, 4], [2, 4, 3, 67, 1], [6, 0, 4, 1, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7272727272727273, 'recall': 0.7272727272727273, 'f1': 0.7272727272727273, 'support': 77}, {'label': 'entertainment', 'precision': 0.8125, 'recall': 0.6724137931034483, 'f1': 0.7358490566037735, 'support': 58}, {'label': 'politics', 'precision': 0.6571428571428571, 'recall': 0.7419354838709677, 'f1': 0.696969696969697, 'support': 62}, {'label': 'sport', 'precision': 0.8481012658227848, 'recall': 0.8701298701298701, 'f1': 0.8589743589743589, 'support': 77}, {'label': 'tech', 'precision': 0.8166666666666667, 'recall': 0.8166666666666667, 'f1': 0.8166666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.95_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:47:27.403961', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6223187446594238, 'features_extracted': 5000, 'reduction_time': 3.920534372329712, 'features_after_reduction': 673, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9554331988562674, 'recall': 0.9550898203592815, 'f1_score': 0.9549566247963424}, 'performance': {'train_time_seconds': 0.13353633880615234, 'total_time_seconds': 5.676389455795288, 'inference_time_ms_per_sample': 0.002130776822210072}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 54, 1, 2, 0], [1, 1, 58, 2, 0], [0, 0, 0, 77, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9642857142857143, 'recall': 0.9310344827586207, 'f1': 0.9473684210526315, 'support': 58}, {'label': 'politics', 'precision': 0.9508196721311475, 'recall': 0.9354838709677419, 'f1': 0.943089430894309, 'support': 62}, {'label': 'sport', 'precision': 0.9390243902439024, 'recall': 1.0, 'f1': 0.9685534591194969, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:57:21.946335', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.840003252029419, 'features_extracted': 10000, 'reduction_time': 0.2700939178466797, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9762177696346824, 'recall': 0.9760479041916168, 'f1_score': 0.9760627347119369}, 'performance': {'train_time_seconds': 0.14048457145690918, 'total_time_seconds': 2.250581741333008, 'inference_time_ms_per_sample': 0.003199377459680249}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 57, 1, 0, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9736842105263158, 'recall': 0.961038961038961, 'f1': 0.9673202614379085, 'support': 77}, {'label': 'entertainment', 'precision': 0.95, 'recall': 0.9827586206896551, 'f1': 0.9661016949152542, 'support': 58}, {'label': 'politics', 'precision': 0.967741935483871, 'recall': 0.967741935483871, 'f1': 0.967741935483871, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:54:39.246559', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.573479413986206, 'features_extracted': 5000, 'reduction_time': 0.1372239589691162, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9821894672194074, 'recall': 0.9820359281437125, 'f1_score': 0.9820447945990619}, 'performance': {'train_time_seconds': 0.012371301651000977, 'total_time_seconds': 1.7230746746063232, 'inference_time_ms_per_sample': 0.003087306450940892}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 57, 0, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:51:43.439776', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5374312400817871, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9940119760479041, 'precision': 0.9940503608168278, 'recall': 0.9940119760479041, 'f1_score': 0.9940086167076787}, 'performance': {'train_time_seconds': 0.6914181709289551, 'total_time_seconds': 1.2288494110107422, 'inference_time_ms_per_sample': 0.003137988244702002}, 'confusion_matrix': [[77, 0, 0, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9838709677419355, 'recall': 0.9838709677419355, 'f1': 0.9838709677419355, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.95_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:47:33.108637', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.7525701522827148, 'features_extracted': 5000, 'reduction_time': 4.006173372268677, 'features_after_reduction': 673, 'metrics': {'accuracy': 0.8083832335329342, 'precision': 0.8233685709308761, 'recall': 0.8083832335329342, 'f1_score': 0.8053789365433826}, 'performance': {'train_time_seconds': 0.3318459987640381, 'total_time_seconds': 6.09058952331543, 'inference_time_ms_per_sample': 0.10299825382803729}, 'confusion_matrix': [[72, 1, 4, 0, 0], [5, 36, 0, 16, 1], [4, 0, 46, 10, 2], [3, 1, 2, 71, 0], [9, 3, 3, 0, 45]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7741935483870968, 'recall': 0.935064935064935, 'f1': 0.8470588235294118, 'support': 77}, {'label': 'entertainment', 'precision': 0.8780487804878049, 'recall': 0.6206896551724138, 'f1': 0.7272727272727273, 'support': 58}, {'label': 'politics', 'precision': 0.8363636363636363, 'recall': 0.7419354838709677, 'f1': 0.7863247863247863, 'support': 62}, {'label': 'sport', 'precision': 0.7319587628865979, 'recall': 0.922077922077922, 'f1': 0.8160919540229885, 'support': 77}, {'label': 'tech', 'precision': 0.9375, 'recall': 0.75, 'f1': 0.8333333333333334, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T15:54:53.931734', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.5518064498901367, 'features_extracted': 5000, 'reduction_time': 0.13871312141418457, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8652694610778443, 'precision': 0.880353034049008, 'recall': 0.8652694610778443, 'f1_score': 0.8652916241278586}, 'performance': {'train_time_seconds': 0.011000394821166992, 'total_time_seconds': 1.7015199661254883, 'inference_time_ms_per_sample': 0.09612123409431138}, 'confusion_matrix': [[69, 3, 2, 3, 0], [0, 56, 1, 1, 0], [8, 0, 53, 1, 0], [0, 6, 1, 69, 1], [7, 11, 0, 0, 42]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8214285714285714, 'recall': 0.8961038961038961, 'f1': 0.8571428571428571, 'support': 77}, {'label': 'entertainment', 'precision': 0.7368421052631579, 'recall': 0.9655172413793104, 'f1': 0.835820895522388, 'support': 58}, {'label': 'politics', 'precision': 0.9298245614035088, 'recall': 0.8548387096774194, 'f1': 0.8907563025210085, 'support': 62}, {'label': 'sport', 'precision': 0.9324324324324325, 'recall': 0.8961038961038961, 'f1': 0.9139072847682119, 'support': 77}, {'label': 'tech', 'precision': 0.9767441860465116, 'recall': 0.7, 'f1': 0.8155339805825242, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.95_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T15:53:57.991454', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.45908308029174805, 'features_extracted': 10000, 'reduction_time': 8.235322952270508, 'features_after_reduction': 1191, 'metrics': {'accuracy': 0.9221556886227545, 'precision': 0.9302486878469781, 'recall': 0.9221556886227545, 'f1_score': 0.9220051629983663}, 'performance': {'train_time_seconds': 0.01758742332458496, 'total_time_seconds': 8.71199345588684, 'inference_time_ms_per_sample': 0.3452515173814968}, 'confusion_matrix': [[62, 1, 12, 1, 1], [1, 51, 2, 1, 3], [0, 0, 61, 0, 1], [1, 0, 0, 75, 1], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.96875, 'recall': 0.8051948051948052, 'f1': 0.8794326241134752, 'support': 77}, {'label': 'entertainment', 'precision': 0.9807692307692307, 'recall': 0.8793103448275862, 'f1': 0.9272727272727272, 'support': 58}, {'label': 'politics', 'precision': 0.8026315789473685, 'recall': 0.9838709677419355, 'f1': 0.8840579710144928, 'support': 62}, {'label': 'sport', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'tech', 'precision': 0.9076923076923077, 'recall': 0.9833333333333333, 'f1': 0.944, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:48:49.450157', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.576235294342041, 'features_extracted': 10000, 'reduction_time': 0.26473379135131836, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.781437125748503, 'precision': 0.7969858907976859, 'recall': 0.781437125748503, 'f1_score': 0.7810521457546135}, 'performance': {'train_time_seconds': 0.08637499809265137, 'total_time_seconds': 1.9273440837860107, 'inference_time_ms_per_sample': 0.002437009069020163}, 'confusion_matrix': [[63, 1, 4, 5, 4], [7, 39, 4, 7, 1], [16, 1, 40, 3, 2], [5, 1, 0, 71, 0], [7, 1, 2, 2, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6428571428571429, 'recall': 0.8181818181818182, 'f1': 0.72, 'support': 77}, {'label': 'entertainment', 'precision': 0.9069767441860465, 'recall': 0.6724137931034483, 'f1': 0.7722772277227723, 'support': 58}, {'label': 'politics', 'precision': 0.8, 'recall': 0.6451612903225806, 'f1': 0.7142857142857143, 'support': 62}, {'label': 'sport', 'precision': 0.8068181818181818, 'recall': 0.922077922077922, 'f1': 0.8606060606060606, 'support': 77}, {'label': 'tech', 'precision': 0.8727272727272727, 'recall': 0.8, 'f1': 0.8347826086956521, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.95_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:44:24.407979', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.481701135635376, 'features_extracted': 10000, 'reduction_time': 6.166067361831665, 'features_after_reduction': 716, 'metrics': {'accuracy': 0.4880239520958084, 'precision': 0.5064255721537791, 'recall': 0.4880239520958084, 'f1_score': 0.48488961800355646}, 'performance': {'train_time_seconds': 0.012621164321899414, 'total_time_seconds': 6.66038966178894, 'inference_time_ms_per_sample': 0.002249272283679711}, 'confusion_matrix': [[27, 6, 10, 20, 14], [2, 28, 4, 21, 3], [6, 2, 29, 17, 8], [3, 6, 12, 50, 6], [9, 4, 12, 6, 29]], 'per_class_metrics': [{'label': 'business', 'precision': 0.574468085106383, 'recall': 0.35064935064935066, 'f1': 0.43548387096774194, 'support': 77}, {'label': 'entertainment', 'precision': 0.6086956521739131, 'recall': 0.4827586206896552, 'f1': 0.5384615384615384, 'support': 58}, {'label': 'politics', 'precision': 0.43283582089552236, 'recall': 0.46774193548387094, 'f1': 0.4496124031007752, 'support': 62}, {'label': 'sport', 'precision': 0.43859649122807015, 'recall': 0.6493506493506493, 'f1': 0.5235602094240838, 'support': 77}, {'label': 'tech', 'precision': 0.48333333333333334, 'recall': 0.48333333333333334, 'f1': 0.48333333333333334, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.9_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:55:20.654059', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.8640756607055664, 'features_extracted': 5000, 'reduction_time': 3.5862700939178467, 'features_after_reduction': 906, 'metrics': {'accuracy': 0.9700598802395209, 'precision': 0.9702456771539004, 'recall': 0.9700598802395209, 'f1_score': 0.969940203638071}, 'performance': {'train_time_seconds': 0.3608078956604004, 'total_time_seconds': 5.8111536502838135, 'inference_time_ms_per_sample': 0.10393479627049611}, 'confusion_matrix': [[75, 1, 1, 0, 0], [1, 54, 2, 0, 1], [3, 0, 58, 0, 1], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9493670886075949, 'recall': 0.974025974025974, 'f1': 0.9615384615384616, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9508196721311475, 'recall': 0.9354838709677419, 'f1': 0.943089430894309, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.967741935483871, 'recall': 1.0, 'f1': 0.9836065573770492, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T15:45:47.320637', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5861318111419678, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9341317365269461, 'precision': 0.9371524981226631, 'recall': 0.9341317365269461, 'f1_score': 0.9341038322810605}, 'performance': {'train_time_seconds': 0.20647907257080078, 'total_time_seconds': 1.7926108837127686, 'inference_time_ms_per_sample': 0.09950834833933209}, 'confusion_matrix': [[73, 0, 3, 0, 1], [3, 50, 1, 3, 1], [4, 0, 57, 1, 0], [0, 0, 0, 77, 0], [4, 0, 1, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8690476190476191, 'recall': 0.948051948051948, 'f1': 0.906832298136646, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.8620689655172413, 'f1': 0.9259259259259259, 'support': 58}, {'label': 'politics', 'precision': 0.9193548387096774, 'recall': 0.9193548387096774, 'f1': 0.9193548387096774, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:43:05.397806', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.5081326961517334, 'features_extracted': 10000, 'reduction_time': 0.27616095542907715, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7994011976047904, 'precision': 0.8019461495985645, 'recall': 0.7994011976047904, 'f1_score': 0.7987767407459456}, 'performance': {'train_time_seconds': 0.1257483959197998, 'total_time_seconds': 0.9100420475006104, 'inference_time_ms_per_sample': 0.0030387661414232083}, 'confusion_matrix': [[62, 2, 6, 3, 4], [5, 40, 6, 5, 2], [10, 2, 45, 3, 2], [2, 3, 2, 70, 0], [7, 1, 2, 0, 50]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7209302325581395, 'recall': 0.8051948051948052, 'f1': 0.7607361963190185, 'support': 77}, {'label': 'entertainment', 'precision': 0.8333333333333334, 'recall': 0.6896551724137931, 'f1': 0.7547169811320755, 'support': 58}, {'label': 'politics', 'precision': 0.7377049180327869, 'recall': 0.7258064516129032, 'f1': 0.7317073170731707, 'support': 62}, {'label': 'sport', 'precision': 0.8641975308641975, 'recall': 0.9090909090909091, 'f1': 0.8860759493670886, 'support': 77}, {'label': 'tech', 'precision': 0.8620689655172413, 'recall': 0.8333333333333334, 'f1': 0.847457627118644, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.9_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:55:09.244575', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.8492505550384521, 'features_extracted': 5000, 'reduction_time': 3.7371456623077393, 'features_after_reduction': 906, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.979473277976272, 'recall': 0.9790419161676647, 'f1_score': 0.9790700186944252}, 'performance': {'train_time_seconds': 0.1078188419342041, 'total_time_seconds': 5.6942150592803955, 'inference_time_ms_per_sample': 0.002766797642507953}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:42:46.363377', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.521425724029541, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9495031171269279, 'recall': 0.9491017964071856, 'f1_score': 0.948947654663291}, 'performance': {'train_time_seconds': 4.482425928115845, 'total_time_seconds': 5.003851652145386, 'inference_time_ms_per_sample': 0.00484260970247006}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 55, 1, 2, 0], [2, 1, 57, 2, 0], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9344262295081968, 'recall': 0.9193548387096774, 'f1': 0.926829268292683, 'support': 62}, {'label': 'sport', 'precision': 0.9390243902439024, 'recall': 1.0, 'f1': 0.9685534591194969, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.9_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:49:49.138851', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5375630855560303, 'features_extracted': 10000, 'reduction_time': 5.8972930908203125, 'features_after_reduction': 515, 'metrics': {'accuracy': 0.6497005988023952, 'precision': 0.6469581513664401, 'recall': 0.6497005988023952, 'f1_score': 0.64759554495832}, 'performance': {'train_time_seconds': 0.8936848640441895, 'total_time_seconds': 8.328541040420532, 'inference_time_ms_per_sample': 0.0016846342714960704}, 'confusion_matrix': [[54, 8, 7, 2, 6], [5, 28, 7, 12, 6], [9, 6, 35, 8, 4], [2, 6, 5, 62, 2], [10, 9, 3, 0, 38]], 'per_class_metrics': [{'label': 'business', 'precision': 0.675, 'recall': 0.7012987012987013, 'f1': 0.6878980891719745, 'support': 77}, {'label': 'entertainment', 'precision': 0.49122807017543857, 'recall': 0.4827586206896552, 'f1': 0.48695652173913045, 'support': 58}, {'label': 'politics', 'precision': 0.6140350877192983, 'recall': 0.5645161290322581, 'f1': 0.5882352941176471, 'support': 62}, {'label': 'sport', 'precision': 0.7380952380952381, 'recall': 0.8051948051948052, 'f1': 0.7701863354037267, 'support': 77}, {'label': 'tech', 'precision': 0.6785714285714286, 'recall': 0.6333333333333333, 'f1': 0.6551724137931034, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.9_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T15:44:07.949686', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.4816932678222656, 'features_extracted': 10000, 'reduction_time': 6.946938753128052, 'features_after_reduction': 446, 'metrics': {'accuracy': 0.7365269461077845, 'precision': 0.7663733809914086, 'recall': 0.7365269461077845, 'f1_score': 0.7307464440044963}, 'performance': {'train_time_seconds': 0.0077266693115234375, 'total_time_seconds': 7.436358690261841, 'inference_time_ms_per_sample': 0.32571475662871036}, 'confusion_matrix': [[70, 2, 3, 1, 1], [9, 40, 0, 9, 0], [15, 8, 35, 4, 0], [1, 4, 2, 69, 1], [18, 3, 4, 3, 32]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6194690265486725, 'recall': 0.9090909090909091, 'f1': 0.7368421052631579, 'support': 77}, {'label': 'entertainment', 'precision': 0.7017543859649122, 'recall': 0.6896551724137931, 'f1': 0.6956521739130435, 'support': 58}, {'label': 'politics', 'precision': 0.7954545454545454, 'recall': 0.5645161290322581, 'f1': 0.660377358490566, 'support': 62}, {'label': 'sport', 'precision': 0.8023255813953488, 'recall': 0.8961038961038961, 'f1': 0.8466257668711656, 'support': 77}, {'label': 'tech', 'precision': 0.9411764705882353, 'recall': 0.5333333333333333, 'f1': 0.6808510638297872, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.9_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:52:34.115665', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.4891231060028076, 'features_extracted': 10000, 'reduction_time': 5.5945799350738525, 'features_after_reduction': 1010, 'metrics': {'accuracy': 0.937125748502994, 'precision': 0.9378919710380602, 'recall': 0.937125748502994, 'f1_score': 0.9373379985833395}, 'performance': {'train_time_seconds': 1.6158514022827148, 'total_time_seconds': 7.699554443359375, 'inference_time_ms_per_sample': 0.0025954789030337762}, 'confusion_matrix': [[72, 1, 4, 0, 0], [0, 52, 4, 0, 2], [4, 0, 56, 1, 1], [0, 1, 1, 75, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9285714285714286, 'recall': 0.896551724137931, 'f1': 0.9122807017543859, 'support': 58}, {'label': 'politics', 'precision': 0.8615384615384616, 'recall': 0.9032258064516129, 'f1': 0.8818897637795275, 'support': 62}, {'label': 'sport', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T15:43:02.459121', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5574617385864258, 'features_extracted': 10000, 'reduction_time': 0.28005266189575195, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9251497005988024, 'precision': 0.9299079178179919, 'recall': 0.9251497005988024, 'f1_score': 0.9256646908532175}, 'performance': {'train_time_seconds': 0.19646167755126953, 'total_time_seconds': 1.0339760780334473, 'inference_time_ms_per_sample': 0.09893514439017473}, 'confusion_matrix': [[72, 0, 2, 1, 2], [4, 50, 0, 4, 0], [5, 0, 57, 0, 0], [1, 0, 0, 76, 0], [5, 1, 0, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8275862068965517, 'recall': 0.935064935064935, 'f1': 0.8780487804878049, 'support': 77}, {'label': 'entertainment', 'precision': 0.9803921568627451, 'recall': 0.8620689655172413, 'f1': 0.9174311926605505, 'support': 58}, {'label': 'politics', 'precision': 0.9661016949152542, 'recall': 0.9193548387096774, 'f1': 0.9421487603305785, 'support': 62}, {'label': 'sport', 'precision': 0.9382716049382716, 'recall': 0.987012987012987, 'f1': 0.9620253164556962, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T15:54:44.683144', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.61151123046875, 'features_extracted': 5000, 'reduction_time': 0.13927507400512695, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.937125748502994, 'precision': 0.9439602936983178, 'recall': 0.937125748502994, 'f1_score': 0.9380506844767021}, 'performance': {'train_time_seconds': 0.20037555694580078, 'total_time_seconds': 1.9511618614196777, 'inference_time_ms_per_sample': 0.09867102800015204}, 'confusion_matrix': [[75, 0, 0, 1, 1], [2, 52, 0, 4, 0], [6, 0, 56, 0, 0], [2, 0, 0, 75, 0], [5, 0, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8333333333333334, 'recall': 0.974025974025974, 'f1': 0.8982035928143712, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.896551724137931, 'f1': 0.9454545454545454, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.9032258064516129, 'f1': 0.9491525423728814, 'support': 62}, {'label': 'sport', 'precision': 0.9375, 'recall': 0.974025974025974, 'f1': 0.9554140127388535, 'support': 77}, {'label': 'tech', 'precision': 0.9821428571428571, 'recall': 0.9166666666666666, 'f1': 0.9482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.9_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:43:37.622400', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.47508978843688965, 'features_extracted': 10000, 'reduction_time': 6.587496995925903, 'features_after_reduction': 446, 'metrics': {'accuracy': 0.8263473053892215, 'precision': 0.8455623806875093, 'recall': 0.8263473053892215, 'f1_score': 0.8220687209297427}, 'performance': {'train_time_seconds': 0.3427412509918213, 'total_time_seconds': 7.405328035354614, 'inference_time_ms_per_sample': 0.098284847008254}, 'confusion_matrix': [[74, 0, 2, 0, 1], [5, 38, 0, 13, 2], [12, 0, 43, 6, 1], [0, 0, 0, 76, 1], [9, 3, 2, 1, 45]], 'per_class_metrics': [{'label': 'business', 'precision': 0.74, 'recall': 0.961038961038961, 'f1': 0.8361581920903954, 'support': 77}, {'label': 'entertainment', 'precision': 0.926829268292683, 'recall': 0.6551724137931034, 'f1': 0.7676767676767676, 'support': 58}, {'label': 'politics', 'precision': 0.9148936170212766, 'recall': 0.6935483870967742, 'f1': 0.7889908256880734, 'support': 62}, {'label': 'sport', 'precision': 0.7916666666666666, 'recall': 0.987012987012987, 'f1': 0.8786127167630058, 'support': 77}, {'label': 'tech', 'precision': 0.9, 'recall': 0.75, 'f1': 0.8181818181818182, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T15:51:58.612582', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.4593467712402344, 'features_extracted': 10000, 'reduction_time': 0.2583303451538086, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8203592814371258, 'precision': 0.86029638003695, 'recall': 0.8203592814371258, 'f1_score': 0.8231476811411306}, 'performance': {'train_time_seconds': 0.008852005004882812, 'total_time_seconds': 0.7265291213989258, 'inference_time_ms_per_sample': 0.09730833019325119}, 'confusion_matrix': [[71, 4, 1, 1, 0], [3, 54, 1, 0, 0], [9, 10, 43, 0, 0], [1, 8, 0, 67, 1], [8, 12, 1, 0, 39]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7717391304347826, 'recall': 0.922077922077922, 'f1': 0.8402366863905325, 'support': 77}, {'label': 'entertainment', 'precision': 0.6136363636363636, 'recall': 0.9310344827586207, 'f1': 0.7397260273972602, 'support': 58}, {'label': 'politics', 'precision': 0.9347826086956522, 'recall': 0.6935483870967742, 'f1': 0.7962962962962963, 'support': 62}, {'label': 'sport', 'precision': 0.9852941176470589, 'recall': 0.8701298701298701, 'f1': 0.9241379310344827, 'support': 77}, {'label': 'tech', 'precision': 0.975, 'recall': 0.65, 'f1': 0.78, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:46:12.406846', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5748968124389648, 'features_extracted': 5000, 'reduction_time': 0.13794636726379395, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7904191616766467, 'precision': 0.7943552324279511, 'recall': 0.7904191616766467, 'f1_score': 0.7911972562416145}, 'performance': {'train_time_seconds': 0.12270283699035645, 'total_time_seconds': 1.8355460166931152, 'inference_time_ms_per_sample': 0.0029095632587364333}, 'confusion_matrix': [[56, 1, 10, 4, 6], [6, 44, 3, 4, 1], [9, 2, 47, 2, 2], [3, 2, 4, 68, 0], [4, 1, 4, 2, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.717948717948718, 'recall': 0.7272727272727273, 'f1': 0.7225806451612903, 'support': 77}, {'label': 'entertainment', 'precision': 0.88, 'recall': 0.7586206896551724, 'f1': 0.8148148148148148, 'support': 58}, {'label': 'politics', 'precision': 0.6911764705882353, 'recall': 0.7580645161290323, 'f1': 0.7230769230769231, 'support': 62}, {'label': 'sport', 'precision': 0.85, 'recall': 0.8831168831168831, 'f1': 0.8662420382165605, 'support': 77}, {'label': 'tech', 'precision': 0.8448275862068966, 'recall': 0.8166666666666667, 'f1': 0.8305084745762712, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T15:54:26.020089', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5900850296020508, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9401197604790419, 'precision': 0.9422012005617301, 'recall': 0.9401197604790419, 'f1_score': 0.9399993915566738}, 'performance': {'train_time_seconds': 0.21389532089233398, 'total_time_seconds': 1.8039803504943848, 'inference_time_ms_per_sample': 0.09747251065191395}, 'confusion_matrix': [[73, 0, 1, 1, 2], [2, 51, 1, 4, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [4, 1, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8902439024390244, 'recall': 0.948051948051948, 'f1': 0.9182389937106918, 'support': 77}, {'label': 'entertainment', 'precision': 0.9807692307692307, 'recall': 0.8793103448275862, 'f1': 0.9272727272727272, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1': 0.9508196721311475, 'support': 62}, {'label': 'sport', 'precision': 0.927710843373494, 'recall': 1.0, 'f1': 0.9625, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:46:04.490746', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6259346008300781, 'features_extracted': 5000, 'reduction_time': 0.13381671905517578, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.958013936715038, 'recall': 0.9580838323353293, 'f1_score': 0.9579418002709207}, 'performance': {'train_time_seconds': 0.3261590003967285, 'total_time_seconds': 2.0859103202819824, 'inference_time_ms_per_sample': 0.006065397205466996}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 0, 1], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.95_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:56:01.095587', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.8727200031280518, 'features_extracted': 5000, 'reduction_time': 3.9323222637176514, 'features_after_reduction': 1105, 'metrics': {'accuracy': 0.9880239520958084, 'precision': 0.9881957696328952, 'recall': 0.9880239520958084, 'f1_score': 0.98806325722334}, 'performance': {'train_time_seconds': 0.1409440040588379, 'total_time_seconds': 5.945986270904541, 'inference_time_ms_per_sample': 0.0033014548752836126}, 'confusion_matrix': [[76, 0, 1, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9833333333333333, 'f1': 0.9915966386554622, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:42:59.912213', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.4969909191131592, 'features_extracted': 10000, 'reduction_time': 0.2761647701263428, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9493412900010231, 'recall': 0.9491017964071856, 'f1_score': 0.9487291399363083}, 'performance': {'train_time_seconds': 0.6362855434417725, 'total_time_seconds': 1.4094412326812744, 'inference_time_ms_per_sample': 0.006246709538077166}, 'confusion_matrix': [[71, 1, 2, 1, 2], [1, 54, 1, 2, 0], [0, 0, 61, 1, 0], [0, 0, 0, 77, 0], [3, 2, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9473684210526315, 'recall': 0.9310344827586207, 'f1': 0.9391304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T15:54:35.847369', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.560831069946289, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9311377245508982, 'precision': 0.9326356646120681, 'recall': 0.9311377245508982, 'f1_score': 0.9309968551205984}, 'performance': {'train_time_seconds': 0.0027849674224853516, 'total_time_seconds': 1.5636160373687744, 'inference_time_ms_per_sample': 0.2916587327054875}, 'confusion_matrix': [[68, 1, 6, 1, 1], [1, 51, 2, 1, 3], [0, 2, 59, 0, 1], [1, 0, 0, 75, 1], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9577464788732394, 'recall': 0.8831168831168831, 'f1': 0.918918918918919, 'support': 77}, {'label': 'entertainment', 'precision': 0.9272727272727272, 'recall': 0.8793103448275862, 'f1': 0.9026548672566371, 'support': 58}, {'label': 'politics', 'precision': 0.8805970149253731, 'recall': 0.9516129032258065, 'f1': 0.9147286821705426, 'support': 62}, {'label': 'sport', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'tech', 'precision': 0.90625, 'recall': 0.9666666666666667, 'f1': 0.9354838709677419, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T15:43:07.215182', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.47812843322753906, 'features_extracted': 10000, 'reduction_time': 0.2713172435760498, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7275449101796407, 'precision': 0.7589080281765495, 'recall': 0.7275449101796407, 'f1_score': 0.7218227029583627}, 'performance': {'train_time_seconds': 0.0075397491455078125, 'total_time_seconds': 0.7569854259490967, 'inference_time_ms_per_sample': 0.316198714479001}, 'confusion_matrix': [[70, 1, 4, 1, 1], [9, 43, 1, 5, 0], [12, 6, 41, 2, 1], [3, 7, 2, 63, 2], [24, 2, 6, 2, 26]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5932203389830508, 'recall': 0.9090909090909091, 'f1': 0.717948717948718, 'support': 77}, {'label': 'entertainment', 'precision': 0.7288135593220338, 'recall': 0.7413793103448276, 'f1': 0.7350427350427351, 'support': 58}, {'label': 'politics', 'precision': 0.7592592592592593, 'recall': 0.6612903225806451, 'f1': 0.7068965517241379, 'support': 62}, {'label': 'sport', 'precision': 0.863013698630137, 'recall': 0.8181818181818182, 'f1': 0.84, 'support': 77}, {'label': 'tech', 'precision': 0.8666666666666667, 'recall': 0.43333333333333335, 'f1': 0.5777777777777777, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T15:54:55.677403', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.5295157432556152, 'features_extracted': 5000, 'reduction_time': 0.13918662071228027, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8622754491017964, 'precision': 0.8805816914774443, 'recall': 0.8622754491017964, 'f1_score': 0.8594374295805852}, 'performance': {'train_time_seconds': 0.0110015869140625, 'total_time_seconds': 1.679703950881958, 'inference_time_ms_per_sample': 0.096490283212262}, 'confusion_matrix': [[73, 1, 1, 2, 0], [5, 51, 1, 1, 0], [2, 4, 55, 1, 0], [1, 2, 1, 73, 0], [14, 9, 1, 0, 36]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7684210526315789, 'recall': 0.948051948051948, 'f1': 0.8488372093023255, 'support': 77}, {'label': 'entertainment', 'precision': 0.7611940298507462, 'recall': 0.8793103448275862, 'f1': 0.816, 'support': 58}, {'label': 'politics', 'precision': 0.9322033898305084, 'recall': 0.8870967741935484, 'f1': 0.9090909090909091, 'support': 62}, {'label': 'sport', 'precision': 0.948051948051948, 'recall': 0.948051948051948, 'f1': 0.948051948051948, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.6, 'f1': 0.75, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.95_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:50:37.544999', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6106672286987305, 'features_extracted': 10000, 'reduction_time': 6.68415379524231, 'features_after_reduction': 789, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9492728645973879, 'recall': 0.9491017964071856, 'f1_score': 0.9489435744755027}, 'performance': {'train_time_seconds': 0.12830257415771484, 'total_time_seconds': 8.423123598098755, 'inference_time_ms_per_sample': 0.002414166570423606}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 54, 1, 2, 0], [2, 0, 58, 1, 1], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.935064935064935, 'recall': 0.935064935064935, 'f1': 0.935064935064935, 'support': 77}, {'label': 'entertainment', 'precision': 0.9642857142857143, 'recall': 0.9310344827586207, 'f1': 0.9473684210526315, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T15:48:33.322240', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5592007637023926, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7215568862275449, 'precision': 0.768309414912812, 'recall': 0.7215568862275449, 'f1_score': 0.7193173840666243}, 'performance': {'train_time_seconds': 0.0031659603118896484, 'total_time_seconds': 1.5623667240142822, 'inference_time_ms_per_sample': 0.43423447066438414}, 'confusion_matrix': [[70, 1, 1, 2, 3], [15, 36, 0, 7, 0], [17, 7, 33, 4, 1], [5, 2, 0, 68, 2], [18, 7, 1, 0, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.56, 'recall': 0.9090909090909091, 'f1': 0.693069306930693, 'support': 77}, {'label': 'entertainment', 'precision': 0.6792452830188679, 'recall': 0.6206896551724138, 'f1': 0.6486486486486487, 'support': 58}, {'label': 'politics', 'precision': 0.9428571428571428, 'recall': 0.532258064516129, 'f1': 0.6804123711340206, 'support': 62}, {'label': 'sport', 'precision': 0.8395061728395061, 'recall': 0.8831168831168831, 'f1': 0.8607594936708861, 'support': 77}, {'label': 'tech', 'precision': 0.85, 'recall': 0.5666666666666667, 'f1': 0.68, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:57:08.816226', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.781041145324707, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7664670658682635, 'precision': 0.7739536720297405, 'recall': 0.7664670658682635, 'f1_score': 0.7679429330166164}, 'performance': {'train_time_seconds': 0.9570167064666748, 'total_time_seconds': 2.738057851791382, 'inference_time_ms_per_sample': 0.0032529145657659293}, 'confusion_matrix': [[53, 4, 8, 4, 8], [6, 41, 6, 5, 0], [10, 0, 49, 1, 2], [4, 2, 4, 65, 2], [8, 0, 4, 0, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.654320987654321, 'recall': 0.6883116883116883, 'f1': 0.6708860759493671, 'support': 77}, {'label': 'entertainment', 'precision': 0.8723404255319149, 'recall': 0.7068965517241379, 'f1': 0.780952380952381, 'support': 58}, {'label': 'politics', 'precision': 0.6901408450704225, 'recall': 0.7903225806451613, 'f1': 0.7368421052631579, 'support': 62}, {'label': 'sport', 'precision': 0.8666666666666667, 'recall': 0.8441558441558441, 'f1': 0.8552631578947368, 'support': 77}, {'label': 'tech', 'precision': 0.8, 'recall': 0.8, 'f1': 0.8, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.9_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:49:40.300695', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.6679489612579346, 'features_extracted': 10000, 'reduction_time': 6.287808179855347, 'features_after_reduction': 515, 'metrics': {'accuracy': 0.6377245508982036, 'precision': 0.6368478393204179, 'recall': 0.6377245508982036, 'f1_score': 0.635873951420278}, 'performance': {'train_time_seconds': 0.8600506782531738, 'total_time_seconds': 8.815807819366455, 'inference_time_ms_per_sample': 0.0020094260484158637}, 'confusion_matrix': [[55, 9, 6, 1, 6], [7, 28, 6, 13, 4], [9, 7, 34, 6, 6], [4, 6, 4, 61, 2], [11, 9, 5, 0, 35]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6395348837209303, 'recall': 0.7142857142857143, 'f1': 0.6748466257668712, 'support': 77}, {'label': 'entertainment', 'precision': 0.4745762711864407, 'recall': 0.4827586206896552, 'f1': 0.47863247863247865, 'support': 58}, {'label': 'politics', 'precision': 0.6181818181818182, 'recall': 0.5483870967741935, 'f1': 0.5811965811965812, 'support': 62}, {'label': 'sport', 'precision': 0.7530864197530864, 'recall': 0.7922077922077922, 'f1': 0.7721518987341772, 'support': 77}, {'label': 'tech', 'precision': 0.660377358490566, 'recall': 0.5833333333333334, 'f1': 0.6194690265486725, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T15:51:59.380574', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.4537849426269531, 'features_extracted': 10000, 'reduction_time': 0.2617008686065674, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.811377245508982, 'precision': 0.8590968708981279, 'recall': 0.811377245508982, 'f1_score': 0.8103465074803756}, 'performance': {'train_time_seconds': 0.008948087692260742, 'total_time_seconds': 0.7244338989257812, 'inference_time_ms_per_sample': 0.09744752666907396}, 'confusion_matrix': [[75, 0, 1, 1, 0], [12, 46, 0, 0, 0], [11, 3, 48, 0, 0], [2, 2, 0, 72, 1], [21, 9, 0, 0, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6198347107438017, 'recall': 0.974025974025974, 'f1': 0.7575757575757576, 'support': 77}, {'label': 'entertainment', 'precision': 0.7666666666666667, 'recall': 0.7931034482758621, 'f1': 0.7796610169491526, 'support': 58}, {'label': 'politics', 'precision': 0.9795918367346939, 'recall': 0.7741935483870968, 'f1': 0.8648648648648649, 'support': 62}, {'label': 'sport', 'precision': 0.9863013698630136, 'recall': 0.935064935064935, 'f1': 0.96, 'support': 77}, {'label': 'tech', 'precision': 0.967741935483871, 'recall': 0.5, 'f1': 0.6593406593406593, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.95_sfull_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:53:15.171462', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5160620212554932, 'features_extracted': 10000, 'reduction_time': 5.68443751335144, 'features_after_reduction': 1191, 'metrics': {'accuracy': 0.9940119760479041, 'precision': 0.9940503608168278, 'recall': 0.9940119760479041, 'f1_score': 0.9940086167076787}, 'performance': {'train_time_seconds': 0.12745237350463867, 'total_time_seconds': 6.327951908111572, 'inference_time_ms_per_sample': 0.00302734489212493}, 'confusion_matrix': [[77, 0, 0, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9838709677419355, 'recall': 0.9838709677419355, 'f1': 0.9838709677419355, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:46:10.526089', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.6322362422943115, 'features_extracted': 5000, 'reduction_time': 0.14122414588928223, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7844917847409094, 'recall': 0.7694610778443114, 'f1_score': 0.7695426464863667}, 'performance': {'train_time_seconds': 0.0968010425567627, 'total_time_seconds': 1.8702614307403564, 'inference_time_ms_per_sample': 0.003165827539866556}, 'confusion_matrix': [[61, 1, 6, 5, 4], [7, 39, 4, 7, 1], [16, 1, 40, 3, 2], [5, 1, 0, 71, 0], [8, 1, 3, 2, 46]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6288659793814433, 'recall': 0.7922077922077922, 'f1': 0.7011494252873564, 'support': 77}, {'label': 'entertainment', 'precision': 0.9069767441860465, 'recall': 0.6724137931034483, 'f1': 0.7722772277227723, 'support': 58}, {'label': 'politics', 'precision': 0.7547169811320755, 'recall': 0.6451612903225806, 'f1': 0.6956521739130435, 'support': 62}, {'label': 'sport', 'precision': 0.8068181818181818, 'recall': 0.922077922077922, 'f1': 0.8606060606060606, 'support': 77}, {'label': 'tech', 'precision': 0.8679245283018868, 'recall': 0.7666666666666667, 'f1': 0.8141592920353983, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:54:40.988964', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.5948879718780518, 'features_extracted': 5000, 'reduction_time': 0.1403038501739502, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9792462012090553, 'recall': 0.9790419161676647, 'f1_score': 0.979051427745181}, 'performance': {'train_time_seconds': 0.08423852920532227, 'total_time_seconds': 1.8194303512573242, 'inference_time_ms_per_sample': 0.0028695888861924586}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 57, 0, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'entertainment', 'precision': 0.9661016949152542, 'recall': 0.9827586206896551, 'f1': 0.9743589743589743, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T15:46:14.252115', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5860247611999512, 'features_extracted': 5000, 'reduction_time': 0.1354386806488037, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.6976047904191617, 'precision': 0.7264321117560886, 'recall': 0.6976047904191617, 'f1_score': 0.6936704706528525}, 'performance': {'train_time_seconds': 0.009641170501708984, 'total_time_seconds': 1.7311046123504639, 'inference_time_ms_per_sample': 0.3323683481730387}, 'confusion_matrix': [[65, 4, 1, 3, 4], [10, 40, 2, 5, 1], [14, 8, 37, 3, 0], [5, 6, 1, 64, 1], [20, 5, 6, 2, 27]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5701754385964912, 'recall': 0.8441558441558441, 'f1': 0.680628272251309, 'support': 77}, {'label': 'entertainment', 'precision': 0.6349206349206349, 'recall': 0.6896551724137931, 'f1': 0.6611570247933884, 'support': 58}, {'label': 'politics', 'precision': 0.7872340425531915, 'recall': 0.5967741935483871, 'f1': 0.6788990825688074, 'support': 62}, {'label': 'sport', 'precision': 0.8311688311688312, 'recall': 0.8311688311688312, 'f1': 0.8311688311688312, 'support': 77}, {'label': 'tech', 'precision': 0.8181818181818182, 'recall': 0.45, 'f1': 0.5806451612903226, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:46:02.216855', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.5581378936767578, 'features_extracted': 5000, 'reduction_time': 0.1414494514465332, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582480715261207, 'recall': 0.9580838323353293, 'f1_score': 0.9579495451843525}, 'performance': {'train_time_seconds': 0.5571768283843994, 'total_time_seconds': 2.2567641735076904, 'inference_time_ms_per_sample': 0.007593703127192881}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T15:48:47.345552', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5877163410186768, 'features_extracted': 10000, 'reduction_time': 0.2713193893432617, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9558182576645651, 'recall': 0.9550898203592815, 'f1_score': 0.9552165096745926}, 'performance': {'train_time_seconds': 0.19641923904418945, 'total_time_seconds': 2.055454969406128, 'inference_time_ms_per_sample': 0.10202601998152133}, 'confusion_matrix': [[74, 0, 1, 0, 2], [1, 55, 1, 1, 0], [3, 0, 58, 0, 1], [0, 0, 0, 76, 1], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9135802469135802, 'recall': 0.961038961038961, 'f1': 0.9367088607594937, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1': 0.9508196721311475, 'support': 62}, {'label': 'sport', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'tech', 'precision': 0.9333333333333333, 'recall': 0.9333333333333333, 'f1': 0.9333333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.95_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:59:49.196517', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.8260657787322998, 'features_extracted': 10000, 'reduction_time': 6.325817823410034, 'features_after_reduction': 1202, 'metrics': {'accuracy': 0.9101796407185628, 'precision': 0.9125616530097699, 'recall': 0.9101796407185628, 'f1_score': 0.9107265663704737}, 'performance': {'train_time_seconds': 1.7695817947387695, 'total_time_seconds': 9.921465396881104, 'inference_time_ms_per_sample': 0.0031950944911933944}, 'confusion_matrix': [[69, 3, 4, 0, 1], [0, 54, 2, 0, 2], [3, 3, 55, 0, 1], [0, 1, 1, 74, 1], [3, 3, 2, 0, 52]], 'per_class_metrics': [{'label': 'business', 'precision': 0.92, 'recall': 0.8961038961038961, 'f1': 0.9078947368421053, 'support': 77}, {'label': 'entertainment', 'precision': 0.84375, 'recall': 0.9310344827586207, 'f1': 0.8852459016393442, 'support': 58}, {'label': 'politics', 'precision': 0.859375, 'recall': 0.8870967741935484, 'f1': 0.873015873015873, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 0.961038961038961, 'f1': 0.9801324503311258, 'support': 77}, {'label': 'tech', 'precision': 0.9122807017543859, 'recall': 0.8666666666666667, 'f1': 0.8888888888888888, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.9_sfull_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:46:31.689601', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.7179596424102783, 'features_extracted': 5000, 'reduction_time': 3.465930461883545, 'features_after_reduction': 420, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.9611116251505706, 'recall': 0.9610778443113772, 'f1_score': 0.9609756376149033}, 'performance': {'train_time_seconds': 0.10936927795410156, 'total_time_seconds': 5.293259382247925, 'inference_time_ms_per_sample': 0.0016403769304652416}, 'confusion_matrix': [[73, 1, 2, 0, 1], [1, 55, 1, 1, 0], [1, 1, 58, 2, 0], [0, 0, 0, 77, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.948051948051948, 'recall': 0.948051948051948, 'f1': 0.948051948051948, 'support': 77}, {'label': 'entertainment', 'precision': 0.9649122807017544, 'recall': 0.9482758620689655, 'f1': 0.9565217391304348, 'support': 58}, {'label': 'politics', 'precision': 0.9508196721311475, 'recall': 0.9354838709677419, 'f1': 0.943089430894309, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:45:36.881721', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.6261684894561768, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9769557169444895, 'recall': 0.9760479041916168, 'f1_score': 0.9760681744843009}, 'performance': {'train_time_seconds': 0.1582961082458496, 'total_time_seconds': 1.7844645977020264, 'inference_time_ms_per_sample': 0.010444018655194494}, 'confusion_matrix': [[73, 0, 2, 0, 2], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9375, 'recall': 1.0, 'f1': 0.967741935483871, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T15:42:53.762921', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5653550624847412, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9251497005988024, 'precision': 0.9293627536327895, 'recall': 0.9251497005988024, 'f1_score': 0.9250167884898424}, 'performance': {'train_time_seconds': 0.2607688903808594, 'total_time_seconds': 0.8261239528656006, 'inference_time_ms_per_sample': 0.097166992233185}, 'confusion_matrix': [[73, 1, 1, 1, 1], [3, 51, 1, 2, 1], [6, 0, 53, 3, 0], [0, 0, 0, 77, 0], [3, 0, 0, 2, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8588235294117647, 'recall': 0.948051948051948, 'f1': 0.9012345679012346, 'support': 77}, {'label': 'entertainment', 'precision': 0.9807692307692307, 'recall': 0.8793103448275862, 'f1': 0.9272727272727272, 'support': 58}, {'label': 'politics', 'precision': 0.9636363636363636, 'recall': 0.8548387096774194, 'f1': 0.905982905982906, 'support': 62}, {'label': 'sport', 'precision': 0.9058823529411765, 'recall': 1.0, 'f1': 0.9506172839506173, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:51:53.131228', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5228366851806641, 'features_extracted': 10000, 'reduction_time': 0.26651978492736816, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9793289561684974, 'recall': 0.9790419161676647, 'f1_score': 0.979066244391906}, 'performance': {'train_time_seconds': 0.13095450401306152, 'total_time_seconds': 0.9203109741210938, 'inference_time_ms_per_sample': 0.0029295504450084207}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 57, 0, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'entertainment', 'precision': 0.95, 'recall': 0.9827586206896551, 'f1': 0.9661016949152542, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:45:44.017910', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6542112827301025, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9580796457931595, 'recall': 0.9580838323353293, 'f1_score': 0.9579491689762678}, 'performance': {'train_time_seconds': 1.6182875633239746, 'total_time_seconds': 3.272498846054077, 'inference_time_ms_per_sample': 0.003929623586688927}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [1, 1, 58, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.96, 'recall': 0.935064935064935, 'f1': 0.9473684210526315, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:45:51.014031', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.5979681015014648, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7365269461077845, 'precision': 0.7515204492222062, 'recall': 0.7365269461077845, 'f1_score': 0.7367861639305352}, 'performance': {'train_time_seconds': 0.30814242362976074, 'total_time_seconds': 1.9061105251312256, 'inference_time_ms_per_sample': 0.002405600633449897}, 'confusion_matrix': [[58, 1, 8, 5, 5], [9, 37, 2, 8, 2], [18, 0, 38, 3, 3], [5, 4, 0, 67, 1], [8, 1, 2, 3, 46]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5918367346938775, 'recall': 0.7532467532467533, 'f1': 0.6628571428571428, 'support': 77}, {'label': 'entertainment', 'precision': 0.8604651162790697, 'recall': 0.6379310344827587, 'f1': 0.7326732673267327, 'support': 58}, {'label': 'politics', 'precision': 0.76, 'recall': 0.6129032258064516, 'f1': 0.6785714285714286, 'support': 62}, {'label': 'sport', 'precision': 0.7790697674418605, 'recall': 0.8701298701298701, 'f1': 0.8220858895705522, 'support': 77}, {'label': 'tech', 'precision': 0.8070175438596491, 'recall': 0.7666666666666667, 'f1': 0.7863247863247863, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.9_sfull_knn_n3_n-1', 'timestamp': '2025-10-21T15:55:40.101589', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.584028959274292, 'features_extracted': 5000, 'reduction_time': 3.666376829147339, 'features_after_reduction': 906, 'metrics': {'accuracy': 0.9191616766467066, 'precision': 0.92133409454928, 'recall': 0.9191616766467066, 'f1_score': 0.918921407499116}, 'performance': {'train_time_seconds': 0.015838146209716797, 'total_time_seconds': 5.266243934631348, 'inference_time_ms_per_sample': 0.33358613887946764}, 'confusion_matrix': [[66, 1, 8, 2, 0], [1, 51, 2, 2, 2], [1, 3, 56, 0, 2], [0, 0, 0, 75, 2], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9705882352941176, 'recall': 0.8571428571428571, 'f1': 0.9103448275862069, 'support': 77}, {'label': 'entertainment', 'precision': 0.9107142857142857, 'recall': 0.8793103448275862, 'f1': 0.8947368421052632, 'support': 58}, {'label': 'politics', 'precision': 0.8484848484848485, 'recall': 0.9032258064516129, 'f1': 0.875, 'support': 62}, {'label': 'sport', 'precision': 0.9493670886075949, 'recall': 0.974025974025974, 'f1': 0.9615384615384616, 'support': 77}, {'label': 'tech', 'precision': 0.9076923076923077, 'recall': 0.9833333333333333, 'f1': 0.944, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.95_sfull_knn_n5_n-1', 'timestamp': '2025-10-21T15:54:06.841421', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.46524572372436523, 'features_extracted': 10000, 'reduction_time': 6.5904624462127686, 'features_after_reduction': 1191, 'metrics': {'accuracy': 0.9191616766467066, 'precision': 0.9247907027551516, 'recall': 0.9191616766467066, 'f1_score': 0.9187763373826019}, 'performance': {'train_time_seconds': 0.01805400848388672, 'total_time_seconds': 7.0737621784210205, 'inference_time_ms_per_sample': 0.3379504837675723}, 'confusion_matrix': [[66, 1, 9, 1, 0], [1, 47, 4, 1, 5], [1, 0, 60, 0, 1], [1, 0, 0, 75, 1], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9565217391304348, 'recall': 0.8571428571428571, 'f1': 0.9041095890410958, 'support': 77}, {'label': 'entertainment', 'precision': 0.9591836734693877, 'recall': 0.8103448275862069, 'f1': 0.8785046728971962, 'support': 58}, {'label': 'politics', 'precision': 0.821917808219178, 'recall': 0.967741935483871, 'f1': 0.8888888888888888, 'support': 62}, {'label': 'sport', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'tech', 'precision': 0.8939393939393939, 'recall': 0.9833333333333333, 'f1': 0.9365079365079365, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_pca_n0.95_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:53:09.560676', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.45745134353637695, 'features_extracted': 10000, 'reduction_time': 5.101076602935791, 'features_after_reduction': 1191, 'metrics': {'accuracy': 0.6227544910179641, 'precision': 0.6785599923148357, 'recall': 0.6227544910179641, 'f1_score': 0.5621474158828608}, 'performance': {'train_time_seconds': 0.01884603500366211, 'total_time_seconds': 5.57737398147583, 'inference_time_ms_per_sample': 0.0031458403535945686}, 'confusion_matrix': [[73, 0, 0, 2, 2], [25, 1, 0, 31, 1], [19, 0, 31, 9, 3], [2, 0, 0, 75, 0], [27, 1, 0, 4, 28]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5, 'recall': 0.948051948051948, 'f1': 0.6547085201793722, 'support': 77}, {'label': 'entertainment', 'precision': 0.5, 'recall': 0.017241379310344827, 'f1': 0.03333333333333333, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.5, 'f1': 0.6666666666666666, 'support': 62}, {'label': 'sport', 'precision': 0.6198347107438017, 'recall': 0.974025974025974, 'f1': 0.7575757575757576, 'support': 77}, {'label': 'tech', 'precision': 0.8235294117647058, 'recall': 0.4666666666666667, 'f1': 0.5957446808510638, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T15:43:01.338057', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5598452091217041, 'features_extracted': 10000, 'reduction_time': 0.27987217903137207, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9520080445883203, 'recall': 0.9520958083832335, 'f1_score': 0.9517685674906047}, 'performance': {'train_time_seconds': 0.2651181221008301, 'total_time_seconds': 1.1048355102539062, 'inference_time_ms_per_sample': 0.006397327263198213}, 'confusion_matrix': [[71, 1, 2, 1, 2], [1, 55, 1, 1, 0], [0, 0, 61, 0, 1], [0, 0, 0, 77, 0], [3, 2, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9473684210526315, 'recall': 0.9, 'f1': 0.9230769230769231, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_pca_n0.9_sfull_decision_tree_m10_r42', 'timestamp': '2025-10-21T15:58:29.249272', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.8512659072875977, 'features_extracted': 10000, 'reduction_time': 5.718913793563843, 'features_after_reduction': 1020, 'metrics': {'accuracy': 0.8952095808383234, 'precision': 0.899626418977544, 'recall': 0.8952095808383234, 'f1_score': 0.8962460511473116}, 'performance': {'train_time_seconds': 1.6285457611083984, 'total_time_seconds': 9.198725461959839, 'inference_time_ms_per_sample': 0.0030494735626403445}, 'confusion_matrix': [[69, 3, 4, 0, 1], [0, 53, 3, 0, 2], [3, 6, 52, 1, 0], [1, 2, 1, 73, 0], [3, 3, 2, 0, 52]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9078947368421053, 'recall': 0.8961038961038961, 'f1': 0.9019607843137255, 'support': 77}, {'label': 'entertainment', 'precision': 0.7910447761194029, 'recall': 0.9137931034482759, 'f1': 0.848, 'support': 58}, {'label': 'politics', 'precision': 0.8387096774193549, 'recall': 0.8387096774193549, 'f1': 0.8387096774193549, 'support': 62}, {'label': 'sport', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'tech', 'precision': 0.9454545454545454, 'recall': 0.8666666666666667, 'f1': 0.9043478260869565, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T15:57:04.069978', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.8307173252105713, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9559555960077702, 'recall': 0.9550898203592815, 'f1_score': 0.9550924155573088}, 'performance': {'train_time_seconds': 0.2334439754486084, 'total_time_seconds': 2.0641613006591797, 'inference_time_ms_per_sample': 0.09643032165344603}, 'confusion_matrix': [[74, 0, 2, 0, 1], [1, 55, 1, 1, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [3, 1, 1, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9135802469135802, 'recall': 0.961038961038961, 'f1': 0.9367088607594937, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9821428571428571, 'recall': 0.9166666666666666, 'f1': 0.9482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:57:17.404182', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.8137810230255127, 'features_extracted': 10000, 'reduction_time': 0.3178081512451172, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.982252624063731, 'recall': 0.9820359281437125, 'f1_score': 0.9820333169176416}, 'performance': {'train_time_seconds': 0.0104827880859375, 'total_time_seconds': 2.1420719623565674, 'inference_time_ms_per_sample': 0.0030394799695043504}, 'confusion_matrix': [[76, 0, 0, 0, 1], [0, 56, 1, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9836065573770492, 'recall': 0.967741935483871, 'f1': 0.975609756097561, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T15:54:34.137228', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.6077516078948975, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9191616766467066, 'precision': 0.9210600036765447, 'recall': 0.9191616766467066, 'f1_score': 0.9191317895095776}, 'performance': {'train_time_seconds': 0.0025320053100585938, 'total_time_seconds': 1.610283613204956, 'inference_time_ms_per_sample': 0.27262664840606876}, 'confusion_matrix': [[68, 1, 6, 1, 1], [0, 51, 2, 2, 3], [1, 2, 55, 0, 4], [1, 0, 0, 75, 1], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9577464788732394, 'recall': 0.8831168831168831, 'f1': 0.918918918918919, 'support': 77}, {'label': 'entertainment', 'precision': 0.9272727272727272, 'recall': 0.8793103448275862, 'f1': 0.9026548672566371, 'support': 58}, {'label': 'politics', 'precision': 0.873015873015873, 'recall': 0.8870967741935484, 'f1': 0.88, 'support': 62}, {'label': 'sport', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'tech', 'precision': 0.8656716417910447, 'recall': 0.9666666666666667, 'f1': 0.9133858267716536, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:48:14.939502', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.605982780456543, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582648903644616, 'recall': 0.9580838323353293, 'f1_score': 0.9580291037037023}, 'performance': {'train_time_seconds': 5.244046449661255, 'total_time_seconds': 6.850029230117798, 'inference_time_ms_per_sample': 0.005247350224477802}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.935064935064935, 'recall': 0.935064935064935, 'f1': 0.935064935064935, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T15:48:55.337821', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.7414300441741943, 'features_extracted': 10000, 'reduction_time': 0.2707512378692627, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7245508982035929, 'precision': 0.7470708885311422, 'recall': 0.7245508982035929, 'f1_score': 0.7204221638466283}, 'performance': {'train_time_seconds': 0.007494449615478516, 'total_time_seconds': 2.0196757316589355, 'inference_time_ms_per_sample': 0.6053768946025186}, 'confusion_matrix': [[66, 3, 4, 2, 2], [5, 44, 1, 8, 0], [13, 7, 38, 2, 2], [4, 8, 1, 64, 0], [18, 3, 7, 2, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6226415094339622, 'recall': 0.8571428571428571, 'f1': 0.7213114754098361, 'support': 77}, {'label': 'entertainment', 'precision': 0.676923076923077, 'recall': 0.7586206896551724, 'f1': 0.7154471544715447, 'support': 58}, {'label': 'politics', 'precision': 0.7450980392156863, 'recall': 0.6129032258064516, 'f1': 0.672566371681416, 'support': 62}, {'label': 'sport', 'precision': 0.8205128205128205, 'recall': 0.8311688311688312, 'f1': 0.8258064516129032, 'support': 77}, {'label': 'tech', 'precision': 0.8823529411764706, 'recall': 0.5, 'f1': 0.6382978723404256, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T15:56:56.574494', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.807344675064087, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9910179640718563, 'precision': 0.9911130120710959, 'recall': 0.9910179640718563, 'f1_score': 0.9910408747721947}, 'performance': {'train_time_seconds': 0.8186724185943604, 'total_time_seconds': 2.6260170936584473, 'inference_time_ms_per_sample': 0.0038175525779495694}, 'confusion_matrix': [[76, 0, 1, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n0.9_sfull_random_forest_n100_m20', 'timestamp': '2025-10-21T15:49:31.280952', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.553257942199707, 'features_extracted': 10000, 'reduction_time': 7.073748350143433, 'features_after_reduction': 515, 'metrics': {'accuracy': 0.8413173652694611, 'precision': 0.8530868158483499, 'recall': 0.8413173652694611, 'f1_score': 0.8400657043185991}, 'performance': {'train_time_seconds': 0.3339223861694336, 'total_time_seconds': 8.960928678512573, 'inference_time_ms_per_sample': 0.10056267241517941}, 'confusion_matrix': [[71, 0, 2, 3, 1], [4, 44, 1, 8, 1], [8, 1, 48, 4, 1], [2, 1, 0, 74, 0], [10, 4, 2, 0, 44]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7473684210526316, 'recall': 0.922077922077922, 'f1': 0.8255813953488372, 'support': 77}, {'label': 'entertainment', 'precision': 0.88, 'recall': 0.7586206896551724, 'f1': 0.8148148148148148, 'support': 58}, {'label': 'politics', 'precision': 0.9056603773584906, 'recall': 0.7741935483870968, 'f1': 0.8347826086956521, 'support': 62}, {'label': 'sport', 'precision': 0.8314606741573034, 'recall': 0.961038961038961, 'f1': 0.891566265060241, 'support': 77}, {'label': 'tech', 'precision': 0.9361702127659575, 'recall': 0.7333333333333333, 'f1': 0.822429906542056, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.9_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T15:47:12.032450', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.5498771667480469, 'features_extracted': 5000, 'reduction_time': 3.255423069000244, 'features_after_reduction': 420, 'metrics': {'accuracy': 0.7305389221556886, 'precision': 0.759815927857825, 'recall': 0.7305389221556886, 'f1_score': 0.7271066231187127}, 'performance': {'train_time_seconds': 0.0076100826263427734, 'total_time_seconds': 4.812910318374634, 'inference_time_ms_per_sample': 0.36711749916305086}, 'confusion_matrix': [[68, 1, 1, 1, 6], [9, 43, 0, 6, 0], [13, 7, 37, 5, 0], [3, 6, 0, 66, 2], [20, 7, 3, 0, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6017699115044248, 'recall': 0.8831168831168831, 'f1': 0.7157894736842105, 'support': 77}, {'label': 'entertainment', 'precision': 0.671875, 'recall': 0.7413793103448276, 'f1': 0.7049180327868853, 'support': 58}, {'label': 'politics', 'precision': 0.9024390243902439, 'recall': 0.5967741935483871, 'f1': 0.7184466019417476, 'support': 62}, {'label': 'sport', 'precision': 0.8461538461538461, 'recall': 0.8571428571428571, 'f1': 0.8516129032258064, 'support': 77}, {'label': 'tech', 'precision': 0.7894736842105263, 'recall': 0.5, 'f1': 0.6122448979591837, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.9_sfull_random_forest_n100_m10', 'timestamp': '2025-10-21T15:43:30.661642', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.535872220993042, 'features_extracted': 10000, 'reduction_time': 6.051342487335205, 'features_after_reduction': 446, 'metrics': {'accuracy': 0.8293413173652695, 'precision': 0.8521843590742565, 'recall': 0.8293413173652695, 'f1_score': 0.8258035040213321}, 'performance': {'train_time_seconds': 0.32001829147338867, 'total_time_seconds': 6.907232999801636, 'inference_time_ms_per_sample': 0.09907862383448436}, 'confusion_matrix': [[75, 0, 1, 1, 0], [8, 40, 0, 9, 1], [10, 1, 43, 7, 1], [1, 0, 0, 76, 0], [10, 4, 2, 1, 43]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7211538461538461, 'recall': 0.974025974025974, 'f1': 0.8287292817679558, 'support': 77}, {'label': 'entertainment', 'precision': 0.8888888888888888, 'recall': 0.6896551724137931, 'f1': 0.7766990291262136, 'support': 58}, {'label': 'politics', 'precision': 0.9347826086956522, 'recall': 0.6935483870967742, 'f1': 0.7962962962962963, 'support': 62}, {'label': 'sport', 'precision': 0.8085106382978723, 'recall': 0.987012987012987, 'f1': 0.8888888888888888, 'support': 77}, {'label': 'tech', 'precision': 0.9555555555555556, 'recall': 0.7166666666666667, 'f1': 0.819047619047619, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T15:57:37.970865', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.8012604713439941, 'features_extracted': 10000, 'reduction_time': 0.29092884063720703, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8532934131736527, 'precision': 0.8806587527623716, 'recall': 0.8532934131736527, 'f1_score': 0.8514239512647979}, 'performance': {'train_time_seconds': 0.009342193603515625, 'total_time_seconds': 2.101531505584717, 'inference_time_ms_per_sample': 0.09760956564349328}, 'confusion_matrix': [[74, 0, 2, 1, 0], [10, 42, 3, 3, 0], [3, 0, 59, 0, 0], [3, 0, 1, 73, 0], [18, 4, 1, 0, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6851851851851852, 'recall': 0.961038961038961, 'f1': 0.8, 'support': 77}, {'label': 'entertainment', 'precision': 0.9130434782608695, 'recall': 0.7241379310344828, 'f1': 0.8076923076923077, 'support': 58}, {'label': 'politics', 'precision': 0.8939393939393939, 'recall': 0.9516129032258065, 'f1': 0.921875, 'support': 62}, {'label': 'sport', 'precision': 0.948051948051948, 'recall': 0.948051948051948, 'f1': 0.948051948051948, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.6166666666666667, 'f1': 0.7628865979381443, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_pca_n0.95_sfull_decision_tree_m20_r42', 'timestamp': '2025-10-21T15:56:31.095359', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.8913171291351318, 'features_extracted': 5000, 'reduction_time': 3.2318224906921387, 'features_after_reduction': 1105, 'metrics': {'accuracy': 0.907185628742515, 'precision': 0.9076164806482937, 'recall': 0.907185628742515, 'f1_score': 0.906852405325547}, 'performance': {'train_time_seconds': 1.732497215270996, 'total_time_seconds': 6.855636835098267, 'inference_time_ms_per_sample': 0.003316445264987603}, 'confusion_matrix': [[72, 1, 2, 0, 2], [2, 48, 3, 3, 2], [3, 1, 54, 1, 3], [0, 1, 1, 75, 0], [1, 1, 4, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9230769230769231, 'recall': 0.935064935064935, 'f1': 0.9290322580645162, 'support': 77}, {'label': 'entertainment', 'precision': 0.9230769230769231, 'recall': 0.8275862068965517, 'f1': 0.8727272727272727, 'support': 58}, {'label': 'politics', 'precision': 0.84375, 'recall': 0.8709677419354839, 'f1': 0.8571428571428571, 'support': 62}, {'label': 'sport', 'precision': 0.9493670886075949, 'recall': 0.974025974025974, 'f1': 0.9615384615384616, 'support': 77}, {'label': 'tech', 'precision': 0.8852459016393442, 'recall': 0.9, 'f1': 0.8925619834710744, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_pca_n0.9_sfull_knn_n10_n-1', 'timestamp': '2025-10-21T15:44:15.519703', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.9, 'svd_solver': 'full'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.48076939582824707, 'features_extracted': 10000, 'reduction_time': 8.255327463150024, 'features_after_reduction': 446, 'metrics': {'accuracy': 0.7425149700598802, 'precision': 0.7806718860415816, 'recall': 0.7425149700598802, 'f1_score': 0.7349197028701656}, 'performance': {'train_time_seconds': 0.007773160934448242, 'total_time_seconds': 8.74387001991272, 'inference_time_ms_per_sample': 0.3597058221965493}, 'confusion_matrix': [[72, 2, 2, 1, 0], [8, 42, 0, 8, 0], [14, 4, 37, 6, 1], [1, 5, 1, 69, 1], [20, 10, 2, 0, 28]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6260869565217392, 'recall': 0.935064935064935, 'f1': 0.75, 'support': 77}, {'label': 'entertainment', 'precision': 0.6666666666666666, 'recall': 0.7241379310344828, 'f1': 0.6942148760330579, 'support': 58}, {'label': 'politics', 'precision': 0.8809523809523809, 'recall': 0.5967741935483871, 'f1': 0.7115384615384616, 'support': 62}, {'label': 'sport', 'precision': 0.8214285714285714, 'recall': 0.8961038961038961, 'f1': 0.8571428571428571, 'support': 77}, {'label': 'tech', 'precision': 0.9333333333333333, 'recall': 0.4666666666666667, 'f1': 0.6222222222222222, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T15:51:50.399282', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.46044254302978516, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9221556886227545, 'precision': 0.9247728937908873, 'recall': 0.9221556886227545, 'f1_score': 0.9220026137557732}, 'performance': {'train_time_seconds': 0.002215147018432617, 'total_time_seconds': 0.4626576900482178, 'inference_time_ms_per_sample': 0.3054092030325336}, 'confusion_matrix': [[68, 1, 6, 1, 1], [1, 49, 2, 2, 4], [0, 0, 60, 0, 2], [1, 0, 0, 75, 1], [0, 3, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9714285714285714, 'recall': 0.8831168831168831, 'f1': 0.9251700680272109, 'support': 77}, {'label': 'entertainment', 'precision': 0.9245283018867925, 'recall': 0.8448275862068966, 'f1': 0.8828828828828829, 'support': 58}, {'label': 'politics', 'precision': 0.8695652173913043, 'recall': 0.967741935483871, 'f1': 0.916030534351145, 'support': 62}, {'label': 'sport', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'tech', 'precision': 0.875, 'recall': 0.9333333333333333, 'f1': 0.9032258064516129, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T15:54:37.517300', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.5610663890838623, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9431137724550899, 'precision': 0.9434680043226686, 'recall': 0.9431137724550899, 'f1_score': 0.9429924445213278}, 'performance': {'train_time_seconds': 0.0026748180389404297, 'total_time_seconds': 1.5637412071228027, 'inference_time_ms_per_sample': 0.4690906958665676}, 'confusion_matrix': [[70, 1, 5, 1, 0], [1, 53, 1, 1, 2], [1, 1, 59, 0, 1], [1, 0, 0, 76, 0], [0, 2, 0, 1, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.958904109589041, 'recall': 0.9090909090909091, 'f1': 0.9333333333333333, 'support': 77}, {'label': 'entertainment', 'precision': 0.9298245614035088, 'recall': 0.9137931034482759, 'f1': 0.9217391304347826, 'support': 58}, {'label': 'politics', 'precision': 0.9076923076923077, 'recall': 0.9516129032258065, 'f1': 0.9291338582677166, 'support': 62}, {'label': 'sport', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'tech', 'precision': 0.95, 'recall': 0.95, 'f1': 0.95, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:42:45.539329', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.4914696216583252, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9764315665903217, 'recall': 0.9760479041916168, 'f1_score': 0.9760572736773053}, 'performance': {'train_time_seconds': 0.31218624114990234, 'total_time_seconds': 0.8036558628082275, 'inference_time_ms_per_sample': 0.03363486535534887}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9866666666666667, 'recall': 0.961038961038961, 'f1': 0.9736842105263158, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9516129032258065, 'recall': 0.9833333333333333, 'f1': 0.9672131147540983, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n0.95_sfull_naive_bayes_a1.0', 'timestamp': '2025-10-21T15:47:16.986686', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 0.95, 'svd_solver': 'full'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.534364938735962, 'features_extracted': 5000, 'reduction_time': 3.6660714149475098, 'features_after_reduction': 673, 'metrics': {'accuracy': 0.5059880239520959, 'precision': 0.50920261514729, 'recall': 0.5059880239520959, 'f1_score': 0.5025398683958711}, 'performance': {'train_time_seconds': 0.014323949813842773, 'total_time_seconds': 5.2147603034973145, 'inference_time_ms_per_sample': 0.0022956711089539674}, 'confusion_matrix': [[35, 15, 3, 14, 10], [7, 30, 1, 16, 4], [8, 8, 28, 11, 7], [5, 7, 11, 52, 2], [15, 11, 7, 3, 24]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5, 'recall': 0.45454545454545453, 'f1': 0.47619047619047616, 'support': 77}, {'label': 'entertainment', 'precision': 0.4225352112676056, 'recall': 0.5172413793103449, 'f1': 0.46511627906976744, 'support': 58}, {'label': 'politics', 'precision': 0.56, 'recall': 0.45161290322580644, 'f1': 0.5, 'support': 62}, {'label': 'sport', 'precision': 0.5416666666666666, 'recall': 0.6753246753246753, 'f1': 0.6011560693641619, 'support': 77}, {'label': 'tech', 'precision': 0.5106382978723404, 'recall': 0.4, 'f1': 0.4485981308411215, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}]};
    </script>
    
    <!-- Walkthrough JS -->
    <script src="assets/js/walkthrough.js"></script>
    
    <!-- Main script -->
    <script>

// ===== VIEW MODE SWITCHING =====
let currentMode = 'hero';

function switchMode(mode) {
    currentMode = mode;
    
    // Update button states
    document.getElementById('btn-hero-mode').classList.toggle('active', mode === 'hero');
    document.getElementById('btn-custom-mode').classList.toggle('active', mode === 'custom');
    
    // Toggle sections
    document.getElementById('hero-mode-section').style.display = mode === 'hero' ? 'block' : 'none';
    document.getElementById('custom-mode-section').style.display = mode === 'custom' ? 'block' : 'none';
    
    // Initialize mode-specific content
    if (mode === 'hero') {
        initializeHeroMode();
    }
}

// ===== OVERVIEW TABS SWITCHING =====
function switchOverviewTab(tab) {
    // Update tab buttons
    const tabBtns = document.querySelectorAll('.overview-tab-btn');
    tabBtns.forEach(btn => btn.classList.remove('active'));
    event.target.classList.add('active');
    
    // Update tab contents
    ['pipeline', 'calculation', 'tutorials', 'code', 'colab'].forEach(t => {
        const content = document.getElementById(`overview-${t}-tab`);
        if (content) {
            content.classList.toggle('active', t === tab);
        }
    });
    
    // Load code dynamically when Code tab is activated
    if (tab === 'code') {
        loadPipelineCode();
    }
}

function loadPipelineCode() {
    const codeBlock = document.getElementById('pipeline-python-code');
    const loadingDiv = document.querySelector('#pipeline-code-block .code-loading');
    const pre = document.querySelector('#pipeline-code-block pre');
    
    if (codeBlock && codeBlock.textContent.trim() === '') {
        fetch('code/bbc_pipeline_comparison.py')
            .then(response => response.text())
            .then(code => {
                codeBlock.textContent = code;
                loadingDiv.style.display = 'none';
                pre.style.display = 'block';
                if (window.Prism) {
                    Prism.highlightElement(codeBlock);
                }
            })
            .catch(error => {
                loadingDiv.textContent = '‚ùå Failed to load code';
                console.error('Error loading code:', error);
            });
    }
}

function copyPipelineCode() {
    const codeBlock = document.getElementById('pipeline-python-code');
    if (codeBlock) {
        navigator.clipboard.writeText(codeBlock.textContent)
            .then(() => {
                alert('‚úÖ Code copied to clipboard!');
            })
            .catch(err => {
                console.error('Failed to copy:', err);
            });
    }
}

// ===== HERO MODE: TOP 9 PERFORMERS =====
let top9Pipelines = [];

function initializeHeroMode() {
    if (!allPipelinesData || !allPipelinesData.all_results) return;
    
    const pipelines = allPipelinesData.all_results;
    
    // Top 3 by Accuracy
    const topAccuracy = [...pipelines]
        .sort((a, b) => b.metrics.accuracy - a.metrics.accuracy)
        .slice(0, 3);
    
    // Top 3 by Training Speed (fastest = lowest time)
    const topTrainSpeed = [...pipelines]
        .filter(p => p.performance.train_time_seconds > 0)
        .sort((a, b) => a.performance.train_time_seconds - b.performance.train_time_seconds)
        .slice(0, 3);
    
    // Top 3 by Inference Speed (fastest = lowest ms/sample)
    const topInferSpeed = [...pipelines]
        .filter(p => p.performance.inference_time_ms_per_sample > 0)
        .sort((a, b) => a.performance.inference_time_ms_per_sample - b.performance.inference_time_ms_per_sample)
        .slice(0, 3);
    
    // Combine and deduplicate (keep unique pipeline_ids)
    const seen = new Set();
    top9Pipelines = [...topAccuracy, ...topTrainSpeed, ...topInferSpeed].filter(p => {
        if (seen.has(p.pipeline_id)) return false;
        seen.add(p.pipeline_id);
        return true;
    });
    
    // Render comparison
    renderTop9Comparison();
}

// ===== RENDER TOP 9 COMPARISON =====
function renderTop9Comparison() {
    // Performance Tab
    renderPerformanceComparison();
    
    // Configuration Tab
    renderConfigurationDetails();
    
    // Formulas Tab
    renderFormulasContent();
    
    // Confusion Matrices
    renderConfusionMatrices();
}

// === Performance Tab ===
function renderPerformanceComparison() {
    const container = document.getElementById('performance-comparison-table');
    if (!container) return;
    
    // Find best values for highlighting
    const bestAcc = Math.max(...top9Pipelines.map(p => p.metrics.accuracy));
    const bestPrecision = Math.max(...top9Pipelines.map(p => p.metrics.precision));
    const bestRecall = Math.max(...top9Pipelines.map(p => p.metrics.recall));
    const bestF1 = Math.max(...top9Pipelines.map(p => p.metrics.f1_score));
    const bestTrain = Math.min(...top9Pipelines.map(p => p.performance.train_time_seconds));
    const bestInfer = Math.min(...top9Pipelines.map(p => p.performance.inference_time_ms_per_sample));
    
    let html = `
        <table class="performance-table">
            <thead>
                <tr>
                    <th>Rank</th>
                    <th>Pipeline</th>
                    <th>Accuracy</th>
                    <th>Precision</th>
                    <th>Recall</th>
                    <th>F1-Score</th>
                    <th>Train Time (s)</th>
                    <th>Inference (ms)</th>
                </tr>
            </thead>
            <tbody>
    `;
    
    top9Pipelines.forEach((p, idx) => {
        const pipelineName = `${p.extractor.name} ‚Üí ${p.reducer.name} ‚Üí ${p.classifier.name}`;
        
        html += `<tr>`;
        html += `<td><strong>${idx + 1}</strong></td>`;
        html += `<td class="pipeline-name-cell">${pipelineName}</td>`;
        html += `<td class="${p.metrics.accuracy === bestAcc ? 'metric-best' : ''}">${(p.metrics.accuracy * 100).toFixed(2)}%</td>`;
        html += `<td class="${p.metrics.precision === bestPrecision ? 'metric-best' : ''}">${(p.metrics.precision * 100).toFixed(2)}%</td>`;
        html += `<td class="${p.metrics.recall === bestRecall ? 'metric-best' : ''}">${(p.metrics.recall * 100).toFixed(2)}%</td>`;
        html += `<td class="${p.metrics.f1_score === bestF1 ? 'metric-best' : ''}">${(p.metrics.f1_score * 100).toFixed(2)}%</td>`;
        html += `<td class="${p.performance.train_time_seconds === bestTrain ? 'metric-best' : ''}">${p.performance.train_time_seconds.toFixed(3)}</td>`;
        html += `<td class="${p.performance.inference_time_ms_per_sample === bestInfer ? 'metric-best' : ''}">${p.performance.inference_time_ms_per_sample.toFixed(4)}</td>`;
        html += `</tr>`;
    });
    
    html += `</tbody></table>`;
    container.innerHTML = html;
}

// === Configuration Tab ===
function formatConfig(config) {
    // Format config object into readable key-value pairs
    if (!config || Object.keys(config).length === 0) {
        return '<em>default</em>';
    }
    
    const items = [];
    for (const [key, value] of Object.entries(config)) {
        let displayValue = value;
        
        // Format ngram_range tuple
        if (key === 'ngram_range' && Array.isArray(value)) {
            displayValue = `(${value[0]}, ${value[1]})`;
        }
        // Format score_func
        else if (key === 'score_func') {
            displayValue = 'chi2';
        }
        // Format floats
        else if (typeof value === 'number' && !Number.isInteger(value)) {
            displayValue = value.toFixed(2);
        }
        
        items.push(`<code>${key}</code>=<strong>${displayValue}</strong>`);
    }
    
    return items.join(', ');
}

function renderConfigurationDetails() {
    const container = document.getElementById('configuration-details');
    if (!container) return;
    
    let html = '<div class="config-grid">';
    
    top9Pipelines.forEach((p, idx) => {
        const pipelineName = `${p.extractor.name} ‚Üí ${p.reducer.name} ‚Üí ${p.classifier.name}`;
        
        html += `
            <div class="config-card">
                <h4>${idx + 1}. ${pipelineName}</h4>
                <table class="config-table-small">
                    <tr>
                        <th rowspan="2">üî¢ Extractor</th>
                        <td><strong>${p.extractor.name}</strong></td>
                    </tr>
                    <tr>
                        <td class="config-details-small">${formatConfig(p.extractor.config)}</td>
                    </tr>
                    
                    <tr>
                        <th rowspan="2">üéØ Reducer</th>
                        <td><strong>${p.reducer.name}</strong></td>
                    </tr>
                    <tr>
                        <td class="config-details-small">${formatConfig(p.reducer.config)}</td>
                    </tr>
                    
                    <tr>
                        <th rowspan="2">ü§ñ Classifier</th>
                        <td><strong>${p.classifier.name}</strong></td>
                    </tr>
                    <tr>
                        <td class="config-details-small">${formatConfig(p.classifier.config)}</td>
                    </tr>
                    
                    <tr>
                        <th>üìä Features</th>
                        <td><strong>${p.features_extracted}</strong> ‚Üí <strong>${p.features_after_reduction}</strong></td>
                    </tr>
                </table>
            </div>
        `;
    });
    
    html += '</div>';
    container.innerHTML = html;
}

// === Formulas Tab (Y CHANG traditional_ml - METRICS formulas) ===
function renderFormulasContent() {
    const container = document.getElementById('formulas-content');
    if (!container) return;
    
    const html = `
        <div style="max-width: 900px; margin: 0 auto;">
            <!-- Classification Metrics -->
            <div class="config-card" style="margin-bottom: 1.5rem;">
                <h4>üìä Classification Metrics</h4>
                <div style="line-height: 2.2;">
                    <div style="padding: 0.75rem; background: #f8f9fa; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>Accuracy:</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}} = \\frac{\\sum_{i=1}^{n} \\text{CM}[i,i]}{\\text{Total Samples}} \\)
                        </span>
                    </div>
                    
                    <div style="padding: 0.75rem; background: #f8f9fa; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>Precision (per class i):</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{Precision}_i = \\frac{\\text{TP}_i}{\\text{TP}_i + \\text{FP}_i} = \\frac{\\text{CM}[i,i]}{\\sum_{j=1}^{n} \\text{CM}[j,i]} \\)
                        </span>
                    </div>
                    
                    <div style="padding: 0.75rem; background: #f8f9fa; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>Recall (per class i):</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{Recall}_i = \\frac{\\text{TP}_i}{\\text{TP}_i + \\text{FN}_i} = \\frac{\\text{CM}[i,i]}{\\sum_{j=1}^{n} \\text{CM}[i,j]} \\)
                        </span>
                    </div>
                    
                    <div style="padding: 0.75rem; background: #f8f9fa; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>F1-Score (per class i):</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{F1}_i = 2 \\times \\frac{\\text{Precision}_i \\times \\text{Recall}_i}{\\text{Precision}_i + \\text{Recall}_i} = \\frac{2 \\times \\text{TP}_i}{2 \\times \\text{TP}_i + \\text{FP}_i + \\text{FN}_i} \\)
                        </span>
                    </div>
                </div>
            </div>
            
            <!-- Averaging Methods -->
            <div class="config-card" style="margin-bottom: 1.5rem;">
                <h4>üìê Averaging Methods</h4>
                <div style="line-height: 2.2;">
                    <div style="padding: 0.75rem; background: #f0f4ff; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>Macro Average:</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{Macro} = \\frac{1}{n} \\sum_{i=1}^{n} \\text{Metric}_i \\)
                        </span><br>
                        <em style="font-size: 0.9rem; color: #666;">Simple average across all classes (treats all classes equally)</em>
                    </div>
                    
                    <div style="padding: 0.75rem; background: #f0f4ff; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>Weighted Average:</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{Weighted} = \\frac{\\sum_{i=1}^{n} \\text{Metric}_i \\times \\text{Support}_i}{\\sum_{i=1}^{n} \\text{Support}_i} \\)
                        </span><br>
                        <em style="font-size: 0.9rem; color: #666;">Weighted by class frequency (better for imbalanced datasets)</em>
                    </div>
                </div>
            </div>
            
            <!-- Confusion Matrix Components -->
            <div class="config-card">
                <h4>üî¢ Confusion Matrix Components</h4>
                <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1rem; margin-top: 1rem;">
                    <div style="background: #d1fae5; padding: 1rem; border-radius: 8px; border-left: 4px solid #10b981;">
                        <strong style="color: #065f46;">True Positive (TP<sub>i</sub>):</strong><br>
                        <span style="font-size: 0.9rem;">CM[i, i] - Correctly predicted as class i</span>
                    </div>
                    
                    <div style="background: #fee2e2; padding: 1rem; border-radius: 8px; border-left: 4px solid #ef4444;">
                        <strong style="color: #991b1b;">False Positive (FP<sub>i</sub>):</strong><br>
                        <span style="font-size: 0.9rem;">Sum of column i (except diagonal) - Incorrectly predicted as i</span>
                    </div>
                    
                    <div style="background: #fef3c7; padding: 1rem; border-radius: 8px; border-left: 4px solid #f59e0b;">
                        <strong style="color: #92400e;">False Negative (FN<sub>i</sub>):</strong><br>
                        <span style="font-size: 0.9rem;">Sum of row i (except diagonal) - Should be i but predicted as other</span>
                    </div>
                    
                    <div style="background: #dbeafe; padding: 1rem; border-radius: 8px; border-left: 4px solid #3b82f6;">
                        <strong style="color: #1e40af;">Support<sub>i</sub>:</strong><br>
                        <span style="font-size: 0.9rem;">Sum of row i - Total samples of class i</span>
                    </div>
                </div>
            </div>
        </div>
    `;
    
    container.innerHTML = html;
    
    // Render KaTeX formulas after content is loaded
    setTimeout(() => {
        if (typeof renderMathInElement !== 'undefined') {
            renderMathInElement(container, {
                delimiters: [
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true}
                ],
                throwOnError: false
            });
        }
    }, 100);
}

// === Confusion Matrices (Y CHANG traditional_ml) ===
function renderConfusionMatrices() {
    const container = document.getElementById('confusion-matrices-grid');
    if (!container) return;
    
    let html = '';
    
    top9Pipelines.forEach((p, idx) => {
        const pipelineName = `${p.extractor.name} ‚Üí ${p.reducer.name} ‚Üí ${p.classifier.name}`;
        const cm = p.confusion_matrix;
        const labels = p.labels;
        
        if (!cm || !labels) return;
        
        // Find max error for coloring
        const maxError = Math.max(...cm.flatMap((row, i) => row.filter((_, j) => i !== j)));
        
        // Build confusion matrix table (y chang traditional_ml)
        const cmHTML = `
            <table class="cm-table">
                <thead>
                    <tr>
                        <th>Actual \\ Pred</th>
                        ${labels.map(l => `<th>${l}</th>`).join('')}
                    </tr>
                </thead>
                <tbody>
                    ${cm.map((row, i) => `
                        <tr>
                            <th>${labels[i]}</th>
                            ${row.map((val, j) => {
                                if (i === j) {
                                    return `<td class="cm-diagonal">${val}</td>`;
                                } else if (val === 0) {
                                    return `<td class="cm-zero">0</td>`;
                                } else {
                                    const severity = val / maxError;
                                    const className = severity > 0.5 ? 'cm-error-high' 
                                                    : severity > 0.2 ? 'cm-error-medium' 
                                                    : 'cm-error-low';
                                    return `<td class="${className}">${val}</td>`;
                                }
                            }).join('')}
                        </tr>
                    `).join('')}
                </tbody>
            </table>
        `;
        
        // Build per-class summary (y chang traditional_ml)
        const perClassMetrics = p.per_class_metrics || [];
        const perClassHTML = `
            <div class="per-class-summary">
                ${perClassMetrics.map(cls => `
                    <div class="per-class-item">
                        <div class="per-class-label">${cls.label}</div>
                        <div class="per-class-value">${((cls.f1 || 0) * 100).toFixed(1)}%</div>
                    </div>
                `).join('')}
            </div>
        `;
        
        // Build card (y chang traditional_ml structure)
        html += `
            <div class="confusion-matrix-card">
                <div class="matrix-header">
                    <h5>${idx + 1}. ${pipelineName} - Accuracy: ${(p.metrics.accuracy * 100).toFixed(2)}%</h5>
                </div>
                <div class="matrix-content">
                    <h4>Per-Class F1-Score</h4>
                    ${perClassHTML}
                    
                    <h4 style="margin-top: 2rem;">Confusion Matrix</h4>
                    
                    <div class="matrix-tabs">
                        <button class="matrix-tab-btn active" onclick="switchMatrixView('${idx}', 'matrix')">
                            üìä Confusion Matrix
                        </button>
                        <button class="matrix-tab-btn" onclick="switchMatrixView('${idx}', 'walkthrough')">
                            üéì Metrics Walkthrough
                        </button>
                    </div>
                    
                    <div id="matrix-view-${idx}" class="matrix-view active">
                        ${cmHTML}
                        <p style="margin-top: 1rem; color: #666; font-size: 0.9rem; text-align: center;">
                            üü¢ Diagonal = Correct Predictions | üü°üü†üî¥ = Errors (color intensity = severity)
                        </p>
                    </div>
                    
                    <div id="walkthrough-view-${idx}" class="matrix-view">
                        <div class="walkthrough-container" id="walkthrough-${idx}">
                            <button class="walkthrough-fullscreen-btn" onclick="toggleFullscreen('${idx}')">‚õ∂ Fullscreen</button>
                            <div class="walkthrough-content">
                                <div class="walkthrough-grid">
                                    <div class="walkthrough-left">
                                        <div class="matrix-display">
                                            <h4 style="margin-bottom: 1rem; color: #333;">Confusion Matrix</h4>
                                            <table class="wt-cm-table" id="wt-matrix-${idx}"></table>
                                        </div>
                                        
                                        <div class="walkthrough-controls">
                                            <button class="wt-btn wt-btn-nav" onclick="wtPrevStep('${idx}')">‚óÄ Previous</button>
                                            <button class="wt-btn wt-btn-nav" onclick="wtNextStep('${idx}')">Next ‚ñ∂</button>
                                            <button class="wt-btn wt-btn-reset" onclick="wtReset('${idx}')">‚Üª Reset</button>
                                        </div>
                                        
                                        <div class="wt-progress-bar">
                                            <div class="wt-progress-fill" id="wt-progress-${idx}"></div>
                                        </div>
                                        <div class="wt-progress-text" id="wt-progress-text-${idx}">Step 1/12</div>
                                    </div>
                                    
                                    <div class="walkthrough-right">
                                        <div class="wt-step-info" id="wt-step-info-${idx}">
                                            <h3>
                                                <span class="wt-step-number" id="wt-step-num-${idx}">1</span>
                                                <span id="wt-step-title-${idx}">Loading...</span>
                                            </h3>
                                            <p id="wt-step-desc-${idx}"></p>
                                        </div>
                                        
                                        <div class="wt-calculations" id="wt-calc-${idx}"></div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        `;
    });
    
    container.innerHTML = html;
    
    // Initialize walkthroughs for each pipeline
    top9Pipelines.forEach((p, idx) => {
        if (p.confusion_matrix && p.labels) {
            initWalkthrough(idx.toString(), p.confusion_matrix, p.labels);
        }
    });
}

// Fullscreen toggle (y chang traditional_ml)
function toggleFullscreen(idx) {
    const container = document.getElementById(`walkthrough-${idx}`);
    const btn = document.querySelector(`#walkthrough-${idx} .walkthrough-fullscreen-btn`);
    
    if (!container || !btn) {
        console.error('Fullscreen elements not found for idx:', idx);
        return;
    }
    
    if (container.classList.contains('fullscreen')) {
        container.classList.remove('fullscreen');
        btn.textContent = '‚õ∂ Fullscreen';
        document.body.style.overflow = '';
    } else {
        container.classList.add('fullscreen');
        btn.textContent = '‚úï Exit';
        document.body.style.overflow = 'hidden';
    }
}

// Matrix view switching (y chang traditional_ml)
function switchMatrixView(idx, view) {
    const matrixView = document.getElementById(`matrix-view-${idx}`);
    const walkthroughView = document.getElementById(`walkthrough-view-${idx}`);
    
    if (!matrixView || !walkthroughView) return;
    
    const matrixContent = matrixView.closest('.matrix-content');
    if (!matrixContent) return;
    
    const tabButtons = matrixContent.querySelectorAll('.matrix-tab-btn');
    tabButtons.forEach((btn, btnIdx) => {
        if ((view === 'matrix' && btnIdx === 0) || (view === 'walkthrough' && btnIdx === 1)) {
            btn.classList.add('active');
        } else {
            btn.classList.remove('active');
        }
    });
    
    if (view === 'matrix') {
        matrixView.classList.add('active');
        walkthroughView.classList.remove('active');
    } else {
        matrixView.classList.remove('active');
        walkthroughView.classList.add('active');
    }
}

// === Tab Switching ===
function switchComparisonTab(tab) {
    // Update buttons
    const buttons = document.querySelectorAll('.comparison-tab-btn');
    buttons.forEach(btn => btn.classList.remove('active'));
    event.target.classList.add('active');
    
    // Update content
    document.getElementById('performance-tab').classList.toggle('active', tab === 'performance');
    document.getElementById('configuration-tab').classList.toggle('active', tab === 'configuration');
    document.getElementById('formulas-tab').classList.toggle('active', tab === 'formulas');
}

// ===== PIPELINE DETAIL TABS =====
function switchDetailTab(mode, tab) {
    // Update tab buttons
    const tabBtns = document.querySelectorAll(`#${mode}-pipeline-details .detail-tab-btn`);
    tabBtns.forEach(btn => btn.classList.remove('active'));
    event.target.classList.add('active');
    
    // Update tab contents
    ['config', 'formula', 'confusion', 'walkthrough'].forEach(t => {
        const content = document.getElementById(`${mode}-${t}-tab`);
        if (content) {
            content.classList.toggle('active', t === tab);
        }
    });
}

function populatePipelineDetails(mode, pipeline) {
    // Configuration tab
    document.getElementById(`${mode}-config-content`).innerHTML = buildConfigContent(pipeline);
    
    // Formula tab
    document.getElementById(`${mode}-formula-content`).innerHTML = buildFormulaContent(pipeline);
    
    // Confusion Matrix tab
    document.getElementById(`${mode}-confusion-content`).innerHTML = buildConfusionContent(pipeline);
    
    // Walkthrough tab
    document.getElementById(`${mode}-walkthrough-content`).innerHTML = buildWalkthroughContent(pipeline);
}

function buildConfigContent(pipeline) {
    return `
        <div class="config-details">
            <h4>üîß Pipeline Configuration</h4>
            <table class="config-table">
                <tr><th>Feature Extractor</th><td>${pipeline.extractor.name} - ${JSON.stringify(pipeline.extractor.config)}</td></tr>
                <tr><th>Dimensionality Reducer</th><td>${pipeline.reducer.name} - ${JSON.stringify(pipeline.reducer.config)}</td></tr>
                <tr><th>Classifier</th><td>${pipeline.classifier.name} - ${JSON.stringify(pipeline.classifier.config)}</td></tr>
                <tr><th>Accuracy</th><td><strong>${(pipeline.metrics.accuracy * 100).toFixed(2)}%</strong></td></tr>
                <tr><th>Precision</th><td>${(pipeline.metrics.precision * 100).toFixed(2)}%</td></tr>
                <tr><th>Recall</th><td>${(pipeline.metrics.recall * 100).toFixed(2)}%</td></tr>
                <tr><th>F1-Score</th><td>${(pipeline.metrics.f1_score * 100).toFixed(2)}%</td></tr>
                <tr><th>Training Time</th><td>${pipeline.performance.train_time_seconds.toFixed(3)}s</td></tr>
                <tr><th>Inference Speed</th><td>${pipeline.performance.inference_time_ms_per_sample.toFixed(4)} ms/sample</td></tr>
            </table>
        </div>
    `;
}

function buildFormulaContent(pipeline) {
    // Placeholder - will add formulas based on pipeline components
    return `
        <div class="formula-details">
            <h4>üìê Mathematical Formulas</h4>
            <p>Formulas for <strong>${pipeline.name}</strong> will be displayed here.</p>
            <p>Coming soon: TF-IDF formula, classifier equations, etc.</p>
        </div>
    `;
}

function buildConfusionContent(pipeline) {
    if (!pipeline.confusion_matrix) {
        return '<p>No confusion matrix data available.</p>';
    }
    
    // Placeholder - will render actual confusion matrix
    return `
        <div class="confusion-matrix-container">
            <h4>üìä Confusion Matrix</h4>
            <div id="cm-plot-${pipeline.id}"></div>
            <p><em>Confusion matrix visualization will be rendered here.</em></p>
        </div>
    `;
}

function buildWalkthroughContent(pipeline) {
    return `
        <div class="walkthrough-details">
            <h4>üö∂ Step-by-Step Walkthrough</h4>
            <div class="walkthrough-steps">
                <div class="walkthrough-step">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h5>Feature Extraction: ${pipeline.extractor.name}</h5>
                        <p>Convert text documents into numerical features.</p>
                        <p><em>Output: ${pipeline.features_extracted} features</em></p>
                    </div>
                </div>
                <div class="walkthrough-step">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h5>Dimensionality Reduction: ${pipeline.reducer.name}</h5>
                        <p>${pipeline.reducer.name !== 'None' ? 'Reduce feature space for efficiency.' : 'No reduction applied, using all features.'}</p>
                        <p><em>Output: ${pipeline.features_after_reduction} features</em></p>
                    </div>
                </div>
                <div class="walkthrough-step">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h5>Classification: ${pipeline.classifier.name}</h5>
                        <p>Train model and predict categories.</p>
                    </div>
                </div>
                <div class="walkthrough-step">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h5>Results</h5>
                        <p>Accuracy: <strong>${(pipeline.metrics.accuracy * 100).toFixed(2)}%</strong></p>
                        <p>F1-Score: <strong>${(pipeline.metrics.f1_score * 100).toFixed(2)}%</strong></p>
                        <p>Training Time: <strong>${pipeline.performance.train_time_seconds.toFixed(3)}s</strong></p>
                    </div>
                </div>
            </div>
        </div>
    `;
}

// ===== GLOBAL STATE =====
let selectedExtractor = 'tfidf';
let selectedReducer = 'none';
let selectedClassifiers = ['logistic', 'svm', 'naive_bayes'];

// ===== INITIALIZATION =====
document.addEventListener('DOMContentLoaded', function() {
    // Initialize hero mode first (default view)
    initializeHeroMode();
    
    // Initialize custom builder
    initializeBuilder();
    updatePreview();
    
    // Add change listeners
    document.querySelectorAll('input[name="extractor"]').forEach(radio => {
        radio.addEventListener('change', handleExtractorChange);
    });
    
    document.querySelectorAll('input[name="reducer"]').forEach(radio => {
        radio.addEventListener('change', handleReducerChange);
    });
    
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.addEventListener('change', handleClassifierChange);
    });
});

function initializeBuilder() {
    // Set initial checked states
    document.querySelector('input[name="extractor"][value="tfidf"]').checked = true;
    document.querySelector('input[name="reducer"][value="none"]').checked = true;
    
    ['logistic', 'svm', 'naive_bayes'].forEach(clf => {
        document.querySelector(`input[name="classifier"][value="${clf}"]`).checked = true;
    });
}

// ===== EVENT HANDLERS =====
function handleExtractorChange(e) {
    selectedExtractor = e.target.value;
    updateRadioStyles('extractor');
    updatePreview();
}

function handleReducerChange(e) {
    selectedReducer = e.target.value;
    updateRadioStyles('reducer');
    updatePreview();
}

function handleClassifierChange(e) {
    if (e.target.checked) {
        selectedClassifiers.push(e.target.value);
    } else {
        selectedClassifiers = selectedClassifiers.filter(c => c !== e.target.value);
    }
    updateCheckboxStyles();
    updatePreview();
}

function updateRadioStyles(name) {
    document.querySelectorAll(`input[name="${name}"]`).forEach(radio => {
        const label = radio.closest('label');
        if (radio.checked) {
            label.classList.add('checked');
        } else {
            label.classList.remove('checked');
        }
    });
}

function updateCheckboxStyles() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        const label = checkbox.closest('label');
        if (checkbox.checked) {
            label.classList.add('checked');
        } else {
            label.classList.remove('checked');
        }
    });
}

function updatePreview() {
    const count = selectedClassifiers.length;
    const extractorName = document.querySelector(`input[name="extractor"][value="${selectedExtractor}"]`).dataset.name;
    const reducerName = document.querySelector(`input[name="reducer"][value="${selectedReducer}"]`).dataset.name;
    
    document.getElementById('preview-count').textContent = count;
    
    const list = document.getElementById('preview-list');
    list.innerHTML = '';
    
    selectedClassifiers.forEach(clf => {
        const classifierName = document.querySelector(`input[name="classifier"][value="${clf}"]`).dataset.name;
        const li = document.createElement('li');
        li.textContent = `${extractorName} ‚Üí ${reducerName} ‚Üí ${classifierName}`;
        list.appendChild(li);
    });
}

// ===== CLASSIFIER ACTIONS =====
function selectAllClassifiers() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.checked = true;
        selectedClassifiers = Array.from(document.querySelectorAll('input[name="classifier"]')).map(cb => cb.value);
    });
    updateCheckboxStyles();
    updatePreview();
}

function deselectAllClassifiers() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.checked = false;
    });
    selectedClassifiers = [];
    updateCheckboxStyles();
    updatePreview();
}

function selectTopClassifiers() {
    // Top 3 fastest: Naive Bayes, SVM, Logistic
    deselectAllClassifiers();
    ['naive_bayes', 'svm', 'logistic'].forEach(clf => {
        const checkbox = document.querySelector(`input[name="classifier"][value="${clf}"]`);
        if (checkbox) {
            checkbox.checked = true;
            selectedClassifiers.push(clf);
        }
    });
    updateCheckboxStyles();
    updatePreview();
}

function resetBuilder() {
    selectedExtractor = 'tfidf';
    selectedReducer = 'none';
    selectedClassifiers = ['logistic', 'svm', 'naive_bayes'];
    initializeBuilder();
    updateRadioStyles('extractor');
    updateRadioStyles('reducer');
    updateCheckboxStyles();
    updatePreview();
    
    // Hide results if shown
    document.getElementById('results-section').style.display = 'none';
}

// ===== COMPARE PIPELINES =====
function comparePipelines() {
    if (selectedClassifiers.length === 0) {
        alert('Please select at least one classifier!');
        return;
    }
    
    // Filter matching pipelines
    const matchingPipelines = allPipelinesData.all_results.filter(pipeline => {
        return pipeline.extractor.type === selectedExtractor &&
               pipeline.reducer.type === selectedReducer &&
               selectedClassifiers.includes(pipeline.classifier.type);
    });
    
    if (matchingPipelines.length === 0) {
        alert('No matching pipelines found! Try different combinations.');
        return;
    }
    
    // Show results section
    document.getElementById('custom-results-section').style.display = 'block';
    
    // Scroll to results
    document.getElementById('custom-results-section').scrollIntoView({ behavior: 'smooth' });
    
    // Build visualizations
    buildBestCards(matchingPipelines);
    buildComparisonTable(matchingPipelines);
    buildHeatmap(matchingPipelines);
    buildTradeoffChart(matchingPipelines);
}

// ===== BUILD BEST CARDS =====
function buildBestCards(pipelines) {
    const bestAccuracy = pipelines.reduce((a, b) => a.metrics.accuracy > b.metrics.accuracy ? a : b);
    const fastestTrain = pipelines.reduce((a, b) => a.performance.total_time_seconds < b.performance.total_time_seconds ? a : b);
    const fastestInfer = pipelines.reduce((a, b) => a.performance.inference_time_ms_per_sample < b.performance.inference_time_ms_per_sample ? a : b);
    
    const html = `
        <div class="best-card accuracy">
            <h3>üèÜ Best Accuracy</h3>
            <div class="metric-value" style="color: #10b981;">${(bestAccuracy.metrics.accuracy * 100).toFixed(2)}%</div>
            <div class="pipeline-name">${formatPipelineName(bestAccuracy)}</div>
        </div>
        <div class="best-card speed">
            <h3>‚ö° Fastest Training</h3>
            <div class="metric-value" style="color: #f59e0b;">${fastestTrain.performance.total_time_seconds.toFixed(2)}s</div>
            <div class="pipeline-name">${formatPipelineName(fastestTrain)}</div>
        </div>
        <div class="best-card size">
            <h3>üí® Fastest Inference</h3>
            <div class="metric-value" style="color: #3b82f6;">${fastestInfer.performance.inference_time_ms_per_sample.toFixed(2)}ms</div>
            <div class="pipeline-name">${formatPipelineName(fastestInfer)}</div>
        </div>
    `;
    
    document.getElementById('custom-best-cards').innerHTML = html;
}

function formatPipelineName(pipeline) {
    return `${pipeline.extractor.name} ‚Üí ${pipeline.reducer.name} ‚Üí ${pipeline.classifier.name}`;
}

// ===== BUILD COMPARISON TABLE =====
function buildComparisonTable(pipelines) {
    // Find best values
    const bestAcc = Math.max(...pipelines.map(p => p.metrics.accuracy));
    const bestF1 = Math.max(...pipelines.map(p => p.metrics.f1_score));
    const bestTrain = Math.min(...pipelines.map(p => p.performance.total_time_seconds));
    const bestInfer = Math.min(...pipelines.map(p => p.performance.inference_time_ms_per_sample));
    
    let rows = '';
    pipelines.forEach(p => {
        const isBestAcc = p.metrics.accuracy === bestAcc;
        const isBestF1 = p.metrics.f1_score === bestF1;
        const isBestTrain = p.performance.total_time_seconds === bestTrain;
        const isBestInfer = p.performance.inference_time_ms_per_sample === bestInfer;
        
        rows += `
            <tr>
                <td class="pipeline-cell">${formatPipelineName(p)}</td>
                <td class="${isBestAcc ? 'metric-best' : ''}">${(p.metrics.accuracy * 100).toFixed(2)}%</td>
                <td class="${isBestF1 ? 'metric-best' : ''}">${(p.metrics.f1_score * 100).toFixed(2)}%</td>
                <td class="${isBestTrain ? 'metric-best' : ''}">${p.performance.total_time_seconds.toFixed(2)}s</td>
                <td class="${isBestInfer ? 'metric-best' : ''}">${p.performance.inference_time_ms_per_sample.toFixed(3)}ms</td>
                <td>${p.features_extracted}</td>
                <td>${p.features_after_reduction}</td>
            </tr>
        `;
    });
    
    const html = `
        <table class="comparison-table">
            <thead>
                <tr>
                    <th>Pipeline</th>
                    <th>Accuracy</th>
                    <th>F1-Score</th>
                    <th>Train Time</th>
                    <th>Inference</th>
                    <th>Features (Raw)</th>
                    <th>Features (Final)</th>
                </tr>
            </thead>
            <tbody>
                ${rows}
            </tbody>
        </table>
    `;
    
    document.getElementById('custom-comparison-table').innerHTML = html;
}

// ===== BUILD HEATMAP =====
function buildHeatmap(allPipelines) {
    // Group by extractor+reducer (x-axis) and classifier (y-axis)
    const classifiers = ['logistic', 'svm', 'naive_bayes', 'random_forest', 'decision_tree'];
    const pipelines_combos = [];
    
    // Get unique extractor+reducer combinations
    const combinations = {};
    allPipelines.forEach(p => {
        const combo = `${p.extractor.type}_${p.reducer.type}`;
        if (!combinations[combo]) {
            combinations[combo] = `${p.extractor.name}+${p.reducer.name}`;
        }
    });
    
    const xLabels = Object.values(combinations);
    const yLabels = classifiers.map(clf => {
        const sample = allPipelines.find(p => p.classifier.type === clf);
        return sample ? sample.classifier.name : clf;
    });
    
    // Build matrix
    const zData = [];
    classifiers.forEach(clf => {
        const row = [];
        Object.keys(combinations).forEach(combo => {
            const [ext, red] = combo.split('_');
            const pipeline = allPipelines.find(p => 
                p.extractor.type === ext && 
                p.reducer.type === red && 
                p.classifier.type === clf
            );
            row.push(pipeline ? pipeline.metrics.accuracy * 100 : null);
        });
        zData.push(row);
    });
    
    const data = [{
        z: zData,
        x: xLabels,
        y: yLabels,
        type: 'heatmap',
        colorscale: [
            [0, '#ef4444'],
            [0.85, '#f59e0b'],
            [0.90, '#fbbf24'],
            [0.95, '#a7f3d0'],
            [1, '#10b981']
        ],
        hovertemplate: '%{y}<br>%{x}<br>Accuracy: %{z:.2f}%<extra></extra>',
        colorbar: {
            title: 'Accuracy (%)',
            titleside: 'right'
        }
    }];
    
    const layout = {
        xaxis: { title: 'Feature Extraction + Reduction', tickangle: -45 },
        yaxis: { title: 'Classifier' },
        margin: { l: 150, r: 50, b: 150, t: 50 },
        height: 500
    };
    
    Plotly.newPlot('custom-heatmap-chart', data, layout, {responsive: true});
}

// ===== BUILD TRADEOFF CHART =====
function buildTradeoffChart(allPipelines) {
    const traces = [];
    const classifiers = [...new Set(allPipelines.map(p => p.classifier.type))];
    const colors = ['#667eea', '#f59e0b', '#10b981', '#ef4444', '#3b82f6'];
    
    classifiers.forEach((clf, idx) => {
        const pipelinesForClf = allPipelines.filter(p => p.classifier.type === clf);
        
        traces.push({
            x: pipelinesForClf.map(p => p.performance.total_time_seconds),
            y: pipelinesForClf.map(p => p.metrics.accuracy * 100),
            mode: 'markers',
            type: 'scatter',
            name: pipelinesForClf[0].classifier.name,
            marker: {
                size: 12,
                color: colors[idx % colors.length]
            },
            text: pipelinesForClf.map(p => formatPipelineName(p)),
            hovertemplate: '%{text}<br>Time: %{x:.2f}s<br>Accuracy: %{y:.2f}%<extra></extra>'
        });
    });
    
    const layout = {
        xaxis: { title: 'Training Time (seconds)', type: 'log' },
        yaxis: { title: 'Accuracy (%)', range: [75, 100] },
        hovermode: 'closest',
        legend: { x: 0.7, y: 0.1 },
        height: 500
    };
    
    Plotly.newPlot('custom-tradeoff-chart', traces, layout, {responsive: true});
}

// ===== BUILD CONFUSION MATRICES =====
function buildConfusionMatrices(pipelines) {
    const html = '<h3>üéØ Confusion Matrices (Selected Pipelines)</h3><div class="cm-grid" id="cm-grid"></div>';
    document.getElementById('confusion-matrices').innerHTML = html;
    
    const grid = document.getElementById('cm-grid');
    
    pipelines.forEach((p, idx) => {
        const div = document.createElement('div');
        div.id = `cm-${idx}`;
        grid.appendChild(div);
        
        const data = [{
            z: p.confusion_matrix,
            x: p.labels,
            y: p.labels,
            type: 'heatmap',
            colorscale: 'Blues',
            hovertemplate: 'True: %{y}<br>Pred: %{x}<br>Count: %{z}<extra></extra>'
        }];
        
        const layout = {
            title: `${formatPipelineName(p)}<br>Accuracy: ${(p.metrics.accuracy * 100).toFixed(2)}%`,
            xaxis: { title: 'Predicted', side: 'bottom' },
            yaxis: { title: 'True', autorange: 'reversed' },
            height: 400,
            margin: { l: 100, r: 50, b: 100, t: 80 }
        };
        
        Plotly.newPlot(`cm-${idx}`, data, layout, {responsive: true});
    });
}

    </script>
</body>
</html>