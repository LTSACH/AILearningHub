<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pipeline Comparison - BBC News Classification | AI Learning Hub</title>
    
    <!-- Plotly for interactive charts -->
    <script src="https://cdn.plot.ly/plotly-2.26.0.min.js"></script>
    
    <!-- KaTeX for math formulas -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <!-- Prism.js for code syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    
    <!-- Walkthrough CSS and JS -->
    <link rel="stylesheet" href="assets/css/walkthrough.css">
    
    <style>

/* ===== RESET & BASE ===== */
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
    line-height: 1.6;
    color: #333;
    background: #f5f7fa;
}

/* ===== NAVBAR ===== */
.navbar {
    background: white;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
    position: sticky;
    top: 0;
    z-index: 1000;
}

.nav-container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 1rem 2rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.brand {
    font-size: 1.5rem;
    font-weight: 700;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    text-decoration: none;
}

.nav-links a {
    color: #667eea;
    text-decoration: none;
    font-weight: 500;
    transition: opacity 0.3s;
}

.nav-links a:hover {
    opacity: 0.7;
}

/* ===== HERO ===== */
.hero {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 3rem 2rem;
    text-align: center;
}

.hero h1 {
    font-size: 2.5rem;
    margin-bottom: 0.5rem;
}

.hero p {
    font-size: 1.1rem;
    opacity: 0.9;
    margin-bottom: 2rem;
}

.hero-stats {
    display: flex;
    justify-content: center;
    gap: 3rem;
    flex-wrap: wrap;
}

.stat-item {
    text-align: center;
}

.stat-value {
    font-size: 2.5rem;
    font-weight: 700;
    margin-bottom: 0.25rem;
}

.stat-label {
    font-size: 0.9rem;
    opacity: 0.9;
    text-transform: uppercase;
    letter-spacing: 1px;
}

/* ===== CONTAINER ===== */
.container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 2rem;
}

.section-description {
    color: #666;
    font-size: 1.1rem;
    margin-bottom: 2rem;
    text-align: center;
}

/* ===== VIEW MODE TOGGLE ===== */
.view-mode-section {
    margin-bottom: 2rem;
}

.mode-toggle {
    display: flex;
    gap: 1rem;
    justify-content: center;
    background: white;
    padding: 1.5rem;
    border-radius: 12px;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
}

.mode-btn {
    padding: 1rem 2.5rem;
    font-size: 1.1rem;
    font-weight: 600;
    border: 2px solid #e0e7ff;
    background: white;
    color: #667eea;
    border-radius: 8px;
    cursor: pointer;
    transition: all 0.3s ease;
}

.mode-btn:hover {
    background: #f0f4ff;
    transform: translateY(-2px);
}

.mode-btn.active {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-color: #667eea;
}

/* ===== PIPELINE OVERVIEW TABS ===== */
.pipeline-overview-section {
    background: white;
    border-radius: 12px;
    padding: 2rem;
    margin-bottom: 2rem;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
}

.overview-tabs-section {
    width: 100%;
}

.overview-tabs {
    display: flex;
    gap: 0.5rem;
    border-bottom: 2px solid #e0e7ff;
    margin-bottom: 1.5rem;
}

.overview-tab-btn {
    padding: 0.75rem 1.5rem;
    background: none;
    border: none;
    border-bottom: 3px solid transparent;
    color: #666;
    font-size: 1.05rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.3s ease;
}

.overview-tab-btn:hover {
    color: #667eea;
    background: #f0f4ff;
}

.overview-tab-btn.active {
    color: #667eea;
    border-bottom-color: #667eea;
    font-weight: 600;
}

.overview-tab-content {
    display: none;
    padding: 1.5rem 0;
}

.overview-tab-content.active {
    display: block;
}

/* Pipeline Diagram */
.pipeline-diagram {
    padding: 1rem;
}

.diagram-flow {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 1rem;
    margin-bottom: 2rem;
    flex-wrap: wrap;
}

.flow-step {
    background: #f0f4ff;
    border: 2px solid #e0e7ff;
    border-radius: 12px;
    padding: 1.5rem 1rem;
    text-align: center;
    min-width: 120px;
}

.flow-step.flow-varied {
    background: linear-gradient(135deg, #fff5f5 0%, #f0f4ff 100%);
    border-color: #667eea;
}

.step-icon-large {
    font-size: 2.5rem;
    margin-bottom: 0.5rem;
}

.step-label {
    font-weight: 600;
    color: #333;
    font-size: 0.95rem;
}

.step-options {
    font-size: 0.8rem;
    color: #667eea;
    margin-top: 0.25rem;
}

.flow-arrow {
    font-size: 1.5rem;
    color: #667eea;
    font-weight: bold;
}

.pipeline-info {
    text-align: center;
    background: #f9fafb;
    padding: 1.5rem;
    border-radius: 8px;
}

.pipeline-info p {
    margin: 0.5rem 0;
    color: #666;
    line-height: 1.6;
}

.pipeline-info strong {
    color: #667eea;
    font-size: 1.1rem;
}

/* Tutorials Grid */
.tutorials-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 1.5rem;
}

.tutorial-card {
    background: #f9fafb;
    border-radius: 8px;
    padding: 1.5rem;
    border: 1px solid #e0e7ff;
}

.tutorial-card h3 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

.tutorial-item {
    margin-bottom: 1rem;
    padding-bottom: 1rem;
    border-bottom: 1px solid #e0e7ff;
}

.tutorial-item:last-child {
    border-bottom: none;
}

.tutorial-item h4 {
    color: #333;
    margin-bottom: 0.5rem;
    font-size: 1rem;
}

.tutorial-item p {
    color: #666;
    font-size: 0.9rem;
    margin-bottom: 0.5rem;
}

.tutorial-item a {
    color: #667eea;
    text-decoration: none;
    font-size: 0.9rem;
}

.tutorial-item a:hover {
    text-decoration: underline;
}

/* Code Actions */
.code-actions {
    display: flex;
    gap: 1rem;
    margin: 1rem 0;
}

.btn-code-action {
    padding: 0.75rem 1.5rem;
    background: #667eea;
    color: white;
    border: none;
    border-radius: 6px;
    cursor: pointer;
    text-decoration: none;
    font-size: 1rem;
    transition: all 0.3s ease;
}

.btn-code-action:hover {
    background: #5568d3;
    transform: translateY(-2px);
}

/* ===== HERO MODE: COMPARISON SECTION ===== */
.hero-mode-section {
    margin-bottom: 2rem;
}

.comparison-section {
    background: white;
    border-radius: 12px;
    padding: 2rem;
    margin-top: 2rem;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
}

.comparison-header {
    text-align: center;
    margin-bottom: 2rem;
}

.comparison-header h2 {
    color: #333;
    margin-bottom: 0.5rem;
}

.comparison-header p {
    color: #666;
    font-size: 1.05rem;
}

/* Comparison Tabs */
.comparison-tabs {
    display: flex;
    gap: 0.5rem;
    border-bottom: 2px solid #e0e7ff;
    margin-bottom: 2rem;
    justify-content: center;
}

.comparison-tab-btn {
    padding: 0.75rem 2rem;
    background: none;
    border: none;
    border-bottom: 3px solid transparent;
    color: #666;
    font-size: 1.05rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.3s ease;
}

.comparison-tab-btn:hover {
    color: #667eea;
    background: #f0f4ff;
}

.comparison-tab-btn.active {
    color: #667eea;
    border-bottom-color: #667eea;
    font-weight: 600;
}

.comparison-tab-content {
    display: none;
    padding: 1.5rem 0;
}

.comparison-tab-content.active {
    display: block;
}

/* Performance Table */
.performance-table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 1rem;
}

.performance-table thead {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
}

.performance-table th {
    padding: 1rem;
    text-align: left;
    font-weight: 600;
}

.performance-table td {
    padding: 0.75rem 1rem;
    border-bottom: 1px solid #e0e7ff;
}

.performance-table tbody tr:hover {
    background: #f0f4ff;
}

.pipeline-name-cell {
    font-weight: 500;
    color: #333;
}

.metric-best {
    background: #d4edda !important;
    color: #155724;
    font-weight: 700;
}

/* Config Grid */
.config-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 1.5rem;
}

.config-card {
    background: #f9fafb;
    border: 1px solid #e0e7ff;
    border-radius: 8px;
    padding: 1.5rem;
}

.config-card h4 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1rem;
}

.config-table-small {
    width: 100%;
    font-size: 0.9rem;
}

.config-table-small th {
    text-align: left;
    padding: 0.5rem;
    background: #e0e7ff;
    color: #333;
    font-weight: 600;
}

.config-table-small td {
    padding: 0.5rem;
    border-bottom: 1px solid #e0e7ff;
}

.config-details-small {
    font-size: 0.85rem;
    color: #666;
    font-family: monospace;
}

/* Formulas */
.formulas-container {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
    gap: 1.5rem;
}

.formula-section {
    background: #f9fafb;
    border-left: 4px solid #667eea;
    padding: 1.5rem;
    border-radius: 8px;
}

.formula-section h4 {
    color: #333;
    margin-bottom: 1rem;
}

.formula-box {
    background: white;
    padding: 1rem;
    border-radius: 6px;
    border: 1px solid #e0e7ff;
}

.formula-math {
    font-family: 'Courier New', monospace;
    background: #f0f4ff;
    padding: 0.5rem;
    margin: 0.5rem 0;
    border-radius: 4px;
    font-size: 0.95rem;
}

/* ===== CONFUSION MATRICES (Y CHANG traditional_ml) ===== */
.confusion-section {
    margin-top: 3rem;
    padding-top: 2rem;
    border-top: 2px solid #e0e7ff;
}

.confusion-section h3 {
    color: #333;
    margin-bottom: 1.5rem;
    text-align: center;
}

.confusion-matrix-card {
    background: white;
    border-radius: 12px;
    overflow: hidden;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    margin: 0.75rem 0;
}

.matrix-header {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 0.75rem 1rem;
}

.matrix-header h5 {
    margin: 0;
    font-size: 1.1rem;
}

.matrix-content {
    padding: 0.75rem;
}

/* Confusion matrix table */
.cm-table {
    width: 100%;
    border-collapse: separate;
    border-spacing: 6px;
    margin: 1rem 0;
}

.cm-table th,
.cm-table td {
    padding: 12px;
    text-align: center;
    font-weight: 600;
    border-radius: 8px;
    transition: all 0.3s ease;
}

.cm-table th {
    background: #667eea;
    color: white;
    font-size: 0.9rem;
}

.cm-table tbody th {
    background: #667eea;
    color: white;
    font-size: 0.9rem;
}

.cm-table td {
    background: #f3f4f6;
    color: #333;
    font-size: 1.1rem;
}

.cm-diagonal {
    background: linear-gradient(135deg, #10b981, #059669) !important;
    color: white !important;
    font-size: 1.2rem !important;
    box-shadow: 0 0 12px rgba(16, 185, 129, 0.4);
}

.cm-error-low {
    background: #fef3c7 !important;
    color: #92400e !important;
}

.cm-error-medium {
    background: #fed7aa !important;
    color: #9a3412 !important;
}

.cm-error-high {
    background: #fecaca !important;
    color: #991b1b !important;
    font-weight: 600 !important;
}

.cm-zero {
    background: #f9fafb !important;
    color: #d1d5db !important;
}

/* Per-class summary */
.per-class-summary {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
    gap: 0.75rem;
    margin: 0.75rem 0;
    padding: 0.75rem;
    background: #f9fafb;
    border-radius: 8px;
}

.per-class-item {
    text-align: center;
    padding: 0.75rem;
    background: white;
    border-radius: 6px;
    border: 1px solid #e5e7eb;
}

.per-class-label {
    font-weight: 600;
    color: #667eea;
    text-transform: capitalize;
    margin-bottom: 0.5rem;
}

.per-class-value {
    font-size: 1.5rem;
    font-weight: bold;
    color: #10b981;
}

/* Matrix view tabs */
.matrix-tabs {
    display: flex;
    gap: 0.5rem;
    margin-bottom: 1.5rem;
    border-bottom: 2px solid #e5e7eb;
}

.matrix-tab-btn {
    padding: 0.75rem 1.5rem;
    background: none;
    border: none;
    border-bottom: 3px solid transparent;
    cursor: pointer;
    font-size: 1rem;
    font-weight: 500;
    color: #666;
    transition: all 0.3s;
}

.matrix-tab-btn:hover {
    color: #667eea;
    background: #f8f9fa;
}

.matrix-tab-btn.active {
    color: #667eea;
    border-bottom-color: #667eea;
    font-weight: 600;
}

.matrix-view {
    display: none;
}

.matrix-view.active {
    display: block;
}

.top-tables-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
    gap: 2rem;
    margin-bottom: 2rem;
}

.top-table-card {
    background: white;
    border-radius: 12px;
    padding: 1.5rem;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
}

.top-table-card h3 {
    font-size: 1.3rem;
    margin-bottom: 1rem;
    color: #333;
    border-bottom: 3px solid #667eea;
    padding-bottom: 0.5rem;
}

/* ===== PIPELINE DETAILS (TABS) ===== */
.pipeline-details-section {
    background: white;
    border-radius: 12px;
    padding: 2rem;
    margin-top: 2rem;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
}

.pipeline-details-section h3 {
    font-size: 1.5rem;
    margin-bottom: 1.5rem;
    color: #333;
}

.pipeline-tabs-container {
    margin-top: 1rem;
}

.detail-tabs {
    display: flex;
    gap: 0.5rem;
    border-bottom: 2px solid #e0e7ff;
    margin-bottom: 1.5rem;
}

.detail-tab-btn {
    padding: 0.75rem 1.5rem;
    background: none;
    border: none;
    border-bottom: 3px solid transparent;
    color: #666;
    font-size: 1rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.3s ease;
}

.detail-tab-btn:hover {
    color: #667eea;
    background: #f0f4ff;
}

.detail-tab-btn.active {
    color: #667eea;
    border-bottom-color: #667eea;
    font-weight: 600;
}

.detail-tab-content {
    display: none;
    padding: 1.5rem;
    background: #f9fafb;
    border-radius: 8px;
    min-height: 300px;
}

.detail-tab-content.active {
    display: block;
}

/* Config Table */
.config-table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 1rem;
}

.config-table th {
    text-align: left;
    padding: 0.75rem;
    background: #667eea;
    color: white;
    font-weight: 600;
}

.config-table td {
    padding: 0.75rem;
    border-bottom: 1px solid #e0e7ff;
}

.config-table tr:hover {
    background: #f0f4ff;
}

/* Walkthrough Steps */
.walkthrough-steps {
    margin-top: 1rem;
}

.walkthrough-step {
    display: flex;
    gap: 1rem;
    margin-bottom: 1.5rem;
    align-items: flex-start;
}

.walkthrough-step .step-number {
    flex-shrink: 0;
    width: 40px;
    height: 40px;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: 700;
    font-size: 1.2rem;
}

.walkthrough-step .step-content {
    flex: 1;
}

.walkthrough-step .step-content h5 {
    margin-bottom: 0.5rem;
    color: #667eea;
}

.walkthrough-step .step-content p {
    color: #666;
    line-height: 1.6;
}

/* Button Styles */
.btn-view-details {
    padding: 0.5rem 1rem;
    background: #667eea;
    color: white;
    border: none;
    border-radius: 6px;
    cursor: pointer;
    font-size: 0.9rem;
    transition: all 0.3s ease;
}

.btn-view-details:hover {
    background: #5568d3;
    transform: scale(1.05);
}

/* ===== PIPELINE BUILDER ===== */
.pipeline-builder-section {
    background: white;
    border-radius: 12px;
    padding: 2rem;
    margin-bottom: 2rem;
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
}

.pipeline-builder-section h2 {
    color: #667eea;
    margin-bottom: 0.5rem;
    font-size: 2rem;
    text-align: center;
}

.pipeline-steps {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 1rem;
    margin: 2rem 0;
}

.step-item {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 0.5rem;
}

.step-number {
    width: 50px;
    height: 50px;
    border-radius: 50%;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 1.5rem;
    font-weight: 700;
}

.step-title {
    font-size: 0.9rem;
    font-weight: 600;
    color: #667eea;
}

.step-arrow {
    font-size: 2rem;
    color: #667eea;
    margin-top: -20px;
}

.builder-card {
    background: #f8f9fa;
    border-radius: 10px;
    padding: 1.5rem;
    margin-bottom: 1.5rem;
}

.builder-card h3 {
    color: #333;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

.option-group {
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.option-radio, .option-checkbox {
    display: flex;
    align-items: flex-start;
    gap: 0.75rem;
    padding: 1rem;
    background: white;
    border: 2px solid #e5e7eb;
    border-radius: 8px;
    cursor: pointer;
    transition: all 0.3s;
}

.option-radio:hover, .option-checkbox:hover {
    border-color: #667eea;
    box-shadow: 0 2px 8px rgba(102, 126, 234, 0.2);
}

.option-radio.checked, .option-checkbox.checked {
    border-color: #667eea;
    background: #f0f4ff;
}

.option-radio input, .option-checkbox input {
    margin-top: 0.2rem;
    cursor: pointer;
}

.option-content {
    display: flex;
    flex-direction: column;
    flex: 1;
}

.option-title {
    font-weight: 600;
    color: #333;
    margin-bottom: 0.25rem;
}

.option-desc {
    font-size: 0.9rem;
    color: #666;
}

.classifier-actions {
    display: flex;
    gap: 0.75rem;
    margin-top: 1rem;
    flex-wrap: wrap;
}

/* ===== PREVIEW & ACTIONS ===== */
.builder-preview {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 10px;
    padding: 1.5rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
    gap: 2rem;
    flex-wrap: wrap;
}

.preview-content {
    flex: 1;
}

.preview-content h4 {
    margin-bottom: 0.5rem;
    font-size: 1.1rem;
}

#pipeline-preview {
    font-size: 1rem;
}

#preview-list {
    margin: 0.75rem 0 0 1.5rem;
    list-style: none;
}

#preview-list li {
    padding: 0.25rem 0;
    opacity: 0.9;
}

#preview-list li::before {
    content: "‚ñ∏ ";
    margin-right: 0.5rem;
}

.preview-actions {
    display: flex;
    gap: 1rem;
    flex-wrap: wrap;
}

/* ===== BUTTONS ===== */
.btn-primary, .btn-secondary {
    padding: 0.75rem 1.5rem;
    border: none;
    border-radius: 8px;
    font-size: 1rem;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s;
    white-space: nowrap;
}

.btn-primary {
    background: white;
    color: #667eea;
}

.btn-primary:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
}

.btn-secondary {
    background: rgba(255, 255, 255, 0.2);
    color: white;
    border: 1px solid white;
}

.btn-secondary:hover {
    background: rgba(255, 255, 255, 0.3);
}

/* ===== RESULTS SECTION ===== */
.results-section {
    margin-top: 2rem;
}

.results-section h2 {
    color: #667eea;
    font-size: 2rem;
    margin-bottom: 2rem;
    text-align: center;
}

.best-cards {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
    gap: 1.5rem;
    margin-bottom: 2rem;
}

.best-card {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    border-top: 4px solid;
}

.best-card.accuracy {
    border-top-color: #10b981;
}

.best-card.speed {
    border-top-color: #f59e0b;
}

.best-card.size {
    border-top-color: #3b82f6;
}

.best-card h3 {
    font-size: 0.9rem;
    text-transform: uppercase;
    letter-spacing: 1px;
    color: #666;
    margin-bottom: 0.5rem;
}

.best-card .metric-value {
    font-size: 2rem;
    font-weight: 700;
    margin-bottom: 0.5rem;
}

.best-card .pipeline-name {
    font-size: 0.9rem;
    color: #666;
}

/* ===== TABLE ===== */
.table-container {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    margin-bottom: 2rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    overflow-x: auto;
}

.comparison-table {
    width: 100%;
    border-collapse: collapse;
    font-size: 0.9rem;
}

.comparison-table th {
    background: #667eea;
    color: white;
    padding: 0.75rem;
    text-align: left;
    font-weight: 600;
    white-space: nowrap;
}

.comparison-table td {
    padding: 0.75rem;
    border-bottom: 1px solid #e5e7eb;
}

.comparison-table tr:hover {
    background: #f8f9fa;
}

.metric-best {
    background: #d1fae5 !important;
    font-weight: 600;
    color: #065f46;
}

.pipeline-cell {
    font-family: 'Courier New', monospace;
    font-size: 0.85rem;
}

/* ===== VISUALIZATIONS ===== */
.viz-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
    gap: 2rem;
    margin-bottom: 2rem;
}

.viz-card {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
}

.viz-card h3 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

/* ===== CONFUSION MATRICES ===== */
.cm-section {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
}

.cm-section h3 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.3rem;
}

.cm-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(450px, 1fr));
    gap: 1.5rem;
    margin-top: 1.5rem;
}

/* ===== PIPELINE CALCULATION ===== */
.pipeline-calculation {
    margin-top: 2rem;
    text-align: center;
}

.btn-calculation {
    background: rgba(255, 255, 255, 0.2);
    color: white;
    border: 2px solid white;
    padding: 0.75rem 1.5rem;
    border-radius: 8px;
    font-size: 1rem;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s;
}

.btn-calculation:hover {
    background: rgba(255, 255, 255, 0.3);
    transform: translateY(-2px);
}

.calculation-details {
    background: white;
    color: #333;
    margin-top: 1.5rem;
    padding: 2rem;
    border-radius: 12px;
    max-width: 1200px;
    margin-left: auto;
    margin-right: auto;
    text-align: left;
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.15);
}

.calc-formula {
    text-align: center;
    margin-bottom: 2rem;
}

.calc-formula h3 {
    color: #667eea;
    margin-bottom: 1rem;
}

.formula-box {
    background: #f8f9fa;
    padding: 1.5rem;
    border-radius: 10px;
    border: 2px solid #667eea;
}

.formula-main {
    font-size: 1.3rem;
    margin-bottom: 0.75rem;
}

.formula-term {
    color: #667eea;
    font-weight: 700;
    padding: 0.25rem 0.5rem;
    background: rgba(102, 126, 234, 0.1);
    border-radius: 4px;
}

.formula-result {
    font-size: 1.5rem;
    color: #10b981;
    font-weight: 700;
    margin-top: 0.75rem;
}

.calc-breakdown {
    margin-top: 2rem;
}

.calc-section {
    margin-bottom: 2rem;
    padding: 1.5rem;
    background: #f8f9fa;
    border-radius: 10px;
}

.calc-section h4 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

.calc-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
    gap: 1rem;
}

.calc-grid-horizontal {
    display: flex;
    gap: 0.75rem;
    flex-wrap: wrap;
    justify-content: center;
}

.calc-item {
    background: white;
    padding: 1rem;
    border-radius: 8px;
    border-left: 4px solid #667eea;
}

.calc-item strong {
    color: #667eea;
    display: block;
    margin-bottom: 0.5rem;
}

.calc-item ul {
    margin: 0.5rem 0 0 1.25rem;
    font-size: 0.9rem;
    color: #666;
}

.calc-item ul li {
    margin: 0.25rem 0;
}

.calc-item-small {
    background: white;
    padding: 0.75rem 1rem;
    border-radius: 8px;
    border: 2px solid #667eea;
    color: #667eea;
    font-weight: 600;
    font-size: 0.9rem;
}

.calc-example {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 1.5rem;
    border-radius: 10px;
    margin-top: 2rem;
}

.calc-example h4 {
    margin-bottom: 1rem;
    text-align: center;
}

.pipeline-example {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 0.75rem;
    flex-wrap: wrap;
}

.pipeline-step {
    background: rgba(255, 255, 255, 0.2);
    padding: 0.75rem 1rem;
    border-radius: 8px;
    font-weight: 600;
    border: 2px solid white;
}

.pipeline-arrow {
    font-size: 1.5rem;
    font-weight: 700;
}

.pipeline-result {
    background: #10b981;
    padding: 0.75rem 1rem;
    border-radius: 8px;
    font-weight: 700;
    border: 2px solid white;
}

/* ===== RESPONSIVE ===== */
@media (max-width: 768px) {
    .hero h1 {
        font-size: 2rem;
    }
    
    .hero-stats {
        gap: 1.5rem;
    }
    
    .stat-value {
        font-size: 2rem;
    }
    
    .builder-preview {
        flex-direction: column;
        align-items: flex-start;
    }
    
    .preview-actions {
        width: 100%;
    }
    
    .preview-actions button {
        flex: 1;
    }
    
    .viz-grid {
        grid-template-columns: 1fr;
    }
    
    .cm-grid {
        grid-template-columns: 1fr;
    }
}

/* ===== LOADING ===== */
.loading {
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 3rem;
    font-size: 1.1rem;
    color: #667eea;
}

.loading::after {
    content: '...';
    animation: dots 1.5s infinite;
}

@keyframes dots {
    0%, 20% { content: '.'; }
    40% { content: '..'; }
    60%, 100% { content: '...'; }
}

    </style>
</head>
<body>
    <!-- Navbar -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="../../../../index.html" class="brand">ü§ñ AI Learning Hub</a>
            <div class="nav-links">
                <a href="../../index.html">‚Üê Back to Text Classification</a>
            </div>
        </div>
    </nav>

    <!-- Hero -->
    <div class="hero">
        <h1>üî¨ Pipeline Comparison</h1>
        <p>Compare feature extraction, dimensionality reduction, and classifier combinations</p>
        <div class="hero-stats">
            <div class="stat-item">
                <div class="stat-value">240</div>
                <div class="stat-label">Total Pipelines</div>
            </div>
            <div class="stat-item">
                <div class="stat-value">99.4%</div>
                <div class="stat-label">Best Accuracy</div>
            </div>
            <div class="stat-item">
                <div class="stat-value">0.46s</div>
                <div class="stat-label">Fastest Training</div>
            </div>
        </div>
        
        <!-- Pipeline calculation explanation -->
        <div class="pipeline-calculation">
            <button onclick="toggleCalculation()" class="btn-calculation">
                üìä How are 180 pipelines calculated?
            </button>
            <div id="calculation-details" class="calculation-details" style="display: none;">
                
                <div class="calc-formula">
                    <h3>üßÆ Total Pipeline Combinations</h3>
                    <div class="formula-box">
                        <div class="formula-main">
                            Total = <span class="formula-term">Extractors</span> √ó 
                                   <span class="formula-term">Reducers</span> √ó 
                                   <span class="formula-term">Classifiers</span>
                        </div>
                        <div class="formula-result">
                            = <strong>6</strong> √ó <strong>6</strong> √ó <strong>5</strong> = <strong>180 pipelines</strong>
                        </div>
                    </div>
                </div>
                
                <div class="calc-breakdown">
                    <div class="calc-section">
                        <h4>1Ô∏è‚É£ Feature Extractors (6 configs)</h4>
                        <div class="calc-grid">
                            <div class="calc-item">
                                <strong>Bag of Words (BoW)</strong> - 3 configs
                                <ul>
                                    <li>5000 features, unigrams (1,1)</li>
                                    <li>5000 features, bigrams (1,2)</li>
                                    <li>10000 features, bigrams (1,2)</li>
                                </ul>
                            </div>
                            <div class="calc-item">
                                <strong>TF-IDF</strong> - 3 configs
                                <ul>
                                    <li>5000 features, unigrams (1,1)</li>
                                    <li>5000 features, bigrams (1,2)</li>
                                    <li>10000 features, bigrams (1,2)</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="calc-section">
                        <h4>2Ô∏è‚É£ Dimensionality Reducers (6 configs)</h4>
                        <div class="calc-grid">
                            <div class="calc-item">
                                <strong>None</strong> - 1 config
                                <ul><li>Use all features (no reduction)</li></ul>
                            </div>
                            <div class="calc-item">
                                <strong>PCA</strong> - 2 configs
                                <ul>
                                    <li>300 components</li>
                                    <li>500 components</li>
                                </ul>
                            </div>
                            <div class="calc-item">
                                <strong>Chi¬≤</strong> - 2 configs
                                <ul>
                                    <li>Select top 500 features</li>
                                    <li>Select top 1000 features</li>
                                </ul>
                            </div>
                            <div class="calc-item">
                                <strong>Truncated SVD</strong> - 1 config
                                <ul><li>300 components</li></ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="calc-section">
                        <h4>3Ô∏è‚É£ Classifiers (5 models)</h4>
                        <div class="calc-grid-horizontal">
                            <div class="calc-item-small">Logistic Regression</div>
                            <div class="calc-item-small">SVM (Linear)</div>
                            <div class="calc-item-small">Naive Bayes</div>
                            <div class="calc-item-small">Random Forest</div>
                            <div class="calc-item-small">Decision Tree</div>
                        </div>
                    </div>
                </div>
                
                <div class="calc-example">
                    <h4>üìù Example Pipeline</h4>
                    <div class="pipeline-example">
                        <div class="pipeline-step">TF-IDF (5000, bigrams)</div>
                        <div class="pipeline-arrow">‚Üí</div>
                        <div class="pipeline-step">Chi¬≤ (top 500)</div>
                        <div class="pipeline-arrow">‚Üí</div>
                        <div class="pipeline-step">Logistic Regression</div>
                        <div class="pipeline-arrow">=</div>
                        <div class="pipeline-result">1 of 180 pipelines</div>
                    </div>
                </div>
    
            </div>
        </div>
    </div>

    <!-- Main content -->
    <div class="container">
        <!-- View Mode Toggle -->
        <section class="view-mode-section">
            <div class="mode-toggle">
                <button id="btn-hero-mode" class="mode-btn active" onclick="switchMode('hero')">
                    üèÜ Top Performers
                </button>
                <button id="btn-custom-mode" class="mode-btn" onclick="switchMode('custom')">
                    üîß Custom Filter
                </button>
            </div>
        </section>

        <!-- Hero Mode: Top Performers Comparison -->
        <section id="hero-mode-section" class="hero-mode-section">
            <!-- Pipeline Overview with Tabs -->
            <div class="pipeline-overview-section">
                
        <div class="overview-tabs-section">
            <!-- Tab buttons -->
            <div class="overview-tabs">
                <button class="overview-tab-btn active" onclick="switchOverviewTab('pipeline')">
                    üîÑ Pipeline
                </button>
                <button class="overview-tab-btn" onclick="switchOverviewTab('tutorials')">
                    üìö Tutorials
                </button>
                <button class="overview-tab-btn" onclick="switchOverviewTab('code')">
                    üíª Code
                </button>
                <button class="overview-tab-btn" onclick="switchOverviewTab('colab')">
                    üöÄ Colab
                </button>
            </div>
            
            <!-- Tab contents -->
            <div id="overview-pipeline-tab" class="overview-tab-content active">
                <div class="pipeline-diagram">
                    <div class="diagram-flow">
                        <div class="flow-step">
                            <div class="step-icon-large">üìù</div>
                            <div class="step-label">Text Input</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="flow-step flow-varied">
                            <div class="step-icon-large">üî¢</div>
                            <div class="step-label">Feature Extraction</div>
                            <div class="step-options">BoW or TF-IDF</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="flow-step flow-varied">
                            <div class="step-icon-large">üéØ</div>
                            <div class="step-label">Dim. Reduction</div>
                            <div class="step-options">None, Chi¬≤, or PCA</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="flow-step flow-varied">
                            <div class="step-icon-large">ü§ñ</div>
                            <div class="step-label">Classifier</div>
                            <div class="step-options">NB, LR, RF, DT, or KNN</div>
                        </div>
                        <div class="flow-arrow">‚Üí</div>
                        <div class="flow-step">
                            <div class="step-icon-large">‚ú®</div>
                            <div class="step-label">Results</div>
                        </div>
                    </div>
                    <div class="pipeline-info">
                        <p><strong>240 Pipeline Combinations</strong> = 6 extractors √ó 4 reducers √ó 10 classifiers</p>
                        <p>Compare accuracy, speed, and model size to find the best approach for your needs.</p>
                    </div>
                </div>
            </div>
            
            <div id="overview-tutorials-tab" class="overview-tab-content">
                
        <div class="tutorials-grid">
            <div class="tutorial-card">
                <h3>üî¢ Feature Extraction</h3>
                <div class="tutorial-item">
                    <h4>Bag of Words (BoW)</h4>
                    <p>Counts word occurrences in documents. Simple but effective baseline.</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" target="_blank">üìö Docs</a>
                </div>
                <div class="tutorial-item">
                    <h4>TF-IDF</h4>
                    <p>Weighs words by importance (frequency √ó uniqueness).</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" target="_blank">üìö Docs</a>
                </div>
            </div>
            
            <div class="tutorial-card">
                <h3>üéØ Dimensionality Reduction</h3>
                <div class="tutorial-item">
                    <h4>Chi¬≤ (Chi-Square)</h4>
                    <p>Selects top K most relevant features for classification.</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html" target="_blank">üìö Docs</a>
                </div>
                <div class="tutorial-item">
                    <h4>PCA (Principal Component Analysis)</h4>
                    <p>Reduces dimensions while preserving variance (90% or 95%).</p>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" target="_blank">üìö Docs</a>
                </div>
            </div>
            
            <div class="tutorial-card">
                <h3>ü§ñ Classifiers</h3>
                <div class="tutorial-item">
                    <h4>Naive Bayes, Logistic Regression, Random Forest</h4>
                    <p>Traditional ML algorithms with different hyperparameters.</p>
                </div>
                <div class="tutorial-item">
                    <h4>Decision Tree, K-Nearest Neighbors</h4>
                    <p>Tested with various configurations for optimal performance.</p>
                </div>
            </div>
        </div>
    
            </div>
            
            <div id="overview-code-tab" class="overview-tab-content">
                
        <div class="code-container">
            <h3>üíª Pipeline Comparison Code</h3>
            <p>Ready-to-run Python code to compare all 240 pipeline combinations.</p>
            <div class="code-actions">
                <button onclick="copyPipelineCode()" class="btn-code-action">üìã Copy Code</button>
                <a href="code/bbc_pipeline_comparison.py" download class="btn-code-action">‚¨áÔ∏è Download Python</a>
            </div>
            <div id="pipeline-code-block" class="code-block-container">
                <div class="code-loading">‚è≥ Loading code...</div>
                <pre style="display:none;"><code id="pipeline-python-code" class="language-python"></code></pre>
            </div>
            <div class="code-features">
                <ul>
                    <li>‚úÖ Auto dataset download</li>
                    <li>‚úÖ 6 feature extractors (BoW + TF-IDF)</li>
                    <li>‚úÖ 4 dimensionality reducers</li>
                    <li>‚úÖ 10 classifier configurations</li>
                    <li>‚úÖ Performance comparison table</li>
                    <li>‚úÖ Timing measurements</li>
                </ul>
            </div>
        </div>
    
            </div>
            
            <div id="overview-colab-tab" class="overview-tab-content">
                
        <div class="colab-container">
            <div class="colab-hero">
                <div class="colab-icon">üöÄ</div>
                <h3>Run Pipeline Comparison in Google Colab</h3>
                <p>Interactive notebook to explore and compare all 240 pipelines.</p>
            </div>
            <div class="colab-action">
                <a href="https://colab.research.google.com/github/LTSACH/AILearningHub/blob/main/04_Natural_Language_Processing/text_classification/notebooks/pipeline_comparison.ipynb" 
                   target="_blank" 
                   class="btn-colab-large">
                    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" style="height:40px;">
                    <span>Open Pipeline Comparison in Colab</span>
                </a>
            </div>
        </div>
    
            </div>
        </div>
    
            </div>
            
            <!-- Top Performers Comparison Section -->
            <div class="comparison-section">
                <div class="comparison-header">
                    <h2>üèÜ Top 9 Performers Comparison</h2>
                    <p>Top 3 by Accuracy, Training Speed, and Inference Speed</p>
                </div>
                
                <!-- Comparison Tabs -->
                <div class="comparison-tabs">
                    <button class="comparison-tab-btn active" onclick="switchComparisonTab('performance')">
                        üìä Performance
                    </button>
                    <button class="comparison-tab-btn" onclick="switchComparisonTab('configuration')">
                        ‚öôÔ∏è Configuration
                    </button>
                    <button class="comparison-tab-btn" onclick="switchComparisonTab('formulas')">
                        üìê Formulas
                    </button>
                </div>
                
                <!-- Tab Contents -->
                <div id="performance-tab" class="comparison-tab-content active">
                    <div id="performance-comparison-table"></div>
                </div>
                
                <div id="configuration-tab" class="comparison-tab-content">
                    <div id="configuration-details"></div>
                </div>
                
                <div id="formulas-tab" class="comparison-tab-content">
                    <div id="formulas-content"></div>
                </div>
                
                <!-- Confusion Matrices & Metrics -->
                <div class="confusion-section">
                    <h3>üéØ Confusion Matrices & Per-Class Metrics</h3>
                    <div id="confusion-matrices-grid"></div>
                </div>
            </div>
        </section>

        <!-- Custom Filter Mode -->
        <section id="custom-mode-section" class="custom-mode-section" style="display: none;">
            <h2>üî¨ Build Your Pipeline</h2>
            <p class="section-description">
                Select feature extraction, dimensionality reduction, and classifiers to compare
            </p>
            
            
        <div class="pipeline-builder">
            <!-- Step indicator -->
            <div class="pipeline-steps">
                <div class="step-item">
                    <div class="step-number">1</div>
                    <div class="step-title">üìù Extract</div>
                </div>
                <div class="step-arrow">‚Üí</div>
                <div class="step-item">
                    <div class="step-number">2</div>
                    <div class="step-title">üéØ Reduce</div>
                </div>
                <div class="step-arrow">‚Üí</div>
                <div class="step-item">
                    <div class="step-number">3</div>
                    <div class="step-title">ü§ñ Classify</div>
                </div>
            </div>
            
            <!-- Step 1: Feature Extraction -->
            <div class="builder-card">
                <h3>STEP 1: Feature Extraction</h3>
                <div class="option-group">
                    <label class="option-radio">
                        <input type="radio" name="extractor" value="bow" data-name="Bag of Words">
                        <span class="option-content">
                            <span class="option-title">Bag of Words (CountVectorizer)</span>
                            <span class="option-desc">Count word occurrences, simple and fast</span>
                        </span>
                    </label>
                    <label class="option-radio checked">
                        <input type="radio" name="extractor" value="tfidf" data-name="TF-IDF" checked>
                        <span class="option-content">
                            <span class="option-title">TF-IDF (TfidfVectorizer)</span>
                            <span class="option-desc">Weight words by importance, better for classification</span>
                        </span>
                    </label>
                </div>
            </div>
            
            <!-- Step 2: Dimensionality Reduction -->
            <div class="builder-card">
                <h3>STEP 2: Dimensionality Reduction (Optional)</h3>
                <div class="option-group">
                    <label class="option-radio checked">
                        <input type="radio" name="reducer" value="none" data-name="None" checked>
                        <span class="option-content">
                            <span class="option-title">None (Use all features)</span>
                            <span class="option-desc">Best accuracy, but slower and larger models</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="pca" data-name="PCA">
                        <span class="option-content">
                            <span class="option-title">PCA (Principal Component Analysis)</span>
                            <span class="option-desc">Reduce to uncorrelated components, good for variance</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="chi2" data-name="Chi¬≤">
                        <span class="option-content">
                            <span class="option-title">Chi¬≤ (SelectKBest)</span>
                            <span class="option-desc">Select most relevant features, good for text</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="svd" data-name="Truncated SVD">
                        <span class="option-content">
                            <span class="option-title">Truncated SVD</span>
                            <span class="option-desc">Like PCA but works with sparse matrices</span>
                        </span>
                    </label>
                </div>
            </div>
            
            <!-- Step 3: Classifiers -->
            <div class="builder-card">
                <h3>STEP 3: Classifiers (Select multiple)</h3>
                <div class="option-group">
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="logistic" data-name="Logistic Regression" checked>
                        <span class="option-content">
                            <span class="option-title">Logistic Regression</span>
                            <span class="option-desc">Fast, interpretable, great baseline (usually best)</span>
                        </span>
                    </label>
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="svm" data-name="SVM" checked>
                        <span class="option-content">
                            <span class="option-title">SVM (Support Vector Machine)</span>
                            <span class="option-desc">Strong for high-dimensional text data</span>
                        </span>
                    </label>
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="naive_bayes" data-name="Naive Bayes" checked>
                        <span class="option-content">
                            <span class="option-title">Naive Bayes</span>
                            <span class="option-desc">Extremely fast, good for large datasets</span>
                        </span>
                    </label>
                    <label class="option-checkbox">
                        <input type="checkbox" name="classifier" value="random_forest" data-name="Random Forest">
                        <span class="option-content">
                            <span class="option-title">Random Forest</span>
                            <span class="option-desc">Ensemble method, robust but slower</span>
                        </span>
                    </label>
                    <label class="option-checkbox">
                        <input type="checkbox" name="classifier" value="decision_tree" data-name="Decision Tree">
                        <span class="option-content">
                            <span class="option-title">Decision Tree</span>
                            <span class="option-desc">Simple, interpretable, usually lower accuracy</span>
                        </span>
                    </label>
                </div>
                <div class="classifier-actions">
                    <button onclick="selectAllClassifiers()" class="btn-secondary">Select All</button>
                    <button onclick="deselectAllClassifiers()" class="btn-secondary">Deselect All</button>
                    <button onclick="selectTopClassifiers()" class="btn-secondary">Top 3 Fastest</button>
                </div>
            </div>
            
            <!-- Preview & Action -->
            <div class="builder-preview">
                <div class="preview-content">
                    <h4>üìä Preview</h4>
                    <div id="pipeline-preview">
                        You will compare <strong id="preview-count">3</strong> pipeline(s):
                        <ul id="preview-list"></ul>
                    </div>
                </div>
                <div class="preview-actions">
                    <button onclick="comparePipelines()" class="btn-primary">
                        üîç Compare These Pipelines
                    </button>
                    <button onclick="resetBuilder()" class="btn-secondary">
                        üîÑ Reset to Defaults
                    </button>
                </div>
            </div>
        </div>
    
            
            <!-- Custom Results -->
            <div id="custom-results-section" class="results-section" style="display: none;">
                <h2>üìä Comparison Results</h2>
                
                <!-- Best pipeline cards -->
                <div id="custom-best-cards" class="best-cards"></div>
                
                <!-- Comparison table -->
                <div id="custom-comparison-table" class="table-container"></div>
                
                <!-- Visualizations -->
                <div class="viz-grid">
                    <div class="viz-card">
                        <h3>üìä Accuracy Heatmap</h3>
                        <div id="custom-heatmap-chart"></div>
                    </div>
                    <div class="viz-card">
                        <h3>‚öñÔ∏è Trade-off: Accuracy vs Speed</h3>
                        <div id="custom-tradeoff-chart"></div>
                    </div>
                </div>
                
                <!-- Pipeline Details (tabs) -->
                <div id="custom-pipeline-details" class="pipeline-details-section" style="display: none;">
                    <h3 id="custom-selected-title">Pipeline Details</h3>
                    
        <div class="pipeline-tabs-container">
            <!-- Tab buttons -->
            <div class="detail-tabs">
                <button class="detail-tab-btn active" onclick="switchDetailTab('custom', 'config')">
                    ‚öôÔ∏è Configuration
                </button>
                <button class="detail-tab-btn" onclick="switchDetailTab('custom', 'formula')">
                    üìê Formulas
                </button>
                <button class="detail-tab-btn" onclick="switchDetailTab('custom', 'confusion')">
                    üìä Confusion Matrix
                </button>
                <button class="detail-tab-btn" onclick="switchDetailTab('custom', 'walkthrough')">
                    üö∂ Walkthrough
                </button>
            </div>
            
            <!-- Tab contents -->
            <div id="custom-config-tab" class="detail-tab-content active">
                <div id="custom-config-content">Select a pipeline to view configuration</div>
            </div>
            
            <div id="custom-formula-tab" class="detail-tab-content">
                <div id="custom-formula-content">Select a pipeline to view formulas</div>
            </div>
            
            <div id="custom-confusion-tab" class="detail-tab-content">
                <div id="custom-confusion-content">Select a pipeline to view confusion matrix</div>
            </div>
            
            <div id="custom-walkthrough-tab" class="detail-tab-content">
                <div id="custom-walkthrough-content">Select a pipeline to view walkthrough</div>
            </div>
        </div>
    
                </div>
            </div>
        </section>
    </div>

    <!-- Data -->
    <script>
        const allPipelinesData = {'total_pipelines': 240, 'successful': 120, 'failed': 120, 'best_accuracy': {'pipeline_id': 'tfidf_m10000_n11_none_default_logistic_C1.0_m1000', 'accuracy': 0.9940119760479041, 'config': 'TF-IDF ‚Üí None ‚Üí Logistic Regression'}, 'fastest_training': {'pipeline_id': 'bow_m10000_n11_none_default_knn_n5_n-1', 'time': 0.45822715759277344, 'config': 'Bag of Words ‚Üí None ‚Üí K-Nearest Neighbors'}, 'fastest_inference': {'pipeline_id': 'tfidf_m5000_n12_none_default_decision_tree_m10_r42', 'time': 0.0021721788509163316, 'config': 'TF-IDF ‚Üí None ‚Üí Decision Tree'}, 'all_results': [{'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T14:01:20.176245', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6583452224731445, 'features_extracted': 5000, 'reduction_time': 0.13660550117492676, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9762070722400643, 'recall': 0.9760479041916168, 'f1_score': 0.9760358804739142}, 'performance': {'train_time_seconds': 0.11777997016906738, 'total_time_seconds': 1.9127306938171387, 'inference_time_ms_per_sample': 0.0029188430237912844}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 57, 0, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9736842105263158, 'recall': 0.961038961038961, 'f1': 0.9673202614379085, 'support': 77}, {'label': 'entertainment', 'precision': 0.95, 'recall': 0.9827586206896551, 'f1': 0.9661016949152542, 'support': 58}, {'label': 'politics', 'precision': 0.9836065573770492, 'recall': 0.967741935483871, 'f1': 0.975609756097561, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T14:01:27.938367', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.566103458404541, 'features_extracted': 5000, 'reduction_time': 0.13735055923461914, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8173652694610778, 'precision': 0.8205447151034237, 'recall': 0.8173652694610778, 'f1_score': 0.8175800385716618}, 'performance': {'train_time_seconds': 0.14774560928344727, 'total_time_seconds': 1.8511996269226074, 'inference_time_ms_per_sample': 0.002478411097726422}, 'confusion_matrix': [[60, 5, 7, 1, 4], [8, 41, 4, 5, 0], [6, 2, 53, 1, 0], [3, 2, 3, 69, 0], [4, 2, 2, 2, 50]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7407407407407407, 'recall': 0.7792207792207793, 'f1': 0.759493670886076, 'support': 77}, {'label': 'entertainment', 'precision': 0.7884615384615384, 'recall': 0.7068965517241379, 'f1': 0.7454545454545455, 'support': 58}, {'label': 'politics', 'precision': 0.7681159420289855, 'recall': 0.8548387096774194, 'f1': 0.8091603053435115, 'support': 62}, {'label': 'sport', 'precision': 0.8846153846153846, 'recall': 0.8961038961038961, 'f1': 0.8903225806451613, 'support': 77}, {'label': 'tech', 'precision': 0.9259259259259259, 'recall': 0.8333333333333334, 'f1': 0.8771929824561403, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T13:59:10.270884', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.570054054260254, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9763295154114302, 'recall': 0.9760479041916168, 'f1_score': 0.9760704058320477}, 'performance': {'train_time_seconds': 0.3191812038421631, 'total_time_seconds': 1.889235258102417, 'inference_time_ms_per_sample': 0.018760115800503484}, 'confusion_matrix': [[75, 0, 1, 0, 1], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 1, 1, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T14:01:07.045873', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.5661494731903076, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7798037976435418, 'recall': 0.7694610778443114, 'f1_score': 0.7698911162806901}, 'performance': {'train_time_seconds': 0.48656749725341797, 'total_time_seconds': 2.0527169704437256, 'inference_time_ms_per_sample': 0.0021721788509163316}, 'confusion_matrix': [[55, 3, 8, 4, 7], [6, 41, 4, 7, 0], [14, 0, 42, 3, 3], [5, 0, 0, 71, 1], [8, 0, 1, 3, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.625, 'recall': 0.7142857142857143, 'f1': 0.6666666666666666, 'support': 77}, {'label': 'entertainment', 'precision': 0.9318181818181818, 'recall': 0.7068965517241379, 'f1': 0.803921568627451, 'support': 58}, {'label': 'politics', 'precision': 0.7636363636363637, 'recall': 0.6774193548387096, 'f1': 0.717948717948718, 'support': 62}, {'label': 'sport', 'precision': 0.8068181818181818, 'recall': 0.922077922077922, 'f1': 0.8606060606060606, 'support': 77}, {'label': 'tech', 'precision': 0.8135593220338984, 'recall': 0.8, 'f1': 0.8067226890756303, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T13:57:31.085358', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5002796649932861, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9588148116452164, 'recall': 0.9580838323353293, 'f1_score': 0.9580231060694141}, 'performance': {'train_time_seconds': 0.2249302864074707, 'total_time_seconds': 0.7252099514007568, 'inference_time_ms_per_sample': 0.09527106484967078}, 'confusion_matrix': [[73, 0, 1, 1, 2], [1, 54, 1, 1, 1], [2, 0, 58, 2, 0], [0, 0, 0, 77, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9358974358974359, 'recall': 0.948051948051948, 'f1': 0.9419354838709677, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9310344827586207, 'f1': 0.9642857142857143, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1': 0.9508196721311475, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T14:00:58.546379', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6072196960449219, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9850299401197605, 'precision': 0.985310628742515, 'recall': 0.9850299401197605, 'f1_score': 0.9850993907933737}, 'performance': {'train_time_seconds': 0.569617748260498, 'total_time_seconds': 2.17683744430542, 'inference_time_ms_per_sample': 0.0032679049554699196}, 'confusion_matrix': [[75, 0, 2, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9833333333333333, 'f1': 0.9915966386554622, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T14:02:23.671489', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5392801761627197, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9101796407185628, 'precision': 0.9119474280167817, 'recall': 0.9101796407185628, 'f1_score': 0.9097967985071983}, 'performance': {'train_time_seconds': 0.0028221607208251953, 'total_time_seconds': 1.542102336883545, 'inference_time_ms_per_sample': 0.2734425539028145}, 'confusion_matrix': [[66, 1, 5, 2, 3], [1, 49, 3, 2, 3], [1, 2, 57, 0, 2], [1, 1, 0, 74, 1], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9428571428571428, 'recall': 0.8571428571428571, 'f1': 0.8979591836734694, 'support': 77}, {'label': 'entertainment', 'precision': 0.9074074074074074, 'recall': 0.8448275862068966, 'f1': 0.875, 'support': 58}, {'label': 'politics', 'precision': 0.8769230769230769, 'recall': 0.9193548387096774, 'f1': 0.8976377952755905, 'support': 62}, {'label': 'sport', 'precision': 0.9487179487179487, 'recall': 0.961038961038961, 'f1': 0.9548387096774194, 'support': 77}, {'label': 'tech', 'precision': 0.8656716417910447, 'recall': 0.9666666666666667, 'f1': 0.9133858267716536, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T14:01:09.107046', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.537149429321289, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7844311377245509, 'precision': 0.7837046408805158, 'recall': 0.7844311377245509, 'f1_score': 0.78251185822289}, 'performance': {'train_time_seconds': 0.7058286666870117, 'total_time_seconds': 2.242978096008301, 'inference_time_ms_per_sample': 0.0022028734584054544}, 'confusion_matrix': [[51, 6, 8, 5, 7], [5, 41, 6, 4, 2], [7, 2, 49, 2, 2], [3, 0, 2, 70, 2], [5, 1, 2, 1, 51]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7183098591549296, 'recall': 0.6623376623376623, 'f1': 0.6891891891891891, 'support': 77}, {'label': 'entertainment', 'precision': 0.82, 'recall': 0.7068965517241379, 'f1': 0.7592592592592593, 'support': 58}, {'label': 'politics', 'precision': 0.7313432835820896, 'recall': 0.7903225806451613, 'f1': 0.7596899224806202, 'support': 62}, {'label': 'sport', 'precision': 0.8536585365853658, 'recall': 0.9090909090909091, 'f1': 0.8805031446540881, 'support': 77}, {'label': 'tech', 'precision': 0.796875, 'recall': 0.85, 'f1': 0.8225806451612904, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T13:59:36.542049', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.5860474109649658, 'features_extracted': 10000, 'reduction_time': 0.26863908767700195, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9730538922155688, 'precision': 0.9737496602766063, 'recall': 0.9730538922155688, 'f1_score': 0.9729928141568138}, 'performance': {'train_time_seconds': 0.014270305633544922, 'total_time_seconds': 1.8689568042755127, 'inference_time_ms_per_sample': 0.004571355031635947}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 54, 2, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T14:00:32.834768', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5100698471069336, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9281437125748503, 'precision': 0.9327158066687695, 'recall': 0.9281437125748503, 'f1_score': 0.9281114296066986}, 'performance': {'train_time_seconds': 0.2092430591583252, 'total_time_seconds': 0.7193129062652588, 'inference_time_ms_per_sample': 0.0981349431112141}, 'confusion_matrix': [[74, 0, 1, 1, 1], [3, 50, 1, 4, 0], [5, 0, 56, 1, 0], [0, 0, 0, 77, 0], [5, 1, 1, 0, 53]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8505747126436781, 'recall': 0.961038961038961, 'f1': 0.9024390243902439, 'support': 77}, {'label': 'entertainment', 'precision': 0.9803921568627451, 'recall': 0.8620689655172413, 'f1': 0.9174311926605505, 'support': 58}, {'label': 'politics', 'precision': 0.9491525423728814, 'recall': 0.9032258064516129, 'f1': 0.9256198347107438, 'support': 62}, {'label': 'sport', 'precision': 0.927710843373494, 'recall': 1.0, 'f1': 0.9625, 'support': 77}, {'label': 'tech', 'precision': 0.9814814814814815, 'recall': 0.8833333333333333, 'f1': 0.9298245614035088, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T13:57:35.519637', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.461367130279541, 'features_extracted': 10000, 'reduction_time': 0.2664179801940918, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9797208779244705, 'recall': 0.9790419161676647, 'f1_score': 0.9789695970982052}, 'performance': {'train_time_seconds': 0.014837026596069336, 'total_time_seconds': 0.7426221370697021, 'inference_time_ms_per_sample': 0.005699917227922085}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 54, 2, 0, 2], [0, 0, 62, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 1.0, 'recall': 0.961038961038961, 'f1': 0.9801324503311258, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9538461538461539, 'recall': 1.0, 'f1': 0.9763779527559056, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T14:02:40.983288', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.706075668334961, 'features_extracted': 10000, 'reduction_time': 0.28229832649230957, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7964071856287425, 'precision': 0.801269900733833, 'recall': 0.7964071856287425, 'f1_score': 0.7975907203643189}, 'performance': {'train_time_seconds': 0.14470195770263672, 'total_time_seconds': 2.1330759525299072, 'inference_time_ms_per_sample': 0.002579060857167501}, 'confusion_matrix': [[55, 2, 11, 4, 5], [5, 45, 5, 3, 0], [9, 1, 50, 1, 1], [3, 2, 2, 68, 2], [5, 3, 4, 0, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7142857142857143, 'recall': 0.7142857142857143, 'f1': 0.7142857142857143, 'support': 77}, {'label': 'entertainment', 'precision': 0.8490566037735849, 'recall': 0.7758620689655172, 'f1': 0.8108108108108109, 'support': 58}, {'label': 'politics', 'precision': 0.6944444444444444, 'recall': 0.8064516129032258, 'f1': 0.746268656716418, 'support': 62}, {'label': 'sport', 'precision': 0.8947368421052632, 'recall': 0.8831168831168831, 'f1': 0.8888888888888888, 'support': 77}, {'label': 'tech', 'precision': 0.8571428571428571, 'recall': 0.8, 'f1': 0.8275862068965517, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T14:00:33.595108', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.4833965301513672, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.9643923345846616, 'recall': 0.9640718562874252, 'f1_score': 0.9640328039573028}, 'performance': {'train_time_seconds': 0.22632217407226562, 'total_time_seconds': 0.7097187042236328, 'inference_time_ms_per_sample': 0.09695212998076112}, 'confusion_matrix': [[74, 0, 1, 1, 1], [1, 56, 1, 0, 0], [2, 0, 59, 1, 0], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9367088607594937, 'recall': 0.961038961038961, 'f1': 0.9487179487179487, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T13:58:36.928367', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.5912725925445557, 'features_extracted': 5000, 'reduction_time': 0.1376814842224121, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7485029940119761, 'precision': 0.7805850298796609, 'recall': 0.7485029940119761, 'f1_score': 0.7439429735975069}, 'performance': {'train_time_seconds': 0.010195493698120117, 'total_time_seconds': 1.739149570465088, 'inference_time_ms_per_sample': 0.28994126234225887}, 'confusion_matrix': [[72, 0, 4, 1, 0], [7, 42, 1, 7, 1], [12, 2, 40, 6, 2], [4, 6, 1, 66, 0], [23, 2, 4, 1, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6101694915254238, 'recall': 0.935064935064935, 'f1': 0.7384615384615385, 'support': 77}, {'label': 'entertainment', 'precision': 0.8076923076923077, 'recall': 0.7241379310344828, 'f1': 0.7636363636363637, 'support': 58}, {'label': 'politics', 'precision': 0.8, 'recall': 0.6451612903225806, 'f1': 0.7142857142857143, 'support': 62}, {'label': 'sport', 'precision': 0.8148148148148148, 'recall': 0.8571428571428571, 'f1': 0.8354430379746836, 'support': 77}, {'label': 'tech', 'precision': 0.9090909090909091, 'recall': 0.5, 'f1': 0.6451612903225806, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T13:58:35.113574', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.5598530769348145, 'features_extracted': 5000, 'reduction_time': 0.13430333137512207, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7305389221556886, 'precision': 0.7512445908859735, 'recall': 0.7305389221556886, 'f1_score': 0.7261457736912116}, 'performance': {'train_time_seconds': 0.009918928146362305, 'total_time_seconds': 1.7040753364562988, 'inference_time_ms_per_sample': 0.2948559686809243}, 'confusion_matrix': [[66, 3, 4, 2, 2], [5, 45, 1, 7, 0], [10, 8, 39, 3, 2], [4, 8, 1, 64, 0], [18, 3, 7, 2, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6407766990291263, 'recall': 0.8571428571428571, 'f1': 0.7333333333333333, 'support': 77}, {'label': 'entertainment', 'precision': 0.6716417910447762, 'recall': 0.7758620689655172, 'f1': 0.72, 'support': 58}, {'label': 'politics', 'precision': 0.75, 'recall': 0.6290322580645161, 'f1': 0.6842105263157895, 'support': 62}, {'label': 'sport', 'precision': 0.8205128205128205, 'recall': 0.8311688311688312, 'f1': 0.8258064516129032, 'support': 77}, {'label': 'tech', 'precision': 0.8823529411764706, 'recall': 0.5, 'f1': 0.6382978723404256, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T14:00:36.459527', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.473860502243042, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9161676646706587, 'precision': 0.9220997922832007, 'recall': 0.9161676646706587, 'f1_score': 0.9161813881785702}, 'performance': {'train_time_seconds': 0.002239704132080078, 'total_time_seconds': 0.47610020637512207, 'inference_time_ms_per_sample': 0.2728165266756526}, 'confusion_matrix': [[64, 1, 8, 1, 3], [1, 50, 3, 1, 3], [1, 0, 60, 0, 1], [1, 0, 1, 74, 1], [0, 1, 1, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9552238805970149, 'recall': 0.8311688311688312, 'f1': 0.8888888888888888, 'support': 77}, {'label': 'entertainment', 'precision': 0.9615384615384616, 'recall': 0.8620689655172413, 'f1': 0.9090909090909091, 'support': 58}, {'label': 'politics', 'precision': 0.821917808219178, 'recall': 0.967741935483871, 'f1': 0.8888888888888888, 'support': 62}, {'label': 'sport', 'precision': 0.9736842105263158, 'recall': 0.961038961038961, 'f1': 0.9673202614379085, 'support': 77}, {'label': 'tech', 'precision': 0.8787878787878788, 'recall': 0.9666666666666667, 'f1': 0.9206349206349206, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T14:01:24.127718', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.593759536743164, 'features_extracted': 5000, 'reduction_time': 0.13709449768066406, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9687904435416547, 'recall': 0.9670658682634731, 'f1_score': 0.9672312816932294}, 'performance': {'train_time_seconds': 0.1969282627105713, 'total_time_seconds': 1.9277822971343994, 'inference_time_ms_per_sample': 0.09754817642851503}, 'confusion_matrix': [[76, 0, 0, 0, 1], [1, 56, 0, 1, 0], [4, 0, 58, 0, 0], [0, 0, 0, 77, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9047619047619048, 'recall': 0.987012987012987, 'f1': 0.9440993788819876, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9830508474576272, 'recall': 0.9354838709677419, 'f1': 0.9586776859504132, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T14:02:18.911030', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.6068975925445557, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7811343773210655, 'recall': 0.7694610778443114, 'f1_score': 0.7718557041264855}, 'performance': {'train_time_seconds': 0.650285005569458, 'total_time_seconds': 2.2571825981140137, 'inference_time_ms_per_sample': 0.002998077940798091}, 'confusion_matrix': [[57, 2, 8, 3, 7], [7, 43, 3, 5, 0], [17, 0, 41, 2, 2], [5, 2, 0, 69, 1], [9, 2, 2, 0, 47]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6, 'recall': 0.7402597402597403, 'f1': 0.6627906976744186, 'support': 77}, {'label': 'entertainment', 'precision': 0.8775510204081632, 'recall': 0.7413793103448276, 'f1': 0.8037383177570093, 'support': 58}, {'label': 'politics', 'precision': 0.7592592592592593, 'recall': 0.6612903225806451, 'f1': 0.7068965517241379, 'support': 62}, {'label': 'sport', 'precision': 0.8734177215189873, 'recall': 0.8961038961038961, 'f1': 0.8846153846153846, 'support': 77}, {'label': 'tech', 'precision': 0.8245614035087719, 'recall': 0.7833333333333333, 'f1': 0.8034188034188035, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T14:02:26.992563', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.5404610633850098, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9524141474184236, 'recall': 0.9520958083832335, 'f1_score': 0.9518580233666162}, 'performance': {'train_time_seconds': 0.0027315616607666016, 'total_time_seconds': 1.5431926250457764, 'inference_time_ms_per_sample': 0.2844769083811137}, 'confusion_matrix': [[70, 1, 4, 1, 1], [1, 53, 1, 1, 2], [1, 0, 61, 0, 0], [1, 0, 0, 76, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.958904109589041, 'recall': 0.9090909090909091, 'f1': 0.9333333333333333, 'support': 77}, {'label': 'entertainment', 'precision': 0.9464285714285714, 'recall': 0.9137931034482759, 'f1': 0.9298245614035088, 'support': 58}, {'label': 'politics', 'precision': 0.9242424242424242, 'recall': 0.9838709677419355, 'f1': 0.953125, 'support': 62}, {'label': 'sport', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T14:00:44.615392', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.46287012100219727, 'features_extracted': 10000, 'reduction_time': 0.2814805507659912, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8353293413173652, 'precision': 0.8601835863157405, 'recall': 0.8353293413173652, 'f1_score': 0.8373033595605403}, 'performance': {'train_time_seconds': 0.008899688720703125, 'total_time_seconds': 0.7532503604888916, 'inference_time_ms_per_sample': 0.21465452845225078}, 'confusion_matrix': [[68, 6, 2, 1, 0], [5, 51, 1, 1, 0], [10, 7, 45, 0, 0], [2, 1, 0, 73, 1], [11, 7, 0, 0, 42]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7083333333333334, 'recall': 0.8831168831168831, 'f1': 0.7861271676300579, 'support': 77}, {'label': 'entertainment', 'precision': 0.7083333333333334, 'recall': 0.8793103448275862, 'f1': 0.7846153846153846, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.7258064516129032, 'f1': 0.8181818181818182, 'support': 62}, {'label': 'sport', 'precision': 0.9733333333333334, 'recall': 0.948051948051948, 'f1': 0.9605263157894737, 'support': 77}, {'label': 'tech', 'precision': 0.9767441860465116, 'recall': 0.7, 'f1': 0.8155339805825242, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T13:59:51.449420', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.6245646476745605, 'features_extracted': 10000, 'reduction_time': 0.271775484085083, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.6976047904191617, 'precision': 0.7264321117560886, 'recall': 0.6976047904191617, 'f1_score': 0.6936704706528525}, 'performance': {'train_time_seconds': 0.0075299739837646484, 'total_time_seconds': 1.9038701057434082, 'inference_time_ms_per_sample': 0.31909328734803344}, 'confusion_matrix': [[65, 4, 1, 3, 4], [10, 40, 2, 5, 1], [14, 8, 37, 3, 0], [5, 6, 1, 64, 1], [20, 5, 6, 2, 27]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5701754385964912, 'recall': 0.8441558441558441, 'f1': 0.680628272251309, 'support': 77}, {'label': 'entertainment', 'precision': 0.6349206349206349, 'recall': 0.6896551724137931, 'f1': 0.6611570247933884, 'support': 58}, {'label': 'politics', 'precision': 0.7872340425531915, 'recall': 0.5967741935483871, 'f1': 0.6788990825688074, 'support': 62}, {'label': 'sport', 'precision': 0.8311688311688312, 'recall': 0.8311688311688312, 'f1': 0.8311688311688312, 'support': 77}, {'label': 'tech', 'precision': 0.8181818181818182, 'recall': 0.45, 'f1': 0.5806451612903226, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T13:57:44.537075', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.48509740829467773, 'features_extracted': 10000, 'reduction_time': 0.2710850238800049, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7485029940119761, 'precision': 0.7785201745968772, 'recall': 0.7485029940119761, 'f1_score': 0.7430762957129579}, 'performance': {'train_time_seconds': 0.007430553436279297, 'total_time_seconds': 0.7636129856109619, 'inference_time_ms_per_sample': 0.2972629969705365}, 'confusion_matrix': [[69, 1, 6, 1, 0], [3, 47, 0, 8, 0], [15, 2, 41, 3, 1], [4, 6, 1, 65, 1], [21, 3, 7, 1, 28]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6160714285714286, 'recall': 0.8961038961038961, 'f1': 0.7301587301587301, 'support': 77}, {'label': 'entertainment', 'precision': 0.7966101694915254, 'recall': 0.8103448275862069, 'f1': 0.8034188034188035, 'support': 58}, {'label': 'politics', 'precision': 0.7454545454545455, 'recall': 0.6612903225806451, 'f1': 0.7008547008547008, 'support': 62}, {'label': 'sport', 'precision': 0.8333333333333334, 'recall': 0.8441558441558441, 'f1': 0.8387096774193549, 'support': 77}, {'label': 'tech', 'precision': 0.9333333333333333, 'recall': 0.4666666666666667, 'f1': 0.6222222222222222, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T13:59:23.307638', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.612043857574463, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9431137724550899, 'precision': 0.9457408407115971, 'recall': 0.9431137724550899, 'f1_score': 0.9430828827706682}, 'performance': {'train_time_seconds': 0.21082139015197754, 'total_time_seconds': 1.8228652477264404, 'inference_time_ms_per_sample': 0.09833338731777168}, 'confusion_matrix': [[74, 0, 2, 0, 1], [1, 52, 0, 4, 1], [4, 0, 56, 2, 0], [0, 0, 0, 77, 0], [4, 0, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.891566265060241, 'recall': 0.961038961038961, 'f1': 0.925, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.896551724137931, 'f1': 0.9454545454545454, 'support': 58}, {'label': 'politics', 'precision': 0.9655172413793104, 'recall': 0.9032258064516129, 'f1': 0.9333333333333333, 'support': 62}, {'label': 'sport', 'precision': 0.927710843373494, 'recall': 1.0, 'f1': 0.9625, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T14:02:36.761747', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5949125289916992, 'features_extracted': 10000, 'reduction_time': 0.27945947647094727, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9589054940965527, 'recall': 0.9580838323353293, 'f1_score': 0.9581549288074961}, 'performance': {'train_time_seconds': 0.19544720649719238, 'total_time_seconds': 2.069819211959839, 'inference_time_ms_per_sample': 0.09637892603160378}, 'confusion_matrix': [[73, 0, 1, 1, 2], [1, 55, 1, 1, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [3, 0, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9125, 'recall': 0.948051948051948, 'f1': 0.9299363057324841, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1': 0.9508196721311475, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T14:02:06.565379', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.5665719509124756, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9850299401197605, 'precision': 0.9852017576568474, 'recall': 0.9850299401197605, 'f1_score': 0.985042316047023}, 'performance': {'train_time_seconds': 0.19913911819458008, 'total_time_seconds': 1.7657110691070557, 'inference_time_ms_per_sample': 0.01553504052990211}, 'confusion_matrix': [[76, 0, 1, 0, 0], [0, 56, 1, 0, 1], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T13:58:27.705958', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6017584800720215, 'features_extracted': 5000, 'reduction_time': 0.13828277587890625, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9681862206267825, 'recall': 0.9670658682634731, 'f1_score': 0.9672450988329659}, 'performance': {'train_time_seconds': 0.2006394863128662, 'total_time_seconds': 1.940680742263794, 'inference_time_ms_per_sample': 0.09683292069121034}, 'confusion_matrix': [[75, 0, 1, 0, 1], [1, 56, 0, 1, 0], [2, 0, 60, 0, 0], [1, 0, 0, 76, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9146341463414634, 'recall': 0.974025974025974, 'f1': 0.9433962264150944, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.967741935483871, 'recall': 0.967741935483871, 'f1': 0.967741935483871, 'support': 62}, {'label': 'sport', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T13:59:38.426895', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.5713434219360352, 'features_extracted': 10000, 'reduction_time': 0.26883506774902344, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582480715261207, 'recall': 0.9580838323353293, 'f1_score': 0.9579495451843525}, 'performance': {'train_time_seconds': 0.5666639804840088, 'total_time_seconds': 2.4068424701690674, 'inference_time_ms_per_sample': 0.006123931108120673}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T14:00:38.204514', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.4547441005706787, 'features_extracted': 10000, 'reduction_time': 0.2753736972808838, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9791281994948433, 'recall': 0.9790419161676647, 'f1_score': 0.9790099071105288}, 'performance': {'train_time_seconds': 0.00978708267211914, 'total_time_seconds': 0.7399048805236816, 'inference_time_ms_per_sample': 0.0026490160091194566}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 55, 2, 0, 1], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9672131147540983, 'recall': 0.9833333333333333, 'f1': 0.9752066115702479, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T13:57:40.037286', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.4885859489440918, 'features_extracted': 10000, 'reduction_time': 0.2731599807739258, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9597344991009152, 'recall': 0.9580838323353293, 'f1_score': 0.9582684020473764}, 'performance': {'train_time_seconds': 0.20526862144470215, 'total_time_seconds': 0.9670145511627197, 'inference_time_ms_per_sample': 0.10125936862237439}, 'confusion_matrix': [[75, 0, 1, 0, 1], [1, 54, 1, 2, 0], [3, 0, 59, 0, 0], [1, 0, 0, 76, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9036144578313253, 'recall': 0.974025974025974, 'f1': 0.9375, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9310344827586207, 'f1': 0.9642857142857143, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T14:00:28.841258', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.4536020755767822, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9770319500858422, 'recall': 0.9760479041916168, 'f1_score': 0.9760204036130006}, 'performance': {'train_time_seconds': 0.18456053733825684, 'total_time_seconds': 0.6381626129150391, 'inference_time_ms_per_sample': 0.015018942827236152}, 'confusion_matrix': [[76, 0, 1, 0, 0], [1, 53, 3, 0, 1], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9137931034482759, 'f1': 0.954954954954955, 'support': 58}, {'label': 'politics', 'precision': 0.9242424242424242, 'recall': 0.9838709677419355, 'f1': 0.953125, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T13:58:15.857451', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.5571367740631104, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7395209580838323, 'precision': 0.7682079396085618, 'recall': 0.7395209580838323, 'f1_score': 0.7351170016814543}, 'performance': {'train_time_seconds': 0.002557992935180664, 'total_time_seconds': 1.559694766998291, 'inference_time_ms_per_sample': 0.42839392930447695}, 'confusion_matrix': [[68, 1, 1, 2, 5], [9, 40, 0, 8, 1], [13, 9, 34, 5, 1], [1, 5, 0, 70, 1], [17, 6, 1, 1, 35]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6296296296296297, 'recall': 0.8831168831168831, 'f1': 0.7351351351351352, 'support': 77}, {'label': 'entertainment', 'precision': 0.6557377049180327, 'recall': 0.6896551724137931, 'f1': 0.6722689075630253, 'support': 58}, {'label': 'politics', 'precision': 0.9444444444444444, 'recall': 0.5483870967741935, 'f1': 0.6938775510204082, 'support': 62}, {'label': 'sport', 'precision': 0.813953488372093, 'recall': 0.9090909090909091, 'f1': 0.8588957055214724, 'support': 77}, {'label': 'tech', 'precision': 0.813953488372093, 'recall': 0.5833333333333334, 'f1': 0.6796116504854369, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T13:59:27.045810', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.605139970779419, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7395209580838323, 'precision': 0.7505434711606478, 'recall': 0.7395209580838323, 'f1_score': 0.7393322511368852}, 'performance': {'train_time_seconds': 0.4319911003112793, 'total_time_seconds': 2.0371310710906982, 'inference_time_ms_per_sample': 0.003089447935184319}, 'confusion_matrix': [[59, 1, 6, 5, 6], [8, 37, 5, 8, 0], [15, 1, 40, 3, 3], [5, 4, 0, 67, 1], [9, 2, 2, 3, 44]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6145833333333334, 'recall': 0.7662337662337663, 'f1': 0.6820809248554913, 'support': 77}, {'label': 'entertainment', 'precision': 0.8222222222222222, 'recall': 0.6379310344827587, 'f1': 0.7184466019417476, 'support': 58}, {'label': 'politics', 'precision': 0.7547169811320755, 'recall': 0.6451612903225806, 'f1': 0.6956521739130435, 'support': 62}, {'label': 'sport', 'precision': 0.7790697674418605, 'recall': 0.8701298701298701, 'f1': 0.8220858895705522, 'support': 77}, {'label': 'tech', 'precision': 0.8148148148148148, 'recall': 0.7333333333333333, 'f1': 0.7719298245614035, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T14:00:34.345481', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.48270630836486816, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.781437125748503, 'precision': 0.793885561246416, 'recall': 0.781437125748503, 'f1_score': 0.7825399223164933}, 'performance': {'train_time_seconds': 0.4638819694519043, 'total_time_seconds': 0.9465882778167725, 'inference_time_ms_per_sample': 0.002516957814108112}, 'confusion_matrix': [[60, 1, 7, 4, 5], [6, 40, 4, 8, 0], [13, 0, 44, 2, 3], [4, 1, 1, 69, 2], [10, 1, 1, 0, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6451612903225806, 'recall': 0.7792207792207793, 'f1': 0.7058823529411765, 'support': 77}, {'label': 'entertainment', 'precision': 0.9302325581395349, 'recall': 0.6896551724137931, 'f1': 0.7920792079207921, 'support': 58}, {'label': 'politics', 'precision': 0.7719298245614035, 'recall': 0.7096774193548387, 'f1': 0.7394957983193278, 'support': 62}, {'label': 'sport', 'precision': 0.8313253012048193, 'recall': 0.8961038961038961, 'f1': 0.8625, 'support': 77}, {'label': 'tech', 'precision': 0.8275862068965517, 'recall': 0.8, 'f1': 0.8135593220338984, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T14:00:31.155014', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5347704887390137, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.979473277976272, 'recall': 0.9790419161676647, 'f1_score': 0.9790700186944252}, 'performance': {'train_time_seconds': 1.1308863162994385, 'total_time_seconds': 1.6656568050384521, 'inference_time_ms_per_sample': 0.003231499723331657}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T14:00:35.299883', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.468325138092041, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7844311377245509, 'precision': 0.7859271045770384, 'recall': 0.7844311377245509, 'f1_score': 0.7841903691397354}, 'performance': {'train_time_seconds': 0.6837265491485596, 'total_time_seconds': 1.1520516872406006, 'inference_time_ms_per_sample': 0.0021771756474843282}, 'confusion_matrix': [[51, 4, 13, 3, 6], [5, 43, 5, 4, 1], [11, 0, 48, 0, 3], [1, 3, 1, 70, 2], [4, 3, 3, 0, 50]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7083333333333334, 'recall': 0.6623376623376623, 'f1': 0.6845637583892618, 'support': 77}, {'label': 'entertainment', 'precision': 0.8113207547169812, 'recall': 0.7413793103448276, 'f1': 0.7747747747747747, 'support': 58}, {'label': 'politics', 'precision': 0.6857142857142857, 'recall': 0.7741935483870968, 'f1': 0.7272727272727273, 'support': 62}, {'label': 'sport', 'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1': 0.9090909090909091, 'support': 77}, {'label': 'tech', 'precision': 0.8064516129032258, 'recall': 0.8333333333333334, 'f1': 0.819672131147541, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T13:57:41.050370', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.4877758026123047, 'features_extracted': 10000, 'reduction_time': 0.2676734924316406, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7874251497005988, 'precision': 0.8054931066118158, 'recall': 0.7874251497005988, 'f1_score': 0.7878794541038044}, 'performance': {'train_time_seconds': 0.08869695663452148, 'total_time_seconds': 0.8441462516784668, 'inference_time_ms_per_sample': 0.002765369986345668}, 'confusion_matrix': [[64, 1, 5, 4, 3], [7, 40, 3, 7, 1], [17, 1, 40, 2, 2], [5, 1, 0, 71, 0], [8, 1, 1, 2, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6336633663366337, 'recall': 0.8311688311688312, 'f1': 0.7191011235955056, 'support': 77}, {'label': 'entertainment', 'precision': 0.9090909090909091, 'recall': 0.6896551724137931, 'f1': 0.7843137254901961, 'support': 58}, {'label': 'politics', 'precision': 0.8163265306122449, 'recall': 0.6451612903225806, 'f1': 0.7207207207207207, 'support': 62}, {'label': 'sport', 'precision': 0.8255813953488372, 'recall': 0.922077922077922, 'f1': 0.8711656441717791, 'support': 77}, {'label': 'tech', 'precision': 0.8888888888888888, 'recall': 0.8, 'f1': 0.8421052631578947, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T14:01:29.801458', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5708606243133545, 'features_extracted': 5000, 'reduction_time': 0.14118099212646484, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8862275449101796, 'precision': 0.893452275147433, 'recall': 0.8862275449101796, 'f1_score': 0.8859488148344287}, 'performance': {'train_time_seconds': 0.011527061462402344, 'total_time_seconds': 1.7235686779022217, 'inference_time_ms_per_sample': 0.09683791748777834}, 'confusion_matrix': [[70, 2, 2, 2, 1], [4, 52, 1, 1, 0], [4, 1, 56, 1, 0], [0, 2, 0, 74, 1], [10, 6, 0, 0, 44]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7954545454545454, 'recall': 0.9090909090909091, 'f1': 0.8484848484848485, 'support': 77}, {'label': 'entertainment', 'precision': 0.8253968253968254, 'recall': 0.896551724137931, 'f1': 0.859504132231405, 'support': 58}, {'label': 'politics', 'precision': 0.9491525423728814, 'recall': 0.9032258064516129, 'f1': 0.9256198347107438, 'support': 62}, {'label': 'sport', 'precision': 0.9487179487179487, 'recall': 0.961038961038961, 'f1': 0.9548387096774194, 'support': 77}, {'label': 'tech', 'precision': 0.9565217391304348, 'recall': 0.7333333333333333, 'f1': 0.8301886792452831, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T14:02:43.130133', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.6071298122406006, 'features_extracted': 10000, 'reduction_time': 0.2825179100036621, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8473053892215568, 'precision': 0.8705461627049951, 'recall': 0.8473053892215568, 'f1_score': 0.8507001984865352}, 'performance': {'train_time_seconds': 0.00883340835571289, 'total_time_seconds': 1.8984811305999756, 'inference_time_ms_per_sample': 0.10189467561459112}, 'confusion_matrix': [[71, 0, 2, 3, 1], [10, 46, 1, 1, 0], [9, 1, 52, 0, 0], [5, 1, 0, 70, 1], [11, 5, 0, 0, 44]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6698113207547169, 'recall': 0.922077922077922, 'f1': 0.7759562841530054, 'support': 77}, {'label': 'entertainment', 'precision': 0.8679245283018868, 'recall': 0.7931034482758621, 'f1': 0.8288288288288288, 'support': 58}, {'label': 'politics', 'precision': 0.9454545454545454, 'recall': 0.8387096774193549, 'f1': 0.8888888888888888, 'support': 62}, {'label': 'sport', 'precision': 0.9459459459459459, 'recall': 0.9090909090909091, 'f1': 0.9271523178807947, 'support': 77}, {'label': 'tech', 'precision': 0.9565217391304348, 'recall': 0.7333333333333333, 'f1': 0.8301886792452831, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T14:02:11.782584', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.8078525066375732, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9825088284968525, 'recall': 0.9820359281437125, 'f1_score': 0.9821213702034858}, 'performance': {'train_time_seconds': 1.4429466724395752, 'total_time_seconds': 3.2507991790771484, 'inference_time_ms_per_sample': 0.003584844623497146}, 'confusion_matrix': [[74, 1, 2, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9866666666666667, 'recall': 0.961038961038961, 'f1': 0.9736842105263158, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9833333333333333, 'f1': 0.9915966386554622, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T13:59:34.863178', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.5238678455352783, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7215568862275449, 'precision': 0.7716045760267021, 'recall': 0.7215568862275449, 'f1_score': 0.7185402591667486}, 'performance': {'train_time_seconds': 0.002795696258544922, 'total_time_seconds': 1.5266635417938232, 'inference_time_ms_per_sample': 0.4301106858396244}, 'confusion_matrix': [[69, 0, 1, 3, 4], [11, 38, 0, 9, 0], [19, 4, 32, 7, 0], [3, 4, 0, 68, 2], [21, 5, 0, 0, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5609756097560976, 'recall': 0.8961038961038961, 'f1': 0.69, 'support': 77}, {'label': 'entertainment', 'precision': 0.7450980392156863, 'recall': 0.6551724137931034, 'f1': 0.6972477064220184, 'support': 58}, {'label': 'politics', 'precision': 0.9696969696969697, 'recall': 0.5161290322580645, 'f1': 0.6736842105263158, 'support': 62}, {'label': 'sport', 'precision': 0.7816091954022989, 'recall': 0.8831168831168831, 'f1': 0.8292682926829268, 'support': 77}, {'label': 'tech', 'precision': 0.85, 'recall': 0.5666666666666667, 'f1': 0.68, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T13:57:42.780126', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.47939276695251465, 'features_extracted': 10000, 'reduction_time': 0.2693488597869873, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7005988023952096, 'precision': 0.7386074223726348, 'recall': 0.7005988023952096, 'f1_score': 0.6979053547915822}, 'performance': {'train_time_seconds': 0.007375955581665039, 'total_time_seconds': 0.756117582321167, 'inference_time_ms_per_sample': 0.3357683113235199}, 'confusion_matrix': [[66, 5, 2, 2, 2], [12, 38, 1, 7, 0], [13, 6, 39, 3, 1], [4, 8, 0, 64, 1], [24, 2, 6, 1, 27]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5546218487394958, 'recall': 0.8571428571428571, 'f1': 0.673469387755102, 'support': 77}, {'label': 'entertainment', 'precision': 0.6440677966101694, 'recall': 0.6551724137931034, 'f1': 0.6495726495726496, 'support': 58}, {'label': 'politics', 'precision': 0.8125, 'recall': 0.6290322580645161, 'f1': 0.7090909090909091, 'support': 62}, {'label': 'sport', 'precision': 0.8311688311688312, 'recall': 0.8311688311688312, 'f1': 0.8311688311688312, 'support': 77}, {'label': 'tech', 'precision': 0.8709677419354839, 'recall': 0.45, 'f1': 0.5934065934065934, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T13:57:34.892118', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.473416805267334, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7455089820359282, 'precision': 0.768395451029746, 'recall': 0.7455089820359282, 'f1_score': 0.7399041325889589}, 'performance': {'train_time_seconds': 0.002554178237915039, 'total_time_seconds': 0.475970983505249, 'inference_time_ms_per_sample': 0.43209726938944376}, 'confusion_matrix': [[70, 0, 1, 4, 2], [9, 35, 1, 12, 1], [11, 1, 39, 10, 1], [0, 4, 1, 70, 2], [15, 8, 1, 1, 35]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6666666666666666, 'recall': 0.9090909090909091, 'f1': 0.7692307692307693, 'support': 77}, {'label': 'entertainment', 'precision': 0.7291666666666666, 'recall': 0.603448275862069, 'f1': 0.660377358490566, 'support': 58}, {'label': 'politics', 'precision': 0.9069767441860465, 'recall': 0.6290322580645161, 'f1': 0.7428571428571429, 'support': 62}, {'label': 'sport', 'precision': 0.7216494845360825, 'recall': 0.9090909090909091, 'f1': 0.8045977011494253, 'support': 77}, {'label': 'tech', 'precision': 0.8536585365853658, 'recall': 0.5833333333333334, 'f1': 0.693069306930693, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T13:59:25.172950', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5783164501190186, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9587195757323855, 'recall': 0.9580838323353293, 'f1_score': 0.9581314365243281}, 'performance': {'train_time_seconds': 0.2391948699951172, 'total_time_seconds': 1.8175113201141357, 'inference_time_ms_per_sample': 0.0970020979464411}, 'confusion_matrix': [[73, 0, 2, 0, 2], [1, 54, 0, 1, 2], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9240506329113924, 'recall': 0.948051948051948, 'f1': 0.9358974358974359, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9310344827586207, 'f1': 0.9642857142857143, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9333333333333333, 'recall': 0.9333333333333333, 'f1': 0.9333333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T13:59:43.117487', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6209297180175781, 'features_extracted': 10000, 'reduction_time': 0.2683990001678467, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9311377245508982, 'precision': 0.9369378651603676, 'recall': 0.9311377245508982, 'f1_score': 0.9318616817611851}, 'performance': {'train_time_seconds': 0.1958777904510498, 'total_time_seconds': 2.0852065086364746, 'inference_time_ms_per_sample': 0.09682007178574979}, 'confusion_matrix': [[75, 0, 1, 0, 1], [2, 52, 1, 3, 0], [7, 0, 55, 0, 0], [2, 0, 0, 74, 1], [4, 0, 0, 1, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8333333333333334, 'recall': 0.974025974025974, 'f1': 0.8982035928143712, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.896551724137931, 'f1': 0.9454545454545454, 'support': 58}, {'label': 'politics', 'precision': 0.9649122807017544, 'recall': 0.8870967741935484, 'f1': 0.9243697478991597, 'support': 62}, {'label': 'sport', 'precision': 0.9487179487179487, 'recall': 0.961038961038961, 'f1': 0.9548387096774194, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T14:02:30.509487', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.637312889099121, 'features_extracted': 10000, 'reduction_time': 0.2775094509124756, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9822509602615772, 'recall': 0.9820359281437125, 'f1_score': 0.9820355339744099}, 'performance': {'train_time_seconds': 0.11729931831359863, 'total_time_seconds': 2.0321216583251953, 'inference_time_ms_per_sample': 0.0028638782615433194}, 'confusion_matrix': [[76, 0, 0, 0, 1], [0, 57, 0, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T13:59:18.749111', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.7287962436676025, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.961126032159464, 'recall': 0.9610778443113772, 'f1_score': 0.960942194123036}, 'performance': {'train_time_seconds': 2.8128652572631836, 'total_time_seconds': 4.541661500930786, 'inference_time_ms_per_sample': 0.004686995180781016}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 57, 1, 0, 0], [0, 0, 59, 1, 2], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.972972972972973, 'recall': 0.935064935064935, 'f1': 0.9536423841059603, 'support': 77}, {'label': 'entertainment', 'precision': 0.9661016949152542, 'recall': 0.9827586206896551, 'f1': 0.9743589743589743, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9491525423728814, 'recall': 0.9333333333333333, 'f1': 0.9411764705882353, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T14:02:34.601061', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6327037811279297, 'features_extracted': 10000, 'reduction_time': 0.281383752822876, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9431137724550899, 'precision': 0.9488539184198133, 'recall': 0.9431137724550899, 'f1_score': 0.9442170462220482}, 'performance': {'train_time_seconds': 0.19954633712768555, 'total_time_seconds': 2.113633871078491, 'inference_time_ms_per_sample': 0.09664732539011334}, 'confusion_matrix': [[74, 0, 0, 1, 2], [2, 55, 0, 1, 0], [6, 0, 56, 0, 0], [2, 0, 0, 75, 0], [5, 0, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8314606741573034, 'recall': 0.961038961038961, 'f1': 0.891566265060241, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.9032258064516129, 'f1': 0.9491525423728814, 'support': 62}, {'label': 'sport', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T14:00:40.781443', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5346448421478271, 'features_extracted': 10000, 'reduction_time': 0.27669572830200195, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9341317365269461, 'precision': 0.9356036662425867, 'recall': 0.9341317365269461, 'f1_score': 0.9341157775392753}, 'performance': {'train_time_seconds': 0.19438576698303223, 'total_time_seconds': 1.0057263374328613, 'inference_time_ms_per_sample': 0.09610838518885081}, 'confusion_matrix': [[71, 0, 3, 1, 2], [0, 53, 0, 5, 0], [3, 0, 58, 1, 0], [1, 0, 0, 76, 0], [4, 1, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8987341772151899, 'recall': 0.922077922077922, 'f1': 0.9102564102564102, 'support': 77}, {'label': 'entertainment', 'precision': 0.9814814814814815, 'recall': 0.9137931034482759, 'f1': 0.9464285714285714, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9156626506024096, 'recall': 0.987012987012987, 'f1': 0.95, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T13:57:31.850725', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.4865257740020752, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7634730538922155, 'precision': 0.7787728905313933, 'recall': 0.7634730538922155, 'f1_score': 0.7643344269165264}, 'performance': {'train_time_seconds': 0.3299379348754883, 'total_time_seconds': 0.8164637088775635, 'inference_time_ms_per_sample': 0.0034592108812160835}, 'confusion_matrix': [[61, 1, 5, 4, 6], [7, 39, 3, 8, 1], [16, 0, 41, 2, 3], [5, 4, 0, 67, 1], [9, 1, 0, 3, 47]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6224489795918368, 'recall': 0.7922077922077922, 'f1': 0.6971428571428572, 'support': 77}, {'label': 'entertainment', 'precision': 0.8666666666666667, 'recall': 0.6724137931034483, 'f1': 0.7572815533980582, 'support': 58}, {'label': 'politics', 'precision': 0.8367346938775511, 'recall': 0.6612903225806451, 'f1': 0.7387387387387387, 'support': 62}, {'label': 'sport', 'precision': 0.7976190476190477, 'recall': 0.8701298701298701, 'f1': 0.8322981366459627, 'support': 77}, {'label': 'tech', 'precision': 0.8103448275862069, 'recall': 0.7833333333333333, 'f1': 0.7966101694915254, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T13:58:08.234442', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5823252201080322, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9700598802395209, 'precision': 0.9708488305720072, 'recall': 0.9700598802395209, 'f1_score': 0.9702399065449924}, 'performance': {'train_time_seconds': 0.2211768627166748, 'total_time_seconds': 1.803502082824707, 'inference_time_ms_per_sample': 0.09858037183384695}, 'confusion_matrix': [[75, 0, 1, 0, 1], [1, 56, 1, 0, 0], [3, 0, 59, 0, 0], [0, 0, 0, 76, 1], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9259259259259259, 'recall': 0.974025974025974, 'f1': 0.9493670886075949, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9672131147540983, 'recall': 0.9516129032258065, 'f1': 0.959349593495935, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 0.987012987012987, 'f1': 0.9934640522875817, 'support': 77}, {'label': 'tech', 'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1': 0.9666666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T13:58:12.007192', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5695805549621582, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7604790419161677, 'precision': 0.7639773036243528, 'recall': 0.7604790419161677, 'f1_score': 0.7604377994759974}, 'performance': {'train_time_seconds': 0.5221512317657471, 'total_time_seconds': 2.0917317867279053, 'inference_time_ms_per_sample': 0.002610469292737767}, 'confusion_matrix': [[53, 4, 11, 3, 6], [5, 39, 7, 6, 1], [8, 2, 47, 2, 3], [3, 3, 2, 67, 2], [7, 0, 4, 1, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6973684210526315, 'recall': 0.6883116883116883, 'f1': 0.6928104575163399, 'support': 77}, {'label': 'entertainment', 'precision': 0.8125, 'recall': 0.6724137931034483, 'f1': 0.7358490566037735, 'support': 58}, {'label': 'politics', 'precision': 0.6619718309859155, 'recall': 0.7580645161290323, 'f1': 0.706766917293233, 'support': 62}, {'label': 'sport', 'precision': 0.8481012658227848, 'recall': 0.8701298701298701, 'f1': 0.8589743589743589, 'support': 77}, {'label': 'tech', 'precision': 0.8, 'recall': 0.8, 'f1': 0.8, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T14:00:37.615226', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.4851217269897461, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9461077844311377, 'precision': 0.948370618660284, 'recall': 0.9461077844311377, 'f1_score': 0.9456643145263546}, 'performance': {'train_time_seconds': 0.002156972885131836, 'total_time_seconds': 0.48727869987487793, 'inference_time_ms_per_sample': 0.28110192921347243}, 'confusion_matrix': [[68, 1, 6, 1, 1], [1, 51, 2, 1, 3], [0, 0, 62, 0, 0], [0, 0, 0, 77, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9855072463768116, 'recall': 0.8831168831168831, 'f1': 0.9315068493150684, 'support': 77}, {'label': 'entertainment', 'precision': 0.9444444444444444, 'recall': 0.8793103448275862, 'f1': 0.9107142857142857, 'support': 58}, {'label': 'politics', 'precision': 0.8857142857142857, 'recall': 1.0, 'f1': 0.9393939393939394, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9354838709677419, 'recall': 0.9666666666666667, 'f1': 0.9508196721311475, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T14:00:42.835620', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 0.47435665130615234, 'features_extracted': 10000, 'reduction_time': 0.2800767421722412, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7994011976047904, 'precision': 0.8081974062999767, 'recall': 0.7994011976047904, 'f1_score': 0.7992305099343296}, 'performance': {'train_time_seconds': 0.11000680923461914, 'total_time_seconds': 0.8644402027130127, 'inference_time_ms_per_sample': 0.0024113112580990363}, 'confusion_matrix': [[64, 1, 6, 2, 4], [4, 42, 4, 8, 0], [14, 1, 43, 2, 2], [3, 1, 0, 72, 1], [9, 2, 3, 0, 46]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6808510638297872, 'recall': 0.8311688311688312, 'f1': 0.7485380116959064, 'support': 77}, {'label': 'entertainment', 'precision': 0.8936170212765957, 'recall': 0.7241379310344828, 'f1': 0.8, 'support': 58}, {'label': 'politics', 'precision': 0.7678571428571429, 'recall': 0.6935483870967742, 'f1': 0.7288135593220338, 'support': 62}, {'label': 'sport', 'precision': 0.8571428571428571, 'recall': 0.935064935064935, 'f1': 0.8944099378881988, 'support': 77}, {'label': 'tech', 'precision': 0.8679245283018868, 'recall': 0.7666666666666667, 'f1': 0.8141592920353983, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T13:58:19.254719', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.5609095096588135, 'features_extracted': 5000, 'reduction_time': 0.13234829902648926, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9730538922155688, 'precision': 0.9737496602766063, 'recall': 0.9730538922155688, 'f1_score': 0.9729928141568138}, 'performance': {'train_time_seconds': 0.017094850540161133, 'total_time_seconds': 1.7103526592254639, 'inference_time_ms_per_sample': 0.0045970528425570735}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 54, 2, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T13:57:56.870445', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.5760023593902588, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9581598373126704, 'recall': 0.9580838323353293, 'f1_score': 0.9579800968580585}, 'performance': {'train_time_seconds': 4.464927673339844, 'total_time_seconds': 6.0409300327301025, 'inference_time_ms_per_sample': 0.0036633657124228104}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [2, 1, 58, 1, 0], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T14:00:38.956390', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.4918687343597412, 'features_extracted': 10000, 'reduction_time': 0.27852725982666016, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9700598802395209, 'precision': 0.9703506518002348, 'recall': 0.9700598802395209, 'f1_score': 0.9700490110058383}, 'performance': {'train_time_seconds': 0.0874791145324707, 'total_time_seconds': 0.8578751087188721, 'inference_time_ms_per_sample': 0.002940971694306699}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 56, 1, 1, 0], [3, 0, 59, 0, 0], [0, 0, 0, 77, 0], [1, 2, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9493670886075949, 'recall': 0.974025974025974, 'f1': 0.9615384615384616, 'support': 77}, {'label': 'entertainment', 'precision': 0.9491525423728814, 'recall': 0.9655172413793104, 'f1': 0.9572649572649573, 'support': 58}, {'label': 'politics', 'precision': 0.9833333333333333, 'recall': 0.9516129032258065, 'f1': 0.9672131147540983, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T13:58:25.695081', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6356544494628906, 'features_extracted': 5000, 'reduction_time': 0.13121390342712402, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9431137724550899, 'precision': 0.9448907419043473, 'recall': 0.9431137724550899, 'f1_score': 0.9434858979971915}, 'performance': {'train_time_seconds': 0.1985321044921875, 'total_time_seconds': 1.9654004573822021, 'inference_time_ms_per_sample': 0.09700709474300909}, 'confusion_matrix': [[72, 0, 2, 1, 2], [1, 54, 0, 3, 0], [4, 0, 58, 0, 0], [1, 0, 0, 75, 1], [4, 0, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8780487804878049, 'recall': 0.935064935064935, 'f1': 0.9056603773584906, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9310344827586207, 'f1': 0.9642857142857143, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1': 0.9508196721311475, 'support': 62}, {'label': 'sport', 'precision': 0.9493670886075949, 'recall': 0.974025974025974, 'f1': 0.9615384615384616, 'support': 77}, {'label': 'tech', 'precision': 0.9491525423728814, 'recall': 0.9333333333333333, 'f1': 0.9411764705882353, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T14:02:25.314076', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.5673959255218506, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9251497005988024, 'precision': 0.9268188527710549, 'recall': 0.9251497005988024, 'f1_score': 0.9249608971665426}, 'performance': {'train_time_seconds': 0.0026051998138427734, 'total_time_seconds': 1.5700011253356934, 'inference_time_ms_per_sample': 0.2976042067933225}, 'confusion_matrix': [[68, 1, 6, 1, 1], [1, 50, 3, 1, 3], [1, 1, 59, 0, 1], [1, 0, 0, 75, 1], [1, 1, 0, 1, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9444444444444444, 'recall': 0.8831168831168831, 'f1': 0.912751677852349, 'support': 77}, {'label': 'entertainment', 'precision': 0.9433962264150944, 'recall': 0.8620689655172413, 'f1': 0.9009009009009009, 'support': 58}, {'label': 'politics', 'precision': 0.8676470588235294, 'recall': 0.9516129032258065, 'f1': 0.9076923076923077, 'support': 62}, {'label': 'sport', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'tech', 'precision': 0.9047619047619048, 'recall': 0.95, 'f1': 0.926829268292683, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T13:59:55.469876', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.6059439182281494, 'features_extracted': 10000, 'reduction_time': 0.27109360694885254, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7485029940119761, 'precision': 0.7805850298796609, 'recall': 0.7485029940119761, 'f1_score': 0.7439429735975069}, 'performance': {'train_time_seconds': 0.00738215446472168, 'total_time_seconds': 1.8844196796417236, 'inference_time_ms_per_sample': 0.2915530861494784}, 'confusion_matrix': [[72, 0, 4, 1, 0], [7, 42, 1, 7, 1], [12, 2, 40, 6, 2], [4, 6, 1, 66, 0], [23, 2, 4, 1, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6101694915254238, 'recall': 0.935064935064935, 'f1': 0.7384615384615385, 'support': 77}, {'label': 'entertainment', 'precision': 0.8076923076923077, 'recall': 0.7241379310344828, 'f1': 0.7636363636363637, 'support': 58}, {'label': 'politics', 'precision': 0.8, 'recall': 0.6451612903225806, 'f1': 0.7142857142857143, 'support': 62}, {'label': 'sport', 'precision': 0.8148148148148148, 'recall': 0.8571428571428571, 'f1': 0.8354430379746836, 'support': 77}, {'label': 'tech', 'precision': 0.9090909090909091, 'recall': 0.5, 'f1': 0.6451612903225806, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T13:57:28.363833', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5379457473754883, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9553975430261775, 'recall': 0.9550898203592815, 'f1_score': 0.9549256583867716}, 'performance': {'train_time_seconds': 1.3049228191375732, 'total_time_seconds': 1.8428685665130615, 'inference_time_ms_per_sample': 0.0038668067155483953}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [1, 1, 59, 1, 0], [0, 0, 0, 77, 0], [3, 1, 1, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9491525423728814, 'recall': 0.9655172413793104, 'f1': 0.9572649572649573, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9821428571428571, 'recall': 0.9166666666666666, 'f1': 0.9482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T13:59:49.334480', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.7030866146087646, 'features_extracted': 10000, 'reduction_time': 0.2727785110473633, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7784431137724551, 'precision': 0.7820767640639236, 'recall': 0.7784431137724551, 'f1_score': 0.7787006522958154}, 'performance': {'train_time_seconds': 0.1243140697479248, 'total_time_seconds': 2.1001791954040527, 'inference_time_ms_per_sample': 0.0031222840269168697}, 'confusion_matrix': [[59, 2, 9, 4, 3], [5, 42, 4, 5, 2], [12, 3, 42, 2, 3], [3, 2, 3, 68, 1], [8, 1, 1, 1, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6781609195402298, 'recall': 0.7662337662337663, 'f1': 0.7195121951219512, 'support': 77}, {'label': 'entertainment', 'precision': 0.84, 'recall': 0.7241379310344828, 'f1': 0.7777777777777778, 'support': 58}, {'label': 'politics', 'precision': 0.711864406779661, 'recall': 0.6774193548387096, 'f1': 0.6942148760330579, 'support': 62}, {'label': 'sport', 'precision': 0.85, 'recall': 0.8831168831168831, 'f1': 0.8662420382165605, 'support': 77}, {'label': 'tech', 'precision': 0.8448275862068966, 'recall': 0.8166666666666667, 'f1': 0.8305084745762712, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T14:00:56.877691', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.554534912109375, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9795946568401658, 'recall': 0.9790419161676647, 'f1_score': 0.9790994973331157}, 'performance': {'train_time_seconds': 0.09773898124694824, 'total_time_seconds': 1.6522738933563232, 'inference_time_ms_per_sample': 0.00796846286979264}, 'confusion_matrix': [[75, 0, 2, 0, 0], [0, 55, 2, 0, 1], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T14:02:15.060565', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.7158699035644531, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.937125748502994, 'precision': 0.9436572233683893, 'recall': 0.937125748502994, 'f1_score': 0.9371907722035053}, 'performance': {'train_time_seconds': 0.21602869033813477, 'total_time_seconds': 1.931898593902588, 'inference_time_ms_per_sample': 0.09778445352337317}, 'confusion_matrix': [[76, 0, 0, 0, 1], [2, 50, 0, 6, 0], [5, 0, 55, 2, 0], [0, 0, 0, 77, 0], [5, 0, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8636363636363636, 'recall': 0.987012987012987, 'f1': 0.9212121212121213, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.8620689655172413, 'f1': 0.9259259259259259, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.8870967741935484, 'f1': 0.9401709401709402, 'support': 62}, {'label': 'sport', 'precision': 0.9058823529411765, 'recall': 1.0, 'f1': 0.9506172839506173, 'support': 77}, {'label': 'tech', 'precision': 0.9821428571428571, 'recall': 0.9166666666666666, 'f1': 0.9482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T14:00:43.710485', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.46773386001586914, 'features_extracted': 10000, 'reduction_time': 0.2782132625579834, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7964071856287425, 'precision': 0.7977692216735719, 'recall': 0.7964071856287425, 'f1_score': 0.7955903885621982}, 'performance': {'train_time_seconds': 0.14786839485168457, 'total_time_seconds': 0.8938155174255371, 'inference_time_ms_per_sample': 0.0027825018602930856}, 'confusion_matrix': [[52, 3, 10, 5, 7], [3, 44, 6, 5, 0], [6, 1, 51, 1, 3], [4, 1, 2, 68, 2], [6, 2, 1, 0, 51]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7323943661971831, 'recall': 0.6753246753246753, 'f1': 0.7027027027027027, 'support': 77}, {'label': 'entertainment', 'precision': 0.8627450980392157, 'recall': 0.7586206896551724, 'f1': 0.8073394495412844, 'support': 58}, {'label': 'politics', 'precision': 0.7285714285714285, 'recall': 0.8225806451612904, 'f1': 0.7727272727272727, 'support': 62}, {'label': 'sport', 'precision': 0.8607594936708861, 'recall': 0.8831168831168831, 'f1': 0.8717948717948718, 'support': 77}, {'label': 'tech', 'precision': 0.8095238095238095, 'recall': 0.85, 'f1': 0.8292682926829268, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T14:02:45.076261', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.5941801071166992, 'features_extracted': 10000, 'reduction_time': 0.2803339958190918, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.844311377245509, 'precision': 0.8635998206095044, 'recall': 0.844311377245509, 'f1_score': 0.845284563498897}, 'performance': {'train_time_seconds': 0.00902700424194336, 'total_time_seconds': 1.8835411071777344, 'inference_time_ms_per_sample': 0.09815136115708037}, 'confusion_matrix': [[72, 1, 2, 2, 0], [8, 45, 4, 1, 0], [10, 1, 51, 0, 0], [1, 1, 3, 72, 0], [11, 6, 1, 0, 42]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7058823529411765, 'recall': 0.935064935064935, 'f1': 0.8044692737430168, 'support': 77}, {'label': 'entertainment', 'precision': 0.8333333333333334, 'recall': 0.7758620689655172, 'f1': 0.8035714285714286, 'support': 58}, {'label': 'politics', 'precision': 0.8360655737704918, 'recall': 0.8225806451612904, 'f1': 0.8292682926829268, 'support': 62}, {'label': 'sport', 'precision': 0.96, 'recall': 0.935064935064935, 'f1': 0.9473684210526315, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.7, 'f1': 0.8235294117647058, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T14:01:05.202774', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.5737314224243164, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.9616706689908869, 'recall': 0.9610778443113772, 'f1_score': 0.9611459439487486}, 'performance': {'train_time_seconds': 0.22729134559631348, 'total_time_seconds': 1.8010227680206299, 'inference_time_ms_per_sample': 0.09919355015554829}, 'confusion_matrix': [[74, 0, 1, 0, 2], [1, 55, 0, 2, 0], [2, 0, 59, 1, 0], [1, 0, 0, 76, 0], [2, 1, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.925, 'recall': 0.961038961038961, 'f1': 0.9426751592356688, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9833333333333333, 'recall': 0.9516129032258065, 'f1': 0.9672131147540983, 'support': 62}, {'label': 'sport', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T13:59:40.852620', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.614889144897461, 'features_extracted': 10000, 'reduction_time': 0.2683532238006592, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.958013936715038, 'recall': 0.9580838323353293, 'f1_score': 0.9579418002709207}, 'performance': {'train_time_seconds': 0.3641183376312256, 'total_time_seconds': 2.2473607063293457, 'inference_time_ms_per_sample': 0.006041840878789296}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 0, 1], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T13:58:14.108193', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5912353992462158, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7005988023952096, 'precision': 0.7392125438118978, 'recall': 0.7005988023952096, 'f1_score': 0.6968495383954719}, 'performance': {'train_time_seconds': 0.002591848373413086, 'total_time_seconds': 1.593827247619629, 'inference_time_ms_per_sample': 0.4390820771634222}, 'confusion_matrix': [[67, 2, 1, 2, 5], [16, 35, 0, 6, 1], [15, 8, 31, 3, 5], [2, 4, 1, 69, 1], [20, 8, 0, 0, 32]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5583333333333333, 'recall': 0.8701298701298701, 'f1': 0.6802030456852792, 'support': 77}, {'label': 'entertainment', 'precision': 0.6140350877192983, 'recall': 0.603448275862069, 'f1': 0.6086956521739131, 'support': 58}, {'label': 'politics', 'precision': 0.9393939393939394, 'recall': 0.5, 'f1': 0.6526315789473685, 'support': 62}, {'label': 'sport', 'precision': 0.8625, 'recall': 0.8961038961038961, 'f1': 0.8789808917197452, 'support': 77}, {'label': 'tech', 'precision': 0.7272727272727273, 'recall': 0.5333333333333333, 'f1': 0.6153846153846154, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T14:00:41.830880', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.48301076889038086, 'features_extracted': 10000, 'reduction_time': 0.27904224395751953, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9539892802626376, 'recall': 0.9520958083832335, 'f1_score': 0.9522534682228914}, 'performance': {'train_time_seconds': 0.19884371757507324, 'total_time_seconds': 0.9608967304229736, 'inference_time_ms_per_sample': 0.09810924530029297}, 'confusion_matrix': [[74, 0, 0, 1, 2], [2, 53, 0, 3, 0], [2, 0, 59, 1, 0], [1, 0, 0, 76, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9024390243902439, 'recall': 0.961038961038961, 'f1': 0.9308176100628931, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9137931034482759, 'f1': 0.954954954954955, 'support': 58}, {'label': 'politics', 'precision': 0.9833333333333333, 'recall': 0.9516129032258065, 'f1': 0.9672131147540983, 'support': 62}, {'label': 'sport', 'precision': 0.9382716049382716, 'recall': 0.987012987012987, 'f1': 0.9620253164556962, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T14:01:26.100750', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.5759351253509521, 'features_extracted': 5000, 'reduction_time': 0.13819575309753418, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7754491017964071, 'precision': 0.80293509290231, 'recall': 0.7754491017964071, 'f1_score': 0.7803227950230056}, 'performance': {'train_time_seconds': 0.11120390892028809, 'total_time_seconds': 1.8253347873687744, 'inference_time_ms_per_sample': 0.0024327261005333083}, 'confusion_matrix': [[63, 2, 6, 1, 5], [11, 38, 4, 5, 0], [16, 1, 43, 1, 1], [9, 1, 0, 67, 0], [10, 1, 1, 0, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5779816513761468, 'recall': 0.8181818181818182, 'f1': 0.6774193548387096, 'support': 77}, {'label': 'entertainment', 'precision': 0.8837209302325582, 'recall': 0.6551724137931034, 'f1': 0.7524752475247525, 'support': 58}, {'label': 'politics', 'precision': 0.7962962962962963, 'recall': 0.6935483870967742, 'f1': 0.7413793103448276, 'support': 62}, {'label': 'sport', 'precision': 0.9054054054054054, 'recall': 0.8701298701298701, 'f1': 0.8874172185430463, 'support': 77}, {'label': 'tech', 'precision': 0.8888888888888888, 'recall': 0.8, 'f1': 0.8421052631578947, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T13:57:33.667251', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 0.4587550163269043, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7245508982035929, 'precision': 0.7609437560397708, 'recall': 0.7245508982035929, 'f1_score': 0.7208932968669342}, 'performance': {'train_time_seconds': 0.00241851806640625, 'total_time_seconds': 0.46117353439331055, 'inference_time_ms_per_sample': 0.4533379377719171}, 'confusion_matrix': [[70, 1, 1, 2, 3], [17, 33, 0, 8, 0], [14, 5, 38, 5, 0], [1, 5, 3, 68, 0], [15, 8, 0, 4, 33]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5982905982905983, 'recall': 0.9090909090909091, 'f1': 0.7216494845360825, 'support': 77}, {'label': 'entertainment', 'precision': 0.6346153846153846, 'recall': 0.5689655172413793, 'f1': 0.6, 'support': 58}, {'label': 'politics', 'precision': 0.9047619047619048, 'recall': 0.6129032258064516, 'f1': 0.7307692307692307, 'support': 62}, {'label': 'sport', 'precision': 0.7816091954022989, 'recall': 0.8831168831168831, 'f1': 0.8292682926829268, 'support': 77}, {'label': 'tech', 'precision': 0.9166666666666666, 'recall': 0.55, 'f1': 0.6875, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T13:58:17.568856', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.5316407680511475, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7425149700598802, 'precision': 0.7638039943989258, 'recall': 0.7425149700598802, 'f1_score': 0.7381551353808873}, 'performance': {'train_time_seconds': 0.002565145492553711, 'total_time_seconds': 1.5342059135437012, 'inference_time_ms_per_sample': 0.42952962978157455}, 'confusion_matrix': [[68, 1, 1, 2, 5], [5, 43, 0, 10, 0], [11, 9, 35, 6, 1], [1, 6, 0, 67, 3], [15, 8, 2, 0, 35]], 'per_class_metrics': [{'label': 'business', 'precision': 0.68, 'recall': 0.8831168831168831, 'f1': 0.768361581920904, 'support': 77}, {'label': 'entertainment', 'precision': 0.6417910447761194, 'recall': 0.7413793103448276, 'f1': 0.688, 'support': 58}, {'label': 'politics', 'precision': 0.9210526315789473, 'recall': 0.5645161290322581, 'f1': 0.7, 'support': 62}, {'label': 'sport', 'precision': 0.788235294117647, 'recall': 0.8701298701298701, 'f1': 0.8271604938271605, 'support': 77}, {'label': 'tech', 'precision': 0.7954545454545454, 'recall': 0.5833333333333334, 'f1': 0.6730769230769231, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T13:59:33.096105', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.5570695400238037, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7365269461077845, 'precision': 0.7875542750976036, 'recall': 0.7365269461077845, 'f1_score': 0.7337345942676484}, 'performance': {'train_time_seconds': 0.002755403518676758, 'total_time_seconds': 1.5598249435424805, 'inference_time_ms_per_sample': 0.5938057414072002}, 'confusion_matrix': [[71, 1, 1, 2, 2], [12, 38, 0, 8, 0], [17, 7, 34, 4, 0], [4, 2, 0, 70, 1], [21, 5, 1, 0, 33]], 'per_class_metrics': [{'label': 'business', 'precision': 0.568, 'recall': 0.922077922077922, 'f1': 0.7029702970297029, 'support': 77}, {'label': 'entertainment', 'precision': 0.7169811320754716, 'recall': 0.6551724137931034, 'f1': 0.6846846846846847, 'support': 58}, {'label': 'politics', 'precision': 0.9444444444444444, 'recall': 0.5483870967741935, 'f1': 0.6938775510204082, 'support': 62}, {'label': 'sport', 'precision': 0.8333333333333334, 'recall': 0.9090909090909091, 'f1': 0.8695652173913043, 'support': 77}, {'label': 'tech', 'precision': 0.9166666666666666, 'recall': 0.55, 'f1': 0.6875, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T14:01:00.738143', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6106598377227783, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.979473277976272, 'recall': 0.9790419161676647, 'f1_score': 0.9790700186944252}, 'performance': {'train_time_seconds': 0.9348258972167969, 'total_time_seconds': 2.545485734939575, 'inference_time_ms_per_sample': 0.0032129401932219546}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T13:57:32.676190', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.4701271057128906, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7745991635492975, 'recall': 0.7694610778443114, 'f1_score': 0.7704612545590968}, 'performance': {'train_time_seconds': 0.5126514434814453, 'total_time_seconds': 0.9827785491943359, 'inference_time_ms_per_sample': 0.0027482381123982505}, 'confusion_matrix': [[56, 1, 11, 3, 6], [4, 42, 4, 7, 1], [9, 2, 45, 3, 3], [3, 3, 5, 65, 1], [7, 0, 3, 1, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7088607594936709, 'recall': 0.7272727272727273, 'f1': 0.717948717948718, 'support': 77}, {'label': 'entertainment', 'precision': 0.875, 'recall': 0.7241379310344828, 'f1': 0.7924528301886793, 'support': 58}, {'label': 'politics', 'precision': 0.6617647058823529, 'recall': 0.7258064516129032, 'f1': 0.6923076923076923, 'support': 62}, {'label': 'sport', 'precision': 0.8227848101265823, 'recall': 0.8441558441558441, 'f1': 0.8333333333333334, 'support': 77}, {'label': 'tech', 'precision': 0.8166666666666667, 'recall': 0.8166666666666667, 'f1': 0.8166666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T14:02:38.878807', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.6851983070373535, 'features_extracted': 10000, 'reduction_time': 0.2856872081756592, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7874251497005988, 'precision': 0.8050414215989689, 'recall': 0.7874251497005988, 'f1_score': 0.7906945506324907}, 'performance': {'train_time_seconds': 0.11870694160461426, 'total_time_seconds': 2.089592456817627, 'inference_time_ms_per_sample': 0.00288172396357188}, 'confusion_matrix': [[63, 1, 7, 2, 4], [7, 42, 3, 5, 1], [16, 1, 43, 1, 1], [7, 2, 0, 68, 0], [9, 2, 2, 0, 47]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6176470588235294, 'recall': 0.8181818181818182, 'f1': 0.7039106145251397, 'support': 77}, {'label': 'entertainment', 'precision': 0.875, 'recall': 0.7241379310344828, 'f1': 0.7924528301886793, 'support': 58}, {'label': 'politics', 'precision': 0.7818181818181819, 'recall': 0.6935483870967742, 'f1': 0.7350427350427351, 'support': 62}, {'label': 'sport', 'precision': 0.8947368421052632, 'recall': 0.8831168831168831, 'f1': 0.8888888888888888, 'support': 77}, {'label': 'tech', 'precision': 0.8867924528301887, 'recall': 0.7833333333333333, 'f1': 0.831858407079646, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T13:57:34.287355', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.4560232162475586, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7395209580838323, 'precision': 0.7783247856731887, 'recall': 0.7395209580838323, 'f1_score': 0.7330287924859743}, 'performance': {'train_time_seconds': 0.0022039413452148438, 'total_time_seconds': 0.45822715759277344, 'inference_time_ms_per_sample': 0.4175922827806301}, 'confusion_matrix': [[72, 0, 1, 2, 2], [19, 31, 1, 7, 0], [14, 4, 35, 9, 0], [2, 0, 2, 72, 1], [14, 4, 2, 3, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5950413223140496, 'recall': 0.935064935064935, 'f1': 0.7272727272727273, 'support': 77}, {'label': 'entertainment', 'precision': 0.7948717948717948, 'recall': 0.5344827586206896, 'f1': 0.6391752577319587, 'support': 58}, {'label': 'politics', 'precision': 0.8536585365853658, 'recall': 0.5645161290322581, 'f1': 0.6796116504854369, 'support': 62}, {'label': 'sport', 'precision': 0.7741935483870968, 'recall': 0.935064935064935, 'f1': 0.8470588235294118, 'support': 77}, {'label': 'tech', 'precision': 0.925, 'recall': 0.6166666666666667, 'f1': 0.74, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T13:59:29.092005', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5836107730865479, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7729690257820706, 'recall': 0.7694610778443114, 'f1_score': 0.7695580602879214}, 'performance': {'train_time_seconds': 0.6894137859344482, 'total_time_seconds': 2.273024559020996, 'inference_time_ms_per_sample': 0.002799633734240503}, 'confusion_matrix': [[56, 3, 11, 2, 5], [5, 39, 6, 7, 1], [8, 2, 46, 2, 4], [2, 4, 3, 67, 1], [6, 0, 4, 1, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7272727272727273, 'recall': 0.7272727272727273, 'f1': 0.7272727272727273, 'support': 77}, {'label': 'entertainment', 'precision': 0.8125, 'recall': 0.6724137931034483, 'f1': 0.7358490566037735, 'support': 58}, {'label': 'politics', 'precision': 0.6571428571428571, 'recall': 0.7419354838709677, 'f1': 0.696969696969697, 'support': 62}, {'label': 'sport', 'precision': 0.8481012658227848, 'recall': 0.8701298701298701, 'f1': 0.8589743589743589, 'support': 77}, {'label': 'tech', 'precision': 0.8166666666666667, 'recall': 0.8166666666666667, 'f1': 0.8166666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T14:02:32.557615', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6122016906738281, 'features_extracted': 10000, 'reduction_time': 0.2766249179840088, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9762177696346824, 'recall': 0.9760479041916168, 'f1_score': 0.9760627347119369}, 'performance': {'train_time_seconds': 0.13847112655639648, 'total_time_seconds': 2.0272977352142334, 'inference_time_ms_per_sample': 0.0028060581869707854}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 57, 1, 0, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9736842105263158, 'recall': 0.961038961038961, 'f1': 0.9673202614379085, 'support': 77}, {'label': 'entertainment', 'precision': 0.95, 'recall': 0.9827586206896551, 'f1': 0.9661016949152542, 'support': 58}, {'label': 'politics', 'precision': 0.967741935483871, 'recall': 0.967741935483871, 'f1': 0.967741935483871, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T14:01:16.568959', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.5750963687896729, 'features_extracted': 5000, 'reduction_time': 0.13562631607055664, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9821894672194074, 'recall': 0.9820359281437125, 'f1_score': 0.9820447945990619}, 'performance': {'train_time_seconds': 0.011970281600952148, 'total_time_seconds': 1.7226929664611816, 'inference_time_ms_per_sample': 0.0026725723357971555}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 57, 0, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T14:00:29.502716', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5128705501556396, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9940119760479041, 'precision': 0.9940503608168278, 'recall': 0.9940119760479041, 'f1_score': 0.9940086167076787}, 'performance': {'train_time_seconds': 1.125338077545166, 'total_time_seconds': 1.6382086277008057, 'inference_time_ms_per_sample': 0.0033635579183430016}, 'confusion_matrix': [[77, 0, 0, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9838709677419355, 'recall': 0.9838709677419355, 'f1': 0.9838709677419355, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T14:01:31.569061', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.5566833019256592, 'features_extracted': 5000, 'reduction_time': 0.1387033462524414, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8652694610778443, 'precision': 0.880353034049008, 'recall': 0.8652694610778443, 'f1_score': 0.8652916241278586}, 'performance': {'train_time_seconds': 0.011525630950927734, 'total_time_seconds': 1.7069122791290283, 'inference_time_ms_per_sample': 0.09658236703472937}, 'confusion_matrix': [[69, 3, 2, 3, 0], [0, 56, 1, 1, 0], [8, 0, 53, 1, 0], [0, 6, 1, 69, 1], [7, 11, 0, 0, 42]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8214285714285714, 'recall': 0.8961038961038961, 'f1': 0.8571428571428571, 'support': 77}, {'label': 'entertainment', 'precision': 0.7368421052631579, 'recall': 0.9655172413793104, 'f1': 0.835820895522388, 'support': 58}, {'label': 'politics', 'precision': 0.9298245614035088, 'recall': 0.8548387096774194, 'f1': 0.8907563025210085, 'support': 62}, {'label': 'sport', 'precision': 0.9324324324324325, 'recall': 0.8961038961038961, 'f1': 0.9139072847682119, 'support': 77}, {'label': 'tech', 'precision': 0.9767441860465116, 'recall': 0.7, 'f1': 0.8155339805825242, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T13:59:47.330898', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.6223230361938477, 'features_extracted': 10000, 'reduction_time': 0.27445101737976074, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.781437125748503, 'precision': 0.7969858907976859, 'recall': 0.781437125748503, 'f1_score': 0.7810521457546135}, 'performance': {'train_time_seconds': 0.09139204025268555, 'total_time_seconds': 1.988166093826294, 'inference_time_ms_per_sample': 0.003121570198835727}, 'confusion_matrix': [[63, 1, 4, 5, 4], [7, 39, 4, 7, 1], [16, 1, 40, 3, 2], [5, 1, 0, 71, 0], [7, 1, 2, 2, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6428571428571429, 'recall': 0.8181818181818182, 'f1': 0.72, 'support': 77}, {'label': 'entertainment', 'precision': 0.9069767441860465, 'recall': 0.6724137931034483, 'f1': 0.7722772277227723, 'support': 58}, {'label': 'politics', 'precision': 0.8, 'recall': 0.6451612903225806, 'f1': 0.7142857142857143, 'support': 62}, {'label': 'sport', 'precision': 0.8068181818181818, 'recall': 0.922077922077922, 'f1': 0.8606060606060606, 'support': 77}, {'label': 'tech', 'precision': 0.8727272727272727, 'recall': 0.8, 'f1': 0.8347826086956521, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T13:58:06.366572', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6114094257354736, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9341317365269461, 'precision': 0.9371524981226631, 'recall': 0.9341317365269461, 'f1_score': 0.9341038322810605}, 'performance': {'train_time_seconds': 0.21379709243774414, 'total_time_seconds': 1.8252065181732178, 'inference_time_ms_per_sample': 0.09965896606445312}, 'confusion_matrix': [[73, 0, 3, 0, 1], [3, 50, 1, 3, 1], [4, 0, 57, 1, 0], [0, 0, 0, 77, 0], [4, 0, 1, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8690476190476191, 'recall': 0.948051948051948, 'f1': 0.906832298136646, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.8620689655172413, 'f1': 0.9259259259259259, 'support': 58}, {'label': 'politics', 'precision': 0.9193548387096774, 'recall': 0.9193548387096774, 'f1': 0.9193548387096774, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T13:57:41.905715', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.47388291358947754, 'features_extracted': 10000, 'reduction_time': 0.2675790786743164, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7994011976047904, 'precision': 0.8019461495985645, 'recall': 0.7994011976047904, 'f1_score': 0.7987767407459456}, 'performance': {'train_time_seconds': 0.12224340438842773, 'total_time_seconds': 0.8637053966522217, 'inference_time_ms_per_sample': 0.0026818521008520066}, 'confusion_matrix': [[62, 2, 6, 3, 4], [5, 40, 6, 5, 2], [10, 2, 45, 3, 2], [2, 3, 2, 70, 0], [7, 1, 2, 0, 50]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7209302325581395, 'recall': 0.8051948051948052, 'f1': 0.7607361963190185, 'support': 77}, {'label': 'entertainment', 'precision': 0.8333333333333334, 'recall': 0.6896551724137931, 'f1': 0.7547169811320755, 'support': 58}, {'label': 'politics', 'precision': 0.7377049180327869, 'recall': 0.7258064516129032, 'f1': 0.7317073170731707, 'support': 62}, {'label': 'sport', 'precision': 0.8641975308641975, 'recall': 0.9090909090909091, 'f1': 0.8860759493670886, 'support': 77}, {'label': 'tech', 'precision': 0.8620689655172413, 'recall': 0.8333333333333334, 'f1': 0.847457627118644, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T13:57:20.754608', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.4871194362640381, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9495031171269279, 'recall': 0.9491017964071856, 'f1_score': 0.948947654663291}, 'performance': {'train_time_seconds': 7.067989110946655, 'total_time_seconds': 7.555108547210693, 'inference_time_ms_per_sample': 0.005130282419170448}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 55, 1, 2, 0], [2, 1, 57, 2, 0], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9344262295081968, 'recall': 0.9193548387096774, 'f1': 0.926829268292683, 'support': 62}, {'label': 'sport', 'precision': 0.9390243902439024, 'recall': 1.0, 'f1': 0.9685534591194969, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T13:57:38.990983', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5397601127624512, 'features_extracted': 10000, 'reduction_time': 0.26845383644104004, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9251497005988024, 'precision': 0.9299079178179919, 'recall': 0.9251497005988024, 'f1_score': 0.9256646908532175}, 'performance': {'train_time_seconds': 0.19397521018981934, 'total_time_seconds': 1.0021891593933105, 'inference_time_ms_per_sample': 0.0982141780282209}, 'confusion_matrix': [[72, 0, 2, 1, 2], [4, 50, 0, 4, 0], [5, 0, 57, 0, 0], [1, 0, 0, 76, 0], [5, 1, 0, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8275862068965517, 'recall': 0.935064935064935, 'f1': 0.8780487804878049, 'support': 77}, {'label': 'entertainment', 'precision': 0.9803921568627451, 'recall': 0.8620689655172413, 'f1': 0.9174311926605505, 'support': 58}, {'label': 'politics', 'precision': 0.9661016949152542, 'recall': 0.9193548387096774, 'f1': 0.9421487603305785, 'support': 62}, {'label': 'sport', 'precision': 0.9382716049382716, 'recall': 0.987012987012987, 'f1': 0.9620253164556962, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_random_forest_n100_m10', 'timestamp': '2025-10-21T14:01:22.104730', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6394598484039307, 'features_extracted': 5000, 'reduction_time': 0.13713622093200684, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.937125748502994, 'precision': 0.9439602936983178, 'recall': 0.937125748502994, 'f1_score': 0.9380506844767021}, 'performance': {'train_time_seconds': 0.20057225227355957, 'total_time_seconds': 1.977168321609497, 'inference_time_ms_per_sample': 0.09755674236548875}, 'confusion_matrix': [[75, 0, 0, 1, 1], [2, 52, 0, 4, 0], [6, 0, 56, 0, 0], [2, 0, 0, 75, 0], [5, 0, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8333333333333334, 'recall': 0.974025974025974, 'f1': 0.8982035928143712, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.896551724137931, 'f1': 0.9454545454545454, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.9032258064516129, 'f1': 0.9491525423728814, 'support': 62}, {'label': 'sport', 'precision': 0.9375, 'recall': 0.974025974025974, 'f1': 0.9554140127388535, 'support': 77}, {'label': 'tech', 'precision': 0.9821428571428571, 'recall': 0.9166666666666666, 'f1': 0.9482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T14:00:45.451334', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.5295569896697998, 'features_extracted': 10000, 'reduction_time': 0.2849910259246826, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8203592814371258, 'precision': 0.86029638003695, 'recall': 0.8203592814371258, 'f1_score': 0.8231476811411306}, 'performance': {'train_time_seconds': 0.009245634078979492, 'total_time_seconds': 0.8237936496734619, 'inference_time_ms_per_sample': 0.13469578977116567}, 'confusion_matrix': [[71, 4, 1, 1, 0], [3, 54, 1, 0, 0], [9, 10, 43, 0, 0], [1, 8, 0, 67, 1], [8, 12, 1, 0, 39]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7717391304347826, 'recall': 0.922077922077922, 'f1': 0.8402366863905325, 'support': 77}, {'label': 'entertainment', 'precision': 0.6136363636363636, 'recall': 0.9310344827586207, 'f1': 0.7397260273972602, 'support': 58}, {'label': 'politics', 'precision': 0.9347826086956522, 'recall': 0.6935483870967742, 'f1': 0.7962962962962963, 'support': 62}, {'label': 'sport', 'precision': 0.9852941176470589, 'recall': 0.8701298701298701, 'f1': 0.9241379310344827, 'support': 77}, {'label': 'tech', 'precision': 0.975, 'recall': 0.65, 'f1': 0.78, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_decision_tree_m20_r42', 'timestamp': '2025-10-21T13:58:31.500980', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5423133373260498, 'features_extracted': 5000, 'reduction_time': 0.1321406364440918, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7904191616766467, 'precision': 0.7943552324279511, 'recall': 0.7904191616766467, 'f1_score': 0.7911972562416145}, 'performance': {'train_time_seconds': 0.12453055381774902, 'total_time_seconds': 1.7989845275878906, 'inference_time_ms_per_sample': 0.0029859428634186704}, 'confusion_matrix': [[56, 1, 10, 4, 6], [6, 44, 3, 4, 1], [9, 2, 47, 2, 2], [3, 2, 4, 68, 0], [4, 1, 4, 2, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.717948717948718, 'recall': 0.7272727272727273, 'f1': 0.7225806451612903, 'support': 77}, {'label': 'entertainment', 'precision': 0.88, 'recall': 0.7586206896551724, 'f1': 0.8148148148148148, 'support': 58}, {'label': 'politics', 'precision': 0.6911764705882353, 'recall': 0.7580645161290323, 'f1': 0.7230769230769231, 'support': 62}, {'label': 'sport', 'precision': 0.85, 'recall': 0.8831168831168831, 'f1': 0.8662420382165605, 'support': 77}, {'label': 'tech', 'precision': 0.8448275862068966, 'recall': 0.8166666666666667, 'f1': 0.8305084745762712, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T14:01:03.298312', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6537272930145264, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9401197604790419, 'precision': 0.9422012005617301, 'recall': 0.9401197604790419, 'f1_score': 0.9399993915566738}, 'performance': {'train_time_seconds': 0.20981073379516602, 'total_time_seconds': 1.8635380268096924, 'inference_time_ms_per_sample': 0.09555374076980316}, 'confusion_matrix': [[73, 0, 1, 1, 2], [2, 51, 1, 4, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [4, 1, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8902439024390244, 'recall': 0.948051948051948, 'f1': 0.9182389937106918, 'support': 77}, {'label': 'entertainment', 'precision': 0.9807692307692307, 'recall': 0.8793103448275862, 'f1': 0.9272727272727272, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1': 0.9508196721311475, 'support': 62}, {'label': 'sport', 'precision': 0.927710843373494, 'recall': 1.0, 'f1': 0.9625, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T13:58:23.425972', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.7285830974578857, 'features_extracted': 5000, 'reduction_time': 0.13496971130371094, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.958013936715038, 'recall': 0.9580838323353293, 'f1_score': 0.9579418002709207}, 'performance': {'train_time_seconds': 0.3886253833770752, 'total_time_seconds': 2.252178192138672, 'inference_time_ms_per_sample': 0.005978310179567623}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 0, 1], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T13:57:36.273386', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.46748805046081543, 'features_extracted': 10000, 'reduction_time': 0.26790285110473633, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9493412900010231, 'recall': 0.9491017964071856, 'f1_score': 0.9487291399363083}, 'performance': {'train_time_seconds': 0.8512661457061768, 'total_time_seconds': 1.5866570472717285, 'inference_time_ms_per_sample': 0.014951842987608767}, 'confusion_matrix': [[71, 1, 2, 1, 2], [1, 54, 1, 2, 0], [0, 0, 61, 1, 0], [0, 0, 0, 77, 0], [3, 2, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9473684210526315, 'recall': 0.9310344827586207, 'f1': 0.9391304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T14:01:13.062306', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.6505515575408936, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9311377245508982, 'precision': 0.9326356646120681, 'recall': 0.9311377245508982, 'f1_score': 0.9309968551205984}, 'performance': {'train_time_seconds': 0.0027649402618408203, 'total_time_seconds': 1.6533164978027344, 'inference_time_ms_per_sample': 0.2802089302839633}, 'confusion_matrix': [[68, 1, 6, 1, 1], [1, 51, 2, 1, 3], [0, 2, 59, 0, 1], [1, 0, 0, 75, 1], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9577464788732394, 'recall': 0.8831168831168831, 'f1': 0.918918918918919, 'support': 77}, {'label': 'entertainment', 'precision': 0.9272727272727272, 'recall': 0.8793103448275862, 'f1': 0.9026548672566371, 'support': 58}, {'label': 'politics', 'precision': 0.8805970149253731, 'recall': 0.9516129032258065, 'f1': 0.9147286821705426, 'support': 62}, {'label': 'sport', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'tech', 'precision': 0.90625, 'recall': 0.9666666666666667, 'f1': 0.9354838709677419, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T13:57:43.663481', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.48328304290771484, 'features_extracted': 10000, 'reduction_time': 0.26644229888916016, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7275449101796407, 'precision': 0.7589080281765495, 'recall': 0.7275449101796407, 'f1_score': 0.7218227029583627}, 'performance': {'train_time_seconds': 0.007210969924926758, 'total_time_seconds': 0.7569363117218018, 'inference_time_ms_per_sample': 0.3173229937068003}, 'confusion_matrix': [[70, 1, 4, 1, 1], [9, 43, 1, 5, 0], [12, 6, 41, 2, 1], [3, 7, 2, 63, 2], [24, 2, 6, 2, 26]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5932203389830508, 'recall': 0.9090909090909091, 'f1': 0.717948717948718, 'support': 77}, {'label': 'entertainment', 'precision': 0.7288135593220338, 'recall': 0.7413793103448276, 'f1': 0.7350427350427351, 'support': 58}, {'label': 'politics', 'precision': 0.7592592592592593, 'recall': 0.6612903225806451, 'f1': 0.7068965517241379, 'support': 62}, {'label': 'sport', 'precision': 0.863013698630137, 'recall': 0.8181818181818182, 'f1': 0.84, 'support': 77}, {'label': 'tech', 'precision': 0.8666666666666667, 'recall': 0.43333333333333335, 'f1': 0.5777777777777777, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T14:01:33.320933', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.5841717720031738, 'features_extracted': 5000, 'reduction_time': 0.13810038566589355, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8622754491017964, 'precision': 0.8805816914774443, 'recall': 0.8622754491017964, 'f1_score': 0.8594374295805852}, 'performance': {'train_time_seconds': 0.011510610580444336, 'total_time_seconds': 1.7337827682495117, 'inference_time_ms_per_sample': 0.09737828534520314}, 'confusion_matrix': [[73, 1, 1, 2, 0], [5, 51, 1, 1, 0], [2, 4, 55, 1, 0], [1, 2, 1, 73, 0], [14, 9, 1, 0, 36]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7684210526315789, 'recall': 0.948051948051948, 'f1': 0.8488372093023255, 'support': 77}, {'label': 'entertainment', 'precision': 0.7611940298507462, 'recall': 0.8793103448275862, 'f1': 0.816, 'support': 58}, {'label': 'politics', 'precision': 0.9322033898305084, 'recall': 0.8870967741935484, 'f1': 0.9090909090909091, 'support': 62}, {'label': 'sport', 'precision': 0.948051948051948, 'recall': 0.948051948051948, 'f1': 0.948051948051948, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.6, 'f1': 0.75, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T13:59:31.373941', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5636990070343018, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7215568862275449, 'precision': 0.768309414912812, 'recall': 0.7215568862275449, 'f1_score': 0.7193173840666243}, 'performance': {'train_time_seconds': 0.0030362606048583984, 'total_time_seconds': 1.5667352676391602, 'inference_time_ms_per_sample': 0.43837181822268545}, 'confusion_matrix': [[70, 1, 1, 2, 3], [15, 36, 0, 7, 0], [17, 7, 33, 4, 1], [5, 2, 0, 68, 2], [18, 7, 1, 0, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.56, 'recall': 0.9090909090909091, 'f1': 0.693069306930693, 'support': 77}, {'label': 'entertainment', 'precision': 0.6792452830188679, 'recall': 0.6206896551724138, 'f1': 0.6486486486486487, 'support': 58}, {'label': 'politics', 'precision': 0.9428571428571428, 'recall': 0.532258064516129, 'f1': 0.6804123711340206, 'support': 62}, {'label': 'sport', 'precision': 0.8395061728395061, 'recall': 0.8831168831168831, 'f1': 0.8607594936708861, 'support': 77}, {'label': 'tech', 'precision': 0.85, 'recall': 0.5666666666666667, 'f1': 0.68, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_decision_tree_m20_r42', 'timestamp': '2025-10-21T14:02:21.177216', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5447990894317627, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7664670658682635, 'precision': 0.7739536720297405, 'recall': 0.7664670658682635, 'f1_score': 0.7679429330166164}, 'performance': {'train_time_seconds': 0.940361738204956, 'total_time_seconds': 2.4851608276367188, 'inference_time_ms_per_sample': 0.0029880843476620977}, 'confusion_matrix': [[53, 4, 8, 4, 8], [6, 41, 6, 5, 0], [10, 0, 49, 1, 2], [4, 2, 4, 65, 2], [8, 0, 4, 0, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.654320987654321, 'recall': 0.6883116883116883, 'f1': 0.6708860759493671, 'support': 77}, {'label': 'entertainment', 'precision': 0.8723404255319149, 'recall': 0.7068965517241379, 'f1': 0.780952380952381, 'support': 58}, {'label': 'politics', 'precision': 0.6901408450704225, 'recall': 0.7903225806451613, 'f1': 0.7368421052631579, 'support': 62}, {'label': 'sport', 'precision': 0.8666666666666667, 'recall': 0.8441558441558441, 'f1': 0.8552631578947368, 'support': 77}, {'label': 'tech', 'precision': 0.8, 'recall': 0.8, 'f1': 0.8, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T14:00:46.330882', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 0.5090997219085693, 'features_extracted': 10000, 'reduction_time': 0.28244566917419434, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.811377245508982, 'precision': 0.8590968708981279, 'recall': 0.811377245508982, 'f1_score': 0.8103465074803756}, 'performance': {'train_time_seconds': 0.009142398834228516, 'total_time_seconds': 0.8006877899169922, 'inference_time_ms_per_sample': 0.10858324473489545}, 'confusion_matrix': [[75, 0, 1, 1, 0], [12, 46, 0, 0, 0], [11, 3, 48, 0, 0], [2, 2, 0, 72, 1], [21, 9, 0, 0, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6198347107438017, 'recall': 0.974025974025974, 'f1': 0.7575757575757576, 'support': 77}, {'label': 'entertainment', 'precision': 0.7666666666666667, 'recall': 0.7931034482758621, 'f1': 0.7796610169491526, 'support': 58}, {'label': 'politics', 'precision': 0.9795918367346939, 'recall': 0.7741935483870968, 'f1': 0.8648648648648649, 'support': 62}, {'label': 'sport', 'precision': 0.9863013698630136, 'recall': 0.935064935064935, 'f1': 0.96, 'support': 77}, {'label': 'tech', 'precision': 0.967741935483871, 'recall': 0.5, 'f1': 0.6593406593406593, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_decision_tree_m10_r42', 'timestamp': '2025-10-21T13:58:29.689393', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.583381175994873, 'features_extracted': 5000, 'reduction_time': 0.13182783126831055, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7844917847409094, 'recall': 0.7694610778443114, 'f1_score': 0.7695426464863667}, 'performance': {'train_time_seconds': 0.08694696426391602, 'total_time_seconds': 1.8021559715270996, 'inference_time_ms_per_sample': 0.00249554297167384}, 'confusion_matrix': [[61, 1, 6, 5, 4], [7, 39, 4, 7, 1], [16, 1, 40, 3, 2], [5, 1, 0, 71, 0], [8, 1, 3, 2, 46]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6288659793814433, 'recall': 0.7922077922077922, 'f1': 0.7011494252873564, 'support': 77}, {'label': 'entertainment', 'precision': 0.9069767441860465, 'recall': 0.6724137931034483, 'f1': 0.7722772277227723, 'support': 58}, {'label': 'politics', 'precision': 0.7547169811320755, 'recall': 0.6451612903225806, 'f1': 0.6956521739130435, 'support': 62}, {'label': 'sport', 'precision': 0.8068181818181818, 'recall': 0.922077922077922, 'f1': 0.8606060606060606, 'support': 77}, {'label': 'tech', 'precision': 0.8679245283018868, 'recall': 0.7666666666666667, 'f1': 0.8141592920353983, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T14:01:18.305426', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6162364482879639, 'features_extracted': 5000, 'reduction_time': 0.14240264892578125, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9792462012090553, 'recall': 0.9790419161676647, 'f1_score': 0.979051427745181}, 'performance': {'train_time_seconds': 0.09617304801940918, 'total_time_seconds': 1.8548121452331543, 'inference_time_ms_per_sample': 0.003004502393528373}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 57, 0, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'entertainment', 'precision': 0.9661016949152542, 'recall': 0.9827586206896551, 'f1': 0.9743589743589743, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_knn_n3_n-1', 'timestamp': '2025-10-21T13:58:33.309622', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5486536026000977, 'features_extracted': 5000, 'reduction_time': 0.1367788314819336, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.6976047904191617, 'precision': 0.7264321117560886, 'recall': 0.6976047904191617, 'f1_score': 0.6936704706528525}, 'performance': {'train_time_seconds': 0.009987831115722656, 'total_time_seconds': 1.695420265197754, 'inference_time_ms_per_sample': 0.28721229758805145}, 'confusion_matrix': [[65, 4, 1, 3, 4], [10, 40, 2, 5, 1], [14, 8, 37, 3, 0], [5, 6, 1, 64, 1], [20, 5, 6, 2, 27]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5701754385964912, 'recall': 0.8441558441558441, 'f1': 0.680628272251309, 'support': 77}, {'label': 'entertainment', 'precision': 0.6349206349206349, 'recall': 0.6896551724137931, 'f1': 0.6611570247933884, 'support': 58}, {'label': 'politics', 'precision': 0.7872340425531915, 'recall': 0.5967741935483871, 'f1': 0.6788990825688074, 'support': 62}, {'label': 'sport', 'precision': 0.8311688311688312, 'recall': 0.8311688311688312, 'f1': 0.8311688311688312, 'support': 77}, {'label': 'tech', 'precision': 0.8181818181818182, 'recall': 0.45, 'f1': 0.5806451612903226, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_logistic_C1.0_m1000', 'timestamp': '2025-10-21T13:58:20.978769', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6716804504394531, 'features_extracted': 5000, 'reduction_time': 0.1387486457824707, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582480715261207, 'recall': 0.9580838323353293, 'f1_score': 0.9579495451843525}, 'performance': {'train_time_seconds': 0.6198067665100098, 'total_time_seconds': 2.4302358627319336, 'inference_time_ms_per_sample': 0.0060518344719252895}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_random_forest_n100_m20', 'timestamp': '2025-10-21T13:59:45.249766', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.573720932006836, 'features_extracted': 10000, 'reduction_time': 0.266876220703125, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9558182576645651, 'recall': 0.9550898203592815, 'f1_score': 0.9552165096745926}, 'performance': {'train_time_seconds': 0.19321179389953613, 'total_time_seconds': 2.033808946609497, 'inference_time_ms_per_sample': 0.09863462276801377}, 'confusion_matrix': [[74, 0, 1, 0, 2], [1, 55, 1, 1, 0], [3, 0, 58, 0, 1], [0, 0, 0, 76, 1], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9135802469135802, 'recall': 0.961038961038961, 'f1': 0.9367088607594937, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1': 0.9508196721311475, 'support': 62}, {'label': 'sport', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'tech', 'precision': 0.9333333333333333, 'recall': 0.9333333333333333, 'f1': 0.9333333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T13:57:55.107472', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.5961380004882812, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9769557169444895, 'recall': 0.9760479041916168, 'f1_score': 0.9760681744843009}, 'performance': {'train_time_seconds': 0.15318083763122559, 'total_time_seconds': 1.7493188381195068, 'inference_time_ms_per_sample': 0.010080680161893011}, 'confusion_matrix': [[73, 0, 2, 0, 2], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9375, 'recall': 1.0, 'f1': 0.967741935483871, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_random_forest_n100_m10', 'timestamp': '2025-10-21T13:57:30.221379', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5519001483917236, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9251497005988024, 'precision': 0.9293627536327895, 'recall': 0.9251497005988024, 'f1_score': 0.9250167884898424}, 'performance': {'train_time_seconds': 0.27045392990112305, 'total_time_seconds': 0.8223540782928467, 'inference_time_ms_per_sample': 0.09850613371340813}, 'confusion_matrix': [[73, 1, 1, 1, 1], [3, 51, 1, 2, 1], [6, 0, 53, 3, 0], [0, 0, 0, 77, 0], [3, 0, 0, 2, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8588235294117647, 'recall': 0.948051948051948, 'f1': 0.9012345679012346, 'support': 77}, {'label': 'entertainment', 'precision': 0.9807692307692307, 'recall': 0.8793103448275862, 'f1': 0.9272727272727272, 'support': 58}, {'label': 'politics', 'precision': 0.9636363636363636, 'recall': 0.8548387096774194, 'f1': 0.905982905982906, 'support': 62}, {'label': 'sport', 'precision': 0.9058823529411765, 'recall': 1.0, 'f1': 0.9506172839506173, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T14:00:39.829142', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.534658670425415, 'features_extracted': 10000, 'reduction_time': 0.27662181854248047, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9793289561684974, 'recall': 0.9790419161676647, 'f1_score': 0.979066244391906}, 'performance': {'train_time_seconds': 0.12584519386291504, 'total_time_seconds': 0.9371256828308105, 'inference_time_ms_per_sample': 0.0028196209205124906}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 57, 0, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'entertainment', 'precision': 0.95, 'recall': 0.9827586206896551, 'f1': 0.9661016949152542, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_logistic_C10.0_m1000', 'timestamp': '2025-10-21T13:58:02.931219', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6283299922943115, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9580796457931595, 'recall': 0.9580838323353293, 'f1_score': 0.9579491689762678}, 'performance': {'train_time_seconds': 1.7646753787994385, 'total_time_seconds': 3.39300537109375, 'inference_time_ms_per_sample': 0.0034199503367532513}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [1, 1, 58, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.96, 'recall': 0.935064935064935, 'f1': 0.9473684210526315, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_decision_tree_m10_r42', 'timestamp': '2025-10-21T13:58:10.080560', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 10, 'random_state': 42}}, 'extraction_time': 1.596785068511963, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7365269461077845, 'precision': 0.7515204492222062, 'recall': 0.7365269461077845, 'f1_score': 0.7367861639305352}, 'performance': {'train_time_seconds': 0.32025980949401855, 'total_time_seconds': 1.9170448780059814, 'inference_time_ms_per_sample': 0.0024148803985047486}, 'confusion_matrix': [[58, 1, 8, 5, 5], [9, 37, 2, 8, 2], [18, 0, 38, 3, 3], [5, 4, 0, 67, 1], [8, 1, 2, 3, 46]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5918367346938775, 'recall': 0.7532467532467533, 'f1': 0.6628571428571428, 'support': 77}, {'label': 'entertainment', 'precision': 0.8604651162790697, 'recall': 0.6379310344827587, 'f1': 0.7326732673267327, 'support': 58}, {'label': 'politics', 'precision': 0.76, 'recall': 0.6129032258064516, 'f1': 0.6785714285714286, 'support': 62}, {'label': 'sport', 'precision': 0.7790697674418605, 'recall': 0.8701298701298701, 'f1': 0.8220858895705522, 'support': 77}, {'label': 'tech', 'precision': 0.8070175438596491, 'recall': 0.7666666666666667, 'f1': 0.7863247863247863, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_chi2_k1000_logistic_C10.0_m1000', 'timestamp': '2025-10-21T13:57:37.879011', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 10.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5232057571411133, 'features_extracted': 10000, 'reduction_time': 0.2717301845550537, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9520080445883203, 'recall': 0.9520958083832335, 'f1_score': 0.9517685674906047}, 'performance': {'train_time_seconds': 0.30063819885253906, 'total_time_seconds': 1.095574140548706, 'inference_time_ms_per_sample': 0.006160336340258935}, 'confusion_matrix': [[71, 1, 2, 1, 2], [1, 55, 1, 1, 0], [0, 0, 61, 0, 1], [0, 0, 0, 77, 0], [3, 2, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9473684210526315, 'recall': 0.9, 'f1': 0.9230769230769231, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_random_forest_n100_m20', 'timestamp': '2025-10-21T14:02:17.034947', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'max_depth': 20, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6036922931671143, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9559555960077702, 'recall': 0.9550898203592815, 'f1_score': 0.9550924155573088}, 'performance': {'train_time_seconds': 0.2294778823852539, 'total_time_seconds': 1.8331701755523682, 'inference_time_ms_per_sample': 0.10006085127413629}, 'confusion_matrix': [[74, 0, 2, 0, 1], [1, 55, 1, 1, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [3, 1, 1, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9135802469135802, 'recall': 0.961038961038961, 'f1': 0.9367088607594937, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9821428571428571, 'recall': 0.9166666666666666, 'f1': 0.9482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_naive_bayes_a1.0', 'timestamp': '2025-10-21T14:02:28.640079', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 1.5619864463806152, 'features_extracted': 10000, 'reduction_time': 0.2743234634399414, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.982252624063731, 'recall': 0.9820359281437125, 'f1_score': 0.9820333169176416}, 'performance': {'train_time_seconds': 0.009948015213012695, 'total_time_seconds': 1.8462579250335693, 'inference_time_ms_per_sample': 0.0030780266858860404}, 'confusion_matrix': [[76, 0, 0, 0, 1], [0, 56, 1, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9836065573770492, 'recall': 0.967741935483871, 'f1': 0.975609756097561, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_knn_n3_n-1', 'timestamp': '2025-10-21T14:01:11.361307', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 3, 'n_jobs': -1}}, 'extraction_time': 1.5481374263763428, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9191616766467066, 'precision': 0.9210600036765447, 'recall': 0.9191616766467066, 'f1_score': 0.9191317895095776}, 'performance': {'train_time_seconds': 0.0026519298553466797, 'total_time_seconds': 1.5507893562316895, 'inference_time_ms_per_sample': 0.4234007018768859}, 'confusion_matrix': [[68, 1, 6, 1, 1], [0, 51, 2, 2, 3], [1, 2, 55, 0, 4], [1, 0, 0, 75, 1], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9577464788732394, 'recall': 0.8831168831168831, 'f1': 0.918918918918919, 'support': 77}, {'label': 'entertainment', 'precision': 0.9272727272727272, 'recall': 0.8793103448275862, 'f1': 0.9026548672566371, 'support': 58}, {'label': 'politics', 'precision': 0.873015873015873, 'recall': 0.8870967741935484, 'f1': 0.88, 'support': 62}, {'label': 'sport', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'tech', 'precision': 0.8656716417910447, 'recall': 0.9666666666666667, 'f1': 0.9133858267716536, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T13:59:12.181322', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.5658226013183594, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582648903644616, 'recall': 0.9580838323353293, 'f1_score': 0.9580291037037023}, 'performance': {'train_time_seconds': 4.986042022705078, 'total_time_seconds': 6.5518646240234375, 'inference_time_ms_per_sample': 0.004675573931482738}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.935064935064935, 'recall': 0.935064935064935, 'f1': 0.935064935064935, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_knn_n5_n-1', 'timestamp': '2025-10-21T13:59:53.481221', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 1.5974071025848389, 'features_extracted': 10000, 'reduction_time': 0.27058935165405273, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7245508982035929, 'precision': 0.7470708885311422, 'recall': 0.7245508982035929, 'f1_score': 0.7204221638466283}, 'performance': {'train_time_seconds': 0.007412910461425781, 'total_time_seconds': 1.8754093647003174, 'inference_time_ms_per_sample': 0.2937987892927524}, 'confusion_matrix': [[66, 3, 4, 2, 2], [5, 44, 1, 8, 0], [13, 7, 38, 2, 2], [4, 8, 1, 64, 0], [18, 3, 7, 2, 30]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6226415094339622, 'recall': 0.8571428571428571, 'f1': 0.7213114754098361, 'support': 77}, {'label': 'entertainment', 'precision': 0.676923076923077, 'recall': 0.7586206896551724, 'f1': 0.7154471544715447, 'support': 58}, {'label': 'politics', 'precision': 0.7450980392156863, 'recall': 0.6129032258064516, 'f1': 0.672566371681416, 'support': 62}, {'label': 'sport', 'precision': 0.8205128205128205, 'recall': 0.8311688311688312, 'f1': 0.8258064516129032, 'support': 77}, {'label': 'tech', 'precision': 0.8823529411764706, 'recall': 0.5, 'f1': 0.6382978723404256, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_none_default_logistic_C1.0_m1000', 'timestamp': '2025-10-21T14:02:08.359466', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6427936553955078, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9910179640718563, 'precision': 0.9911130120710959, 'recall': 0.9910179640718563, 'f1_score': 0.9910408747721947}, 'performance': {'train_time_seconds': 1.76491117477417, 'total_time_seconds': 3.4077048301696777, 'inference_time_ms_per_sample': 0.003948183116798629}, 'confusion_matrix': [[76, 0, 1, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n12_chi2_k1000_knn_n10_n-1', 'timestamp': '2025-10-21T14:02:47.006291', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.6179664134979248, 'features_extracted': 10000, 'reduction_time': 0.2791481018066406, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8532934131736527, 'precision': 0.8806587527623716, 'recall': 0.8532934131736527, 'f1_score': 0.8514239512647979}, 'performance': {'train_time_seconds': 0.008962392807006836, 'total_time_seconds': 1.9060769081115723, 'inference_time_ms_per_sample': 0.09852826238392356}, 'confusion_matrix': [[74, 0, 2, 1, 0], [10, 42, 3, 3, 0], [3, 0, 59, 0, 0], [3, 0, 1, 73, 0], [18, 4, 1, 0, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6851851851851852, 'recall': 0.961038961038961, 'f1': 0.8, 'support': 77}, {'label': 'entertainment', 'precision': 0.9130434782608695, 'recall': 0.7241379310344828, 'f1': 0.8076923076923077, 'support': 58}, {'label': 'politics', 'precision': 0.8939393939393939, 'recall': 0.9516129032258065, 'f1': 0.921875, 'support': 62}, {'label': 'sport', 'precision': 0.948051948051948, 'recall': 0.948051948051948, 'f1': 0.948051948051948, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.6166666666666667, 'f1': 0.7628865979381443, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m10000_n11_none_default_knn_n5_n-1', 'timestamp': '2025-10-21T14:00:37.034826', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 5, 'n_jobs': -1}}, 'extraction_time': 0.4751858711242676, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9221556886227545, 'precision': 0.9247728937908873, 'recall': 0.9221556886227545, 'f1_score': 0.9220026137557732}, 'performance': {'train_time_seconds': 0.002213716506958008, 'total_time_seconds': 0.4773995876312256, 'inference_time_ms_per_sample': 0.2841107145754877}, 'confusion_matrix': [[68, 1, 6, 1, 1], [1, 49, 2, 2, 4], [0, 0, 60, 0, 2], [1, 0, 0, 75, 1], [0, 3, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9714285714285714, 'recall': 0.8831168831168831, 'f1': 0.9251700680272109, 'support': 77}, {'label': 'entertainment', 'precision': 0.9245283018867925, 'recall': 0.8448275862068966, 'f1': 0.8828828828828829, 'support': 58}, {'label': 'politics', 'precision': 0.8695652173913043, 'recall': 0.967741935483871, 'f1': 0.916030534351145, 'support': 62}, {'label': 'sport', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'tech', 'precision': 0.875, 'recall': 0.9333333333333333, 'f1': 0.9032258064516129, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n12_none_default_knn_n10_n-1', 'timestamp': '2025-10-21T14:01:14.818336', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'knn', 'name': 'K-Nearest Neighbors', 'config': {'n_neighbors': 10, 'n_jobs': -1}}, 'extraction_time': 1.639854907989502, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9431137724550899, 'precision': 0.9434680043226686, 'recall': 0.9431137724550899, 'f1_score': 0.9429924445213278}, 'performance': {'train_time_seconds': 0.002937793731689453, 'total_time_seconds': 1.6427927017211914, 'inference_time_ms_per_sample': 0.2965848602934512}, 'confusion_matrix': [[70, 1, 5, 1, 0], [1, 53, 1, 1, 2], [1, 1, 59, 0, 1], [1, 0, 0, 76, 0], [0, 2, 0, 1, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.958904109589041, 'recall': 0.9090909090909091, 'f1': 0.9333333333333333, 'support': 77}, {'label': 'entertainment', 'precision': 0.9298245614035088, 'recall': 0.9137931034482759, 'f1': 0.9217391304347826, 'support': 58}, {'label': 'politics', 'precision': 0.9076923076923077, 'recall': 0.9516129032258065, 'f1': 0.9291338582677166, 'support': 62}, {'label': 'sport', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'tech', 'precision': 0.95, 'recall': 0.95, 'f1': 0.95, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n11_none_default_naive_bayes_a1.0', 'timestamp': '2025-10-21T13:57:19.941140', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {'alpha': 1.0}}, 'extraction_time': 0.48388123512268066, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9764315665903217, 'recall': 0.9760479041916168, 'f1_score': 0.9760572736773053}, 'performance': {'train_time_seconds': 0.3092026710510254, 'total_time_seconds': 0.793083906173706, 'inference_time_ms_per_sample': 0.03441436561995637}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9866666666666667, 'recall': 0.961038961038961, 'f1': 0.9736842105263158, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9516129032258065, 'recall': 0.9833333333333333, 'f1': 0.9672131147540983, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}]};
    </script>
    
    <!-- Walkthrough JS -->
    <script src="assets/js/walkthrough.js"></script>
    
    <!-- Main script -->
    <script>

// ===== PIPELINE CALCULATION TOGGLE =====
function toggleCalculation() {
    const details = document.getElementById('calculation-details');
    const btn = event.target;
    
    if (details.style.display === 'none') {
        details.style.display = 'block';
        btn.textContent = '‚ùå Close explanation';
    } else {
        details.style.display = 'none';
        btn.textContent = 'üìä How are 180 pipelines calculated?';
    }
}

// ===== VIEW MODE SWITCHING =====
let currentMode = 'hero';

function switchMode(mode) {
    currentMode = mode;
    
    // Update button states
    document.getElementById('btn-hero-mode').classList.toggle('active', mode === 'hero');
    document.getElementById('btn-custom-mode').classList.toggle('active', mode === 'custom');
    
    // Toggle sections
    document.getElementById('hero-mode-section').style.display = mode === 'hero' ? 'block' : 'none';
    document.getElementById('custom-mode-section').style.display = mode === 'custom' ? 'block' : 'none';
    
    // Initialize mode-specific content
    if (mode === 'hero') {
        initializeHeroMode();
    }
}

// ===== OVERVIEW TABS SWITCHING =====
function switchOverviewTab(tab) {
    // Update tab buttons
    const tabBtns = document.querySelectorAll('.overview-tab-btn');
    tabBtns.forEach(btn => btn.classList.remove('active'));
    event.target.classList.add('active');
    
    // Update tab contents
    ['pipeline', 'tutorials', 'code', 'colab'].forEach(t => {
        const content = document.getElementById(`overview-${t}-tab`);
        if (content) {
            content.classList.toggle('active', t === tab);
        }
    });
    
    // Load code dynamically when Code tab is activated
    if (tab === 'code') {
        loadPipelineCode();
    }
}

function loadPipelineCode() {
    const codeBlock = document.getElementById('pipeline-python-code');
    const loadingDiv = document.querySelector('#pipeline-code-block .code-loading');
    const pre = document.querySelector('#pipeline-code-block pre');
    
    if (codeBlock && codeBlock.textContent.trim() === '') {
        fetch('code/bbc_pipeline_comparison.py')
            .then(response => response.text())
            .then(code => {
                codeBlock.textContent = code;
                loadingDiv.style.display = 'none';
                pre.style.display = 'block';
                if (window.Prism) {
                    Prism.highlightElement(codeBlock);
                }
            })
            .catch(error => {
                loadingDiv.textContent = '‚ùå Failed to load code';
                console.error('Error loading code:', error);
            });
    }
}

function copyPipelineCode() {
    const codeBlock = document.getElementById('pipeline-python-code');
    if (codeBlock) {
        navigator.clipboard.writeText(codeBlock.textContent)
            .then(() => {
                alert('‚úÖ Code copied to clipboard!');
            })
            .catch(err => {
                console.error('Failed to copy:', err);
            });
    }
}

// ===== HERO MODE: TOP 9 PERFORMERS =====
let top9Pipelines = [];

function initializeHeroMode() {
    if (!allPipelinesData || !allPipelinesData.all_results) return;
    
    const pipelines = allPipelinesData.all_results;
    
    // Top 3 by Accuracy
    const topAccuracy = [...pipelines]
        .sort((a, b) => b.metrics.accuracy - a.metrics.accuracy)
        .slice(0, 3);
    
    // Top 3 by Training Speed (fastest = lowest time)
    const topTrainSpeed = [...pipelines]
        .filter(p => p.performance.train_time_seconds > 0)
        .sort((a, b) => a.performance.train_time_seconds - b.performance.train_time_seconds)
        .slice(0, 3);
    
    // Top 3 by Inference Speed (fastest = lowest ms/sample)
    const topInferSpeed = [...pipelines]
        .filter(p => p.performance.inference_time_ms_per_sample > 0)
        .sort((a, b) => a.performance.inference_time_ms_per_sample - b.performance.inference_time_ms_per_sample)
        .slice(0, 3);
    
    // Combine and deduplicate (keep unique pipeline_ids)
    const seen = new Set();
    top9Pipelines = [...topAccuracy, ...topTrainSpeed, ...topInferSpeed].filter(p => {
        if (seen.has(p.pipeline_id)) return false;
        seen.add(p.pipeline_id);
        return true;
    });
    
    // Render comparison
    renderTop9Comparison();
}

// ===== RENDER TOP 9 COMPARISON =====
function renderTop9Comparison() {
    // Performance Tab
    renderPerformanceComparison();
    
    // Configuration Tab
    renderConfigurationDetails();
    
    // Formulas Tab
    renderFormulasContent();
    
    // Confusion Matrices
    renderConfusionMatrices();
}

// === Performance Tab ===
function renderPerformanceComparison() {
    const container = document.getElementById('performance-comparison-table');
    if (!container) return;
    
    // Find best values for highlighting
    const bestAcc = Math.max(...top9Pipelines.map(p => p.metrics.accuracy));
    const bestF1 = Math.max(...top9Pipelines.map(p => p.metrics.f1_score));
    const bestTrain = Math.min(...top9Pipelines.map(p => p.performance.train_time_seconds));
    const bestInfer = Math.min(...top9Pipelines.map(p => p.performance.inference_time_ms_per_sample));
    
    let html = `
        <table class="performance-table">
            <thead>
                <tr>
                    <th>Rank</th>
                    <th>Pipeline</th>
                    <th>Accuracy</th>
                    <th>Precision</th>
                    <th>Recall</th>
                    <th>F1-Score</th>
                    <th>Train Time (s)</th>
                    <th>Inference (ms)</th>
                </tr>
            </thead>
            <tbody>
    `;
    
    top9Pipelines.forEach((p, idx) => {
        const pipelineName = `${p.extractor.name} ‚Üí ${p.reducer.name} ‚Üí ${p.classifier.name}`;
        
        html += `<tr>`;
        html += `<td><strong>${idx + 1}</strong></td>`;
        html += `<td class="pipeline-name-cell">${pipelineName}</td>`;
        html += `<td class="${p.metrics.accuracy === bestAcc ? 'metric-best' : ''}">${(p.metrics.accuracy * 100).toFixed(2)}%</td>`;
        html += `<td>${(p.metrics.precision * 100).toFixed(2)}%</td>`;
        html += `<td>${(p.metrics.recall * 100).toFixed(2)}%</td>`;
        html += `<td class="${p.metrics.f1_score === bestF1 ? 'metric-best' : ''}">${(p.metrics.f1_score * 100).toFixed(2)}%</td>`;
        html += `<td class="${p.performance.train_time_seconds === bestTrain ? 'metric-best' : ''}">${p.performance.train_time_seconds.toFixed(3)}</td>`;
        html += `<td class="${p.performance.inference_time_ms_per_sample === bestInfer ? 'metric-best' : ''}">${p.performance.inference_time_ms_per_sample.toFixed(4)}</td>`;
        html += `</tr>`;
    });
    
    html += `</tbody></table>`;
    container.innerHTML = html;
}

// === Configuration Tab ===
function renderConfigurationDetails() {
    const container = document.getElementById('configuration-details');
    if (!container) return;
    
    let html = '<div class="config-grid">';
    
    top9Pipelines.forEach((p, idx) => {
        const pipelineName = `${p.extractor.name} ‚Üí ${p.reducer.name} ‚Üí ${p.classifier.name}`;
        
        html += `
            <div class="config-card">
                <h4>${idx + 1}. ${pipelineName}</h4>
                <table class="config-table-small">
                    <tr><th>Extractor</th><td>${p.extractor.name}</td></tr>
                    <tr><td colspan="2" class="config-details-small">${JSON.stringify(p.extractor.config).replace(/[{}]/g, '').replace(/"/g, '')}</td></tr>
                    
                    <tr><th>Reducer</th><td>${p.reducer.name}</td></tr>
                    <tr><td colspan="2" class="config-details-small">${JSON.stringify(p.reducer.config).replace(/[{}]/g, '').replace(/"/g, '')}</td></tr>
                    
                    <tr><th>Classifier</th><td>${p.classifier.name}</td></tr>
                    <tr><td colspan="2" class="config-details-small">${JSON.stringify(p.classifier.config).replace(/[{}]/g, '').replace(/"/g, '')}</td></tr>
                    
                    <tr><th>Features</th><td>${p.features_extracted} ‚Üí ${p.features_after_reduction}</td></tr>
                </table>
            </div>
        `;
    });
    
    html += '</div>';
    container.innerHTML = html;
}

// === Formulas Tab (Y CHANG traditional_ml - METRICS formulas) ===
function renderFormulasContent() {
    const container = document.getElementById('formulas-content');
    if (!container) return;
    
    const html = `
        <div style="max-width: 900px; margin: 0 auto;">
            <!-- Classification Metrics -->
            <div class="config-card" style="margin-bottom: 1.5rem;">
                <h4>üìä Classification Metrics</h4>
                <div style="line-height: 2.2;">
                    <div style="padding: 0.75rem; background: #f8f9fa; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>Accuracy:</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}} = \\frac{\\sum_{i=1}^{n} \\text{CM}[i,i]}{\\text{Total Samples}} \\)
                        </span>
                    </div>
                    
                    <div style="padding: 0.75rem; background: #f8f9fa; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>Precision (per class i):</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{Precision}_i = \\frac{\\text{TP}_i}{\\text{TP}_i + \\text{FP}_i} = \\frac{\\text{CM}[i,i]}{\\sum_{j=1}^{n} \\text{CM}[j,i]} \\)
                        </span>
                    </div>
                    
                    <div style="padding: 0.75rem; background: #f8f9fa; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>Recall (per class i):</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{Recall}_i = \\frac{\\text{TP}_i}{\\text{TP}_i + \\text{FN}_i} = \\frac{\\text{CM}[i,i]}{\\sum_{j=1}^{n} \\text{CM}[i,j]} \\)
                        </span>
                    </div>
                    
                    <div style="padding: 0.75rem; background: #f8f9fa; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>F1-Score (per class i):</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{F1}_i = 2 \\times \\frac{\\text{Precision}_i \\times \\text{Recall}_i}{\\text{Precision}_i + \\text{Recall}_i} = \\frac{2 \\times \\text{TP}_i}{2 \\times \\text{TP}_i + \\text{FP}_i + \\text{FN}_i} \\)
                        </span>
                    </div>
                </div>
            </div>
            
            <!-- Averaging Methods -->
            <div class="config-card" style="margin-bottom: 1.5rem;">
                <h4>üìê Averaging Methods</h4>
                <div style="line-height: 2.2;">
                    <div style="padding: 0.75rem; background: #f0f4ff; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>Macro Average:</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{Macro} = \\frac{1}{n} \\sum_{i=1}^{n} \\text{Metric}_i \\)
                        </span><br>
                        <em style="font-size: 0.9rem; color: #666;">Simple average across all classes (treats all classes equally)</em>
                    </div>
                    
                    <div style="padding: 0.75rem; background: #f0f4ff; border-radius: 8px; margin-bottom: 0.5rem;">
                        <strong>Weighted Average:</strong><br>
                        <span style="font-size: 1.1rem; color: #667eea;">
                            \\( \\text{Weighted} = \\frac{\\sum_{i=1}^{n} \\text{Metric}_i \\times \\text{Support}_i}{\\sum_{i=1}^{n} \\text{Support}_i} \\)
                        </span><br>
                        <em style="font-size: 0.9rem; color: #666;">Weighted by class frequency (better for imbalanced datasets)</em>
                    </div>
                </div>
            </div>
            
            <!-- Confusion Matrix Components -->
            <div class="config-card">
                <h4>üî¢ Confusion Matrix Components</h4>
                <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1rem; margin-top: 1rem;">
                    <div style="background: #d1fae5; padding: 1rem; border-radius: 8px; border-left: 4px solid #10b981;">
                        <strong style="color: #065f46;">True Positive (TP<sub>i</sub>):</strong><br>
                        <span style="font-size: 0.9rem;">CM[i, i] - Correctly predicted as class i</span>
                    </div>
                    
                    <div style="background: #fee2e2; padding: 1rem; border-radius: 8px; border-left: 4px solid #ef4444;">
                        <strong style="color: #991b1b;">False Positive (FP<sub>i</sub>):</strong><br>
                        <span style="font-size: 0.9rem;">Sum of column i (except diagonal) - Incorrectly predicted as i</span>
                    </div>
                    
                    <div style="background: #fef3c7; padding: 1rem; border-radius: 8px; border-left: 4px solid #f59e0b;">
                        <strong style="color: #92400e;">False Negative (FN<sub>i</sub>):</strong><br>
                        <span style="font-size: 0.9rem;">Sum of row i (except diagonal) - Should be i but predicted as other</span>
                    </div>
                    
                    <div style="background: #dbeafe; padding: 1rem; border-radius: 8px; border-left: 4px solid #3b82f6;">
                        <strong style="color: #1e40af;">Support<sub>i</sub>:</strong><br>
                        <span style="font-size: 0.9rem;">Sum of row i - Total samples of class i</span>
                    </div>
                </div>
            </div>
        </div>
    `;
    
    container.innerHTML = html;
    
    // Render KaTeX formulas after content is loaded
    setTimeout(() => {
        if (typeof renderMathInElement !== 'undefined') {
            renderMathInElement(container, {
                delimiters: [
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true}
                ],
                throwOnError: false
            });
        }
    }, 100);
}

// === Confusion Matrices (Y CHANG traditional_ml) ===
function renderConfusionMatrices() {
    const container = document.getElementById('confusion-matrices-grid');
    if (!container) return;
    
    let html = '';
    
    top9Pipelines.forEach((p, idx) => {
        const pipelineName = `${p.extractor.name} ‚Üí ${p.reducer.name} ‚Üí ${p.classifier.name}`;
        const cm = p.confusion_matrix;
        const labels = p.labels;
        
        if (!cm || !labels) return;
        
        // Find max error for coloring
        const maxError = Math.max(...cm.flatMap((row, i) => row.filter((_, j) => i !== j)));
        
        // Build confusion matrix table (y chang traditional_ml)
        const cmHTML = `
            <table class="cm-table">
                <thead>
                    <tr>
                        <th>Actual \\ Pred</th>
                        ${labels.map(l => `<th>${l}</th>`).join('')}
                    </tr>
                </thead>
                <tbody>
                    ${cm.map((row, i) => `
                        <tr>
                            <th>${labels[i]}</th>
                            ${row.map((val, j) => {
                                if (i === j) {
                                    return `<td class="cm-diagonal">${val}</td>`;
                                } else if (val === 0) {
                                    return `<td class="cm-zero">0</td>`;
                                } else {
                                    const severity = val / maxError;
                                    const className = severity > 0.5 ? 'cm-error-high' 
                                                    : severity > 0.2 ? 'cm-error-medium' 
                                                    : 'cm-error-low';
                                    return `<td class="${className}">${val}</td>`;
                                }
                            }).join('')}
                        </tr>
                    `).join('')}
                </tbody>
            </table>
        `;
        
        // Build per-class summary (y chang traditional_ml)
        const perClassMetrics = p.per_class_metrics || [];
        const perClassHTML = `
            <div class="per-class-summary">
                ${perClassMetrics.map(cls => `
                    <div class="per-class-item">
                        <div class="per-class-label">${cls.label}</div>
                        <div class="per-class-value">${((cls.f1 || 0) * 100).toFixed(1)}%</div>
                    </div>
                `).join('')}
            </div>
        `;
        
        // Build card (y chang traditional_ml structure)
        html += `
            <div class="confusion-matrix-card">
                <div class="matrix-header">
                    <h5>${idx + 1}. ${pipelineName} - Accuracy: ${(p.metrics.accuracy * 100).toFixed(2)}%</h5>
                </div>
                <div class="matrix-content">
                    <h4>Per-Class F1-Score</h4>
                    ${perClassHTML}
                    
                    <h4 style="margin-top: 2rem;">Confusion Matrix</h4>
                    
                    <div class="matrix-tabs">
                        <button class="matrix-tab-btn active" onclick="switchMatrixView('${idx}', 'matrix')">
                            üìä Confusion Matrix
                        </button>
                        <button class="matrix-tab-btn" onclick="switchMatrixView('${idx}', 'walkthrough')">
                            üéì Metrics Walkthrough
                        </button>
                    </div>
                    
                    <div id="matrix-view-${idx}" class="matrix-view active">
                        ${cmHTML}
                        <p style="margin-top: 1rem; color: #666; font-size: 0.9rem; text-align: center;">
                            üü¢ Diagonal = Correct Predictions | üü°üü†üî¥ = Errors (color intensity = severity)
                        </p>
                    </div>
                    
                    <div id="walkthrough-view-${idx}" class="matrix-view">
                        <div class="walkthrough-container" id="walkthrough-${idx}">
                            <button class="walkthrough-fullscreen-btn" onclick="toggleFullscreen('${idx}')">‚õ∂ Fullscreen</button>
                            <div class="walkthrough-content">
                                <div class="walkthrough-grid">
                                    <div class="walkthrough-left">
                                        <div class="matrix-display">
                                            <h4 style="margin-bottom: 1rem; color: #333;">Confusion Matrix</h4>
                                            <table class="wt-cm-table" id="wt-matrix-${idx}"></table>
                                        </div>
                                        
                                        <div class="walkthrough-controls">
                                            <button class="wt-btn wt-btn-nav" onclick="wtPrevStep('${idx}')">‚óÄ Previous</button>
                                            <button class="wt-btn wt-btn-nav" onclick="wtNextStep('${idx}')">Next ‚ñ∂</button>
                                            <button class="wt-btn wt-btn-reset" onclick="wtReset('${idx}')">‚Üª Reset</button>
                                        </div>
                                        
                                        <div class="wt-progress-bar">
                                            <div class="wt-progress-fill" id="wt-progress-${idx}"></div>
                                        </div>
                                        <div class="wt-progress-text" id="wt-progress-text-${idx}">Step 1/12</div>
                                    </div>
                                    
                                    <div class="walkthrough-right">
                                        <div class="wt-step-info" id="wt-step-info-${idx}">
                                            <h3>
                                                <span class="wt-step-number" id="wt-step-num-${idx}">1</span>
                                                <span id="wt-step-title-${idx}">Loading...</span>
                                            </h3>
                                            <p id="wt-step-desc-${idx}"></p>
                                        </div>
                                        
                                        <div class="wt-calculations" id="wt-calc-${idx}"></div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        `;
    });
    
    container.innerHTML = html;
    
    // Initialize walkthroughs for each pipeline
    top9Pipelines.forEach((p, idx) => {
        if (p.confusion_matrix && p.labels) {
            initWalkthrough(idx.toString(), p.confusion_matrix, p.labels);
        }
    });
}

// Fullscreen toggle (y chang traditional_ml)
function toggleFullscreen(idx) {
    const container = document.getElementById(`walkthrough-${idx}`);
    const btn = document.querySelector(`#walkthrough-${idx} .walkthrough-fullscreen-btn`);
    
    if (!container || !btn) {
        console.error('Fullscreen elements not found for idx:', idx);
        return;
    }
    
    if (container.classList.contains('fullscreen')) {
        container.classList.remove('fullscreen');
        btn.textContent = '‚õ∂ Fullscreen';
        document.body.style.overflow = '';
    } else {
        container.classList.add('fullscreen');
        btn.textContent = '‚úï Exit';
        document.body.style.overflow = 'hidden';
    }
}

// Matrix view switching (y chang traditional_ml)
function switchMatrixView(idx, view) {
    const matrixView = document.getElementById(`matrix-view-${idx}`);
    const walkthroughView = document.getElementById(`walkthrough-view-${idx}`);
    
    if (!matrixView || !walkthroughView) return;
    
    const matrixContent = matrixView.closest('.matrix-content');
    if (!matrixContent) return;
    
    const tabButtons = matrixContent.querySelectorAll('.matrix-tab-btn');
    tabButtons.forEach((btn, btnIdx) => {
        if ((view === 'matrix' && btnIdx === 0) || (view === 'walkthrough' && btnIdx === 1)) {
            btn.classList.add('active');
        } else {
            btn.classList.remove('active');
        }
    });
    
    if (view === 'matrix') {
        matrixView.classList.add('active');
        walkthroughView.classList.remove('active');
    } else {
        matrixView.classList.remove('active');
        walkthroughView.classList.add('active');
    }
}

// === Tab Switching ===
function switchComparisonTab(tab) {
    // Update buttons
    const buttons = document.querySelectorAll('.comparison-tab-btn');
    buttons.forEach(btn => btn.classList.remove('active'));
    event.target.classList.add('active');
    
    // Update content
    document.getElementById('performance-tab').classList.toggle('active', tab === 'performance');
    document.getElementById('configuration-tab').classList.toggle('active', tab === 'configuration');
    document.getElementById('formulas-tab').classList.toggle('active', tab === 'formulas');
}

// ===== PIPELINE DETAIL TABS =====
function switchDetailTab(mode, tab) {
    // Update tab buttons
    const tabBtns = document.querySelectorAll(`#${mode}-pipeline-details .detail-tab-btn`);
    tabBtns.forEach(btn => btn.classList.remove('active'));
    event.target.classList.add('active');
    
    // Update tab contents
    ['config', 'formula', 'confusion', 'walkthrough'].forEach(t => {
        const content = document.getElementById(`${mode}-${t}-tab`);
        if (content) {
            content.classList.toggle('active', t === tab);
        }
    });
}

function populatePipelineDetails(mode, pipeline) {
    // Configuration tab
    document.getElementById(`${mode}-config-content`).innerHTML = buildConfigContent(pipeline);
    
    // Formula tab
    document.getElementById(`${mode}-formula-content`).innerHTML = buildFormulaContent(pipeline);
    
    // Confusion Matrix tab
    document.getElementById(`${mode}-confusion-content`).innerHTML = buildConfusionContent(pipeline);
    
    // Walkthrough tab
    document.getElementById(`${mode}-walkthrough-content`).innerHTML = buildWalkthroughContent(pipeline);
}

function buildConfigContent(pipeline) {
    return `
        <div class="config-details">
            <h4>üîß Pipeline Configuration</h4>
            <table class="config-table">
                <tr><th>Feature Extractor</th><td>${pipeline.extractor.name} - ${JSON.stringify(pipeline.extractor.config)}</td></tr>
                <tr><th>Dimensionality Reducer</th><td>${pipeline.reducer.name} - ${JSON.stringify(pipeline.reducer.config)}</td></tr>
                <tr><th>Classifier</th><td>${pipeline.classifier.name} - ${JSON.stringify(pipeline.classifier.config)}</td></tr>
                <tr><th>Accuracy</th><td><strong>${(pipeline.metrics.accuracy * 100).toFixed(2)}%</strong></td></tr>
                <tr><th>Precision</th><td>${(pipeline.metrics.precision * 100).toFixed(2)}%</td></tr>
                <tr><th>Recall</th><td>${(pipeline.metrics.recall * 100).toFixed(2)}%</td></tr>
                <tr><th>F1-Score</th><td>${(pipeline.metrics.f1_score * 100).toFixed(2)}%</td></tr>
                <tr><th>Training Time</th><td>${pipeline.performance.train_time_seconds.toFixed(3)}s</td></tr>
                <tr><th>Inference Speed</th><td>${pipeline.performance.inference_time_ms_per_sample.toFixed(4)} ms/sample</td></tr>
            </table>
        </div>
    `;
}

function buildFormulaContent(pipeline) {
    // Placeholder - will add formulas based on pipeline components
    return `
        <div class="formula-details">
            <h4>üìê Mathematical Formulas</h4>
            <p>Formulas for <strong>${pipeline.name}</strong> will be displayed here.</p>
            <p>Coming soon: TF-IDF formula, classifier equations, etc.</p>
        </div>
    `;
}

function buildConfusionContent(pipeline) {
    if (!pipeline.confusion_matrix) {
        return '<p>No confusion matrix data available.</p>';
    }
    
    // Placeholder - will render actual confusion matrix
    return `
        <div class="confusion-matrix-container">
            <h4>üìä Confusion Matrix</h4>
            <div id="cm-plot-${pipeline.id}"></div>
            <p><em>Confusion matrix visualization will be rendered here.</em></p>
        </div>
    `;
}

function buildWalkthroughContent(pipeline) {
    return `
        <div class="walkthrough-details">
            <h4>üö∂ Step-by-Step Walkthrough</h4>
            <div class="walkthrough-steps">
                <div class="walkthrough-step">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h5>Feature Extraction: ${pipeline.extractor.name}</h5>
                        <p>Convert text documents into numerical features.</p>
                        <p><em>Output: ${pipeline.features_extracted} features</em></p>
                    </div>
                </div>
                <div class="walkthrough-step">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h5>Dimensionality Reduction: ${pipeline.reducer.name}</h5>
                        <p>${pipeline.reducer.name !== 'None' ? 'Reduce feature space for efficiency.' : 'No reduction applied, using all features.'}</p>
                        <p><em>Output: ${pipeline.features_after_reduction} features</em></p>
                    </div>
                </div>
                <div class="walkthrough-step">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h5>Classification: ${pipeline.classifier.name}</h5>
                        <p>Train model and predict categories.</p>
                    </div>
                </div>
                <div class="walkthrough-step">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h5>Results</h5>
                        <p>Accuracy: <strong>${(pipeline.metrics.accuracy * 100).toFixed(2)}%</strong></p>
                        <p>F1-Score: <strong>${(pipeline.metrics.f1_score * 100).toFixed(2)}%</strong></p>
                        <p>Training Time: <strong>${pipeline.performance.train_time_seconds.toFixed(3)}s</strong></p>
                    </div>
                </div>
            </div>
        </div>
    `;
}

// ===== GLOBAL STATE =====
let selectedExtractor = 'tfidf';
let selectedReducer = 'none';
let selectedClassifiers = ['logistic', 'svm', 'naive_bayes'];

// ===== INITIALIZATION =====
document.addEventListener('DOMContentLoaded', function() {
    // Initialize hero mode first (default view)
    initializeHeroMode();
    
    // Initialize custom builder
    initializeBuilder();
    updatePreview();
    
    // Add change listeners
    document.querySelectorAll('input[name="extractor"]').forEach(radio => {
        radio.addEventListener('change', handleExtractorChange);
    });
    
    document.querySelectorAll('input[name="reducer"]').forEach(radio => {
        radio.addEventListener('change', handleReducerChange);
    });
    
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.addEventListener('change', handleClassifierChange);
    });
});

function initializeBuilder() {
    // Set initial checked states
    document.querySelector('input[name="extractor"][value="tfidf"]').checked = true;
    document.querySelector('input[name="reducer"][value="none"]').checked = true;
    
    ['logistic', 'svm', 'naive_bayes'].forEach(clf => {
        document.querySelector(`input[name="classifier"][value="${clf}"]`).checked = true;
    });
}

// ===== EVENT HANDLERS =====
function handleExtractorChange(e) {
    selectedExtractor = e.target.value;
    updateRadioStyles('extractor');
    updatePreview();
}

function handleReducerChange(e) {
    selectedReducer = e.target.value;
    updateRadioStyles('reducer');
    updatePreview();
}

function handleClassifierChange(e) {
    if (e.target.checked) {
        selectedClassifiers.push(e.target.value);
    } else {
        selectedClassifiers = selectedClassifiers.filter(c => c !== e.target.value);
    }
    updateCheckboxStyles();
    updatePreview();
}

function updateRadioStyles(name) {
    document.querySelectorAll(`input[name="${name}"]`).forEach(radio => {
        const label = radio.closest('label');
        if (radio.checked) {
            label.classList.add('checked');
        } else {
            label.classList.remove('checked');
        }
    });
}

function updateCheckboxStyles() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        const label = checkbox.closest('label');
        if (checkbox.checked) {
            label.classList.add('checked');
        } else {
            label.classList.remove('checked');
        }
    });
}

function updatePreview() {
    const count = selectedClassifiers.length;
    const extractorName = document.querySelector(`input[name="extractor"][value="${selectedExtractor}"]`).dataset.name;
    const reducerName = document.querySelector(`input[name="reducer"][value="${selectedReducer}"]`).dataset.name;
    
    document.getElementById('preview-count').textContent = count;
    
    const list = document.getElementById('preview-list');
    list.innerHTML = '';
    
    selectedClassifiers.forEach(clf => {
        const classifierName = document.querySelector(`input[name="classifier"][value="${clf}"]`).dataset.name;
        const li = document.createElement('li');
        li.textContent = `${extractorName} ‚Üí ${reducerName} ‚Üí ${classifierName}`;
        list.appendChild(li);
    });
}

// ===== CLASSIFIER ACTIONS =====
function selectAllClassifiers() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.checked = true;
        selectedClassifiers = Array.from(document.querySelectorAll('input[name="classifier"]')).map(cb => cb.value);
    });
    updateCheckboxStyles();
    updatePreview();
}

function deselectAllClassifiers() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.checked = false;
    });
    selectedClassifiers = [];
    updateCheckboxStyles();
    updatePreview();
}

function selectTopClassifiers() {
    // Top 3 fastest: Naive Bayes, SVM, Logistic
    deselectAllClassifiers();
    ['naive_bayes', 'svm', 'logistic'].forEach(clf => {
        const checkbox = document.querySelector(`input[name="classifier"][value="${clf}"]`);
        if (checkbox) {
            checkbox.checked = true;
            selectedClassifiers.push(clf);
        }
    });
    updateCheckboxStyles();
    updatePreview();
}

function resetBuilder() {
    selectedExtractor = 'tfidf';
    selectedReducer = 'none';
    selectedClassifiers = ['logistic', 'svm', 'naive_bayes'];
    initializeBuilder();
    updateRadioStyles('extractor');
    updateRadioStyles('reducer');
    updateCheckboxStyles();
    updatePreview();
    
    // Hide results if shown
    document.getElementById('results-section').style.display = 'none';
}

// ===== COMPARE PIPELINES =====
function comparePipelines() {
    if (selectedClassifiers.length === 0) {
        alert('Please select at least one classifier!');
        return;
    }
    
    // Filter matching pipelines
    const matchingPipelines = allPipelinesData.all_results.filter(pipeline => {
        return pipeline.extractor.type === selectedExtractor &&
               pipeline.reducer.type === selectedReducer &&
               selectedClassifiers.includes(pipeline.classifier.type);
    });
    
    if (matchingPipelines.length === 0) {
        alert('No matching pipelines found! Try different combinations.');
        return;
    }
    
    // Show results section
    document.getElementById('custom-results-section').style.display = 'block';
    
    // Scroll to results
    document.getElementById('custom-results-section').scrollIntoView({ behavior: 'smooth' });
    
    // Build visualizations
    buildBestCards(matchingPipelines);
    buildComparisonTable(matchingPipelines);
    buildHeatmap(matchingPipelines);
    buildTradeoffChart(matchingPipelines);
}

// ===== BUILD BEST CARDS =====
function buildBestCards(pipelines) {
    const bestAccuracy = pipelines.reduce((a, b) => a.metrics.accuracy > b.metrics.accuracy ? a : b);
    const fastestTrain = pipelines.reduce((a, b) => a.performance.total_time_seconds < b.performance.total_time_seconds ? a : b);
    const fastestInfer = pipelines.reduce((a, b) => a.performance.inference_time_ms_per_sample < b.performance.inference_time_ms_per_sample ? a : b);
    
    const html = `
        <div class="best-card accuracy">
            <h3>üèÜ Best Accuracy</h3>
            <div class="metric-value" style="color: #10b981;">${(bestAccuracy.metrics.accuracy * 100).toFixed(2)}%</div>
            <div class="pipeline-name">${formatPipelineName(bestAccuracy)}</div>
        </div>
        <div class="best-card speed">
            <h3>‚ö° Fastest Training</h3>
            <div class="metric-value" style="color: #f59e0b;">${fastestTrain.performance.total_time_seconds.toFixed(2)}s</div>
            <div class="pipeline-name">${formatPipelineName(fastestTrain)}</div>
        </div>
        <div class="best-card size">
            <h3>üí® Fastest Inference</h3>
            <div class="metric-value" style="color: #3b82f6;">${fastestInfer.performance.inference_time_ms_per_sample.toFixed(2)}ms</div>
            <div class="pipeline-name">${formatPipelineName(fastestInfer)}</div>
        </div>
    `;
    
    document.getElementById('custom-best-cards').innerHTML = html;
}

function formatPipelineName(pipeline) {
    return `${pipeline.extractor.name} ‚Üí ${pipeline.reducer.name} ‚Üí ${pipeline.classifier.name}`;
}

// ===== BUILD COMPARISON TABLE =====
function buildComparisonTable(pipelines) {
    // Find best values
    const bestAcc = Math.max(...pipelines.map(p => p.metrics.accuracy));
    const bestF1 = Math.max(...pipelines.map(p => p.metrics.f1_score));
    const bestTrain = Math.min(...pipelines.map(p => p.performance.total_time_seconds));
    const bestInfer = Math.min(...pipelines.map(p => p.performance.inference_time_ms_per_sample));
    
    let rows = '';
    pipelines.forEach(p => {
        const isBestAcc = p.metrics.accuracy === bestAcc;
        const isBestF1 = p.metrics.f1_score === bestF1;
        const isBestTrain = p.performance.total_time_seconds === bestTrain;
        const isBestInfer = p.performance.inference_time_ms_per_sample === bestInfer;
        
        rows += `
            <tr>
                <td class="pipeline-cell">${formatPipelineName(p)}</td>
                <td class="${isBestAcc ? 'metric-best' : ''}">${(p.metrics.accuracy * 100).toFixed(2)}%</td>
                <td class="${isBestF1 ? 'metric-best' : ''}">${(p.metrics.f1_score * 100).toFixed(2)}%</td>
                <td class="${isBestTrain ? 'metric-best' : ''}">${p.performance.total_time_seconds.toFixed(2)}s</td>
                <td class="${isBestInfer ? 'metric-best' : ''}">${p.performance.inference_time_ms_per_sample.toFixed(3)}ms</td>
                <td>${p.features_extracted}</td>
                <td>${p.features_after_reduction}</td>
            </tr>
        `;
    });
    
    const html = `
        <table class="comparison-table">
            <thead>
                <tr>
                    <th>Pipeline</th>
                    <th>Accuracy</th>
                    <th>F1-Score</th>
                    <th>Train Time</th>
                    <th>Inference</th>
                    <th>Features (Raw)</th>
                    <th>Features (Final)</th>
                </tr>
            </thead>
            <tbody>
                ${rows}
            </tbody>
        </table>
    `;
    
    document.getElementById('custom-comparison-table').innerHTML = html;
}

// ===== BUILD HEATMAP =====
function buildHeatmap(allPipelines) {
    // Group by extractor+reducer (x-axis) and classifier (y-axis)
    const classifiers = ['logistic', 'svm', 'naive_bayes', 'random_forest', 'decision_tree'];
    const pipelines_combos = [];
    
    // Get unique extractor+reducer combinations
    const combinations = {};
    allPipelines.forEach(p => {
        const combo = `${p.extractor.type}_${p.reducer.type}`;
        if (!combinations[combo]) {
            combinations[combo] = `${p.extractor.name}+${p.reducer.name}`;
        }
    });
    
    const xLabels = Object.values(combinations);
    const yLabels = classifiers.map(clf => {
        const sample = allPipelines.find(p => p.classifier.type === clf);
        return sample ? sample.classifier.name : clf;
    });
    
    // Build matrix
    const zData = [];
    classifiers.forEach(clf => {
        const row = [];
        Object.keys(combinations).forEach(combo => {
            const [ext, red] = combo.split('_');
            const pipeline = allPipelines.find(p => 
                p.extractor.type === ext && 
                p.reducer.type === red && 
                p.classifier.type === clf
            );
            row.push(pipeline ? pipeline.metrics.accuracy * 100 : null);
        });
        zData.push(row);
    });
    
    const data = [{
        z: zData,
        x: xLabels,
        y: yLabels,
        type: 'heatmap',
        colorscale: [
            [0, '#ef4444'],
            [0.85, '#f59e0b'],
            [0.90, '#fbbf24'],
            [0.95, '#a7f3d0'],
            [1, '#10b981']
        ],
        hovertemplate: '%{y}<br>%{x}<br>Accuracy: %{z:.2f}%<extra></extra>',
        colorbar: {
            title: 'Accuracy (%)',
            titleside: 'right'
        }
    }];
    
    const layout = {
        xaxis: { title: 'Feature Extraction + Reduction', tickangle: -45 },
        yaxis: { title: 'Classifier' },
        margin: { l: 150, r: 50, b: 150, t: 50 },
        height: 500
    };
    
    Plotly.newPlot('custom-heatmap-chart', data, layout, {responsive: true});
}

// ===== BUILD TRADEOFF CHART =====
function buildTradeoffChart(allPipelines) {
    const traces = [];
    const classifiers = [...new Set(allPipelines.map(p => p.classifier.type))];
    const colors = ['#667eea', '#f59e0b', '#10b981', '#ef4444', '#3b82f6'];
    
    classifiers.forEach((clf, idx) => {
        const pipelinesForClf = allPipelines.filter(p => p.classifier.type === clf);
        
        traces.push({
            x: pipelinesForClf.map(p => p.performance.total_time_seconds),
            y: pipelinesForClf.map(p => p.metrics.accuracy * 100),
            mode: 'markers',
            type: 'scatter',
            name: pipelinesForClf[0].classifier.name,
            marker: {
                size: 12,
                color: colors[idx % colors.length]
            },
            text: pipelinesForClf.map(p => formatPipelineName(p)),
            hovertemplate: '%{text}<br>Time: %{x:.2f}s<br>Accuracy: %{y:.2f}%<extra></extra>'
        });
    });
    
    const layout = {
        xaxis: { title: 'Training Time (seconds)', type: 'log' },
        yaxis: { title: 'Accuracy (%)', range: [75, 100] },
        hovermode: 'closest',
        legend: { x: 0.7, y: 0.1 },
        height: 500
    };
    
    Plotly.newPlot('custom-tradeoff-chart', traces, layout, {responsive: true});
}

// ===== BUILD CONFUSION MATRICES =====
function buildConfusionMatrices(pipelines) {
    const html = '<h3>üéØ Confusion Matrices (Selected Pipelines)</h3><div class="cm-grid" id="cm-grid"></div>';
    document.getElementById('confusion-matrices').innerHTML = html;
    
    const grid = document.getElementById('cm-grid');
    
    pipelines.forEach((p, idx) => {
        const div = document.createElement('div');
        div.id = `cm-${idx}`;
        grid.appendChild(div);
        
        const data = [{
            z: p.confusion_matrix,
            x: p.labels,
            y: p.labels,
            type: 'heatmap',
            colorscale: 'Blues',
            hovertemplate: 'True: %{y}<br>Pred: %{x}<br>Count: %{z}<extra></extra>'
        }];
        
        const layout = {
            title: `${formatPipelineName(p)}<br>Accuracy: ${(p.metrics.accuracy * 100).toFixed(2)}%`,
            xaxis: { title: 'Predicted', side: 'bottom' },
            yaxis: { title: 'True', autorange: 'reversed' },
            height: 400,
            margin: { l: 100, r: 50, b: 100, t: 80 }
        };
        
        Plotly.newPlot(`cm-${idx}`, data, layout, {responsive: true});
    });
}

    </script>
</body>
</html>