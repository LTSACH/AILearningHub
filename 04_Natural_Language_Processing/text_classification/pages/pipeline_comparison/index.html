<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pipeline Comparison - BBC News Classification | AI Learning Hub</title>
    
    <!-- Plotly for interactive charts -->
    <script src="https://cdn.plot.ly/plotly-2.26.0.min.js"></script>
    
    <!-- KaTeX for math formulas -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <style>

/* ===== RESET & BASE ===== */
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
    line-height: 1.6;
    color: #333;
    background: #f5f7fa;
}

/* ===== NAVBAR ===== */
.navbar {
    background: white;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
    position: sticky;
    top: 0;
    z-index: 1000;
}

.nav-container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 1rem 2rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.brand {
    font-size: 1.5rem;
    font-weight: 700;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    text-decoration: none;
}

.nav-links a {
    color: #667eea;
    text-decoration: none;
    font-weight: 500;
    transition: opacity 0.3s;
}

.nav-links a:hover {
    opacity: 0.7;
}

/* ===== HERO ===== */
.hero {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 3rem 2rem;
    text-align: center;
}

.hero h1 {
    font-size: 2.5rem;
    margin-bottom: 0.5rem;
}

.hero p {
    font-size: 1.1rem;
    opacity: 0.9;
    margin-bottom: 2rem;
}

.hero-stats {
    display: flex;
    justify-content: center;
    gap: 3rem;
    flex-wrap: wrap;
}

.stat-item {
    text-align: center;
}

.stat-value {
    font-size: 2.5rem;
    font-weight: 700;
    margin-bottom: 0.25rem;
}

.stat-label {
    font-size: 0.9rem;
    opacity: 0.9;
    text-transform: uppercase;
    letter-spacing: 1px;
}

/* ===== CONTAINER ===== */
.container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 2rem;
}

.section-description {
    color: #666;
    font-size: 1.1rem;
    margin-bottom: 2rem;
    text-align: center;
}

/* ===== PIPELINE BUILDER ===== */
.pipeline-builder-section {
    background: white;
    border-radius: 12px;
    padding: 2rem;
    margin-bottom: 2rem;
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
}

.pipeline-builder-section h2 {
    color: #667eea;
    margin-bottom: 0.5rem;
    font-size: 2rem;
    text-align: center;
}

.pipeline-steps {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 1rem;
    margin: 2rem 0;
}

.step-item {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 0.5rem;
}

.step-number {
    width: 50px;
    height: 50px;
    border-radius: 50%;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 1.5rem;
    font-weight: 700;
}

.step-title {
    font-size: 0.9rem;
    font-weight: 600;
    color: #667eea;
}

.step-arrow {
    font-size: 2rem;
    color: #667eea;
    margin-top: -20px;
}

.builder-card {
    background: #f8f9fa;
    border-radius: 10px;
    padding: 1.5rem;
    margin-bottom: 1.5rem;
}

.builder-card h3 {
    color: #333;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

.option-group {
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.option-radio, .option-checkbox {
    display: flex;
    align-items: flex-start;
    gap: 0.75rem;
    padding: 1rem;
    background: white;
    border: 2px solid #e5e7eb;
    border-radius: 8px;
    cursor: pointer;
    transition: all 0.3s;
}

.option-radio:hover, .option-checkbox:hover {
    border-color: #667eea;
    box-shadow: 0 2px 8px rgba(102, 126, 234, 0.2);
}

.option-radio.checked, .option-checkbox.checked {
    border-color: #667eea;
    background: #f0f4ff;
}

.option-radio input, .option-checkbox input {
    margin-top: 0.2rem;
    cursor: pointer;
}

.option-content {
    display: flex;
    flex-direction: column;
    flex: 1;
}

.option-title {
    font-weight: 600;
    color: #333;
    margin-bottom: 0.25rem;
}

.option-desc {
    font-size: 0.9rem;
    color: #666;
}

.classifier-actions {
    display: flex;
    gap: 0.75rem;
    margin-top: 1rem;
    flex-wrap: wrap;
}

/* ===== PREVIEW & ACTIONS ===== */
.builder-preview {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 10px;
    padding: 1.5rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
    gap: 2rem;
    flex-wrap: wrap;
}

.preview-content {
    flex: 1;
}

.preview-content h4 {
    margin-bottom: 0.5rem;
    font-size: 1.1rem;
}

#pipeline-preview {
    font-size: 1rem;
}

#preview-list {
    margin: 0.75rem 0 0 1.5rem;
    list-style: none;
}

#preview-list li {
    padding: 0.25rem 0;
    opacity: 0.9;
}

#preview-list li::before {
    content: "‚ñ∏ ";
    margin-right: 0.5rem;
}

.preview-actions {
    display: flex;
    gap: 1rem;
    flex-wrap: wrap;
}

/* ===== BUTTONS ===== */
.btn-primary, .btn-secondary {
    padding: 0.75rem 1.5rem;
    border: none;
    border-radius: 8px;
    font-size: 1rem;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s;
    white-space: nowrap;
}

.btn-primary {
    background: white;
    color: #667eea;
}

.btn-primary:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
}

.btn-secondary {
    background: rgba(255, 255, 255, 0.2);
    color: white;
    border: 1px solid white;
}

.btn-secondary:hover {
    background: rgba(255, 255, 255, 0.3);
}

/* ===== RESULTS SECTION ===== */
.results-section {
    margin-top: 2rem;
}

.results-section h2 {
    color: #667eea;
    font-size: 2rem;
    margin-bottom: 2rem;
    text-align: center;
}

.best-cards {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
    gap: 1.5rem;
    margin-bottom: 2rem;
}

.best-card {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    border-top: 4px solid;
}

.best-card.accuracy {
    border-top-color: #10b981;
}

.best-card.speed {
    border-top-color: #f59e0b;
}

.best-card.size {
    border-top-color: #3b82f6;
}

.best-card h3 {
    font-size: 0.9rem;
    text-transform: uppercase;
    letter-spacing: 1px;
    color: #666;
    margin-bottom: 0.5rem;
}

.best-card .metric-value {
    font-size: 2rem;
    font-weight: 700;
    margin-bottom: 0.5rem;
}

.best-card .pipeline-name {
    font-size: 0.9rem;
    color: #666;
}

/* ===== TABLE ===== */
.table-container {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    margin-bottom: 2rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    overflow-x: auto;
}

.comparison-table {
    width: 100%;
    border-collapse: collapse;
    font-size: 0.9rem;
}

.comparison-table th {
    background: #667eea;
    color: white;
    padding: 0.75rem;
    text-align: left;
    font-weight: 600;
    white-space: nowrap;
}

.comparison-table td {
    padding: 0.75rem;
    border-bottom: 1px solid #e5e7eb;
}

.comparison-table tr:hover {
    background: #f8f9fa;
}

.metric-best {
    background: #d1fae5 !important;
    font-weight: 600;
    color: #065f46;
}

.pipeline-cell {
    font-family: 'Courier New', monospace;
    font-size: 0.85rem;
}

/* ===== VISUALIZATIONS ===== */
.viz-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
    gap: 2rem;
    margin-bottom: 2rem;
}

.viz-card {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
}

.viz-card h3 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

/* ===== CONFUSION MATRICES ===== */
.cm-section {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
}

.cm-section h3 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.3rem;
}

.cm-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(450px, 1fr));
    gap: 1.5rem;
    margin-top: 1.5rem;
}

/* ===== PIPELINE CALCULATION ===== */
.pipeline-calculation {
    margin-top: 2rem;
    text-align: center;
}

.btn-calculation {
    background: rgba(255, 255, 255, 0.2);
    color: white;
    border: 2px solid white;
    padding: 0.75rem 1.5rem;
    border-radius: 8px;
    font-size: 1rem;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s;
}

.btn-calculation:hover {
    background: rgba(255, 255, 255, 0.3);
    transform: translateY(-2px);
}

.calculation-details {
    background: white;
    color: #333;
    margin-top: 1.5rem;
    padding: 2rem;
    border-radius: 12px;
    max-width: 1200px;
    margin-left: auto;
    margin-right: auto;
    text-align: left;
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.15);
}

.calc-formula {
    text-align: center;
    margin-bottom: 2rem;
}

.calc-formula h3 {
    color: #667eea;
    margin-bottom: 1rem;
}

.formula-box {
    background: #f8f9fa;
    padding: 1.5rem;
    border-radius: 10px;
    border: 2px solid #667eea;
}

.formula-main {
    font-size: 1.3rem;
    margin-bottom: 0.75rem;
}

.formula-term {
    color: #667eea;
    font-weight: 700;
    padding: 0.25rem 0.5rem;
    background: rgba(102, 126, 234, 0.1);
    border-radius: 4px;
}

.formula-result {
    font-size: 1.5rem;
    color: #10b981;
    font-weight: 700;
    margin-top: 0.75rem;
}

.calc-breakdown {
    margin-top: 2rem;
}

.calc-section {
    margin-bottom: 2rem;
    padding: 1.5rem;
    background: #f8f9fa;
    border-radius: 10px;
}

.calc-section h4 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

.calc-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
    gap: 1rem;
}

.calc-grid-horizontal {
    display: flex;
    gap: 0.75rem;
    flex-wrap: wrap;
    justify-content: center;
}

.calc-item {
    background: white;
    padding: 1rem;
    border-radius: 8px;
    border-left: 4px solid #667eea;
}

.calc-item strong {
    color: #667eea;
    display: block;
    margin-bottom: 0.5rem;
}

.calc-item ul {
    margin: 0.5rem 0 0 1.25rem;
    font-size: 0.9rem;
    color: #666;
}

.calc-item ul li {
    margin: 0.25rem 0;
}

.calc-item-small {
    background: white;
    padding: 0.75rem 1rem;
    border-radius: 8px;
    border: 2px solid #667eea;
    color: #667eea;
    font-weight: 600;
    font-size: 0.9rem;
}

.calc-example {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 1.5rem;
    border-radius: 10px;
    margin-top: 2rem;
}

.calc-example h4 {
    margin-bottom: 1rem;
    text-align: center;
}

.pipeline-example {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 0.75rem;
    flex-wrap: wrap;
}

.pipeline-step {
    background: rgba(255, 255, 255, 0.2);
    padding: 0.75rem 1rem;
    border-radius: 8px;
    font-weight: 600;
    border: 2px solid white;
}

.pipeline-arrow {
    font-size: 1.5rem;
    font-weight: 700;
}

.pipeline-result {
    background: #10b981;
    padding: 0.75rem 1rem;
    border-radius: 8px;
    font-weight: 700;
    border: 2px solid white;
}

/* ===== RESPONSIVE ===== */
@media (max-width: 768px) {
    .hero h1 {
        font-size: 2rem;
    }
    
    .hero-stats {
        gap: 1.5rem;
    }
    
    .stat-value {
        font-size: 2rem;
    }
    
    .builder-preview {
        flex-direction: column;
        align-items: flex-start;
    }
    
    .preview-actions {
        width: 100%;
    }
    
    .preview-actions button {
        flex: 1;
    }
    
    .viz-grid {
        grid-template-columns: 1fr;
    }
    
    .cm-grid {
        grid-template-columns: 1fr;
    }
}

/* ===== LOADING ===== */
.loading {
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 3rem;
    font-size: 1.1rem;
    color: #667eea;
}

.loading::after {
    content: '...';
    animation: dots 1.5s infinite;
}

@keyframes dots {
    0%, 20% { content: '.'; }
    40% { content: '..'; }
    60%, 100% { content: '...'; }
}

    </style>
</head>
<body>
    <!-- Navbar -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="../../../../index.html" class="brand">ü§ñ AI Learning Hub</a>
            <div class="nav-links">
                <a href="../../index.html">‚Üê Back to Text Classification</a>
            </div>
        </div>
    </nav>

    <!-- Hero -->
    <div class="hero">
        <h1>üî¨ Pipeline Comparison</h1>
        <p>Compare feature extraction, dimensionality reduction, and classifier combinations</p>
        <div class="hero-stats">
            <div class="stat-item">
                <div class="stat-value">117</div>
                <div class="stat-label">Total Pipelines</div>
            </div>
            <div class="stat-item">
                <div class="stat-value">99.4%</div>
                <div class="stat-label">Best Accuracy</div>
            </div>
            <div class="stat-item">
                <div class="stat-value">0.60s</div>
                <div class="stat-label">Fastest Training</div>
            </div>
        </div>
        
        <!-- Pipeline calculation explanation -->
        <div class="pipeline-calculation">
            <button onclick="toggleCalculation()" class="btn-calculation">
                üìä How are 180 pipelines calculated?
            </button>
            <div id="calculation-details" class="calculation-details" style="display: none;">
                
                <div class="calc-formula">
                    <h3>üßÆ Total Pipeline Combinations</h3>
                    <div class="formula-box">
                        <div class="formula-main">
                            Total = <span class="formula-term">Extractors</span> √ó 
                                   <span class="formula-term">Reducers</span> √ó 
                                   <span class="formula-term">Classifiers</span>
                        </div>
                        <div class="formula-result">
                            = <strong>6</strong> √ó <strong>6</strong> √ó <strong>5</strong> = <strong>180 pipelines</strong>
                        </div>
                    </div>
                </div>
                
                <div class="calc-breakdown">
                    <div class="calc-section">
                        <h4>1Ô∏è‚É£ Feature Extractors (6 configs)</h4>
                        <div class="calc-grid">
                            <div class="calc-item">
                                <strong>Bag of Words (BoW)</strong> - 3 configs
                                <ul>
                                    <li>5000 features, unigrams (1,1)</li>
                                    <li>5000 features, bigrams (1,2)</li>
                                    <li>10000 features, bigrams (1,2)</li>
                                </ul>
                            </div>
                            <div class="calc-item">
                                <strong>TF-IDF</strong> - 3 configs
                                <ul>
                                    <li>5000 features, unigrams (1,1)</li>
                                    <li>5000 features, bigrams (1,2)</li>
                                    <li>10000 features, bigrams (1,2)</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="calc-section">
                        <h4>2Ô∏è‚É£ Dimensionality Reducers (6 configs)</h4>
                        <div class="calc-grid">
                            <div class="calc-item">
                                <strong>None</strong> - 1 config
                                <ul><li>Use all features (no reduction)</li></ul>
                            </div>
                            <div class="calc-item">
                                <strong>PCA</strong> - 2 configs
                                <ul>
                                    <li>300 components</li>
                                    <li>500 components</li>
                                </ul>
                            </div>
                            <div class="calc-item">
                                <strong>Chi¬≤</strong> - 2 configs
                                <ul>
                                    <li>Select top 500 features</li>
                                    <li>Select top 1000 features</li>
                                </ul>
                            </div>
                            <div class="calc-item">
                                <strong>Truncated SVD</strong> - 1 config
                                <ul><li>300 components</li></ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="calc-section">
                        <h4>3Ô∏è‚É£ Classifiers (5 models)</h4>
                        <div class="calc-grid-horizontal">
                            <div class="calc-item-small">Logistic Regression</div>
                            <div class="calc-item-small">SVM (Linear)</div>
                            <div class="calc-item-small">Naive Bayes</div>
                            <div class="calc-item-small">Random Forest</div>
                            <div class="calc-item-small">Decision Tree</div>
                        </div>
                    </div>
                </div>
                
                <div class="calc-example">
                    <h4>üìù Example Pipeline</h4>
                    <div class="pipeline-example">
                        <div class="pipeline-step">TF-IDF (5000, bigrams)</div>
                        <div class="pipeline-arrow">‚Üí</div>
                        <div class="pipeline-step">Chi¬≤ (top 500)</div>
                        <div class="pipeline-arrow">‚Üí</div>
                        <div class="pipeline-step">Logistic Regression</div>
                        <div class="pipeline-arrow">=</div>
                        <div class="pipeline-result">1 of 180 pipelines</div>
                    </div>
                </div>
    
            </div>
        </div>
    </div>

    <!-- Main content -->
    <div class="container">
        <!-- Pipeline Builder Section -->
        <section class="pipeline-builder-section">
            <h2>üî¨ Build Your Pipeline</h2>
            <p class="section-description">
                Select feature extraction, dimensionality reduction, and classifiers to compare
            </p>
            
            
        <div class="pipeline-builder">
            <!-- Step indicator -->
            <div class="pipeline-steps">
                <div class="step-item">
                    <div class="step-number">1</div>
                    <div class="step-title">üìù Extract</div>
                </div>
                <div class="step-arrow">‚Üí</div>
                <div class="step-item">
                    <div class="step-number">2</div>
                    <div class="step-title">üéØ Reduce</div>
                </div>
                <div class="step-arrow">‚Üí</div>
                <div class="step-item">
                    <div class="step-number">3</div>
                    <div class="step-title">ü§ñ Classify</div>
                </div>
            </div>
            
            <!-- Step 1: Feature Extraction -->
            <div class="builder-card">
                <h3>STEP 1: Feature Extraction</h3>
                <div class="option-group">
                    <label class="option-radio">
                        <input type="radio" name="extractor" value="bow" data-name="Bag of Words">
                        <span class="option-content">
                            <span class="option-title">Bag of Words (CountVectorizer)</span>
                            <span class="option-desc">Count word occurrences, simple and fast</span>
                        </span>
                    </label>
                    <label class="option-radio checked">
                        <input type="radio" name="extractor" value="tfidf" data-name="TF-IDF" checked>
                        <span class="option-content">
                            <span class="option-title">TF-IDF (TfidfVectorizer)</span>
                            <span class="option-desc">Weight words by importance, better for classification</span>
                        </span>
                    </label>
                </div>
            </div>
            
            <!-- Step 2: Dimensionality Reduction -->
            <div class="builder-card">
                <h3>STEP 2: Dimensionality Reduction (Optional)</h3>
                <div class="option-group">
                    <label class="option-radio checked">
                        <input type="radio" name="reducer" value="none" data-name="None" checked>
                        <span class="option-content">
                            <span class="option-title">None (Use all features)</span>
                            <span class="option-desc">Best accuracy, but slower and larger models</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="pca" data-name="PCA">
                        <span class="option-content">
                            <span class="option-title">PCA (Principal Component Analysis)</span>
                            <span class="option-desc">Reduce to uncorrelated components, good for variance</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="chi2" data-name="Chi¬≤">
                        <span class="option-content">
                            <span class="option-title">Chi¬≤ (SelectKBest)</span>
                            <span class="option-desc">Select most relevant features, good for text</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="svd" data-name="Truncated SVD">
                        <span class="option-content">
                            <span class="option-title">Truncated SVD</span>
                            <span class="option-desc">Like PCA but works with sparse matrices</span>
                        </span>
                    </label>
                </div>
            </div>
            
            <!-- Step 3: Classifiers -->
            <div class="builder-card">
                <h3>STEP 3: Classifiers (Select multiple)</h3>
                <div class="option-group">
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="logistic" data-name="Logistic Regression" checked>
                        <span class="option-content">
                            <span class="option-title">Logistic Regression</span>
                            <span class="option-desc">Fast, interpretable, great baseline (usually best)</span>
                        </span>
                    </label>
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="svm" data-name="SVM" checked>
                        <span class="option-content">
                            <span class="option-title">SVM (Support Vector Machine)</span>
                            <span class="option-desc">Strong for high-dimensional text data</span>
                        </span>
                    </label>
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="naive_bayes" data-name="Naive Bayes" checked>
                        <span class="option-content">
                            <span class="option-title">Naive Bayes</span>
                            <span class="option-desc">Extremely fast, good for large datasets</span>
                        </span>
                    </label>
                    <label class="option-checkbox">
                        <input type="checkbox" name="classifier" value="random_forest" data-name="Random Forest">
                        <span class="option-content">
                            <span class="option-title">Random Forest</span>
                            <span class="option-desc">Ensemble method, robust but slower</span>
                        </span>
                    </label>
                    <label class="option-checkbox">
                        <input type="checkbox" name="classifier" value="decision_tree" data-name="Decision Tree">
                        <span class="option-content">
                            <span class="option-title">Decision Tree</span>
                            <span class="option-desc">Simple, interpretable, usually lower accuracy</span>
                        </span>
                    </label>
                </div>
                <div class="classifier-actions">
                    <button onclick="selectAllClassifiers()" class="btn-secondary">Select All</button>
                    <button onclick="deselectAllClassifiers()" class="btn-secondary">Deselect All</button>
                    <button onclick="selectTopClassifiers()" class="btn-secondary">Top 3 Fastest</button>
                </div>
            </div>
            
            <!-- Preview & Action -->
            <div class="builder-preview">
                <div class="preview-content">
                    <h4>üìä Preview</h4>
                    <div id="pipeline-preview">
                        You will compare <strong id="preview-count">3</strong> pipeline(s):
                        <ul id="preview-list"></ul>
                    </div>
                </div>
                <div class="preview-actions">
                    <button onclick="comparePipelines()" class="btn-primary">
                        üîç Compare These Pipelines
                    </button>
                    <button onclick="resetBuilder()" class="btn-secondary">
                        üîÑ Reset to Defaults
                    </button>
                </div>
            </div>
        </div>
    
        </section>

        <!-- Results Section (initially hidden, shown after Compare) -->
        <section id="results-section" class="results-section" style="display: none;">
            <h2>üìä Comparison Results</h2>
            
            <!-- Best pipeline cards -->
            <div id="best-cards" class="best-cards"></div>
            
            <!-- Comparison table -->
            <div id="comparison-table-container" class="table-container"></div>
            
            <!-- Visualizations -->
            <div class="viz-grid">
                <div class="viz-card">
                    <h3>üìä Accuracy Heatmap</h3>
                    <div id="heatmap-chart"></div>
                </div>
                <div class="viz-card">
                    <h3>‚öñÔ∏è Trade-off: Accuracy vs Speed</h3>
                    <div id="tradeoff-chart"></div>
                </div>
            </div>
            
            <!-- Confusion matrices -->
            <div id="confusion-matrices" class="cm-section"></div>
        </section>
    </div>

    <!-- Data -->
    <script>
        const allPipelinesData = {'total_pipelines': 117, 'successful': 117, 'failed': 0, 'best_accuracy': {'pipeline_id': 'tfidf_m5000_n11_pca_n500_logistic', 'accuracy': 0.9940119760479041, 'config': 'TF-IDF ‚Üí PCA ‚Üí Logistic Regression'}, 'fastest_training': {'pipeline_id': 'tfidf_m5000_n11_none_default_naive_bayes', 'time': 0.5966465473175049, 'config': 'TF-IDF ‚Üí None ‚Üí Naive Bayes'}, 'fastest_inference': {'pipeline_id': 'tfidf_m5000_n11_none_default_svm', 'time': 0.0013091607008151665, 'config': 'TF-IDF ‚Üí None ‚Üí SVM'}, 'all_results': [{'pipeline_id': 'bow_m10000_n12_svd_n300_svm', 'timestamp': '2025-10-21T13:01:23.553852', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.672633171081543, 'features_extracted': 10000, 'reduction_time': 52.485894203186035, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9677637962464865, 'recall': 0.9670658682634731, 'f1_score': 0.9670614818553867}, 'performance': {'train_time_seconds': 0.5321898460388184, 'total_time_seconds': 54.6907172203064, 'inference_time_ms_per_sample': 0.0016246727126801087}, 'confusion_matrix': [[72, 0, 3, 1, 1], [1, 55, 1, 1, 0], [1, 0, 60, 0, 1], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.972972972972973, 'recall': 0.935064935064935, 'f1': 0.9536423841059603, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.9230769230769231, 'recall': 0.967741935483871, 'f1': 0.9448818897637795, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9672131147540983, 'recall': 0.9833333333333333, 'f1': 0.9752066115702479, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n500_decision_tree', 'timestamp': '2025-10-21T12:58:22.140397', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.4767022132873535, 'features_extracted': 5000, 'reduction_time': 5.456620216369629, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.6347305389221557, 'precision': 0.6550988368182153, 'recall': 0.6347305389221557, 'f1_score': 0.6399511635057905}, 'performance': {'train_time_seconds': 1.1673941612243652, 'total_time_seconds': 7.100716590881348, 'inference_time_ms_per_sample': 0.003090875591346604}, 'confusion_matrix': [[47, 8, 12, 3, 7], [6, 34, 10, 5, 3], [8, 9, 39, 6, 0], [3, 12, 4, 58, 0], [10, 13, 3, 0, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6351351351351351, 'recall': 0.6103896103896104, 'f1': 0.6225165562913907, 'support': 77}, {'label': 'entertainment', 'precision': 0.4473684210526316, 'recall': 0.5862068965517241, 'f1': 0.5074626865671642, 'support': 58}, {'label': 'politics', 'precision': 0.5735294117647058, 'recall': 0.6290322580645161, 'f1': 0.6, 'support': 62}, {'label': 'sport', 'precision': 0.8055555555555556, 'recall': 0.7532467532467533, 'f1': 0.7785234899328859, 'support': 77}, {'label': 'tech', 'precision': 0.7727272727272727, 'recall': 0.5666666666666667, 'f1': 0.6538461538461539, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_svd_n300_decision_tree', 'timestamp': '2025-10-21T13:04:43.562906', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.5794517993927002, 'features_extracted': 10000, 'reduction_time': 17.07272696495056, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.6526946107784432, 'precision': 0.6547175580424871, 'recall': 0.6526946107784432, 'f1_score': 0.6531960228111857}, 'performance': {'train_time_seconds': 0.5466048717498779, 'total_time_seconds': 19.19878363609314, 'inference_time_ms_per_sample': 0.0020044292518478666}, 'confusion_matrix': [[47, 10, 8, 4, 8], [8, 34, 2, 8, 6], [6, 8, 39, 6, 3], [3, 9, 3, 57, 5], [10, 2, 5, 2, 41]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6351351351351351, 'recall': 0.6103896103896104, 'f1': 0.6225165562913907, 'support': 77}, {'label': 'entertainment', 'precision': 0.5396825396825397, 'recall': 0.5862068965517241, 'f1': 0.5619834710743802, 'support': 58}, {'label': 'politics', 'precision': 0.6842105263157895, 'recall': 0.6290322580645161, 'f1': 0.6554621848739496, 'support': 62}, {'label': 'sport', 'precision': 0.7402597402597403, 'recall': 0.7402597402597403, 'f1': 0.7402597402597403, 'support': 77}, {'label': 'tech', 'precision': 0.6507936507936508, 'recall': 0.6833333333333333, 'f1': 0.6666666666666666, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_svd_n300_svm', 'timestamp': '2025-10-21T13:10:34.732883', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5926759243011475, 'features_extracted': 5000, 'reduction_time': 189.43781232833862, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9850299401197605, 'precision': 0.9852798705866954, 'recall': 0.9850299401197605, 'f1_score': 0.9850455528370969}, 'performance': {'train_time_seconds': 0.18546438217163086, 'total_time_seconds': 190.2159526348114, 'inference_time_ms_per_sample': 0.002292101968548255}, 'confusion_matrix': [[74, 0, 2, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9866666666666667, 'recall': 0.961038961038961, 'f1': 0.9736842105263158, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9836065573770492, 'recall': 1.0, 'f1': 0.9917355371900827, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n500_svm', 'timestamp': '2025-10-21T13:01:02.012799', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.7265665531158447, 'features_extracted': 5000, 'reduction_time': 5.695241928100586, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9523519043065024, 'recall': 0.9520958083832335, 'f1_score': 0.9520587222160383}, 'performance': {'train_time_seconds': 18.687238216400146, 'total_time_seconds': 26.109046697616577, 'inference_time_ms_per_sample': 0.003497043769516631}, 'confusion_matrix': [[72, 1, 3, 0, 1], [0, 55, 1, 2, 0], [4, 0, 57, 1, 0], [0, 0, 0, 77, 0], [0, 1, 2, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9649122807017544, 'recall': 0.9482758620689655, 'f1': 0.9565217391304348, 'support': 58}, {'label': 'politics', 'precision': 0.9047619047619048, 'recall': 0.9193548387096774, 'f1': 0.912, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_chi2_k1000_svm', 'timestamp': '2025-10-21T13:07:45.006961', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.1041028499603271, 'features_extracted': 5000, 'reduction_time': 0.2057514190673828, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9764468275758919, 'recall': 0.9760479041916168, 'f1_score': 0.9760815195674889}, 'performance': {'train_time_seconds': 0.07337546348571777, 'total_time_seconds': 1.3832297325134277, 'inference_time_ms_per_sample': 0.00403455631461686}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 56, 0, 2, 0], [1, 0, 60, 1, 0], [0, 0, 0, 77, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'entertainment', 'precision': 0.9491525423728814, 'recall': 0.9655172413793104, 'f1': 0.9572649572649573, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_logistic', 'timestamp': '2025-10-21T13:07:52.234700', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.9115254878997803, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582648903644616, 'recall': 0.9580838323353293, 'f1_score': 0.9580291037037023}, 'performance': {'train_time_seconds': 70.48697519302368, 'total_time_seconds': 73.39850068092346, 'inference_time_ms_per_sample': 0.004749812051921548}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.935064935064935, 'recall': 0.935064935064935, 'f1': 0.935064935064935, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_random_forest', 'timestamp': '2025-10-21T13:00:07.354116', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 2.8087317943573, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.9651922086507346, 'recall': 0.9640718562874252, 'f1_score': 0.9642510868569181}, 'performance': {'train_time_seconds': 0.8687279224395752, 'total_time_seconds': 3.677459716796875, 'inference_time_ms_per_sample': 0.24240388127858054}, 'confusion_matrix': [[75, 0, 1, 0, 1], [1, 56, 1, 0, 0], [2, 0, 59, 1, 0], [1, 0, 0, 76, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9146341463414634, 'recall': 0.974025974025974, 'f1': 0.9433962264150944, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n300_decision_tree', 'timestamp': '2025-10-21T12:58:38.846284', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.8837659358978271, 'features_extracted': 10000, 'reduction_time': 3.9689180850982666, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.6287425149700598, 'precision': 0.629186299255533, 'recall': 0.6287425149700598, 'f1_score': 0.6281753916019414}, 'performance': {'train_time_seconds': 0.7798285484313965, 'total_time_seconds': 6.63251256942749, 'inference_time_ms_per_sample': 0.0026954148343937127}, 'confusion_matrix': [[50, 10, 7, 3, 7], [5, 29, 6, 14, 4], [7, 10, 34, 7, 4], [1, 5, 7, 59, 5], [9, 7, 4, 2, 38]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6944444444444444, 'recall': 0.6493506493506493, 'f1': 0.6711409395973155, 'support': 77}, {'label': 'entertainment', 'precision': 0.47540983606557374, 'recall': 0.5, 'f1': 0.48739495798319327, 'support': 58}, {'label': 'politics', 'precision': 0.5862068965517241, 'recall': 0.5483870967741935, 'f1': 0.5666666666666667, 'support': 62}, {'label': 'sport', 'precision': 0.6941176470588235, 'recall': 0.7662337662337663, 'f1': 0.7283950617283951, 'support': 77}, {'label': 'tech', 'precision': 0.6551724137931034, 'recall': 0.6333333333333333, 'f1': 0.6440677966101694, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_none_default_random_forest', 'timestamp': '2025-10-21T13:05:06.146999', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5597803592681885, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9586640034279252, 'recall': 0.9580838323353293, 'f1_score': 0.9581207027763639}, 'performance': {'train_time_seconds': 0.22922062873840332, 'total_time_seconds': 0.7890009880065918, 'inference_time_ms_per_sample': 0.09620546580788618}, 'confusion_matrix': [[73, 0, 2, 1, 1], [2, 56, 0, 0, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9125, 'recall': 0.948051948051948, 'f1': 0.9299363057324841, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9508196721311475, 'recall': 0.9354838709677419, 'f1': 0.943089430894309, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k500_svm', 'timestamp': '2025-10-21T13:04:57.313882', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.6186070442199707, 'features_extracted': 5000, 'reduction_time': 0.1700115203857422, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9521095217958485, 'recall': 0.9520958083832335, 'f1_score': 0.951900443887059}, 'performance': {'train_time_seconds': 0.17199468612670898, 'total_time_seconds': 2.960613250732422, 'inference_time_ms_per_sample': 0.004083096624134543}, 'confusion_matrix': [[71, 1, 4, 0, 1], [1, 55, 0, 2, 0], [1, 0, 60, 0, 1], [0, 0, 0, 77, 0], [3, 2, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9342105263157895, 'recall': 0.922077922077922, 'f1': 0.9281045751633987, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.967741935483871, 'f1': 0.9523809523809523, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k500_random_forest', 'timestamp': '2025-10-21T13:05:02.986464', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 3.0175206661224365, 'features_extracted': 5000, 'reduction_time': 0.14148974418640137, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9598304514108398, 'recall': 0.9580838323353293, 'f1_score': 0.9584771907261772}, 'performance': {'train_time_seconds': 0.24176597595214844, 'total_time_seconds': 3.4007763862609863, 'inference_time_ms_per_sample': 0.2636538294261087}, 'confusion_matrix': [[74, 0, 1, 0, 2], [1, 55, 0, 2, 0], [3, 0, 59, 0, 0], [2, 0, 0, 75, 0], [3, 0, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.891566265060241, 'recall': 0.961038961038961, 'f1': 0.925, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.9833333333333333, 'recall': 0.9516129032258065, 'f1': 0.9672131147540983, 'support': 62}, {'label': 'sport', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_svd_n300_naive_bayes', 'timestamp': '2025-10-21T12:59:17.883641', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.003124713897705, 'features_extracted': 5000, 'reduction_time': 30.922466039657593, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.5598802395209581, 'precision': 0.5745001089484502, 'recall': 0.5598802395209581, 'f1_score': 0.5594175733321571}, 'performance': {'train_time_seconds': 0.006031513214111328, 'total_time_seconds': 31.93162226676941, 'inference_time_ms_per_sample': 0.001811695669939418}, 'confusion_matrix': [[33, 7, 14, 6, 17], [2, 39, 8, 3, 6], [5, 6, 40, 6, 5], [4, 8, 12, 49, 4], [11, 9, 12, 2, 26]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'support': 77}, {'label': 'entertainment', 'precision': 0.5652173913043478, 'recall': 0.6724137931034483, 'f1': 0.6141732283464567, 'support': 58}, {'label': 'politics', 'precision': 0.46511627906976744, 'recall': 0.6451612903225806, 'f1': 0.5405405405405406, 'support': 62}, {'label': 'sport', 'precision': 0.7424242424242424, 'recall': 0.6363636363636364, 'f1': 0.6853146853146853, 'support': 77}, {'label': 'tech', 'precision': 0.4482758620689655, 'recall': 0.43333333333333335, 'f1': 0.4406779661016949, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_pca_n300_decision_tree', 'timestamp': '2025-10-21T13:05:23.303520', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.49419164657592773, 'features_extracted': 5000, 'reduction_time': 3.070535898208618, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9161676646706587, 'precision': 0.9159162085396263, 'recall': 0.9161676646706587, 'f1_score': 0.9156340403516678}, 'performance': {'train_time_seconds': 0.6116607189178467, 'total_time_seconds': 4.176388263702393, 'inference_time_ms_per_sample': 0.0020643908106638287}, 'confusion_matrix': [[70, 2, 5, 0, 0], [1, 52, 1, 1, 3], [2, 4, 51, 2, 3], [1, 0, 1, 75, 0], [1, 1, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9333333333333333, 'recall': 0.9090909090909091, 'f1': 0.9210526315789473, 'support': 77}, {'label': 'entertainment', 'precision': 0.8813559322033898, 'recall': 0.896551724137931, 'f1': 0.8888888888888888, 'support': 58}, {'label': 'politics', 'precision': 0.8793103448275862, 'recall': 0.8225806451612904, 'f1': 0.85, 'support': 62}, {'label': 'sport', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'tech', 'precision': 0.90625, 'recall': 0.9666666666666667, 'f1': 0.9354838709677419, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_naive_bayes', 'timestamp': '2025-10-21T13:01:02.495311', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.9423048496246338, 'features_extracted': 10000, 'reduction_time': 0.3939788341522217, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9730538922155688, 'precision': 0.9737496602766063, 'recall': 0.9730538922155688, 'f1_score': 0.9729928141568138}, 'performance': {'train_time_seconds': 0.026805400848388672, 'total_time_seconds': 2.363089084625244, 'inference_time_ms_per_sample': 0.007021213006116672}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 54, 2, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_none_default_svm', 'timestamp': '2025-10-21T13:05:04.926624', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5325043201446533, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9730538922155688, 'precision': 0.9734728928274042, 'recall': 0.9730538922155688, 'f1_score': 0.9730539131987211}, 'performance': {'train_time_seconds': 0.06553339958190918, 'total_time_seconds': 0.5980377197265625, 'inference_time_ms_per_sample': 0.0013091607008151665}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 56, 1, 1, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 1, 1, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_decision_tree', 'timestamp': '2025-10-21T13:00:11.144476', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.8699986934661865, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7604790419161677, 'precision': 0.7639773036243528, 'recall': 0.7604790419161677, 'f1_score': 0.7604377994759974}, 'performance': {'train_time_seconds': 0.5189423561096191, 'total_time_seconds': 2.3889410495758057, 'inference_time_ms_per_sample': 0.002451285630643011}, 'confusion_matrix': [[53, 4, 11, 3, 6], [5, 39, 7, 6, 1], [8, 2, 47, 2, 3], [3, 3, 2, 67, 2], [7, 0, 4, 1, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6973684210526315, 'recall': 0.6883116883116883, 'f1': 0.6928104575163399, 'support': 77}, {'label': 'entertainment', 'precision': 0.8125, 'recall': 0.6724137931034483, 'f1': 0.7358490566037735, 'support': 58}, {'label': 'politics', 'precision': 0.6619718309859155, 'recall': 0.7580645161290323, 'f1': 0.706766917293233, 'support': 62}, {'label': 'sport', 'precision': 0.8481012658227848, 'recall': 0.8701298701298701, 'f1': 0.8589743589743589, 'support': 77}, {'label': 'tech', 'precision': 0.8, 'recall': 0.8, 'f1': 0.8, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k500_decision_tree', 'timestamp': '2025-10-21T13:00:53.912584', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.6077733039855957, 'features_extracted': 10000, 'reduction_time': 0.311065673828125, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.7784431137724551, 'precision': 0.7795401418367189, 'recall': 0.7784431137724551, 'f1_score': 0.7768763739040079}, 'performance': {'train_time_seconds': 0.14038801193237305, 'total_time_seconds': 2.0592269897460938, 'inference_time_ms_per_sample': 0.00344921728808009}, 'confusion_matrix': [[57, 3, 8, 4, 5], [6, 41, 4, 6, 1], [12, 2, 41, 4, 3], [2, 2, 0, 70, 3], [6, 1, 2, 0, 51]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6867469879518072, 'recall': 0.7402597402597403, 'f1': 0.7125, 'support': 77}, {'label': 'entertainment', 'precision': 0.8367346938775511, 'recall': 0.7068965517241379, 'f1': 0.7663551401869159, 'support': 58}, {'label': 'politics', 'precision': 0.7454545454545455, 'recall': 0.6612903225806451, 'f1': 0.7008547008547008, 'support': 62}, {'label': 'sport', 'precision': 0.8333333333333334, 'recall': 0.9090909090909091, 'f1': 0.8695652173913043, 'support': 77}, {'label': 'tech', 'precision': 0.8095238095238095, 'recall': 0.85, 'f1': 0.8292682926829268, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_svd_n300_svm', 'timestamp': '2025-10-21T13:05:50.238966', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.9226772785186768, 'features_extracted': 5000, 'reduction_time': 31.169883012771606, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.964577502097597, 'recall': 0.9640718562874252, 'f1_score': 0.963970479001272}, 'performance': {'train_time_seconds': 0.48691320419311523, 'total_time_seconds': 33.5794734954834, 'inference_time_ms_per_sample': 0.0016853480995772127}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 55, 1, 1, 0], [1, 0, 60, 0, 1], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9726027397260274, 'recall': 0.922077922077922, 'f1': 0.9466666666666667, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9230769230769231, 'recall': 0.967741935483871, 'f1': 0.9448818897637795, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9672131147540983, 'recall': 0.9833333333333333, 'f1': 0.9752066115702479, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_pca_n500_naive_bayes', 'timestamp': '2025-10-21T13:06:22.467825', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 0.9444835186004639, 'features_extracted': 5000, 'reduction_time': 11.762717962265015, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.6047904191616766, 'precision': 0.7747241102376323, 'recall': 0.6047904191616766, 'f1_score': 0.5554466823290696}, 'performance': {'train_time_seconds': 0.2808568477630615, 'total_time_seconds': 12.98805832862854, 'inference_time_ms_per_sample': 0.014375069898045706}, 'confusion_matrix': [[69, 0, 0, 8, 0], [25, 4, 0, 29, 0], [22, 0, 30, 10, 0], [1, 0, 0, 75, 1], [29, 0, 0, 7, 24]], 'per_class_metrics': [{'label': 'business', 'precision': 0.4726027397260274, 'recall': 0.8961038961038961, 'f1': 0.6188340807174888, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.06896551724137931, 'f1': 0.12903225806451613, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.4838709677419355, 'f1': 0.6521739130434783, 'support': 62}, {'label': 'sport', 'precision': 0.5813953488372093, 'recall': 0.974025974025974, 'f1': 0.7281553398058253, 'support': 77}, {'label': 'tech', 'precision': 0.96, 'recall': 0.4, 'f1': 0.5647058823529412, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_none_default_naive_bayes', 'timestamp': '2025-10-21T13:05:05.531796', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 0.4971933364868164, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9850299401197605, 'precision': 0.9851161731835868, 'recall': 0.9850299401197605, 'f1_score': 0.984973969231511}, 'performance': {'train_time_seconds': 0.09945321083068848, 'total_time_seconds': 0.5966465473175049, 'inference_time_ms_per_sample': 0.018246873410162096}, 'confusion_matrix': [[76, 1, 0, 0, 0], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9838709677419355, 'recall': 0.9838709677419355, 'f1': 0.9838709677419355, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.967741935483871, 'recall': 1.0, 'f1': 0.9836065573770492, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k500_random_forest', 'timestamp': '2025-10-21T13:00:50.647999', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 2.7205097675323486, 'features_extracted': 10000, 'reduction_time': 0.29329442977905273, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9598304514108398, 'recall': 0.9580838323353293, 'f1_score': 0.9584771907261772}, 'performance': {'train_time_seconds': 0.20423150062561035, 'total_time_seconds': 3.2180356979370117, 'inference_time_ms_per_sample': 0.09682863772272349}, 'confusion_matrix': [[74, 0, 1, 0, 2], [1, 55, 0, 2, 0], [3, 0, 59, 0, 0], [2, 0, 0, 75, 0], [3, 0, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.891566265060241, 'recall': 0.961038961038961, 'f1': 0.925, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.9833333333333333, 'recall': 0.9516129032258065, 'f1': 0.9672131147540983, 'support': 62}, {'label': 'sport', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k500_svm', 'timestamp': '2025-10-21T12:58:31.869512', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.8454303741455078, 'features_extracted': 5000, 'reduction_time': 0.16742634773254395, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9528863511896907, 'recall': 0.9520958083832335, 'f1_score': 0.951977611140072}, 'performance': {'train_time_seconds': 0.1584920883178711, 'total_time_seconds': 1.1713488101959229, 'inference_time_ms_per_sample': 0.002965241849065541}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 0, 2, 0], [0, 2, 60, 0, 0], [0, 0, 0, 77, 0], [3, 3, 0, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9016393442622951, 'recall': 0.9482758620689655, 'f1': 0.9243697478991597, 'support': 58}, {'label': 'politics', 'precision': 0.967741935483871, 'recall': 0.967741935483871, 'f1': 0.967741935483871, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9818181818181818, 'recall': 0.9, 'f1': 0.9391304347826087, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_none_default_random_forest', 'timestamp': '2025-10-21T13:07:54.081465', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.042994737625122, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.953277091136297, 'recall': 0.9520958083832335, 'f1_score': 0.9523977845480633}, 'performance': {'train_time_seconds': 1.9043095111846924, 'total_time_seconds': 2.9473042488098145, 'inference_time_ms_per_sample': 0.5017183497994246}, 'confusion_matrix': [[73, 0, 2, 0, 2], [1, 55, 1, 1, 0], [3, 0, 59, 0, 0], [1, 0, 0, 75, 1], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9012345679012346, 'recall': 0.948051948051948, 'f1': 0.9240506329113924, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'tech', 'precision': 0.9491525423728814, 'recall': 0.9333333333333333, 'f1': 0.9411764705882353, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_svd_n300_naive_bayes', 'timestamp': '2025-10-21T13:02:18.259733', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.839815616607666, 'features_extracted': 10000, 'reduction_time': 89.77955746650696, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.5419161676646707, 'precision': 0.5493592237501864, 'recall': 0.5419161676646707, 'f1_score': 0.5402083540528153}, 'performance': {'train_time_seconds': 0.006906986236572266, 'total_time_seconds': 91.6262800693512, 'inference_time_ms_per_sample': 0.0019530336300056137}, 'confusion_matrix': [[39, 12, 7, 7, 12], [2, 38, 3, 8, 7], [5, 13, 31, 6, 7], [5, 13, 7, 51, 1], [14, 10, 9, 5, 22]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6, 'recall': 0.5064935064935064, 'f1': 0.5492957746478874, 'support': 77}, {'label': 'entertainment', 'precision': 0.4418604651162791, 'recall': 0.6551724137931034, 'f1': 0.5277777777777778, 'support': 58}, {'label': 'politics', 'precision': 0.543859649122807, 'recall': 0.5, 'f1': 0.5210084033613446, 'support': 62}, {'label': 'sport', 'precision': 0.6623376623376623, 'recall': 0.6623376623376623, 'f1': 0.6623376623376623, 'support': 77}, {'label': 'tech', 'precision': 0.4489795918367347, 'recall': 0.36666666666666664, 'f1': 0.4036697247706422, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_svd_n300_decision_tree', 'timestamp': '2025-10-21T13:06:56.875455', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.868582010269165, 'features_extracted': 5000, 'reduction_time': 52.90783381462097, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.6497005988023952, 'precision': 0.6496076482759809, 'recall': 0.6497005988023952, 'f1_score': 0.6481731448732191}, 'performance': {'train_time_seconds': 0.5700473785400391, 'total_time_seconds': 55.346463203430176, 'inference_time_ms_per_sample': 0.0016896310680640672}, 'confusion_matrix': [[47, 8, 8, 7, 7], [2, 30, 7, 15, 4], [6, 4, 41, 4, 7], [5, 7, 6, 59, 0], [8, 6, 3, 3, 40]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6911764705882353, 'recall': 0.6103896103896104, 'f1': 0.6482758620689655, 'support': 77}, {'label': 'entertainment', 'precision': 0.5454545454545454, 'recall': 0.5172413793103449, 'f1': 0.5309734513274337, 'support': 58}, {'label': 'politics', 'precision': 0.6307692307692307, 'recall': 0.6612903225806451, 'f1': 0.6456692913385826, 'support': 62}, {'label': 'sport', 'precision': 0.6704545454545454, 'recall': 0.7662337662337663, 'f1': 0.7151515151515152, 'support': 77}, {'label': 'tech', 'precision': 0.6896551724137931, 'recall': 0.6666666666666666, 'f1': 0.6779661016949152, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n500_decision_tree', 'timestamp': '2025-10-21T13:00:28.871373', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.6343498229980469, 'features_extracted': 10000, 'reduction_time': 9.74869155883789, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.6467065868263473, 'precision': 0.6418553738312804, 'recall': 0.6467065868263473, 'f1_score': 0.6424447203076884}, 'performance': {'train_time_seconds': 1.3571853637695312, 'total_time_seconds': 12.740226745605469, 'inference_time_ms_per_sample': 0.0028131964677822092}, 'confusion_matrix': [[53, 6, 6, 5, 7], [8, 28, 6, 13, 3], [8, 7, 34, 7, 6], [1, 3, 6, 64, 3], [10, 9, 3, 1, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6625, 'recall': 0.6883116883116883, 'f1': 0.6751592356687898, 'support': 77}, {'label': 'entertainment', 'precision': 0.5283018867924528, 'recall': 0.4827586206896552, 'f1': 0.5045045045045045, 'support': 58}, {'label': 'politics', 'precision': 0.6181818181818182, 'recall': 0.5483870967741935, 'f1': 0.5811965811965812, 'support': 62}, {'label': 'sport', 'precision': 0.7111111111111111, 'recall': 0.8311688311688312, 'f1': 0.7664670658682635, 'support': 77}, {'label': 'tech', 'precision': 0.6607142857142857, 'recall': 0.6166666666666667, 'f1': 0.6379310344827587, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n300_naive_bayes', 'timestamp': '2025-10-21T13:12:22.639515', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 4.692835330963135, 'features_extracted': 10000, 'reduction_time': 57.051581621170044, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.46706586826347307, 'precision': 0.4958392016092651, 'recall': 0.46706586826347307, 'f1_score': 0.46585546678680445}, 'performance': {'train_time_seconds': 0.08049368858337402, 'total_time_seconds': 61.82491064071655, 'inference_time_ms_per_sample': 0.014069551479316758}, 'confusion_matrix': [[25, 24, 6, 11, 11], [4, 25, 3, 20, 6], [5, 14, 24, 14, 5], [3, 11, 8, 50, 5], [4, 12, 8, 4, 32]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6097560975609756, 'recall': 0.3246753246753247, 'f1': 0.423728813559322, 'support': 77}, {'label': 'entertainment', 'precision': 0.29069767441860467, 'recall': 0.43103448275862066, 'f1': 0.3472222222222222, 'support': 58}, {'label': 'politics', 'precision': 0.4897959183673469, 'recall': 0.3870967741935484, 'f1': 0.43243243243243246, 'support': 62}, {'label': 'sport', 'precision': 0.5050505050505051, 'recall': 0.6493506493506493, 'f1': 0.5681818181818182, 'support': 77}, {'label': 'tech', 'precision': 0.5423728813559322, 'recall': 0.5333333333333333, 'f1': 0.5378151260504201, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_svm', 'timestamp': '2025-10-21T13:09:05.652326', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 9.17022705078125, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9552637254483006, 'recall': 0.9550898203592815, 'f1_score': 0.9549596275836564}, 'performance': {'train_time_seconds': 5.941255569458008, 'total_time_seconds': 15.111482620239258, 'inference_time_ms_per_sample': 0.004030987174211148}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [2, 1, 58, 1, 0], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9491525423728814, 'recall': 0.9655172413793104, 'f1': 0.9572649572649573, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_none_default_decision_tree', 'timestamp': '2025-10-21T13:05:06.976055', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.49210357666015625, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7994011976047904, 'precision': 0.8040000348541732, 'recall': 0.7994011976047904, 'f1_score': 0.7993697684821617}, 'performance': {'train_time_seconds': 0.5738468170166016, 'total_time_seconds': 1.0659503936767578, 'inference_time_ms_per_sample': 0.0021985904899186003}, 'confusion_matrix': [[60, 1, 6, 4, 6], [5, 41, 5, 6, 1], [8, 0, 50, 3, 1], [4, 2, 1, 69, 1], [8, 3, 2, 0, 47]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7058823529411765, 'recall': 0.7792207792207793, 'f1': 0.7407407407407407, 'support': 77}, {'label': 'entertainment', 'precision': 0.8723404255319149, 'recall': 0.7068965517241379, 'f1': 0.780952380952381, 'support': 58}, {'label': 'politics', 'precision': 0.78125, 'recall': 0.8064516129032258, 'f1': 0.7936507936507936, 'support': 62}, {'label': 'sport', 'precision': 0.8414634146341463, 'recall': 0.8961038961038961, 'f1': 0.8679245283018868, 'support': 77}, {'label': 'tech', 'precision': 0.8392857142857143, 'recall': 0.7833333333333333, 'f1': 0.8103448275862069, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_none_default_logistic', 'timestamp': '2025-10-21T13:07:30.388214', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.9657576084136963, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9550625835443449, 'recall': 0.9550898203592815, 'f1_score': 0.9549353389163149}, 'performance': {'train_time_seconds': 18.80290198326111, 'total_time_seconds': 20.768659591674805, 'inference_time_ms_per_sample': 0.009133430298217043}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [2, 0, 58, 1, 1], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_logistic', 'timestamp': '2025-10-21T12:59:56.560252', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6035923957824707, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9581598373126704, 'recall': 0.9580838323353293, 'f1_score': 0.9579800968580585}, 'performance': {'train_time_seconds': 4.910040378570557, 'total_time_seconds': 6.513632774353027, 'inference_time_ms_per_sample': 0.003640523213826254}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [2, 1, 58, 1, 0], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n300_logistic', 'timestamp': '2025-10-21T13:08:02.468367', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 3.791438579559326, 'features_extracted': 5000, 'reduction_time': 74.67068815231323, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9700598802395209, 'precision': 0.9705184453183566, 'recall': 0.9700598802395209, 'f1_score': 0.9698992211388385}, 'performance': {'train_time_seconds': 4.5461976528167725, 'total_time_seconds': 83.00832438468933, 'inference_time_ms_per_sample': 0.002074384403799822}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 56, 1, 0, 0], [0, 0, 60, 1, 1], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9861111111111112, 'recall': 0.922077922077922, 'f1': 0.9530201342281879, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.967741935483871, 'f1': 0.9523809523809523, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.967741935483871, 'recall': 1.0, 'f1': 0.9836065573770492, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_naive_bayes', 'timestamp': '2025-10-21T13:09:20.789723', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 3.0153117179870605, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9763295154114302, 'recall': 0.9760479041916168, 'f1_score': 0.9760704058320477}, 'performance': {'train_time_seconds': 0.9923293590545654, 'total_time_seconds': 4.007641077041626, 'inference_time_ms_per_sample': 0.6016250142080342}, 'confusion_matrix': [[75, 0, 1, 0, 1], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 1, 1, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_svd_n300_decision_tree', 'timestamp': '2025-10-21T12:59:53.276729', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.4998323917388916, 'features_extracted': 5000, 'reduction_time': 2.2651586532592773, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.6317365269461078, 'precision': 0.6253152372327065, 'recall': 0.6317365269461078, 'f1_score': 0.6253811699188849}, 'performance': {'train_time_seconds': 0.5071611404418945, 'total_time_seconds': 3.2721521854400635, 'inference_time_ms_per_sample': 0.0018316828562114052}, 'confusion_matrix': [[48, 5, 11, 8, 5], [9, 25, 7, 12, 5], [8, 7, 32, 6, 9], [4, 9, 2, 61, 1], [8, 0, 2, 5, 45]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6233766233766234, 'recall': 0.6233766233766234, 'f1': 0.6233766233766234, 'support': 77}, {'label': 'entertainment', 'precision': 0.5434782608695652, 'recall': 0.43103448275862066, 'f1': 0.4807692307692308, 'support': 58}, {'label': 'politics', 'precision': 0.5925925925925926, 'recall': 0.5161290322580645, 'f1': 0.5517241379310345, 'support': 62}, {'label': 'sport', 'precision': 0.6630434782608695, 'recall': 0.7922077922077922, 'f1': 0.7218934911242604, 'support': 77}, {'label': 'tech', 'precision': 0.6923076923076923, 'recall': 0.75, 'f1': 0.72, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n300_logistic', 'timestamp': '2025-10-21T13:09:38.548805', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 8.380199670791626, 'features_extracted': 10000, 'reduction_time': 54.88011384010315, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.964013345726934, 'recall': 0.9640718562874252, 'f1_score': 0.9639831295504603}, 'performance': {'train_time_seconds': 4.93297266960144, 'total_time_seconds': 68.19328618049622, 'inference_time_ms_per_sample': 0.016815648107471583}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 56, 1, 0, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1': 0.9666666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_pca_n500_random_forest', 'timestamp': '2025-10-21T13:06:35.477828', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.0571832656860352, 'features_extracted': 5000, 'reduction_time': 23.212948322296143, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9820695654695452, 'recall': 0.9820359281437125, 'f1_score': 0.981990418622943}, 'performance': {'train_time_seconds': 0.8081624507904053, 'total_time_seconds': 25.078294038772583, 'inference_time_ms_per_sample': 0.2068738023677986}, 'confusion_matrix': [[73, 1, 3, 0, 0], [0, 58, 0, 0, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9733333333333334, 'recall': 0.948051948051948, 'f1': 0.9605263157894737, 'support': 77}, {'label': 'entertainment', 'precision': 0.9830508474576272, 'recall': 1.0, 'f1': 0.9914529914529915, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k500_random_forest', 'timestamp': '2025-10-21T12:58:33.690663', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5440988540649414, 'features_extracted': 5000, 'reduction_time': 0.13120746612548828, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9501566015526858, 'recall': 0.9491017964071856, 'f1_score': 0.9492783390593047}, 'performance': {'train_time_seconds': 0.39505434036254883, 'total_time_seconds': 1.0703606605529785, 'inference_time_ms_per_sample': 0.10210311341428471}, 'confusion_matrix': [[74, 0, 2, 0, 1], [2, 54, 0, 1, 1], [3, 0, 59, 0, 0], [0, 0, 0, 75, 2], [3, 1, 1, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9024390243902439, 'recall': 0.961038961038961, 'f1': 0.9308176100628931, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'tech', 'precision': 0.9322033898305084, 'recall': 0.9166666666666666, 'f1': 0.9243697478991597, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n300_naive_bayes', 'timestamp': '2025-10-21T13:00:35.291185', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.5840215682983398, 'features_extracted': 5000, 'reduction_time': 5.193512678146362, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.5029940119760479, 'precision': 0.5086916574029304, 'recall': 0.5029940119760479, 'f1_score': 0.5006479376062571}, 'performance': {'train_time_seconds': 0.01135396957397461, 'total_time_seconds': 6.788888216018677, 'inference_time_ms_per_sample': 0.002735389206937687}, 'confusion_matrix': [[30, 15, 7, 15, 10], [7, 28, 1, 15, 7], [6, 9, 28, 11, 8], [4, 8, 13, 48, 4], [8, 10, 5, 3, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5454545454545454, 'recall': 0.38961038961038963, 'f1': 0.45454545454545453, 'support': 77}, {'label': 'entertainment', 'precision': 0.4, 'recall': 0.4827586206896552, 'f1': 0.4375, 'support': 58}, {'label': 'politics', 'precision': 0.5185185185185185, 'recall': 0.45161290322580644, 'f1': 0.4827586206896552, 'support': 62}, {'label': 'sport', 'precision': 0.5217391304347826, 'recall': 0.6233766233766234, 'f1': 0.5680473372781065, 'support': 77}, {'label': 'tech', 'precision': 0.5396825396825397, 'recall': 0.5666666666666667, 'f1': 0.5528455284552846, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_chi2_k1000_decision_tree', 'timestamp': '2025-10-21T13:07:49.709846', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.633450984954834, 'features_extracted': 5000, 'reduction_time': 0.1578502655029297, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.8173652694610778, 'precision': 0.819743101619316, 'recall': 0.8173652694610778, 'f1_score': 0.8180847747604065}, 'performance': {'train_time_seconds': 0.2108604907989502, 'total_time_seconds': 2.002161741256714, 'inference_time_ms_per_sample': 0.002727537098045121}, 'confusion_matrix': [[60, 2, 7, 4, 4], [3, 46, 4, 4, 1], [8, 2, 49, 1, 2], [5, 2, 1, 68, 1], [7, 2, 1, 0, 50]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7228915662650602, 'recall': 0.7792207792207793, 'f1': 0.75, 'support': 77}, {'label': 'entertainment', 'precision': 0.8518518518518519, 'recall': 0.7931034482758621, 'f1': 0.8214285714285714, 'support': 58}, {'label': 'politics', 'precision': 0.7903225806451613, 'recall': 0.7903225806451613, 'f1': 0.7903225806451613, 'support': 62}, {'label': 'sport', 'precision': 0.8831168831168831, 'recall': 0.8831168831168831, 'f1': 0.8831168831168831, 'support': 77}, {'label': 'tech', 'precision': 0.8620689655172413, 'recall': 0.8333333333333334, 'f1': 0.847457627118644, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_chi2_k1000_logistic', 'timestamp': '2025-10-21T13:07:43.359793', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.0914616584777832, 'features_extracted': 5000, 'reduction_time': 0.24610066413879395, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9730538922155688, 'precision': 0.9732073452325316, 'recall': 0.9730538922155688, 'f1_score': 0.9730378111767702}, 'performance': {'train_time_seconds': 0.2683868408203125, 'total_time_seconds': 1.6059491634368896, 'inference_time_ms_per_sample': 0.013781164934535226}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 56, 1, 1, 0], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [1, 2, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9615384615384616, 'recall': 0.974025974025974, 'f1': 0.967741935483871, 'support': 77}, {'label': 'entertainment', 'precision': 0.9491525423728814, 'recall': 0.9655172413793104, 'f1': 0.9572649572649573, 'support': 58}, {'label': 'politics', 'precision': 0.9836065573770492, 'recall': 0.967741935483871, 'f1': 0.975609756097561, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_svd_n300_svm', 'timestamp': '2025-10-21T12:58:47.503440', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5390479564666748, 'features_extracted': 5000, 'reduction_time': 29.351847171783447, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9588747473033694, 'recall': 0.9580838323353293, 'f1_score': 0.957964885415162}, 'performance': {'train_time_seconds': 0.4788017272949219, 'total_time_seconds': 30.369696855545044, 'inference_time_ms_per_sample': 0.00168748958382064}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 54, 1, 2, 0], [0, 0, 60, 1, 1], [0, 0, 0, 77, 0], [1, 0, 1, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9726027397260274, 'recall': 0.922077922077922, 'f1': 0.9466666666666667, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9230769230769231, 'recall': 0.967741935483871, 'f1': 0.9448818897637795, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1': 0.9666666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n300_decision_tree', 'timestamp': '2025-10-21T13:00:48.982681', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.6116774082183838, 'features_extracted': 5000, 'reduction_time': 2.862575054168701, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.6047904191616766, 'precision': 0.6127298043347043, 'recall': 0.6047904191616766, 'f1_score': 0.6073168958472448}, 'performance': {'train_time_seconds': 0.5669608116149902, 'total_time_seconds': 5.041213274002075, 'inference_time_ms_per_sample': 0.0015747047470001403}, 'confusion_matrix': [[48, 11, 8, 4, 6], [14, 24, 7, 10, 3], [8, 9, 35, 7, 3], [2, 13, 3, 57, 2], [10, 8, 2, 2, 38]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5853658536585366, 'recall': 0.6233766233766234, 'f1': 0.6037735849056604, 'support': 77}, {'label': 'entertainment', 'precision': 0.36923076923076925, 'recall': 0.41379310344827586, 'f1': 0.3902439024390244, 'support': 58}, {'label': 'politics', 'precision': 0.6363636363636364, 'recall': 0.5645161290322581, 'f1': 0.5982905982905983, 'support': 62}, {'label': 'sport', 'precision': 0.7125, 'recall': 0.7402597402597403, 'f1': 0.7261146496815286, 'support': 77}, {'label': 'tech', 'precision': 0.7307692307692307, 'recall': 0.6333333333333333, 'f1': 0.6785714285714286, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_svd_n300_logistic', 'timestamp': '2025-10-21T13:05:24.636031', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.6515331268310547, 'features_extracted': 5000, 'reduction_time': 22.570535898208618, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.9610494286098068, 'recall': 0.9610778443113772, 'f1_score': 0.960965347296765}, 'performance': {'train_time_seconds': 0.3636772632598877, 'total_time_seconds': 25.58574628829956, 'inference_time_ms_per_sample': 0.0015168846724276056}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 56, 1, 0, 0], [1, 1, 59, 1, 0], [0, 0, 0, 77, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k1000_naive_bayes', 'timestamp': '2025-10-21T12:58:39.390850', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 0.5457711219787598, 'features_extracted': 5000, 'reduction_time': 0.137986421585083, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9797208779244705, 'recall': 0.9790419161676647, 'f1_score': 0.9789695970982052}, 'performance': {'train_time_seconds': 0.014998435974121094, 'total_time_seconds': 0.6987559795379639, 'inference_time_ms_per_sample': 0.005108153748655034}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 54, 2, 0, 2], [0, 0, 62, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 1.0, 'recall': 0.961038961038961, 'f1': 0.9801324503311258, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9538461538461539, 'recall': 1.0, 'f1': 0.9763779527559056, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_random_forest', 'timestamp': '2025-10-21T13:05:18.476953', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 2.7683823108673096, 'features_extracted': 5000, 'reduction_time': 0.19776463508605957, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.958853372892966, 'recall': 0.9580838323353293, 'f1_score': 0.9582775575572604}, 'performance': {'train_time_seconds': 0.44312429428100586, 'total_time_seconds': 3.409271240234375, 'inference_time_ms_per_sample': 0.10132289932159606}, 'confusion_matrix': [[73, 0, 2, 0, 2], [0, 56, 1, 1, 0], [3, 0, 59, 0, 0], [1, 0, 0, 76, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9125, 'recall': 0.948051948051948, 'f1': 0.9299363057324841, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_random_forest', 'timestamp': '2025-10-21T13:01:04.885850', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 2.328251361846924, 'features_extracted': 10000, 'reduction_time': 0.27485084533691406, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9678120960972296, 'recall': 0.9670658682634731, 'f1_score': 0.9672242803539094}, 'performance': {'train_time_seconds': 0.20060229301452637, 'total_time_seconds': 2.8037045001983643, 'inference_time_ms_per_sample': 0.2187290591394116}, 'confusion_matrix': [[75, 0, 1, 0, 1], [0, 56, 1, 1, 0], [2, 0, 60, 0, 0], [1, 0, 0, 75, 1], [3, 0, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9259259259259259, 'recall': 0.974025974025974, 'f1': 0.9493670886075949, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.967741935483871, 'recall': 0.967741935483871, 'f1': 0.967741935483871, 'support': 62}, {'label': 'sport', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_chi2_k500_random_forest', 'timestamp': '2025-10-21T13:07:39.522409', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.9631779193878174, 'features_extracted': 5000, 'reduction_time': 0.18687963485717773, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9589271666466519, 'recall': 0.9580838323353293, 'f1_score': 0.9582928824328064}, 'performance': {'train_time_seconds': 0.6683154106140137, 'total_time_seconds': 1.8183729648590088, 'inference_time_ms_per_sample': 1.313773457875509}, 'confusion_matrix': [[74, 0, 1, 0, 2], [0, 56, 1, 1, 0], [3, 0, 59, 0, 0], [1, 0, 0, 75, 1], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9135802469135802, 'recall': 0.961038961038961, 'f1': 0.9367088607594937, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'tech', 'precision': 0.9491525423728814, 'recall': 0.9333333333333333, 'f1': 0.9411764705882353, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_svm', 'timestamp': '2025-10-21T13:05:12.526739', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.91782546043396, 'features_extracted': 5000, 'reduction_time': 0.1746985912322998, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9492687808402563, 'recall': 0.9491017964071856, 'f1_score': 0.9488098068555353}, 'performance': {'train_time_seconds': 0.19890618324279785, 'total_time_seconds': 3.2914302349090576, 'inference_time_ms_per_sample': 0.007485201258859235}, 'confusion_matrix': [[71, 1, 2, 1, 2], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 2, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9322033898305084, 'recall': 0.9482758620689655, 'f1': 0.9401709401709402, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.967741935483871, 'f1': 0.9523809523809523, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_chi2_k1000_naive_bayes', 'timestamp': '2025-10-21T13:07:46.416002', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.129448652267456, 'features_extracted': 5000, 'reduction_time': 0.16614603996276855, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9791281994948433, 'recall': 0.9790419161676647, 'f1_score': 0.9790099071105288}, 'performance': {'train_time_seconds': 0.04185223579406738, 'total_time_seconds': 1.337446928024292, 'inference_time_ms_per_sample': 0.007070467143715498}, 'confusion_matrix': [[75, 1, 0, 0, 1], [0, 55, 2, 0, 1], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9672131147540983, 'recall': 0.9833333333333333, 'f1': 0.9752066115702479, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k500_naive_bayes', 'timestamp': '2025-10-21T12:58:33.050571', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 0.4868159294128418, 'features_extracted': 5000, 'reduction_time': 0.13109803199768066, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9764910292311348, 'recall': 0.9760479041916168, 'f1_score': 0.9759020155011993}, 'performance': {'train_time_seconds': 0.00901341438293457, 'total_time_seconds': 0.626927375793457, 'inference_time_ms_per_sample': 0.00265900960225545}, 'confusion_matrix': [[75, 0, 1, 0, 1], [1, 53, 2, 0, 2], [0, 0, 62, 0, 0], [0, 0, 0, 77, 0], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'entertainment', 'precision': 0.9814814814814815, 'recall': 0.9137931034482759, 'f1': 0.9464285714285714, 'support': 58}, {'label': 'politics', 'precision': 0.9538461538461539, 'recall': 1.0, 'f1': 0.9763779527559056, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9516129032258065, 'recall': 0.9833333333333333, 'f1': 0.9672131147540983, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n300_svm', 'timestamp': '2025-10-21T13:09:25.542356', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.0847766399383545, 'features_extracted': 5000, 'reduction_time': 55.00177884101868, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9700598802395209, 'precision': 0.97004884004884, 'recall': 0.9700598802395209, 'f1_score': 0.9699957911003121}, 'performance': {'train_time_seconds': 17.38807702064514, 'total_time_seconds': 73.47463250160217, 'inference_time_ms_per_sample': 0.025490800777595198}, 'confusion_matrix': [[72, 1, 3, 0, 1], [0, 57, 1, 0, 0], [2, 0, 59, 1, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.96, 'recall': 0.935064935064935, 'f1': 0.9473684210526315, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_pca_n300_naive_bayes', 'timestamp': '2025-10-21T13:05:15.868433', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 0.46632885932922363, 'features_extracted': 5000, 'reduction_time': 2.895212173461914, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.592814371257485, 'precision': 0.7802294765308093, 'recall': 0.592814371257485, 'f1_score': 0.5469539333326039}, 'performance': {'train_time_seconds': 0.01089620590209961, 'total_time_seconds': 3.3724372386932373, 'inference_time_ms_per_sample': 0.0016389492743029564}, 'confusion_matrix': [[68, 0, 0, 9, 0], [28, 6, 0, 24, 0], [25, 0, 27, 10, 0], [1, 0, 0, 76, 0], [33, 0, 0, 6, 21]], 'per_class_metrics': [{'label': 'business', 'precision': 0.43870967741935485, 'recall': 0.8831168831168831, 'f1': 0.5862068965517241, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.10344827586206896, 'f1': 0.1875, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.43548387096774194, 'f1': 0.6067415730337079, 'support': 62}, {'label': 'sport', 'precision': 0.608, 'recall': 0.987012987012987, 'f1': 0.7524752475247525, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.35, 'f1': 0.5185185185185185, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_chi2_k1000_random_forest', 'timestamp': '2025-10-21T13:07:47.771211', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.0626723766326904, 'features_extracted': 5000, 'reduction_time': 0.19446492195129395, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9592027402957266, 'recall': 0.9580838323353293, 'f1_score': 0.9583270307416183}, 'performance': {'train_time_seconds': 0.5865724086761475, 'total_time_seconds': 1.8437097072601318, 'inference_time_ms_per_sample': 0.23440115466089306}, 'confusion_matrix': [[73, 0, 2, 0, 2], [2, 55, 0, 1, 0], [2, 0, 60, 0, 0], [1, 0, 0, 76, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9012345679012346, 'recall': 0.948051948051948, 'f1': 0.9240506329113924, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k500_decision_tree', 'timestamp': '2025-10-21T13:05:06.487959', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.6276748180389404, 'features_extracted': 5000, 'reduction_time': 0.13436055183410645, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.7784431137724551, 'precision': 0.7795401418367189, 'recall': 0.7784431137724551, 'f1_score': 0.7768763739040079}, 'performance': {'train_time_seconds': 0.08132529258728027, 'total_time_seconds': 1.8433606624603271, 'inference_time_ms_per_sample': 0.0021314906502912147}, 'confusion_matrix': [[57, 3, 8, 4, 5], [6, 41, 4, 6, 1], [12, 2, 41, 4, 3], [2, 2, 0, 70, 3], [6, 1, 2, 0, 51]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6867469879518072, 'recall': 0.7402597402597403, 'f1': 0.7125, 'support': 77}, {'label': 'entertainment', 'precision': 0.8367346938775511, 'recall': 0.7068965517241379, 'f1': 0.7663551401869159, 'support': 58}, {'label': 'politics', 'precision': 0.7454545454545455, 'recall': 0.6612903225806451, 'f1': 0.7008547008547008, 'support': 62}, {'label': 'sport', 'precision': 0.8333333333333334, 'recall': 0.9090909090909091, 'f1': 0.8695652173913043, 'support': 77}, {'label': 'tech', 'precision': 0.8095238095238095, 'recall': 0.85, 'f1': 0.8292682926829268, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n300_decision_tree', 'timestamp': '2025-10-21T13:12:33.623691', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 2.4712212085723877, 'features_extracted': 5000, 'reduction_time': 69.57891821861267, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.625748502994012, 'precision': 0.6361675338928134, 'recall': 0.625748502994012, 'f1_score': 0.6287380632179407}, 'performance': {'train_time_seconds': 2.633044719696045, 'total_time_seconds': 74.6831841468811, 'inference_time_ms_per_sample': 0.0021978766618374578}, 'confusion_matrix': [[46, 10, 9, 3, 9], [7, 31, 11, 6, 3], [9, 7, 36, 9, 1], [2, 11, 3, 60, 1], [6, 12, 5, 1, 36]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6571428571428571, 'recall': 0.5974025974025974, 'f1': 0.6258503401360545, 'support': 77}, {'label': 'entertainment', 'precision': 0.43661971830985913, 'recall': 0.5344827586206896, 'f1': 0.4806201550387597, 'support': 58}, {'label': 'politics', 'precision': 0.5625, 'recall': 0.5806451612903226, 'f1': 0.5714285714285714, 'support': 62}, {'label': 'sport', 'precision': 0.759493670886076, 'recall': 0.7792207792207793, 'f1': 0.7692307692307693, 'support': 77}, {'label': 'tech', 'precision': 0.72, 'recall': 0.6, 'f1': 0.6545454545454545, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_pca_n300_svm', 'timestamp': '2025-10-21T13:05:11.722942', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.0311501026153564, 'features_extracted': 5000, 'reduction_time': 2.940229654312134, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.979473277976272, 'recall': 0.9790419161676647, 'f1_score': 0.9790700186944252}, 'performance': {'train_time_seconds': 0.1661081314086914, 'total_time_seconds': 4.137487888336182, 'inference_time_ms_per_sample': 0.0013562733541705651}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_none_default_decision_tree', 'timestamp': '2025-10-21T13:07:57.225857', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 2.458287477493286, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7754491017964071, 'precision': 0.7838044303814433, 'recall': 0.7754491017964071, 'f1_score': 0.7769709676702614}, 'performance': {'train_time_seconds': 2.730668544769287, 'total_time_seconds': 5.188956022262573, 'inference_time_ms_per_sample': 0.003330721826610451}, 'confusion_matrix': [[57, 1, 9, 5, 5], [4, 42, 5, 6, 1], [8, 2, 46, 3, 3], [5, 1, 4, 66, 1], [4, 0, 7, 1, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7307692307692307, 'recall': 0.7402597402597403, 'f1': 0.7354838709677419, 'support': 77}, {'label': 'entertainment', 'precision': 0.9130434782608695, 'recall': 0.7241379310344828, 'f1': 0.8076923076923077, 'support': 58}, {'label': 'politics', 'precision': 0.647887323943662, 'recall': 0.7419354838709677, 'f1': 0.6917293233082706, 'support': 62}, {'label': 'sport', 'precision': 0.8148148148148148, 'recall': 0.8571428571428571, 'f1': 0.8354430379746836, 'support': 77}, {'label': 'tech', 'precision': 0.8275862068965517, 'recall': 0.8, 'f1': 0.8135593220338984, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_svd_n300_random_forest', 'timestamp': '2025-10-21T13:03:49.911112', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.7122464179992676, 'features_extracted': 10000, 'reduction_time': 51.65170955657959, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.8832335329341318, 'precision': 0.8919948448092161, 'recall': 0.8832335329341318, 'f1_score': 0.8815055798633552}, 'performance': {'train_time_seconds': 0.24036073684692383, 'total_time_seconds': 53.60431671142578, 'inference_time_ms_per_sample': 0.09389551813730937}, 'confusion_matrix': [[76, 0, 1, 0, 0], [4, 46, 1, 7, 0], [6, 1, 49, 6, 0], [0, 1, 0, 76, 0], [5, 2, 4, 1, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8351648351648352, 'recall': 0.987012987012987, 'f1': 0.9047619047619048, 'support': 77}, {'label': 'entertainment', 'precision': 0.92, 'recall': 0.7931034482758621, 'f1': 0.8518518518518519, 'support': 58}, {'label': 'politics', 'precision': 0.8909090909090909, 'recall': 0.7903225806451613, 'f1': 0.8376068376068376, 'support': 62}, {'label': 'sport', 'precision': 0.8444444444444444, 'recall': 0.987012987012987, 'f1': 0.9101796407185628, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.8, 'f1': 0.8888888888888888, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_decision_tree', 'timestamp': '2025-10-21T13:09:29.794411', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 6.5147621631622314, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7729690257820706, 'recall': 0.7694610778443114, 'f1_score': 0.7695580602879214}, 'performance': {'train_time_seconds': 2.2202770709991455, 'total_time_seconds': 8.735039234161377, 'inference_time_ms_per_sample': 0.005161690854740713}, 'confusion_matrix': [[56, 3, 11, 2, 5], [5, 39, 6, 7, 1], [8, 2, 46, 2, 4], [2, 4, 3, 67, 1], [6, 0, 4, 1, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7272727272727273, 'recall': 0.7272727272727273, 'f1': 0.7272727272727273, 'support': 77}, {'label': 'entertainment', 'precision': 0.8125, 'recall': 0.6724137931034483, 'f1': 0.7358490566037735, 'support': 58}, {'label': 'politics', 'precision': 0.6571428571428571, 'recall': 0.7419354838709677, 'f1': 0.696969696969697, 'support': 62}, {'label': 'sport', 'precision': 0.8481012658227848, 'recall': 0.8701298701298701, 'f1': 0.8589743589743589, 'support': 77}, {'label': 'tech', 'precision': 0.8166666666666667, 'recall': 0.8166666666666667, 'f1': 0.8166666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_pca_n500_decision_tree', 'timestamp': '2025-10-21T13:07:00.645232', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.080005168914795, 'features_extracted': 5000, 'reduction_time': 31.866745471954346, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9251497005988024, 'precision': 0.9256395794448591, 'recall': 0.9251497005988024, 'f1_score': 0.9248858552959698}, 'performance': {'train_time_seconds': 1.359027624130249, 'total_time_seconds': 34.30577826499939, 'inference_time_ms_per_sample': 0.0026118969489000517}, 'confusion_matrix': [[70, 2, 5, 0, 0], [1, 53, 1, 0, 3], [2, 4, 52, 1, 3], [1, 0, 1, 75, 0], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9459459459459459, 'recall': 0.9090909090909091, 'f1': 0.9271523178807947, 'support': 77}, {'label': 'entertainment', 'precision': 0.8833333333333333, 'recall': 0.9137931034482759, 'f1': 0.8983050847457628, 'support': 58}, {'label': 'politics', 'precision': 0.8813559322033898, 'recall': 0.8387096774193549, 'f1': 0.859504132231405, 'support': 62}, {'label': 'sport', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'tech', 'precision': 0.9076923076923077, 'recall': 0.9833333333333333, 'f1': 0.944, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_pca_n500_svm', 'timestamp': '2025-10-21T13:05:54.023668', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.0021846294403076, 'features_extracted': 5000, 'reduction_time': 27.153167724609375, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.979473277976272, 'recall': 0.9790419161676647, 'f1_score': 0.9790700186944252}, 'performance': {'train_time_seconds': 0.26601409912109375, 'total_time_seconds': 28.421366453170776, 'inference_time_ms_per_sample': 0.0027896401411045095}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k1000_random_forest', 'timestamp': '2025-10-21T12:58:40.099840', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5072946548461914, 'features_extracted': 5000, 'reduction_time': 0.13511896133422852, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9528874213598121, 'recall': 0.9520958083832335, 'f1_score': 0.9520363843469225}, 'performance': {'train_time_seconds': 0.7187511920928955, 'total_time_seconds': 1.3611648082733154, 'inference_time_ms_per_sample': 0.20461168117865833}, 'confusion_matrix': [[73, 0, 2, 0, 2], [1, 53, 0, 2, 2], [2, 0, 59, 1, 0], [0, 0, 0, 77, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9240506329113924, 'recall': 0.948051948051948, 'f1': 0.9358974358974359, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9137931034482759, 'f1': 0.954954954954955, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9333333333333333, 'recall': 0.9333333333333333, 'f1': 0.9333333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_decision_tree', 'timestamp': '2025-10-21T13:01:07.792255', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 2.357182502746582, 'features_extracted': 10000, 'reduction_time': 0.27425432205200195, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7784431137724551, 'precision': 0.7820767640639236, 'recall': 0.7784431137724551, 'f1_score': 0.7787006522958154}, 'performance': {'train_time_seconds': 0.12883710861206055, 'total_time_seconds': 2.7602739334106445, 'inference_time_ms_per_sample': 0.003114431918024303}, 'confusion_matrix': [[59, 2, 9, 4, 3], [5, 42, 4, 5, 2], [12, 3, 42, 2, 3], [3, 2, 3, 68, 1], [8, 1, 1, 1, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6781609195402298, 'recall': 0.7662337662337663, 'f1': 0.7195121951219512, 'support': 77}, {'label': 'entertainment', 'precision': 0.84, 'recall': 0.7241379310344828, 'f1': 0.7777777777777778, 'support': 58}, {'label': 'politics', 'precision': 0.711864406779661, 'recall': 0.6774193548387096, 'f1': 0.6942148760330579, 'support': 62}, {'label': 'sport', 'precision': 0.85, 'recall': 0.8831168831168831, 'f1': 0.8662420382165605, 'support': 77}, {'label': 'tech', 'precision': 0.8448275862068966, 'recall': 0.8166666666666667, 'f1': 0.8305084745762712, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_svd_n300_logistic', 'timestamp': '2025-10-21T13:01:10.567477', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.721118688583374, 'features_extracted': 10000, 'reduction_time': 10.813473224639893, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.9641165228313715, 'recall': 0.9640718562874252, 'f1_score': 0.9640051880045576}, 'performance': {'train_time_seconds': 0.4311497211456299, 'total_time_seconds': 12.965741634368896, 'inference_time_ms_per_sample': 0.0016603641167372287}, 'confusion_matrix': [[73, 1, 2, 0, 1], [1, 55, 1, 1, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.948051948051948, 'recall': 0.948051948051948, 'f1': 0.948051948051948, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1': 0.9666666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_svd_n300_logistic', 'timestamp': '2025-10-21T13:07:51.721033', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5114312171936035, 'features_extracted': 5000, 'reduction_time': 162.437397480011, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9910179640718563, 'precision': 0.9911695596149473, 'recall': 0.9910179640718563, 'f1_score': 0.9910307515151535}, 'performance': {'train_time_seconds': 0.04974937438964844, 'total_time_seconds': 162.99857807159424, 'inference_time_ms_per_sample': 0.0014233731937979511}, 'confusion_matrix': [[77, 0, 0, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9838709677419355, 'recall': 0.9838709677419355, 'f1': 0.9838709677419355, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9833333333333333, 'f1': 0.9915966386554622, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n500_svm', 'timestamp': '2025-10-21T12:56:57.229311', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.068403720855713, 'features_extracted': 5000, 'reduction_time': 47.20204830169678, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.95245745977042, 'recall': 0.9520958083832335, 'f1_score': 0.9519860198586759}, 'performance': {'train_time_seconds': 19.901919841766357, 'total_time_seconds': 68.17237186431885, 'inference_time_ms_per_sample': 0.005288038425102919}, 'confusion_matrix': [[71, 1, 3, 1, 1], [0, 55, 1, 2, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [0, 2, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9594594594594594, 'recall': 0.922077922077922, 'f1': 0.9403973509933775, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9206349206349206, 'recall': 0.9354838709677419, 'f1': 0.928, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_none_default_naive_bayes', 'timestamp': '2025-10-21T13:07:52.784191', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.0432376861572266, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9764315665903217, 'recall': 0.9760479041916168, 'f1_score': 0.9760572736773053}, 'performance': {'train_time_seconds': 0.22748470306396484, 'total_time_seconds': 1.2707223892211914, 'inference_time_ms_per_sample': 0.03943828765503661}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9866666666666667, 'recall': 0.961038961038961, 'f1': 0.9736842105263158, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9516129032258065, 'recall': 0.9833333333333333, 'f1': 0.9672131147540983, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n500_naive_bayes', 'timestamp': '2025-10-21T12:58:05.475362', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.842015266418457, 'features_extracted': 5000, 'reduction_time': 8.587058067321777, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.5329341317365269, 'precision': 0.5409022990433698, 'recall': 0.5329341317365269, 'f1_score': 0.528508189093391}, 'performance': {'train_time_seconds': 0.1042332649230957, 'total_time_seconds': 10.53330659866333, 'inference_time_ms_per_sample': 0.0036719316493965194}, 'confusion_matrix': [[30, 8, 7, 16, 16], [3, 30, 2, 19, 4], [7, 3, 31, 14, 7], [4, 6, 11, 53, 3], [7, 4, 12, 3, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5882352941176471, 'recall': 0.38961038961038963, 'f1': 0.46875, 'support': 77}, {'label': 'entertainment', 'precision': 0.5882352941176471, 'recall': 0.5172413793103449, 'f1': 0.5504587155963303, 'support': 58}, {'label': 'politics', 'precision': 0.49206349206349204, 'recall': 0.5, 'f1': 0.496, 'support': 62}, {'label': 'sport', 'precision': 0.5047619047619047, 'recall': 0.6883116883116883, 'f1': 0.5824175824175825, 'support': 77}, {'label': 'tech', 'precision': 0.53125, 'recall': 0.5666666666666667, 'f1': 0.5483870967741935, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_random_forest', 'timestamp': '2025-10-21T13:09:25.019867', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 3.4840221405029297, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9570552642093025, 'recall': 0.9550898203592815, 'f1_score': 0.9553410479190152}, 'performance': {'train_time_seconds': 1.1184580326080322, 'total_time_seconds': 4.602480173110962, 'inference_time_ms_per_sample': 0.42960672321433796}, 'confusion_matrix': [[74, 0, 1, 0, 2], [1, 54, 0, 2, 1], [5, 0, 57, 0, 0], [1, 0, 0, 76, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.891566265060241, 'recall': 0.961038961038961, 'f1': 0.925, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9310344827586207, 'f1': 0.9642857142857143, 'support': 58}, {'label': 'politics', 'precision': 0.9827586206896551, 'recall': 0.9193548387096774, 'f1': 0.95, 'support': 62}, {'label': 'sport', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_naive_bayes', 'timestamp': '2025-10-21T13:05:15.840056', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 2.4644343852996826, 'features_extracted': 5000, 'reduction_time': 0.13908624649047852, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9730538922155688, 'precision': 0.9737496602766063, 'recall': 0.9730538922155688, 'f1_score': 0.9729928141568138}, 'performance': {'train_time_seconds': 0.016907930374145508, 'total_time_seconds': 2.6204285621643066, 'inference_time_ms_per_sample': 0.004591342217907935}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 54, 2, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n500_svm', 'timestamp': '2025-10-21T12:59:15.218400', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.693120241165161, 'features_extracted': 10000, 'reduction_time': 30.339335441589355, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9553885024437342, 'recall': 0.9550898203592815, 'f1_score': 0.9550230061056472}, 'performance': {'train_time_seconds': 17.726267099380493, 'total_time_seconds': 50.75872278213501, 'inference_time_ms_per_sample': 0.00796846286979264}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 55, 1, 2, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [0, 2, 2, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9605263157894737, 'recall': 0.948051948051948, 'f1': 0.954248366013072, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9206349206349206, 'recall': 0.9354838709677419, 'f1': 0.928, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_svd_n300_logistic', 'timestamp': '2025-10-21T12:58:43.479536', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.721653938293457, 'features_extracted': 5000, 'reduction_time': 2.8649544715881348, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9700598802395209, 'precision': 0.970683682925388, 'recall': 0.9700598802395209, 'f1_score': 0.969878180796915}, 'performance': {'train_time_seconds': 0.41942262649536133, 'total_time_seconds': 4.006031036376953, 'inference_time_ms_per_sample': 0.0017838563747748645}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 55, 1, 1, 0], [0, 0, 61, 1, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9861111111111112, 'recall': 0.922077922077922, 'f1': 0.9530201342281879, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9836065573770492, 'recall': 1.0, 'f1': 0.9917355371900827, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n300_svm', 'timestamp': '2025-10-21T13:10:46.817398', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 8.177136182785034, 'features_extracted': 10000, 'reduction_time': 65.00843167304993, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9669744984861264, 'recall': 0.9670658682634731, 'f1_score': 0.966919993074902}, 'performance': {'train_time_seconds': 22.60979437828064, 'total_time_seconds': 95.7953622341156, 'inference_time_ms_per_sample': 0.0027325338946131176}, 'confusion_matrix': [[72, 1, 3, 0, 1], [0, 56, 1, 1, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.96, 'recall': 0.935064935064935, 'f1': 0.9473684210526315, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9836065573770492, 'recall': 1.0, 'f1': 0.9917355371900827, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k500_logistic', 'timestamp': '2025-10-21T13:04:43.874692', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.8496215343475342, 'features_extracted': 5000, 'reduction_time': 0.18430829048156738, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9495617956125221, 'recall': 0.9491017964071856, 'f1_score': 0.948905694821008}, 'performance': {'train_time_seconds': 11.345314025878906, 'total_time_seconds': 13.379243850708008, 'inference_time_ms_per_sample': 0.05319232712248842}, 'confusion_matrix': [[70, 2, 3, 1, 1], [1, 56, 0, 1, 0], [1, 1, 59, 1, 0], [0, 0, 0, 77, 0], [3, 2, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9333333333333333, 'recall': 0.9090909090909091, 'f1': 0.9210526315789473, 'support': 77}, {'label': 'entertainment', 'precision': 0.9180327868852459, 'recall': 0.9655172413793104, 'f1': 0.9411764705882353, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9821428571428571, 'recall': 0.9166666666666666, 'f1': 0.9482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n300_random_forest', 'timestamp': '2025-10-21T12:58:32.772734', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6664080619812012, 'features_extracted': 10000, 'reduction_time': 3.880789279937744, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.8473053892215568, 'precision': 0.8557731805270882, 'recall': 0.8473053892215568, 'f1_score': 0.8471911626987415}, 'performance': {'train_time_seconds': 0.47530531883239746, 'total_time_seconds': 6.022502660751343, 'inference_time_ms_per_sample': 0.10471215505086019}, 'confusion_matrix': [[70, 1, 5, 0, 1], [5, 46, 0, 5, 2], [7, 1, 50, 4, 0], [2, 3, 0, 72, 0], [10, 3, 2, 0, 45]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7446808510638298, 'recall': 0.9090909090909091, 'f1': 0.8187134502923976, 'support': 77}, {'label': 'entertainment', 'precision': 0.8518518518518519, 'recall': 0.7931034482758621, 'f1': 0.8214285714285714, 'support': 58}, {'label': 'politics', 'precision': 0.8771929824561403, 'recall': 0.8064516129032258, 'f1': 0.8403361344537815, 'support': 62}, {'label': 'sport', 'precision': 0.8888888888888888, 'recall': 0.935064935064935, 'f1': 0.9113924050632911, 'support': 77}, {'label': 'tech', 'precision': 0.9375, 'recall': 0.75, 'f1': 0.8333333333333334, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_pca_n300_logistic', 'timestamp': '2025-10-21T13:05:08.049382', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.48766303062438965, 'features_extracted': 5000, 'reduction_time': 3.118912696838379, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9850299401197605, 'precision': 0.985310628742515, 'recall': 0.9850299401197605, 'f1_score': 0.9850993907933737}, 'performance': {'train_time_seconds': 0.05446147918701172, 'total_time_seconds': 3.6610372066497803, 'inference_time_ms_per_sample': 0.0018559530109702469}, 'confusion_matrix': [[75, 0, 2, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 0.9833333333333333, 'f1': 0.9915966386554622, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_chi2_k500_decision_tree', 'timestamp': '2025-10-21T13:07:41.795620', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.2077152729034424, 'features_extracted': 5000, 'reduction_time': 0.1836073398590088, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.8173652694610778, 'precision': 0.8179836392177247, 'recall': 0.8173652694610778, 'f1_score': 0.8169996179353054}, 'performance': {'train_time_seconds': 0.15802979469299316, 'total_time_seconds': 1.5493524074554443, 'inference_time_ms_per_sample': 0.002609041636575482}, 'confusion_matrix': [[58, 3, 6, 4, 6], [4, 46, 4, 3, 1], [9, 2, 48, 3, 0], [3, 1, 0, 72, 1], [6, 2, 2, 1, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.725, 'recall': 0.7532467532467533, 'f1': 0.7388535031847133, 'support': 77}, {'label': 'entertainment', 'precision': 0.8518518518518519, 'recall': 0.7931034482758621, 'f1': 0.8214285714285714, 'support': 58}, {'label': 'politics', 'precision': 0.8, 'recall': 0.7741935483870968, 'f1': 0.7868852459016393, 'support': 62}, {'label': 'sport', 'precision': 0.8674698795180723, 'recall': 0.935064935064935, 'f1': 0.9, 'support': 77}, {'label': 'tech', 'precision': 0.8596491228070176, 'recall': 0.8166666666666667, 'f1': 0.8376068376068376, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_svd_n300_naive_bayes', 'timestamp': '2025-10-21T13:06:23.830569', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.7148122787475586, 'features_extracted': 5000, 'reduction_time': 7.176835298538208, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.5838323353293413, 'precision': 0.5871535398103316, 'recall': 0.5838323353293413, 'f1_score': 0.5831316809873897}, 'performance': {'train_time_seconds': 0.00707244873046875, 'total_time_seconds': 8.898720026016235, 'inference_time_ms_per_sample': 0.0019794452690078826}, 'confusion_matrix': [[46, 5, 8, 7, 11], [4, 39, 2, 8, 5], [4, 8, 33, 8, 9], [4, 13, 7, 50, 3], [12, 10, 7, 4, 27]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6571428571428571, 'recall': 0.5974025974025974, 'f1': 0.6258503401360545, 'support': 77}, {'label': 'entertainment', 'precision': 0.52, 'recall': 0.6724137931034483, 'f1': 0.5864661654135338, 'support': 58}, {'label': 'politics', 'precision': 0.5789473684210527, 'recall': 0.532258064516129, 'f1': 0.5546218487394958, 'support': 62}, {'label': 'sport', 'precision': 0.6493506493506493, 'recall': 0.6493506493506493, 'f1': 0.6493506493506493, 'support': 77}, {'label': 'tech', 'precision': 0.4909090909090909, 'recall': 0.45, 'f1': 0.46956521739130436, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n500_random_forest', 'timestamp': '2025-10-21T13:02:21.170799', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 2.417283773422241, 'features_extracted': 5000, 'reduction_time': 84.33489632606506, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.8413173652694611, 'precision': 0.8518544996037711, 'recall': 0.8413173652694611, 'f1_score': 0.8400937612857041}, 'performance': {'train_time_seconds': 0.7317929267883301, 'total_time_seconds': 87.48397302627563, 'inference_time_ms_per_sample': 0.10274698634347515}, 'confusion_matrix': [[69, 0, 4, 2, 2], [5, 44, 0, 9, 0], [6, 2, 47, 6, 1], [2, 0, 0, 75, 0], [8, 3, 2, 1, 46]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7666666666666667, 'recall': 0.8961038961038961, 'f1': 0.8263473053892215, 'support': 77}, {'label': 'entertainment', 'precision': 0.8979591836734694, 'recall': 0.7586206896551724, 'f1': 0.822429906542056, 'support': 58}, {'label': 'politics', 'precision': 0.8867924528301887, 'recall': 0.7580645161290323, 'f1': 0.8173913043478261, 'support': 62}, {'label': 'sport', 'precision': 0.8064516129032258, 'recall': 0.974025974025974, 'f1': 0.8823529411764706, 'support': 77}, {'label': 'tech', 'precision': 0.9387755102040817, 'recall': 0.7666666666666667, 'f1': 0.8440366972477065, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k500_naive_bayes', 'timestamp': '2025-10-21T13:05:00.295304', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 2.5288589000701904, 'features_extracted': 5000, 'reduction_time': 0.13412880897521973, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9823089592595371, 'recall': 0.9820359281437125, 'f1_score': 0.9820616790388387}, 'performance': {'train_time_seconds': 0.009320735931396484, 'total_time_seconds': 2.6723084449768066, 'inference_time_ms_per_sample': 0.0026297426509286114}, 'confusion_matrix': [[76, 0, 0, 0, 1], [1, 56, 0, 0, 1], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9672131147540983, 'recall': 0.9833333333333333, 'f1': 0.9752066115702479, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_pca_n500_logistic', 'timestamp': '2025-10-21T13:05:27.493332', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.050386905670166, 'features_extracted': 5000, 'reduction_time': 23.90876531600952, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9940119760479041, 'precision': 0.9940503608168278, 'recall': 0.9940119760479041, 'f1_score': 0.9940086167076787}, 'performance': {'train_time_seconds': 1.5540430545806885, 'total_time_seconds': 26.513195276260376, 'inference_time_ms_per_sample': 0.002159329945455768}, 'confusion_matrix': [[77, 0, 0, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9838709677419355, 'recall': 0.9838709677419355, 'f1': 0.9838709677419355, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n500_decision_tree', 'timestamp': '2025-10-21T13:03:48.705173', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 2.0633480548858643, 'features_extracted': 5000, 'reduction_time': 51.86408233642578, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.6586826347305389, 'precision': 0.6550600864259349, 'recall': 0.6586826347305389, 'f1_score': 0.6559981666424016}, 'performance': {'train_time_seconds': 1.2282698154449463, 'total_time_seconds': 55.15570020675659, 'inference_time_ms_per_sample': 0.0021664682262671924}, 'confusion_matrix': [[51, 8, 6, 4, 8], [7, 29, 7, 11, 4], [10, 6, 36, 4, 6], [3, 7, 2, 65, 0], [7, 6, 6, 2, 39]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6538461538461539, 'recall': 0.6623376623376623, 'f1': 0.6580645161290323, 'support': 77}, {'label': 'entertainment', 'precision': 0.5178571428571429, 'recall': 0.5, 'f1': 0.5087719298245614, 'support': 58}, {'label': 'politics', 'precision': 0.631578947368421, 'recall': 0.5806451612903226, 'f1': 0.6050420168067226, 'support': 62}, {'label': 'sport', 'precision': 0.7558139534883721, 'recall': 0.8441558441558441, 'f1': 0.7975460122699386, 'support': 77}, {'label': 'tech', 'precision': 0.6842105263157895, 'recall': 0.65, 'f1': 0.6666666666666666, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_svm', 'timestamp': '2025-10-21T13:00:03.116445', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6231625080108643, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.955132880061035, 'recall': 0.9550898203592815, 'f1_score': 0.954929793129267}, 'performance': {'train_time_seconds': 0.8094727993011475, 'total_time_seconds': 2.4326353073120117, 'inference_time_ms_per_sample': 0.002163612913942622}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [1, 1, 58, 1, 1], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.96, 'recall': 0.935064935064935, 'f1': 0.9473684210526315, 'support': 77}, {'label': 'entertainment', 'precision': 0.9491525423728814, 'recall': 0.9655172413793104, 'f1': 0.9572649572649573, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n300_svm', 'timestamp': '2025-10-21T13:00:19.253692', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.9251790046691895, 'features_extracted': 5000, 'reduction_time': 3.343489170074463, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.9612472706571393, 'recall': 0.9610778443113772, 'f1_score': 0.9608690821855964}, 'performance': {'train_time_seconds': 9.753958225250244, 'total_time_seconds': 16.022626399993896, 'inference_time_ms_per_sample': 0.0020058569080101513}, 'confusion_matrix': [[71, 1, 3, 1, 1], [0, 55, 1, 2, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9594594594594594, 'recall': 0.922077922077922, 'f1': 0.9403973509933775, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9836065573770492, 'recall': 1.0, 'f1': 0.9917355371900827, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k1000_svm', 'timestamp': '2025-10-21T12:58:38.525021', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5708105564117432, 'features_extracted': 5000, 'reduction_time': 0.13814759254455566, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9493306201985031, 'recall': 0.9491017964071856, 'f1_score': 0.9486712288048192}, 'performance': {'train_time_seconds': 0.14265084266662598, 'total_time_seconds': 0.8516089916229248, 'inference_time_ms_per_sample': 0.004753381192327259}, 'confusion_matrix': [[71, 1, 2, 1, 2], [0, 55, 1, 2, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [3, 3, 1, 0, 53]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9322033898305084, 'recall': 0.9482758620689655, 'f1': 0.9401709401709402, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9636363636363636, 'recall': 0.8833333333333333, 'f1': 0.9217391304347826, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n300_random_forest', 'timestamp': '2025-10-21T13:11:33.519445', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6963255405426025, 'features_extracted': 5000, 'reduction_time': 56.65960383415222, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.8592814371257484, 'precision': 0.8662905311717382, 'recall': 0.8592814371257484, 'f1_score': 0.8575404936884088}, 'performance': {'train_time_seconds': 1.4839725494384766, 'total_time_seconds': 59.8399019241333, 'inference_time_ms_per_sample': 0.6937345344863252}, 'confusion_matrix': [[72, 1, 1, 2, 1], [4, 43, 1, 9, 1], [7, 1, 48, 5, 1], [0, 0, 2, 75, 0], [6, 4, 1, 0, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8089887640449438, 'recall': 0.935064935064935, 'f1': 0.8674698795180723, 'support': 77}, {'label': 'entertainment', 'precision': 0.8775510204081632, 'recall': 0.7413793103448276, 'f1': 0.8037383177570093, 'support': 58}, {'label': 'politics', 'precision': 0.9056603773584906, 'recall': 0.7741935483870968, 'f1': 0.8347826086956521, 'support': 62}, {'label': 'sport', 'precision': 0.8241758241758241, 'recall': 0.974025974025974, 'f1': 0.8928571428571429, 'support': 77}, {'label': 'tech', 'precision': 0.9423076923076923, 'recall': 0.8166666666666667, 'f1': 0.875, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k500_logistic', 'timestamp': '2025-10-21T13:00:41.633316', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.9386179447174072, 'features_extracted': 10000, 'reduction_time': 0.26361846923828125, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9495617956125221, 'recall': 0.9491017964071856, 'f1_score': 0.948905694821008}, 'performance': {'train_time_seconds': 1.0289056301116943, 'total_time_seconds': 3.231142044067383, 'inference_time_ms_per_sample': 0.004350068326481802}, 'confusion_matrix': [[70, 2, 3, 1, 1], [1, 56, 0, 1, 0], [1, 1, 59, 1, 0], [0, 0, 0, 77, 0], [3, 2, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9333333333333333, 'recall': 0.9090909090909091, 'f1': 0.9210526315789473, 'support': 77}, {'label': 'entertainment', 'precision': 0.9180327868852459, 'recall': 0.9655172413793104, 'f1': 0.9411764705882353, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9821428571428571, 'recall': 0.9166666666666666, 'f1': 0.9482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n300_naive_bayes', 'timestamp': '2025-10-21T13:10:39.070373', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 3.0391228199005127, 'features_extracted': 5000, 'reduction_time': 51.23336148262024, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.49700598802395207, 'precision': 0.5109417528579205, 'recall': 0.49700598802395207, 'f1_score': 0.493993047782573}, 'performance': {'train_time_seconds': 0.10698723793029785, 'total_time_seconds': 54.37947154045105, 'inference_time_ms_per_sample': 0.01969451675871889}, 'confusion_matrix': [[28, 9, 9, 17, 14], [3, 28, 2, 18, 7], [6, 5, 31, 13, 7], [4, 11, 11, 47, 4], [4, 7, 13, 4, 32]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6222222222222222, 'recall': 0.36363636363636365, 'f1': 0.45901639344262296, 'support': 77}, {'label': 'entertainment', 'precision': 0.4666666666666667, 'recall': 0.4827586206896552, 'f1': 0.4745762711864407, 'support': 58}, {'label': 'politics', 'precision': 0.4696969696969697, 'recall': 0.5, 'f1': 0.484375, 'support': 62}, {'label': 'sport', 'precision': 0.47474747474747475, 'recall': 0.6103896103896104, 'f1': 0.5340909090909091, 'support': 77}, {'label': 'tech', 'precision': 0.5, 'recall': 0.5333333333333333, 'f1': 0.5161290322580645, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n500_logistic', 'timestamp': '2025-10-21T13:00:54.035751', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.5639257431030273, 'features_extracted': 5000, 'reduction_time': 6.161293268203735, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9553666788698633, 'recall': 0.9550898203592815, 'f1_score': 0.9550008050524863}, 'performance': {'train_time_seconds': 0.23241949081420898, 'total_time_seconds': 7.957638502120972, 'inference_time_ms_per_sample': 0.0019323326156524842}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 55, 1, 1, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.921875, 'recall': 0.9516129032258065, 'f1': 0.9365079365079365, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_svm', 'timestamp': '2025-10-21T13:00:59.615386', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.4067094326019287, 'features_extracted': 10000, 'reduction_time': 0.30031394958496094, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9492687808402563, 'recall': 0.9491017964071856, 'f1_score': 0.9488098068555353}, 'performance': {'train_time_seconds': 0.14721441268920898, 'total_time_seconds': 2.8542377948760986, 'inference_time_ms_per_sample': 0.005160263198578429}, 'confusion_matrix': [[71, 1, 2, 1, 2], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 2, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9322033898305084, 'recall': 0.9482758620689655, 'f1': 0.9401709401709402, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.967741935483871, 'f1': 0.9523809523809523, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_chi2_k500_svm', 'timestamp': '2025-10-21T13:07:36.910965', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.102191686630249, 'features_extracted': 5000, 'reduction_time': 0.18958568572998047, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9793057790794519, 'recall': 0.9790419161676647, 'f1_score': 0.9790628068071686}, 'performance': {'train_time_seconds': 0.04607558250427246, 'total_time_seconds': 1.337852954864502, 'inference_time_ms_per_sample': 0.002814624123944494}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 2, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9866666666666667, 'recall': 0.961038961038961, 'f1': 0.9736842105263158, 'support': 77}, {'label': 'entertainment', 'precision': 0.95, 'recall': 0.9827586206896551, 'f1': 0.9661016949152542, 'support': 58}, {'label': 'politics', 'precision': 0.9682539682539683, 'recall': 0.9838709677419355, 'f1': 0.976, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n500_logistic', 'timestamp': '2025-10-21T12:55:51.195698', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.1096909046173096, 'features_extracted': 5000, 'reduction_time': 55.2117440700531, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9553666788698633, 'recall': 0.9550898203592815, 'f1_score': 0.9550008050524863}, 'performance': {'train_time_seconds': 9.637257814407349, 'total_time_seconds': 65.95869278907776, 'inference_time_ms_per_sample': 0.03356276871915349}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 55, 1, 1, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.921875, 'recall': 0.9516129032258065, 'f1': 0.9365079365079365, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n500_naive_bayes', 'timestamp': '2025-10-21T13:00:05.997614', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.7218735218048096, 'features_extracted': 10000, 'reduction_time': 8.79366135597229, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.47305389221556887, 'precision': 0.4898371273647038, 'recall': 0.47305389221556887, 'f1_score': 0.46532977206903015}, 'performance': {'train_time_seconds': 0.06958913803100586, 'total_time_seconds': 10.585124015808105, 'inference_time_ms_per_sample': 0.0050824559377339075}, 'confusion_matrix': [[22, 18, 4, 13, 20], [3, 28, 1, 19, 7], [4, 13, 24, 10, 11], [3, 10, 10, 50, 4], [8, 9, 6, 3, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.55, 'recall': 0.2857142857142857, 'f1': 0.37606837606837606, 'support': 77}, {'label': 'entertainment', 'precision': 0.358974358974359, 'recall': 0.4827586206896552, 'f1': 0.4117647058823529, 'support': 58}, {'label': 'politics', 'precision': 0.5333333333333333, 'recall': 0.3870967741935484, 'f1': 0.4485981308411215, 'support': 62}, {'label': 'sport', 'precision': 0.5263157894736842, 'recall': 0.6493506493506493, 'f1': 0.5813953488372093, 'support': 77}, {'label': 'tech', 'precision': 0.4473684210526316, 'recall': 0.5666666666666667, 'f1': 0.5, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_logistic', 'timestamp': '2025-10-21T13:00:55.996838', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.754443645477295, 'features_extracted': 10000, 'reduction_time': 0.2762587070465088, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582480715261207, 'recall': 0.9580838323353293, 'f1_score': 0.9579495451843525}, 'performance': {'train_time_seconds': 0.5704948902130127, 'total_time_seconds': 3.6011972427368164, 'inference_time_ms_per_sample': 0.006095377984874977}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_logistic', 'timestamp': '2025-10-21T13:05:08.343888', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.822279930114746, 'features_extracted': 5000, 'reduction_time': 0.18422675132751465, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582480715261207, 'recall': 0.9580838323353293, 'f1_score': 0.9579495451843525}, 'performance': {'train_time_seconds': 1.158940076828003, 'total_time_seconds': 4.165446758270264, 'inference_time_ms_per_sample': 0.00643516015149876}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k1000_decision_tree', 'timestamp': '2025-10-21T12:58:41.545107', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.6093406677246094, 'features_extracted': 5000, 'reduction_time': 0.18863511085510254, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7994011976047904, 'precision': 0.8019461495985645, 'recall': 0.7994011976047904, 'f1_score': 0.7987767407459456}, 'performance': {'train_time_seconds': 0.12679386138916016, 'total_time_seconds': 1.924769639968872, 'inference_time_ms_per_sample': 0.002955248255929547}, 'confusion_matrix': [[62, 2, 6, 3, 4], [5, 40, 6, 5, 2], [10, 2, 45, 3, 2], [2, 3, 2, 70, 0], [7, 1, 2, 0, 50]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7209302325581395, 'recall': 0.8051948051948052, 'f1': 0.7607361963190185, 'support': 77}, {'label': 'entertainment', 'precision': 0.8333333333333334, 'recall': 0.6896551724137931, 'f1': 0.7547169811320755, 'support': 58}, {'label': 'politics', 'precision': 0.7377049180327869, 'recall': 0.7258064516129032, 'f1': 0.7317073170731707, 'support': 62}, {'label': 'sport', 'precision': 0.8641975308641975, 'recall': 0.9090909090909091, 'f1': 0.8860759493670886, 'support': 77}, {'label': 'tech', 'precision': 0.8620689655172413, 'recall': 0.8333333333333334, 'f1': 0.847457627118644, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k1000_logistic', 'timestamp': '2025-10-21T12:58:36.223984', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.747957706451416, 'features_extracted': 5000, 'reduction_time': 0.2319326400756836, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9493412900010231, 'recall': 0.9491017964071856, 'f1_score': 0.9487291399363083}, 'performance': {'train_time_seconds': 1.3057658672332764, 'total_time_seconds': 2.285656213760376, 'inference_time_ms_per_sample': 0.006331655079733112}, 'confusion_matrix': [[71, 1, 2, 1, 2], [1, 54, 1, 2, 0], [0, 0, 61, 1, 0], [0, 0, 0, 77, 0], [3, 2, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9473684210526315, 'recall': 0.9310344827586207, 'f1': 0.9391304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k500_logistic', 'timestamp': '2025-10-21T12:58:29.261013', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.1311838626861572, 'features_extracted': 5000, 'reduction_time': 0.1803886890411377, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.955096479972386, 'recall': 0.9550898203592815, 'f1_score': 0.9548787636704571}, 'performance': {'train_time_seconds': 1.2370555400848389, 'total_time_seconds': 2.548628091812134, 'inference_time_ms_per_sample': 0.02702981412053822}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 0, 60, 1, 1], [0, 0, 0, 77, 0], [3, 2, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n300_random_forest', 'timestamp': '2025-10-21T13:00:42.100079', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.7279973030090332, 'features_extracted': 5000, 'reduction_time': 4.794756174087524, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.8562874251497006, 'precision': 0.8621242528380139, 'recall': 0.8562874251497006, 'f1_score': 0.8561982105510918}, 'performance': {'train_time_seconds': 0.31194448471069336, 'total_time_seconds': 6.834697961807251, 'inference_time_ms_per_sample': 0.10056624155558512}, 'confusion_matrix': [[71, 1, 3, 1, 1], [4, 46, 0, 7, 1], [6, 0, 51, 5, 0], [3, 4, 0, 70, 0], [5, 4, 3, 0, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.797752808988764, 'recall': 0.922077922077922, 'f1': 0.8554216867469879, 'support': 77}, {'label': 'entertainment', 'precision': 0.8363636363636363, 'recall': 0.7931034482758621, 'f1': 0.8141592920353983, 'support': 58}, {'label': 'politics', 'precision': 0.8947368421052632, 'recall': 0.8225806451612904, 'f1': 0.8571428571428571, 'support': 62}, {'label': 'sport', 'precision': 0.8433734939759037, 'recall': 0.9090909090909091, 'f1': 0.875, 'support': 77}, {'label': 'tech', 'precision': 0.96, 'recall': 0.8, 'f1': 0.8727272727272727, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k500_naive_bayes', 'timestamp': '2025-10-21T13:00:48.561374', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.7845983505249023, 'features_extracted': 10000, 'reduction_time': 0.2703547477722168, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9823089592595371, 'recall': 0.9820359281437125, 'f1_score': 0.9820616790388387}, 'performance': {'train_time_seconds': 0.009134054183959961, 'total_time_seconds': 2.064087152481079, 'inference_time_ms_per_sample': 0.0024869770347001312}, 'confusion_matrix': [[76, 0, 0, 0, 1], [1, 56, 0, 0, 1], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9672131147540983, 'recall': 0.9833333333333333, 'f1': 0.9752066115702479, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k500_decision_tree', 'timestamp': '2025-10-21T12:58:34.804555', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.0693485736846924, 'features_extracted': 5000, 'reduction_time': 0.1916356086730957, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.7934131736526946, 'precision': 0.7949682879010527, 'recall': 0.7934131736526946, 'f1_score': 0.7925932783075914}, 'performance': {'train_time_seconds': 0.14272379875183105, 'total_time_seconds': 1.4037079811096191, 'inference_time_ms_per_sample': 0.002999505596960376}, 'confusion_matrix': [[60, 3, 6, 3, 5], [4, 42, 4, 8, 0], [11, 2, 44, 2, 3], [2, 1, 1, 70, 3], [7, 2, 2, 0, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7142857142857143, 'recall': 0.7792207792207793, 'f1': 0.7453416149068323, 'support': 77}, {'label': 'entertainment', 'precision': 0.84, 'recall': 0.7241379310344828, 'f1': 0.7777777777777778, 'support': 58}, {'label': 'politics', 'precision': 0.7719298245614035, 'recall': 0.7096774193548387, 'f1': 0.7394957983193278, 'support': 62}, {'label': 'sport', 'precision': 0.8433734939759037, 'recall': 0.9090909090909091, 'f1': 0.875, 'support': 77}, {'label': 'tech', 'precision': 0.8166666666666667, 'recall': 0.8166666666666667, 'f1': 0.8166666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_svd_n300_random_forest', 'timestamp': '2025-10-21T12:59:49.826092', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.49426770210266113, 'features_extracted': 5000, 'reduction_time': 2.6601459980010986, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.8652694610778443, 'precision': 0.8723286151555663, 'recall': 0.8652694610778443, 'f1_score': 0.864191453582739}, 'performance': {'train_time_seconds': 0.25342226028442383, 'total_time_seconds': 3.4078359603881836, 'inference_time_ms_per_sample': 0.09766809954614696}, 'confusion_matrix': [[69, 3, 2, 1, 2], [5, 47, 0, 6, 0], [6, 2, 49, 5, 0], [0, 0, 0, 77, 0], [5, 6, 1, 1, 47]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8117647058823529, 'recall': 0.8961038961038961, 'f1': 0.8518518518518519, 'support': 77}, {'label': 'entertainment', 'precision': 0.8103448275862069, 'recall': 0.8103448275862069, 'f1': 0.8103448275862069, 'support': 58}, {'label': 'politics', 'precision': 0.9423076923076923, 'recall': 0.7903225806451613, 'f1': 0.8596491228070176, 'support': 62}, {'label': 'sport', 'precision': 0.8555555555555555, 'recall': 1.0, 'f1': 0.9221556886227545, 'support': 77}, {'label': 'tech', 'precision': 0.9591836734693877, 'recall': 0.7833333333333333, 'f1': 0.8623853211009175, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k500_svm', 'timestamp': '2025-10-21T13:00:44.887512', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 3.15437388420105, 'features_extracted': 10000, 'reduction_time': 0.3427734375, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9521095217958485, 'recall': 0.9520958083832335, 'f1_score': 0.951900443887059}, 'performance': {'train_time_seconds': 0.1607213020324707, 'total_time_seconds': 3.6578686237335205, 'inference_time_ms_per_sample': 0.0029152738833855725}, 'confusion_matrix': [[71, 1, 4, 0, 1], [1, 55, 0, 2, 0], [1, 0, 60, 0, 1], [0, 0, 0, 77, 0], [3, 2, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9342105263157895, 'recall': 0.922077922077922, 'f1': 0.9281045751633987, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.967741935483871, 'f1': 0.9523809523809523, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_none_default_svm', 'timestamp': '2025-10-21T13:07:51.179109', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.7562706470489502, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582955955257405, 'recall': 0.9580838323353293, 'f1_score': 0.9579734972801608}, 'performance': {'train_time_seconds': 0.835099458694458, 'total_time_seconds': 1.5913701057434082, 'inference_time_ms_per_sample': 0.002931691929251848}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [2, 0, 59, 1, 0], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n300_logistic', 'timestamp': '2025-10-21T13:00:13.542377', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.5569851398468018, 'features_extracted': 5000, 'reduction_time': 2.944516658782959, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.967220084440634, 'recall': 0.9670658682634731, 'f1_score': 0.9668787539237004}, 'performance': {'train_time_seconds': 0.18973898887634277, 'total_time_seconds': 5.6912407875061035, 'inference_time_ms_per_sample': 0.0015804153716492797}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 56, 1, 0, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9726027397260274, 'recall': 0.922077922077922, 'f1': 0.9466666666666667, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.967741935483871, 'recall': 1.0, 'f1': 0.9836065573770492, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_decision_tree', 'timestamp': '2025-10-21T13:05:21.932819', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 2.2867414951324463, 'features_extracted': 5000, 'reduction_time': 0.20044302940368652, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7904191616766467, 'precision': 0.7943552324279511, 'recall': 0.7904191616766467, 'f1_score': 0.7911972562416145}, 'performance': {'train_time_seconds': 0.19538331031799316, 'total_time_seconds': 2.682567834854126, 'inference_time_ms_per_sample': 0.0046220368253970575}, 'confusion_matrix': [[56, 1, 10, 4, 6], [6, 44, 3, 4, 1], [9, 2, 47, 2, 2], [3, 2, 4, 68, 0], [4, 1, 4, 2, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.717948717948718, 'recall': 0.7272727272727273, 'f1': 0.7225806451612903, 'support': 77}, {'label': 'entertainment', 'precision': 0.88, 'recall': 0.7586206896551724, 'f1': 0.8148148148148148, 'support': 58}, {'label': 'politics', 'precision': 0.6911764705882353, 'recall': 0.7580645161290323, 'f1': 0.7230769230769231, 'support': 62}, {'label': 'sport', 'precision': 0.85, 'recall': 0.8831168831168831, 'f1': 0.8662420382165605, 'support': 77}, {'label': 'tech', 'precision': 0.8448275862068966, 'recall': 0.8166666666666667, 'f1': 0.8305084745762712, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n500_naive_bayes', 'timestamp': '2025-10-21T13:01:28.138264', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 3.0339667797088623, 'features_extracted': 5000, 'reduction_time': 49.9078106880188, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.4880239520958084, 'precision': 0.4871875806940995, 'recall': 0.4880239520958084, 'f1_score': 0.48375210831832743}, 'performance': {'train_time_seconds': 0.06585144996643066, 'total_time_seconds': 53.00762891769409, 'inference_time_ms_per_sample': 0.0026989839747994246}, 'confusion_matrix': [[29, 11, 5, 16, 16], [6, 29, 2, 16, 5], [8, 7, 25, 11, 11], [5, 9, 13, 48, 2], [13, 8, 5, 2, 32]], 'per_class_metrics': [{'label': 'business', 'precision': 0.47540983606557374, 'recall': 0.37662337662337664, 'f1': 0.42028985507246375, 'support': 77}, {'label': 'entertainment', 'precision': 0.453125, 'recall': 0.5, 'f1': 0.47540983606557374, 'support': 58}, {'label': 'politics', 'precision': 0.5, 'recall': 0.4032258064516129, 'f1': 0.44642857142857145, 'support': 62}, {'label': 'sport', 'precision': 0.5161290322580645, 'recall': 0.6233766233766234, 'f1': 0.5647058823529412, 'support': 77}, {'label': 'tech', 'precision': 0.48484848484848486, 'recall': 0.5333333333333333, 'f1': 0.5079365079365079, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_naive_bayes', 'timestamp': '2025-10-21T13:00:05.562148', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.606860876083374, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9769557169444895, 'recall': 0.9760479041916168, 'f1_score': 0.9760681744843009}, 'performance': {'train_time_seconds': 0.16846847534179688, 'total_time_seconds': 1.775329351425171, 'inference_time_ms_per_sample': 0.010465433497628766}, 'confusion_matrix': [[73, 0, 2, 0, 2], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9375, 'recall': 1.0, 'f1': 0.967741935483871, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_none_default_logistic', 'timestamp': '2025-10-21T13:05:02.778592', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5500969886779785, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9940119760479041, 'precision': 0.9940503608168278, 'recall': 0.9940119760479041, 'f1_score': 0.9940086167076787}, 'performance': {'train_time_seconds': 1.527048110961914, 'total_time_seconds': 2.0771450996398926, 'inference_time_ms_per_sample': 0.003015209814745509}, 'confusion_matrix': [[77, 0, 0, 0, 0], [0, 57, 1, 0, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9827586206896551, 'f1': 0.991304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9838709677419355, 'recall': 0.9838709677419355, 'f1': 0.9838709677419355, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_svd_n300_random_forest', 'timestamp': '2025-10-21T13:06:32.741318', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.838632583618164, 'features_extracted': 5000, 'reduction_time': 22.013195276260376, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.8383233532934131, 'precision': 0.8527636543606731, 'recall': 0.8383233532934131, 'f1_score': 0.8371985141645243}, 'performance': {'train_time_seconds': 0.23624849319458008, 'total_time_seconds': 24.08807635307312, 'inference_time_ms_per_sample': 0.10041705148662636}, 'confusion_matrix': [[72, 0, 2, 1, 2], [6, 43, 0, 8, 1], [9, 1, 46, 5, 1], [2, 2, 0, 73, 0], [7, 1, 2, 4, 46]], 'per_class_metrics': [{'label': 'business', 'precision': 0.75, 'recall': 0.935064935064935, 'f1': 0.8323699421965318, 'support': 77}, {'label': 'entertainment', 'precision': 0.9148936170212766, 'recall': 0.7413793103448276, 'f1': 0.819047619047619, 'support': 58}, {'label': 'politics', 'precision': 0.92, 'recall': 0.7419354838709677, 'f1': 0.8214285714285714, 'support': 62}, {'label': 'sport', 'precision': 0.8021978021978022, 'recall': 0.948051948051948, 'f1': 0.8690476190476191, 'support': 77}, {'label': 'tech', 'precision': 0.92, 'recall': 0.7666666666666667, 'f1': 0.8363636363636363, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n500_logistic', 'timestamp': '2025-10-21T12:58:45.505091', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.948129177093506, 'features_extracted': 10000, 'reduction_time': 25.3087317943573, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.9611079378179738, 'recall': 0.9610778443113772, 'f1_score': 0.9610100504984803}, 'performance': {'train_time_seconds': 1.4394886493682861, 'total_time_seconds': 29.696349620819092, 'inference_time_ms_per_sample': 0.007640101952467135}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 56, 1, 0, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n500_random_forest', 'timestamp': '2025-10-21T13:00:16.642849', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 2.8174712657928467, 'features_extracted': 10000, 'reduction_time': 8.997152328491211, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.8353293413173652, 'precision': 0.8457073898333426, 'recall': 0.8353293413173652, 'f1_score': 0.834265189493075}, 'performance': {'train_time_seconds': 0.36716723442077637, 'total_time_seconds': 12.181790828704834, 'inference_time_ms_per_sample': 0.10181401304142204}, 'confusion_matrix': [[69, 0, 3, 3, 2], [4, 43, 0, 11, 0], [5, 1, 50, 6, 0], [1, 3, 0, 73, 0], [9, 4, 3, 0, 44]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7840909090909091, 'recall': 0.8961038961038961, 'f1': 0.8363636363636363, 'support': 77}, {'label': 'entertainment', 'precision': 0.8431372549019608, 'recall': 0.7413793103448276, 'f1': 0.7889908256880734, 'support': 58}, {'label': 'politics', 'precision': 0.8928571428571429, 'recall': 0.8064516129032258, 'f1': 0.847457627118644, 'support': 62}, {'label': 'sport', 'precision': 0.7849462365591398, 'recall': 0.948051948051948, 'f1': 0.8588235294117647, 'support': 77}, {'label': 'tech', 'precision': 0.9565217391304348, 'recall': 0.7333333333333333, 'f1': 0.8301886792452831, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n500_random_forest', 'timestamp': '2025-10-21T12:58:16.024201', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5613861083984375, 'features_extracted': 5000, 'reduction_time': 5.172078609466553, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.8143712574850299, 'precision': 0.8273532523310462, 'recall': 0.8143712574850299, 'f1_score': 0.8111639814406696}, 'performance': {'train_time_seconds': 0.3358938694000244, 'total_time_seconds': 6.069358587265015, 'inference_time_ms_per_sample': 0.10824560405251508}, 'confusion_matrix': [[72, 0, 3, 2, 0], [4, 38, 1, 14, 1], [8, 1, 44, 8, 1], [0, 2, 1, 73, 1], [8, 4, 2, 1, 45]], 'per_class_metrics': [{'label': 'business', 'precision': 0.782608695652174, 'recall': 0.935064935064935, 'f1': 0.8520710059171598, 'support': 77}, {'label': 'entertainment', 'precision': 0.8444444444444444, 'recall': 0.6551724137931034, 'f1': 0.7378640776699029, 'support': 58}, {'label': 'politics', 'precision': 0.8627450980392157, 'recall': 0.7096774193548387, 'f1': 0.7787610619469026, 'support': 62}, {'label': 'sport', 'precision': 0.7448979591836735, 'recall': 0.948051948051948, 'f1': 0.8342857142857143, 'support': 77}, {'label': 'tech', 'precision': 0.9375, 'recall': 0.75, 'f1': 0.8333333333333334, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_pca_n300_random_forest', 'timestamp': '2025-10-21T13:05:19.252981', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5428793430328369, 'features_extracted': 5000, 'reduction_time': 3.151127338409424, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9759701913110029, 'recall': 0.9760479041916168, 'f1_score': 0.9759024926559149}, 'performance': {'train_time_seconds': 0.3113372325897217, 'total_time_seconds': 4.005343914031982, 'inference_time_ms_per_sample': 0.11014938354492188}, 'confusion_matrix': [[74, 1, 2, 0, 0], [0, 57, 0, 1, 0], [2, 0, 58, 1, 1], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9736842105263158, 'recall': 0.961038961038961, 'f1': 0.9673202614379085, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1': 0.9508196721311475, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9836065573770492, 'recall': 1.0, 'f1': 0.9917355371900827, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_chi2_k500_naive_bayes', 'timestamp': '2025-10-21T13:07:38.263383', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.0532057285308838, 'features_extracted': 5000, 'reduction_time': 0.17985177040100098, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9674554594864836, 'recall': 0.9670658682634731, 'f1_score': 0.9670692178531747}, 'performance': {'train_time_seconds': 0.01250314712524414, 'total_time_seconds': 1.245560646057129, 'inference_time_ms_per_sample': 0.0026061863242509125}, 'confusion_matrix': [[75, 0, 1, 0, 1], [1, 55, 2, 0, 0], [2, 0, 59, 1, 0], [0, 0, 0, 77, 0], [2, 1, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9375, 'recall': 0.974025974025974, 'f1': 0.9554140127388535, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'tfidf_m5000_n11_chi2_k500_logistic', 'timestamp': '2025-10-21T13:07:34.970452', 'extractor': {'type': 'tfidf', 'name': 'TF-IDF', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2, 'max_df': 0.8}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.0479092597961426, 'features_extracted': 5000, 'reduction_time': 0.21671843528747559, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9675942929941925, 'recall': 0.9670658682634731, 'f1_score': 0.9669764709584607}, 'performance': {'train_time_seconds': 0.6624515056610107, 'total_time_seconds': 1.927079200744629, 'inference_time_ms_per_sample': 0.0026454468687137447}, 'confusion_matrix': [[76, 0, 0, 0, 1], [0, 55, 1, 2, 0], [3, 0, 59, 0, 0], [0, 0, 0, 77, 0], [2, 2, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9382716049382716, 'recall': 0.987012987012987, 'f1': 0.9620253164556962, 'support': 77}, {'label': 'entertainment', 'precision': 0.9649122807017544, 'recall': 0.9482758620689655, 'f1': 0.9565217391304348, 'support': 58}, {'label': 'politics', 'precision': 0.9833333333333333, 'recall': 0.9516129032258065, 'f1': 0.9672131147540983, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}]};
    </script>
    
    <!-- Main script -->
    <script>

// ===== PIPELINE CALCULATION TOGGLE =====
function toggleCalculation() {
    const details = document.getElementById('calculation-details');
    const btn = event.target;
    
    if (details.style.display === 'none') {
        details.style.display = 'block';
        btn.textContent = '‚ùå Close explanation';
    } else {
        details.style.display = 'none';
        btn.textContent = 'üìä How are 180 pipelines calculated?';
    }
}

// ===== GLOBAL STATE =====
let selectedExtractor = 'tfidf';
let selectedReducer = 'none';
let selectedClassifiers = ['logistic', 'svm', 'naive_bayes'];

// ===== INITIALIZATION =====
document.addEventListener('DOMContentLoaded', function() {
    initializeBuilder();
    updatePreview();
    
    // Add change listeners
    document.querySelectorAll('input[name="extractor"]').forEach(radio => {
        radio.addEventListener('change', handleExtractorChange);
    });
    
    document.querySelectorAll('input[name="reducer"]').forEach(radio => {
        radio.addEventListener('change', handleReducerChange);
    });
    
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.addEventListener('change', handleClassifierChange);
    });
});

function initializeBuilder() {
    // Set initial checked states
    document.querySelector('input[name="extractor"][value="tfidf"]').checked = true;
    document.querySelector('input[name="reducer"][value="none"]').checked = true;
    
    ['logistic', 'svm', 'naive_bayes'].forEach(clf => {
        document.querySelector(`input[name="classifier"][value="${clf}"]`).checked = true;
    });
}

// ===== EVENT HANDLERS =====
function handleExtractorChange(e) {
    selectedExtractor = e.target.value;
    updateRadioStyles('extractor');
    updatePreview();
}

function handleReducerChange(e) {
    selectedReducer = e.target.value;
    updateRadioStyles('reducer');
    updatePreview();
}

function handleClassifierChange(e) {
    if (e.target.checked) {
        selectedClassifiers.push(e.target.value);
    } else {
        selectedClassifiers = selectedClassifiers.filter(c => c !== e.target.value);
    }
    updateCheckboxStyles();
    updatePreview();
}

function updateRadioStyles(name) {
    document.querySelectorAll(`input[name="${name}"]`).forEach(radio => {
        const label = radio.closest('label');
        if (radio.checked) {
            label.classList.add('checked');
        } else {
            label.classList.remove('checked');
        }
    });
}

function updateCheckboxStyles() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        const label = checkbox.closest('label');
        if (checkbox.checked) {
            label.classList.add('checked');
        } else {
            label.classList.remove('checked');
        }
    });
}

function updatePreview() {
    const count = selectedClassifiers.length;
    const extractorName = document.querySelector(`input[name="extractor"][value="${selectedExtractor}"]`).dataset.name;
    const reducerName = document.querySelector(`input[name="reducer"][value="${selectedReducer}"]`).dataset.name;
    
    document.getElementById('preview-count').textContent = count;
    
    const list = document.getElementById('preview-list');
    list.innerHTML = '';
    
    selectedClassifiers.forEach(clf => {
        const classifierName = document.querySelector(`input[name="classifier"][value="${clf}"]`).dataset.name;
        const li = document.createElement('li');
        li.textContent = `${extractorName} ‚Üí ${reducerName} ‚Üí ${classifierName}`;
        list.appendChild(li);
    });
}

// ===== CLASSIFIER ACTIONS =====
function selectAllClassifiers() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.checked = true;
        selectedClassifiers = Array.from(document.querySelectorAll('input[name="classifier"]')).map(cb => cb.value);
    });
    updateCheckboxStyles();
    updatePreview();
}

function deselectAllClassifiers() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.checked = false;
    });
    selectedClassifiers = [];
    updateCheckboxStyles();
    updatePreview();
}

function selectTopClassifiers() {
    // Top 3 fastest: Naive Bayes, SVM, Logistic
    deselectAllClassifiers();
    ['naive_bayes', 'svm', 'logistic'].forEach(clf => {
        const checkbox = document.querySelector(`input[name="classifier"][value="${clf}"]`);
        if (checkbox) {
            checkbox.checked = true;
            selectedClassifiers.push(clf);
        }
    });
    updateCheckboxStyles();
    updatePreview();
}

function resetBuilder() {
    selectedExtractor = 'tfidf';
    selectedReducer = 'none';
    selectedClassifiers = ['logistic', 'svm', 'naive_bayes'];
    initializeBuilder();
    updateRadioStyles('extractor');
    updateRadioStyles('reducer');
    updateCheckboxStyles();
    updatePreview();
    
    // Hide results if shown
    document.getElementById('results-section').style.display = 'none';
}

// ===== COMPARE PIPELINES =====
function comparePipelines() {
    if (selectedClassifiers.length === 0) {
        alert('Please select at least one classifier!');
        return;
    }
    
    // Filter matching pipelines
    const matchingPipelines = allPipelinesData.all_results.filter(pipeline => {
        return pipeline.extractor.type === selectedExtractor &&
               pipeline.reducer.type === selectedReducer &&
               selectedClassifiers.includes(pipeline.classifier.type);
    });
    
    if (matchingPipelines.length === 0) {
        alert('No matching pipelines found! Try different combinations.');
        return;
    }
    
    // Show results section
    document.getElementById('results-section').style.display = 'block';
    
    // Scroll to results
    document.getElementById('results-section').scrollIntoView({ behavior: 'smooth' });
    
    // Build visualizations
    buildBestCards(matchingPipelines);
    buildComparisonTable(matchingPipelines);
    buildHeatmap(allPipelinesData.all_results);
    buildTradeoffChart(allPipelinesData.all_results);
    buildConfusionMatrices(matchingPipelines);
}

// ===== BUILD BEST CARDS =====
function buildBestCards(pipelines) {
    const bestAccuracy = pipelines.reduce((a, b) => a.metrics.accuracy > b.metrics.accuracy ? a : b);
    const fastestTrain = pipelines.reduce((a, b) => a.performance.total_time_seconds < b.performance.total_time_seconds ? a : b);
    const fastestInfer = pipelines.reduce((a, b) => a.performance.inference_time_ms_per_sample < b.performance.inference_time_ms_per_sample ? a : b);
    
    const html = `
        <div class="best-card accuracy">
            <h3>üèÜ Best Accuracy</h3>
            <div class="metric-value" style="color: #10b981;">${(bestAccuracy.metrics.accuracy * 100).toFixed(2)}%</div>
            <div class="pipeline-name">${formatPipelineName(bestAccuracy)}</div>
        </div>
        <div class="best-card speed">
            <h3>‚ö° Fastest Training</h3>
            <div class="metric-value" style="color: #f59e0b;">${fastestTrain.performance.total_time_seconds.toFixed(2)}s</div>
            <div class="pipeline-name">${formatPipelineName(fastestTrain)}</div>
        </div>
        <div class="best-card size">
            <h3>üí® Fastest Inference</h3>
            <div class="metric-value" style="color: #3b82f6;">${fastestInfer.performance.inference_time_ms_per_sample.toFixed(2)}ms</div>
            <div class="pipeline-name">${formatPipelineName(fastestInfer)}</div>
        </div>
    `;
    
    document.getElementById('best-cards').innerHTML = html;
}

function formatPipelineName(pipeline) {
    return `${pipeline.extractor.name} ‚Üí ${pipeline.reducer.name} ‚Üí ${pipeline.classifier.name}`;
}

// ===== BUILD COMPARISON TABLE =====
function buildComparisonTable(pipelines) {
    // Find best values
    const bestAcc = Math.max(...pipelines.map(p => p.metrics.accuracy));
    const bestF1 = Math.max(...pipelines.map(p => p.metrics.f1_score));
    const bestTrain = Math.min(...pipelines.map(p => p.performance.total_time_seconds));
    const bestInfer = Math.min(...pipelines.map(p => p.performance.inference_time_ms_per_sample));
    
    let rows = '';
    pipelines.forEach(p => {
        const isBestAcc = p.metrics.accuracy === bestAcc;
        const isBestF1 = p.metrics.f1_score === bestF1;
        const isBestTrain = p.performance.total_time_seconds === bestTrain;
        const isBestInfer = p.performance.inference_time_ms_per_sample === bestInfer;
        
        rows += `
            <tr>
                <td class="pipeline-cell">${formatPipelineName(p)}</td>
                <td class="${isBestAcc ? 'metric-best' : ''}">${(p.metrics.accuracy * 100).toFixed(2)}%</td>
                <td class="${isBestF1 ? 'metric-best' : ''}">${(p.metrics.f1_score * 100).toFixed(2)}%</td>
                <td class="${isBestTrain ? 'metric-best' : ''}">${p.performance.total_time_seconds.toFixed(2)}s</td>
                <td class="${isBestInfer ? 'metric-best' : ''}">${p.performance.inference_time_ms_per_sample.toFixed(3)}ms</td>
                <td>${p.features_extracted}</td>
                <td>${p.features_after_reduction}</td>
            </tr>
        `;
    });
    
    const html = `
        <table class="comparison-table">
            <thead>
                <tr>
                    <th>Pipeline</th>
                    <th>Accuracy</th>
                    <th>F1-Score</th>
                    <th>Train Time</th>
                    <th>Inference</th>
                    <th>Features (Raw)</th>
                    <th>Features (Final)</th>
                </tr>
            </thead>
            <tbody>
                ${rows}
            </tbody>
        </table>
    `;
    
    document.getElementById('comparison-table-container').innerHTML = html;
}

// ===== BUILD HEATMAP =====
function buildHeatmap(allPipelines) {
    // Group by extractor+reducer (x-axis) and classifier (y-axis)
    const classifiers = ['logistic', 'svm', 'naive_bayes', 'random_forest', 'decision_tree'];
    const pipelines_combos = [];
    
    // Get unique extractor+reducer combinations
    const combinations = {};
    allPipelines.forEach(p => {
        const combo = `${p.extractor.type}_${p.reducer.type}`;
        if (!combinations[combo]) {
            combinations[combo] = `${p.extractor.name}+${p.reducer.name}`;
        }
    });
    
    const xLabels = Object.values(combinations);
    const yLabels = classifiers.map(clf => {
        const sample = allPipelines.find(p => p.classifier.type === clf);
        return sample ? sample.classifier.name : clf;
    });
    
    // Build matrix
    const zData = [];
    classifiers.forEach(clf => {
        const row = [];
        Object.keys(combinations).forEach(combo => {
            const [ext, red] = combo.split('_');
            const pipeline = allPipelines.find(p => 
                p.extractor.type === ext && 
                p.reducer.type === red && 
                p.classifier.type === clf
            );
            row.push(pipeline ? pipeline.metrics.accuracy * 100 : null);
        });
        zData.push(row);
    });
    
    const data = [{
        z: zData,
        x: xLabels,
        y: yLabels,
        type: 'heatmap',
        colorscale: [
            [0, '#ef4444'],
            [0.85, '#f59e0b'],
            [0.90, '#fbbf24'],
            [0.95, '#a7f3d0'],
            [1, '#10b981']
        ],
        hovertemplate: '%{y}<br>%{x}<br>Accuracy: %{z:.2f}%<extra></extra>',
        colorbar: {
            title: 'Accuracy (%)',
            titleside: 'right'
        }
    }];
    
    const layout = {
        xaxis: { title: 'Feature Extraction + Reduction', tickangle: -45 },
        yaxis: { title: 'Classifier' },
        margin: { l: 150, r: 50, b: 150, t: 50 },
        height: 500
    };
    
    Plotly.newPlot('heatmap-chart', data, layout, {responsive: true});
}

// ===== BUILD TRADEOFF CHART =====
function buildTradeoffChart(allPipelines) {
    const traces = [];
    const classifiers = [...new Set(allPipelines.map(p => p.classifier.type))];
    const colors = ['#667eea', '#f59e0b', '#10b981', '#ef4444', '#3b82f6'];
    
    classifiers.forEach((clf, idx) => {
        const pipelinesForClf = allPipelines.filter(p => p.classifier.type === clf);
        
        traces.push({
            x: pipelinesForClf.map(p => p.performance.total_time_seconds),
            y: pipelinesForClf.map(p => p.metrics.accuracy * 100),
            mode: 'markers',
            type: 'scatter',
            name: pipelinesForClf[0].classifier.name,
            marker: {
                size: 12,
                color: colors[idx % colors.length]
            },
            text: pipelinesForClf.map(p => formatPipelineName(p)),
            hovertemplate: '%{text}<br>Time: %{x:.2f}s<br>Accuracy: %{y:.2f}%<extra></extra>'
        });
    });
    
    const layout = {
        xaxis: { title: 'Training Time (seconds)', type: 'log' },
        yaxis: { title: 'Accuracy (%)', range: [75, 100] },
        hovermode: 'closest',
        legend: { x: 0.7, y: 0.1 },
        height: 500
    };
    
    Plotly.newPlot('tradeoff-chart', traces, layout, {responsive: true});
}

// ===== BUILD CONFUSION MATRICES =====
function buildConfusionMatrices(pipelines) {
    const html = '<h3>üéØ Confusion Matrices (Selected Pipelines)</h3><div class="cm-grid" id="cm-grid"></div>';
    document.getElementById('confusion-matrices').innerHTML = html;
    
    const grid = document.getElementById('cm-grid');
    
    pipelines.forEach((p, idx) => {
        const div = document.createElement('div');
        div.id = `cm-${idx}`;
        grid.appendChild(div);
        
        const data = [{
            z: p.confusion_matrix,
            x: p.labels,
            y: p.labels,
            type: 'heatmap',
            colorscale: 'Blues',
            hovertemplate: 'True: %{y}<br>Pred: %{x}<br>Count: %{z}<extra></extra>'
        }];
        
        const layout = {
            title: `${formatPipelineName(p)}<br>Accuracy: ${(p.metrics.accuracy * 100).toFixed(2)}%`,
            xaxis: { title: 'Predicted', side: 'bottom' },
            yaxis: { title: 'True', autorange: 'reversed' },
            height: 400,
            margin: { l: 100, r: 50, b: 100, t: 80 }
        };
        
        Plotly.newPlot(`cm-${idx}`, data, layout, {responsive: true});
    });
}

    </script>
</body>
</html>