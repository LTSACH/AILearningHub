<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pipeline Comparison - BBC News Classification | AI Learning Hub</title>
    
    <!-- Plotly for interactive charts -->
    <script src="https://cdn.plot.ly/plotly-2.26.0.min.js"></script>
    
    <!-- KaTeX for math formulas -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <style>

/* ===== RESET & BASE ===== */
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
    line-height: 1.6;
    color: #333;
    background: #f5f7fa;
}

/* ===== NAVBAR ===== */
.navbar {
    background: white;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
    position: sticky;
    top: 0;
    z-index: 1000;
}

.nav-container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 1rem 2rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.brand {
    font-size: 1.5rem;
    font-weight: 700;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    text-decoration: none;
}

.nav-links a {
    color: #667eea;
    text-decoration: none;
    font-weight: 500;
    transition: opacity 0.3s;
}

.nav-links a:hover {
    opacity: 0.7;
}

/* ===== HERO ===== */
.hero {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 3rem 2rem;
    text-align: center;
}

.hero h1 {
    font-size: 2.5rem;
    margin-bottom: 0.5rem;
}

.hero p {
    font-size: 1.1rem;
    opacity: 0.9;
    margin-bottom: 2rem;
}

.hero-stats {
    display: flex;
    justify-content: center;
    gap: 3rem;
    flex-wrap: wrap;
}

.stat-item {
    text-align: center;
}

.stat-value {
    font-size: 2.5rem;
    font-weight: 700;
    margin-bottom: 0.25rem;
}

.stat-label {
    font-size: 0.9rem;
    opacity: 0.9;
    text-transform: uppercase;
    letter-spacing: 1px;
}

/* ===== CONTAINER ===== */
.container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 2rem;
}

.section-description {
    color: #666;
    font-size: 1.1rem;
    margin-bottom: 2rem;
    text-align: center;
}

/* ===== PIPELINE BUILDER ===== */
.pipeline-builder-section {
    background: white;
    border-radius: 12px;
    padding: 2rem;
    margin-bottom: 2rem;
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
}

.pipeline-builder-section h2 {
    color: #667eea;
    margin-bottom: 0.5rem;
    font-size: 2rem;
    text-align: center;
}

.pipeline-steps {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 1rem;
    margin: 2rem 0;
}

.step-item {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 0.5rem;
}

.step-number {
    width: 50px;
    height: 50px;
    border-radius: 50%;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 1.5rem;
    font-weight: 700;
}

.step-title {
    font-size: 0.9rem;
    font-weight: 600;
    color: #667eea;
}

.step-arrow {
    font-size: 2rem;
    color: #667eea;
    margin-top: -20px;
}

.builder-card {
    background: #f8f9fa;
    border-radius: 10px;
    padding: 1.5rem;
    margin-bottom: 1.5rem;
}

.builder-card h3 {
    color: #333;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

.option-group {
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.option-radio, .option-checkbox {
    display: flex;
    align-items: flex-start;
    gap: 0.75rem;
    padding: 1rem;
    background: white;
    border: 2px solid #e5e7eb;
    border-radius: 8px;
    cursor: pointer;
    transition: all 0.3s;
}

.option-radio:hover, .option-checkbox:hover {
    border-color: #667eea;
    box-shadow: 0 2px 8px rgba(102, 126, 234, 0.2);
}

.option-radio.checked, .option-checkbox.checked {
    border-color: #667eea;
    background: #f0f4ff;
}

.option-radio input, .option-checkbox input {
    margin-top: 0.2rem;
    cursor: pointer;
}

.option-content {
    display: flex;
    flex-direction: column;
    flex: 1;
}

.option-title {
    font-weight: 600;
    color: #333;
    margin-bottom: 0.25rem;
}

.option-desc {
    font-size: 0.9rem;
    color: #666;
}

.classifier-actions {
    display: flex;
    gap: 0.75rem;
    margin-top: 1rem;
    flex-wrap: wrap;
}

/* ===== PREVIEW & ACTIONS ===== */
.builder-preview {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 10px;
    padding: 1.5rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
    gap: 2rem;
    flex-wrap: wrap;
}

.preview-content {
    flex: 1;
}

.preview-content h4 {
    margin-bottom: 0.5rem;
    font-size: 1.1rem;
}

#pipeline-preview {
    font-size: 1rem;
}

#preview-list {
    margin: 0.75rem 0 0 1.5rem;
    list-style: none;
}

#preview-list li {
    padding: 0.25rem 0;
    opacity: 0.9;
}

#preview-list li::before {
    content: "‚ñ∏ ";
    margin-right: 0.5rem;
}

.preview-actions {
    display: flex;
    gap: 1rem;
    flex-wrap: wrap;
}

/* ===== BUTTONS ===== */
.btn-primary, .btn-secondary {
    padding: 0.75rem 1.5rem;
    border: none;
    border-radius: 8px;
    font-size: 1rem;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s;
    white-space: nowrap;
}

.btn-primary {
    background: white;
    color: #667eea;
}

.btn-primary:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
}

.btn-secondary {
    background: rgba(255, 255, 255, 0.2);
    color: white;
    border: 1px solid white;
}

.btn-secondary:hover {
    background: rgba(255, 255, 255, 0.3);
}

/* ===== RESULTS SECTION ===== */
.results-section {
    margin-top: 2rem;
}

.results-section h2 {
    color: #667eea;
    font-size: 2rem;
    margin-bottom: 2rem;
    text-align: center;
}

.best-cards {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
    gap: 1.5rem;
    margin-bottom: 2rem;
}

.best-card {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    border-top: 4px solid;
}

.best-card.accuracy {
    border-top-color: #10b981;
}

.best-card.speed {
    border-top-color: #f59e0b;
}

.best-card.size {
    border-top-color: #3b82f6;
}

.best-card h3 {
    font-size: 0.9rem;
    text-transform: uppercase;
    letter-spacing: 1px;
    color: #666;
    margin-bottom: 0.5rem;
}

.best-card .metric-value {
    font-size: 2rem;
    font-weight: 700;
    margin-bottom: 0.5rem;
}

.best-card .pipeline-name {
    font-size: 0.9rem;
    color: #666;
}

/* ===== TABLE ===== */
.table-container {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    margin-bottom: 2rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    overflow-x: auto;
}

.comparison-table {
    width: 100%;
    border-collapse: collapse;
    font-size: 0.9rem;
}

.comparison-table th {
    background: #667eea;
    color: white;
    padding: 0.75rem;
    text-align: left;
    font-weight: 600;
    white-space: nowrap;
}

.comparison-table td {
    padding: 0.75rem;
    border-bottom: 1px solid #e5e7eb;
}

.comparison-table tr:hover {
    background: #f8f9fa;
}

.metric-best {
    background: #d1fae5 !important;
    font-weight: 600;
    color: #065f46;
}

.pipeline-cell {
    font-family: 'Courier New', monospace;
    font-size: 0.85rem;
}

/* ===== VISUALIZATIONS ===== */
.viz-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
    gap: 2rem;
    margin-bottom: 2rem;
}

.viz-card {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
}

.viz-card h3 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.2rem;
}

/* ===== CONFUSION MATRICES ===== */
.cm-section {
    background: white;
    border-radius: 10px;
    padding: 1.5rem;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
}

.cm-section h3 {
    color: #667eea;
    margin-bottom: 1rem;
    font-size: 1.3rem;
}

.cm-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(450px, 1fr));
    gap: 1.5rem;
    margin-top: 1.5rem;
}

/* ===== RESPONSIVE ===== */
@media (max-width: 768px) {
    .hero h1 {
        font-size: 2rem;
    }
    
    .hero-stats {
        gap: 1.5rem;
    }
    
    .stat-value {
        font-size: 2rem;
    }
    
    .builder-preview {
        flex-direction: column;
        align-items: flex-start;
    }
    
    .preview-actions {
        width: 100%;
    }
    
    .preview-actions button {
        flex: 1;
    }
    
    .viz-grid {
        grid-template-columns: 1fr;
    }
    
    .cm-grid {
        grid-template-columns: 1fr;
    }
}

/* ===== LOADING ===== */
.loading {
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 3rem;
    font-size: 1.1rem;
    color: #667eea;
}

.loading::after {
    content: '...';
    animation: dots 1.5s infinite;
}

@keyframes dots {
    0%, 20% { content: '.'; }
    40% { content: '..'; }
    60%, 100% { content: '...'; }
}

    </style>
</head>
<body>
    <!-- Navbar -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="../../../../index.html" class="brand">ü§ñ AI Learning Hub</a>
            <div class="nav-links">
                <a href="../../index.html">‚Üê Back to Text Classification</a>
            </div>
        </div>
    </nav>

    <!-- Hero -->
    <div class="hero">
        <h1>üî¨ Pipeline Comparison</h1>
        <p>Compare feature extraction, dimensionality reduction, and classifier combinations</p>
        <div class="hero-stats">
            <div class="stat-item">
                <div class="stat-value">78</div>
                <div class="stat-label">Total Pipelines</div>
            </div>
            <div class="stat-item">
                <div class="stat-value">98.2%</div>
                <div class="stat-label">Best Accuracy</div>
            </div>
            <div class="stat-item">
                <div class="stat-value">0.63s</div>
                <div class="stat-label">Fastest Training</div>
            </div>
        </div>
    </div>

    <!-- Main content -->
    <div class="container">
        <!-- Pipeline Builder Section -->
        <section class="pipeline-builder-section">
            <h2>üî¨ Build Your Pipeline</h2>
            <p class="section-description">
                Select feature extraction, dimensionality reduction, and classifiers to compare
            </p>
            
            
        <div class="pipeline-builder">
            <!-- Step indicator -->
            <div class="pipeline-steps">
                <div class="step-item">
                    <div class="step-number">1</div>
                    <div class="step-title">üìù Extract</div>
                </div>
                <div class="step-arrow">‚Üí</div>
                <div class="step-item">
                    <div class="step-number">2</div>
                    <div class="step-title">üéØ Reduce</div>
                </div>
                <div class="step-arrow">‚Üí</div>
                <div class="step-item">
                    <div class="step-number">3</div>
                    <div class="step-title">ü§ñ Classify</div>
                </div>
            </div>
            
            <!-- Step 1: Feature Extraction -->
            <div class="builder-card">
                <h3>STEP 1: Feature Extraction</h3>
                <div class="option-group">
                    <label class="option-radio">
                        <input type="radio" name="extractor" value="bow" data-name="Bag of Words">
                        <span class="option-content">
                            <span class="option-title">Bag of Words (CountVectorizer)</span>
                            <span class="option-desc">Count word occurrences, simple and fast</span>
                        </span>
                    </label>
                    <label class="option-radio checked">
                        <input type="radio" name="extractor" value="tfidf" data-name="TF-IDF" checked>
                        <span class="option-content">
                            <span class="option-title">TF-IDF (TfidfVectorizer)</span>
                            <span class="option-desc">Weight words by importance, better for classification</span>
                        </span>
                    </label>
                </div>
            </div>
            
            <!-- Step 2: Dimensionality Reduction -->
            <div class="builder-card">
                <h3>STEP 2: Dimensionality Reduction (Optional)</h3>
                <div class="option-group">
                    <label class="option-radio checked">
                        <input type="radio" name="reducer" value="none" data-name="None" checked>
                        <span class="option-content">
                            <span class="option-title">None (Use all features)</span>
                            <span class="option-desc">Best accuracy, but slower and larger models</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="pca" data-name="PCA">
                        <span class="option-content">
                            <span class="option-title">PCA (Principal Component Analysis)</span>
                            <span class="option-desc">Reduce to uncorrelated components, good for variance</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="chi2" data-name="Chi¬≤">
                        <span class="option-content">
                            <span class="option-title">Chi¬≤ (SelectKBest)</span>
                            <span class="option-desc">Select most relevant features, good for text</span>
                        </span>
                    </label>
                    <label class="option-radio">
                        <input type="radio" name="reducer" value="svd" data-name="Truncated SVD">
                        <span class="option-content">
                            <span class="option-title">Truncated SVD</span>
                            <span class="option-desc">Like PCA but works with sparse matrices</span>
                        </span>
                    </label>
                </div>
            </div>
            
            <!-- Step 3: Classifiers -->
            <div class="builder-card">
                <h3>STEP 3: Classifiers (Select multiple)</h3>
                <div class="option-group">
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="logistic" data-name="Logistic Regression" checked>
                        <span class="option-content">
                            <span class="option-title">Logistic Regression</span>
                            <span class="option-desc">Fast, interpretable, great baseline (usually best)</span>
                        </span>
                    </label>
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="svm" data-name="SVM" checked>
                        <span class="option-content">
                            <span class="option-title">SVM (Support Vector Machine)</span>
                            <span class="option-desc">Strong for high-dimensional text data</span>
                        </span>
                    </label>
                    <label class="option-checkbox checked">
                        <input type="checkbox" name="classifier" value="naive_bayes" data-name="Naive Bayes" checked>
                        <span class="option-content">
                            <span class="option-title">Naive Bayes</span>
                            <span class="option-desc">Extremely fast, good for large datasets</span>
                        </span>
                    </label>
                    <label class="option-checkbox">
                        <input type="checkbox" name="classifier" value="random_forest" data-name="Random Forest">
                        <span class="option-content">
                            <span class="option-title">Random Forest</span>
                            <span class="option-desc">Ensemble method, robust but slower</span>
                        </span>
                    </label>
                    <label class="option-checkbox">
                        <input type="checkbox" name="classifier" value="decision_tree" data-name="Decision Tree">
                        <span class="option-content">
                            <span class="option-title">Decision Tree</span>
                            <span class="option-desc">Simple, interpretable, usually lower accuracy</span>
                        </span>
                    </label>
                </div>
                <div class="classifier-actions">
                    <button onclick="selectAllClassifiers()" class="btn-secondary">Select All</button>
                    <button onclick="deselectAllClassifiers()" class="btn-secondary">Deselect All</button>
                    <button onclick="selectTopClassifiers()" class="btn-secondary">Top 3 Fastest</button>
                </div>
            </div>
            
            <!-- Preview & Action -->
            <div class="builder-preview">
                <div class="preview-content">
                    <h4>üìä Preview</h4>
                    <div id="pipeline-preview">
                        You will compare <strong id="preview-count">3</strong> pipeline(s):
                        <ul id="preview-list"></ul>
                    </div>
                </div>
                <div class="preview-actions">
                    <button onclick="comparePipelines()" class="btn-primary">
                        üîç Compare These Pipelines
                    </button>
                    <button onclick="resetBuilder()" class="btn-secondary">
                        üîÑ Reset to Defaults
                    </button>
                </div>
            </div>
        </div>
    
        </section>

        <!-- Results Section (initially hidden, shown after Compare) -->
        <section id="results-section" class="results-section" style="display: none;">
            <h2>üìä Comparison Results</h2>
            
            <!-- Best pipeline cards -->
            <div id="best-cards" class="best-cards"></div>
            
            <!-- Comparison table -->
            <div id="comparison-table-container" class="table-container"></div>
            
            <!-- Visualizations -->
            <div class="viz-grid">
                <div class="viz-card">
                    <h3>üìä Accuracy Heatmap</h3>
                    <div id="heatmap-chart"></div>
                </div>
                <div class="viz-card">
                    <h3>‚öñÔ∏è Trade-off: Accuracy vs Speed</h3>
                    <div id="tradeoff-chart"></div>
                </div>
            </div>
            
            <!-- Confusion matrices -->
            <div id="confusion-matrices" class="cm-section"></div>
        </section>
    </div>

    <!-- Data -->
    <script>
        const allPipelinesData = {'total_pipelines': 78, 'successful': 78, 'failed': 0, 'best_accuracy': {'pipeline_id': 'bow_m10000_n12_chi2_k500_naive_bayes', 'accuracy': 0.9820359281437125, 'config': 'Bag of Words ‚Üí Chi¬≤ ‚Üí Naive Bayes'}, 'fastest_training': {'pipeline_id': 'bow_m5000_n11_chi2_k500_naive_bayes', 'time': 0.626927375793457, 'config': 'Bag of Words ‚Üí Chi¬≤ ‚Üí Naive Bayes'}, 'fastest_inference': {'pipeline_id': 'bow_m5000_n12_pca_n300_decision_tree', 'time': 0.0015747047470001403, 'config': 'Bag of Words ‚Üí PCA ‚Üí Decision Tree'}, 'all_results': [{'pipeline_id': 'bow_m5000_n11_pca_n500_decision_tree', 'timestamp': '2025-10-21T12:58:22.140397', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.4767022132873535, 'features_extracted': 5000, 'reduction_time': 5.456620216369629, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.6347305389221557, 'precision': 0.6550988368182153, 'recall': 0.6347305389221557, 'f1_score': 0.6399511635057905}, 'performance': {'train_time_seconds': 1.1673941612243652, 'total_time_seconds': 7.100716590881348, 'inference_time_ms_per_sample': 0.003090875591346604}, 'confusion_matrix': [[47, 8, 12, 3, 7], [6, 34, 10, 5, 3], [8, 9, 39, 6, 0], [3, 12, 4, 58, 0], [10, 13, 3, 0, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6351351351351351, 'recall': 0.6103896103896104, 'f1': 0.6225165562913907, 'support': 77}, {'label': 'entertainment', 'precision': 0.4473684210526316, 'recall': 0.5862068965517241, 'f1': 0.5074626865671642, 'support': 58}, {'label': 'politics', 'precision': 0.5735294117647058, 'recall': 0.6290322580645161, 'f1': 0.6, 'support': 62}, {'label': 'sport', 'precision': 0.8055555555555556, 'recall': 0.7532467532467533, 'f1': 0.7785234899328859, 'support': 77}, {'label': 'tech', 'precision': 0.7727272727272727, 'recall': 0.5666666666666667, 'f1': 0.6538461538461539, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n500_svm', 'timestamp': '2025-10-21T13:01:02.012799', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.7265665531158447, 'features_extracted': 5000, 'reduction_time': 5.695241928100586, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9523519043065024, 'recall': 0.9520958083832335, 'f1_score': 0.9520587222160383}, 'performance': {'train_time_seconds': 18.687238216400146, 'total_time_seconds': 26.109046697616577, 'inference_time_ms_per_sample': 0.003497043769516631}, 'confusion_matrix': [[72, 1, 3, 0, 1], [0, 55, 1, 2, 0], [4, 0, 57, 1, 0], [0, 0, 0, 77, 0], [0, 1, 2, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9649122807017544, 'recall': 0.9482758620689655, 'f1': 0.9565217391304348, 'support': 58}, {'label': 'politics', 'precision': 0.9047619047619048, 'recall': 0.9193548387096774, 'f1': 0.912, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_logistic', 'timestamp': '2025-10-21T12:57:48.823336', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6378867626190186, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582648903644616, 'recall': 0.9580838323353293, 'f1_score': 0.9580291037037023}, 'performance': {'train_time_seconds': 3.24992299079895, 'total_time_seconds': 4.887809753417969, 'inference_time_ms_per_sample': 0.004878301106527179}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.935064935064935, 'recall': 0.935064935064935, 'f1': 0.935064935064935, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_random_forest', 'timestamp': '2025-10-21T13:00:07.354116', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 2.8087317943573, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.9651922086507346, 'recall': 0.9640718562874252, 'f1_score': 0.9642510868569181}, 'performance': {'train_time_seconds': 0.8687279224395752, 'total_time_seconds': 3.677459716796875, 'inference_time_ms_per_sample': 0.24240388127858054}, 'confusion_matrix': [[75, 0, 1, 0, 1], [1, 56, 1, 0, 0], [2, 0, 59, 1, 0], [1, 0, 0, 76, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9146341463414634, 'recall': 0.974025974025974, 'f1': 0.9433962264150944, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n300_decision_tree', 'timestamp': '2025-10-21T12:58:38.846284', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.8837659358978271, 'features_extracted': 10000, 'reduction_time': 3.9689180850982666, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.6287425149700598, 'precision': 0.629186299255533, 'recall': 0.6287425149700598, 'f1_score': 0.6281753916019414}, 'performance': {'train_time_seconds': 0.7798285484313965, 'total_time_seconds': 6.63251256942749, 'inference_time_ms_per_sample': 0.0026954148343937127}, 'confusion_matrix': [[50, 10, 7, 3, 7], [5, 29, 6, 14, 4], [7, 10, 34, 7, 4], [1, 5, 7, 59, 5], [9, 7, 4, 2, 38]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6944444444444444, 'recall': 0.6493506493506493, 'f1': 0.6711409395973155, 'support': 77}, {'label': 'entertainment', 'precision': 0.47540983606557374, 'recall': 0.5, 'f1': 0.48739495798319327, 'support': 58}, {'label': 'politics', 'precision': 0.5862068965517241, 'recall': 0.5483870967741935, 'f1': 0.5666666666666667, 'support': 62}, {'label': 'sport', 'precision': 0.6941176470588235, 'recall': 0.7662337662337663, 'f1': 0.7283950617283951, 'support': 77}, {'label': 'tech', 'precision': 0.6551724137931034, 'recall': 0.6333333333333333, 'f1': 0.6440677966101694, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_svd_n300_naive_bayes', 'timestamp': '2025-10-21T12:59:17.883641', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.003124713897705, 'features_extracted': 5000, 'reduction_time': 30.922466039657593, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.5598802395209581, 'precision': 0.5745001089484502, 'recall': 0.5598802395209581, 'f1_score': 0.5594175733321571}, 'performance': {'train_time_seconds': 0.006031513214111328, 'total_time_seconds': 31.93162226676941, 'inference_time_ms_per_sample': 0.001811695669939418}, 'confusion_matrix': [[33, 7, 14, 6, 17], [2, 39, 8, 3, 6], [5, 6, 40, 6, 5], [4, 8, 12, 49, 4], [11, 9, 12, 2, 26]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6, 'recall': 0.42857142857142855, 'f1': 0.5, 'support': 77}, {'label': 'entertainment', 'precision': 0.5652173913043478, 'recall': 0.6724137931034483, 'f1': 0.6141732283464567, 'support': 58}, {'label': 'politics', 'precision': 0.46511627906976744, 'recall': 0.6451612903225806, 'f1': 0.5405405405405406, 'support': 62}, {'label': 'sport', 'precision': 0.7424242424242424, 'recall': 0.6363636363636364, 'f1': 0.6853146853146853, 'support': 77}, {'label': 'tech', 'precision': 0.4482758620689655, 'recall': 0.43333333333333335, 'f1': 0.4406779661016949, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_naive_bayes', 'timestamp': '2025-10-21T13:01:02.495311', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.9423048496246338, 'features_extracted': 10000, 'reduction_time': 0.3939788341522217, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9730538922155688, 'precision': 0.9737496602766063, 'recall': 0.9730538922155688, 'f1_score': 0.9729928141568138}, 'performance': {'train_time_seconds': 0.026805400848388672, 'total_time_seconds': 2.363089084625244, 'inference_time_ms_per_sample': 0.007021213006116672}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 54, 2, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_decision_tree', 'timestamp': '2025-10-21T13:00:11.144476', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.8699986934661865, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7604790419161677, 'precision': 0.7639773036243528, 'recall': 0.7604790419161677, 'f1_score': 0.7604377994759974}, 'performance': {'train_time_seconds': 0.5189423561096191, 'total_time_seconds': 2.3889410495758057, 'inference_time_ms_per_sample': 0.002451285630643011}, 'confusion_matrix': [[53, 4, 11, 3, 6], [5, 39, 7, 6, 1], [8, 2, 47, 2, 3], [3, 3, 2, 67, 2], [7, 0, 4, 1, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6973684210526315, 'recall': 0.6883116883116883, 'f1': 0.6928104575163399, 'support': 77}, {'label': 'entertainment', 'precision': 0.8125, 'recall': 0.6724137931034483, 'f1': 0.7358490566037735, 'support': 58}, {'label': 'politics', 'precision': 0.6619718309859155, 'recall': 0.7580645161290323, 'f1': 0.706766917293233, 'support': 62}, {'label': 'sport', 'precision': 0.8481012658227848, 'recall': 0.8701298701298701, 'f1': 0.8589743589743589, 'support': 77}, {'label': 'tech', 'precision': 0.8, 'recall': 0.8, 'f1': 0.8, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k500_decision_tree', 'timestamp': '2025-10-21T13:00:53.912584', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.6077733039855957, 'features_extracted': 10000, 'reduction_time': 0.311065673828125, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.7784431137724551, 'precision': 0.7795401418367189, 'recall': 0.7784431137724551, 'f1_score': 0.7768763739040079}, 'performance': {'train_time_seconds': 0.14038801193237305, 'total_time_seconds': 2.0592269897460938, 'inference_time_ms_per_sample': 0.00344921728808009}, 'confusion_matrix': [[57, 3, 8, 4, 5], [6, 41, 4, 6, 1], [12, 2, 41, 4, 3], [2, 2, 0, 70, 3], [6, 1, 2, 0, 51]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6867469879518072, 'recall': 0.7402597402597403, 'f1': 0.7125, 'support': 77}, {'label': 'entertainment', 'precision': 0.8367346938775511, 'recall': 0.7068965517241379, 'f1': 0.7663551401869159, 'support': 58}, {'label': 'politics', 'precision': 0.7454545454545455, 'recall': 0.6612903225806451, 'f1': 0.7008547008547008, 'support': 62}, {'label': 'sport', 'precision': 0.8333333333333334, 'recall': 0.9090909090909091, 'f1': 0.8695652173913043, 'support': 77}, {'label': 'tech', 'precision': 0.8095238095238095, 'recall': 0.85, 'f1': 0.8292682926829268, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_svd_n300_svm', 'timestamp': '2025-10-21T12:54:18.890976', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.8932640552520752, 'features_extracted': 5000, 'reduction_time': 42.705310583114624, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.9646064745262904, 'recall': 0.9640718562874252, 'f1_score': 0.9639879828357268}, 'performance': {'train_time_seconds': 0.5324277877807617, 'total_time_seconds': 45.13100242614746, 'inference_time_ms_per_sample': 0.002953820599767262}, 'confusion_matrix': [[72, 1, 3, 0, 1], [1, 54, 1, 2, 0], [1, 0, 60, 0, 1], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.972972972972973, 'recall': 0.935064935064935, 'f1': 0.9536423841059603, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9230769230769231, 'recall': 0.967741935483871, 'f1': 0.9448818897637795, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9672131147540983, 'recall': 0.9833333333333333, 'f1': 0.9752066115702479, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k500_random_forest', 'timestamp': '2025-10-21T13:00:50.647999', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 2.7205097675323486, 'features_extracted': 10000, 'reduction_time': 0.29329442977905273, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9598304514108398, 'recall': 0.9580838323353293, 'f1_score': 0.9584771907261772}, 'performance': {'train_time_seconds': 0.20423150062561035, 'total_time_seconds': 3.2180356979370117, 'inference_time_ms_per_sample': 0.09682863772272349}, 'confusion_matrix': [[74, 0, 1, 0, 2], [1, 55, 0, 2, 0], [3, 0, 59, 0, 0], [2, 0, 0, 75, 0], [3, 0, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.891566265060241, 'recall': 0.961038961038961, 'f1': 0.925, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.9833333333333333, 'recall': 0.9516129032258065, 'f1': 0.9672131147540983, 'support': 62}, {'label': 'sport', 'precision': 0.974025974025974, 'recall': 0.974025974025974, 'f1': 0.974025974025974, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k500_svm', 'timestamp': '2025-10-21T12:58:31.869512', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.8454303741455078, 'features_extracted': 5000, 'reduction_time': 0.16742634773254395, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9528863511896907, 'recall': 0.9520958083832335, 'f1_score': 0.951977611140072}, 'performance': {'train_time_seconds': 0.1584920883178711, 'total_time_seconds': 1.1713488101959229, 'inference_time_ms_per_sample': 0.002965241849065541}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 0, 2, 0], [0, 2, 60, 0, 0], [0, 0, 0, 77, 0], [3, 3, 0, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9016393442622951, 'recall': 0.9482758620689655, 'f1': 0.9243697478991597, 'support': 58}, {'label': 'politics', 'precision': 0.967741935483871, 'recall': 0.967741935483871, 'f1': 0.967741935483871, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9818181818181818, 'recall': 0.9, 'f1': 0.9391304347826087, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_none_default_random_forest', 'timestamp': '2025-10-21T12:53:18.146760', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5232946872711182, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.953277091136297, 'recall': 0.9520958083832335, 'f1_score': 0.9523977845480633}, 'performance': {'train_time_seconds': 0.3029148578643799, 'total_time_seconds': 0.826209545135498, 'inference_time_ms_per_sample': 0.09678438038169267}, 'confusion_matrix': [[73, 0, 2, 0, 2], [1, 55, 1, 1, 0], [3, 0, 59, 0, 0], [1, 0, 0, 75, 1], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9012345679012346, 'recall': 0.948051948051948, 'f1': 0.9240506329113924, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'tech', 'precision': 0.9491525423728814, 'recall': 0.9333333333333333, 'f1': 0.9411764705882353, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_svd_n300_decision_tree', 'timestamp': '2025-10-21T12:57:42.947919', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 2.203129291534424, 'features_extracted': 5000, 'reduction_time': 3.0848183631896973, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.6017964071856288, 'precision': 0.6025000151488158, 'recall': 0.6017964071856288, 'f1_score': 0.601758378394343}, 'performance': {'train_time_seconds': 0.575354814529419, 'total_time_seconds': 5.86330246925354, 'inference_time_ms_per_sample': 0.0017288916125268994}, 'confusion_matrix': [[41, 12, 8, 4, 12], [9, 29, 5, 12, 3], [6, 6, 38, 5, 7], [10, 6, 4, 56, 1], [9, 8, 2, 4, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5466666666666666, 'recall': 0.5324675324675324, 'f1': 0.5394736842105263, 'support': 77}, {'label': 'entertainment', 'precision': 0.47540983606557374, 'recall': 0.5, 'f1': 0.48739495798319327, 'support': 58}, {'label': 'politics', 'precision': 0.6666666666666666, 'recall': 0.6129032258064516, 'f1': 0.6386554621848739, 'support': 62}, {'label': 'sport', 'precision': 0.691358024691358, 'recall': 0.7272727272727273, 'f1': 0.7088607594936709, 'support': 77}, {'label': 'tech', 'precision': 0.6166666666666667, 'recall': 0.6166666666666667, 'f1': 0.6166666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n500_decision_tree', 'timestamp': '2025-10-21T13:00:28.871373', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.6343498229980469, 'features_extracted': 10000, 'reduction_time': 9.74869155883789, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.6467065868263473, 'precision': 0.6418553738312804, 'recall': 0.6467065868263473, 'f1_score': 0.6424447203076884}, 'performance': {'train_time_seconds': 1.3571853637695312, 'total_time_seconds': 12.740226745605469, 'inference_time_ms_per_sample': 0.0028131964677822092}, 'confusion_matrix': [[53, 6, 6, 5, 7], [8, 28, 6, 13, 3], [8, 7, 34, 7, 6], [1, 3, 6, 64, 3], [10, 9, 3, 1, 37]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6625, 'recall': 0.6883116883116883, 'f1': 0.6751592356687898, 'support': 77}, {'label': 'entertainment', 'precision': 0.5283018867924528, 'recall': 0.4827586206896552, 'f1': 0.5045045045045045, 'support': 58}, {'label': 'politics', 'precision': 0.6181818181818182, 'recall': 0.5483870967741935, 'f1': 0.5811965811965812, 'support': 62}, {'label': 'sport', 'precision': 0.7111111111111111, 'recall': 0.8311688311688312, 'f1': 0.7664670658682635, 'support': 77}, {'label': 'tech', 'precision': 0.6607142857142857, 'recall': 0.6166666666666667, 'f1': 0.6379310344827587, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n300_naive_bayes', 'timestamp': '2025-10-21T12:58:26.189830', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 2.3482396602630615, 'features_extracted': 10000, 'reduction_time': 4.163530349731445, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.46706586826347307, 'precision': 0.4958392016092651, 'recall': 0.46706586826347307, 'f1_score': 0.46585546678680445}, 'performance': {'train_time_seconds': 0.04742312431335449, 'total_time_seconds': 6.559193134307861, 'inference_time_ms_per_sample': 0.004380049105889783}, 'confusion_matrix': [[25, 24, 6, 11, 11], [4, 25, 3, 20, 6], [5, 14, 24, 14, 5], [3, 11, 8, 50, 5], [4, 12, 8, 4, 32]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6097560975609756, 'recall': 0.3246753246753247, 'f1': 0.423728813559322, 'support': 77}, {'label': 'entertainment', 'precision': 0.29069767441860467, 'recall': 0.43103448275862066, 'f1': 0.3472222222222222, 'support': 58}, {'label': 'politics', 'precision': 0.4897959183673469, 'recall': 0.3870967741935484, 'f1': 0.43243243243243246, 'support': 62}, {'label': 'sport', 'precision': 0.5050505050505051, 'recall': 0.6493506493506493, 'f1': 0.5681818181818182, 'support': 77}, {'label': 'tech', 'precision': 0.5423728813559322, 'recall': 0.5333333333333333, 'f1': 0.5378151260504201, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_svm', 'timestamp': '2025-10-21T12:57:53.726956', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6575243473052979, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9552637254483006, 'recall': 0.9550898203592815, 'f1_score': 0.9549596275836564}, 'performance': {'train_time_seconds': 1.0602998733520508, 'total_time_seconds': 2.7178242206573486, 'inference_time_ms_per_sample': 0.0026433053844703174}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [2, 1, 58, 1, 0], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9491525423728814, 'recall': 0.9655172413793104, 'f1': 0.9572649572649573, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_none_default_logistic', 'timestamp': '2025-10-21T12:53:11.964559', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5097923278808594, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9550625835443449, 'recall': 0.9550898203592815, 'f1_score': 0.9549353389163149}, 'performance': {'train_time_seconds': 3.69842791557312, 'total_time_seconds': 4.2082202434539795, 'inference_time_ms_per_sample': 0.006181037354612065}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [2, 0, 58, 1, 1], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_logistic', 'timestamp': '2025-10-21T12:59:56.560252', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6035923957824707, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9581598373126704, 'recall': 0.9580838323353293, 'f1_score': 0.9579800968580585}, 'performance': {'train_time_seconds': 4.910040378570557, 'total_time_seconds': 6.513632774353027, 'inference_time_ms_per_sample': 0.003640523213826254}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [2, 1, 58, 1, 0], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n300_logistic', 'timestamp': '2025-10-21T12:53:19.918366', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.4919264316558838, 'features_extracted': 5000, 'reduction_time': 2.3604018688201904, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9700598802395209, 'precision': 0.9705184453183566, 'recall': 0.9700598802395209, 'f1_score': 0.9698992211388385}, 'performance': {'train_time_seconds': 0.3765695095062256, 'total_time_seconds': 3.2288978099823, 'inference_time_ms_per_sample': 0.022160792779065894}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 56, 1, 0, 0], [0, 0, 60, 1, 1], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9861111111111112, 'recall': 0.922077922077922, 'f1': 0.9530201342281879, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.967741935483871, 'f1': 0.9523809523809523, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.967741935483871, 'recall': 1.0, 'f1': 0.9836065573770492, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_naive_bayes', 'timestamp': '2025-10-21T12:57:56.457807', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.71124267578125, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9763295154114302, 'recall': 0.9760479041916168, 'f1_score': 0.9760704058320477}, 'performance': {'train_time_seconds': 0.31275010108947754, 'total_time_seconds': 2.0239927768707275, 'inference_time_ms_per_sample': 0.034920469729486335}, 'confusion_matrix': [[75, 0, 1, 0, 1], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 1, 1, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_svd_n300_decision_tree', 'timestamp': '2025-10-21T12:59:53.276729', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.4998323917388916, 'features_extracted': 5000, 'reduction_time': 2.2651586532592773, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.6317365269461078, 'precision': 0.6253152372327065, 'recall': 0.6317365269461078, 'f1_score': 0.6253811699188849}, 'performance': {'train_time_seconds': 0.5071611404418945, 'total_time_seconds': 3.2721521854400635, 'inference_time_ms_per_sample': 0.0018316828562114052}, 'confusion_matrix': [[48, 5, 11, 8, 5], [9, 25, 7, 12, 5], [8, 7, 32, 6, 9], [4, 9, 2, 61, 1], [8, 0, 2, 5, 45]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6233766233766234, 'recall': 0.6233766233766234, 'f1': 0.6233766233766234, 'support': 77}, {'label': 'entertainment', 'precision': 0.5434782608695652, 'recall': 0.43103448275862066, 'f1': 0.4807692307692308, 'support': 58}, {'label': 'politics', 'precision': 0.5925925925925926, 'recall': 0.5161290322580645, 'f1': 0.5517241379310345, 'support': 62}, {'label': 'sport', 'precision': 0.6630434782608695, 'recall': 0.7922077922077922, 'f1': 0.7218934911242604, 'support': 77}, {'label': 'tech', 'precision': 0.6923076923076923, 'recall': 0.75, 'f1': 0.72, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n300_logistic', 'timestamp': '2025-10-21T12:58:02.835451', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6059601306915283, 'features_extracted': 10000, 'reduction_time': 4.300638198852539, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.964013345726934, 'recall': 0.9640718562874252, 'f1_score': 0.9639831295504603}, 'performance': {'train_time_seconds': 0.3732490539550781, 'total_time_seconds': 6.2798473834991455, 'inference_time_ms_per_sample': 0.006064683377385853}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 56, 1, 0, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1': 0.9666666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k500_random_forest', 'timestamp': '2025-10-21T12:58:33.690663', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5440988540649414, 'features_extracted': 5000, 'reduction_time': 0.13120746612548828, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9501566015526858, 'recall': 0.9491017964071856, 'f1_score': 0.9492783390593047}, 'performance': {'train_time_seconds': 0.39505434036254883, 'total_time_seconds': 1.0703606605529785, 'inference_time_ms_per_sample': 0.10210311341428471}, 'confusion_matrix': [[74, 0, 2, 0, 1], [2, 54, 0, 1, 1], [3, 0, 59, 0, 0], [0, 0, 0, 75, 2], [3, 1, 1, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9024390243902439, 'recall': 0.961038961038961, 'f1': 0.9308176100628931, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'tech', 'precision': 0.9322033898305084, 'recall': 0.9166666666666666, 'f1': 0.9243697478991597, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n300_naive_bayes', 'timestamp': '2025-10-21T13:00:35.291185', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.5840215682983398, 'features_extracted': 5000, 'reduction_time': 5.193512678146362, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.5029940119760479, 'precision': 0.5086916574029304, 'recall': 0.5029940119760479, 'f1_score': 0.5006479376062571}, 'performance': {'train_time_seconds': 0.01135396957397461, 'total_time_seconds': 6.788888216018677, 'inference_time_ms_per_sample': 0.002735389206937687}, 'confusion_matrix': [[30, 15, 7, 15, 10], [7, 28, 1, 15, 7], [6, 9, 28, 11, 8], [4, 8, 13, 48, 4], [8, 10, 5, 3, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5454545454545454, 'recall': 0.38961038961038963, 'f1': 0.45454545454545453, 'support': 77}, {'label': 'entertainment', 'precision': 0.4, 'recall': 0.4827586206896552, 'f1': 0.4375, 'support': 58}, {'label': 'politics', 'precision': 0.5185185185185185, 'recall': 0.45161290322580644, 'f1': 0.4827586206896552, 'support': 62}, {'label': 'sport', 'precision': 0.5217391304347826, 'recall': 0.6233766233766234, 'f1': 0.5680473372781065, 'support': 77}, {'label': 'tech', 'precision': 0.5396825396825397, 'recall': 0.5666666666666667, 'f1': 0.5528455284552846, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_svd_n300_svm', 'timestamp': '2025-10-21T12:58:47.503440', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5390479564666748, 'features_extracted': 5000, 'reduction_time': 29.351847171783447, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9588747473033694, 'recall': 0.9580838323353293, 'f1_score': 0.957964885415162}, 'performance': {'train_time_seconds': 0.4788017272949219, 'total_time_seconds': 30.369696855545044, 'inference_time_ms_per_sample': 0.00168748958382064}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 54, 1, 2, 0], [0, 0, 60, 1, 1], [0, 0, 0, 77, 0], [1, 0, 1, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9726027397260274, 'recall': 0.922077922077922, 'f1': 0.9466666666666667, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9230769230769231, 'recall': 0.967741935483871, 'f1': 0.9448818897637795, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1': 0.9666666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n300_decision_tree', 'timestamp': '2025-10-21T13:00:48.982681', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.6116774082183838, 'features_extracted': 5000, 'reduction_time': 2.862575054168701, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.6047904191616766, 'precision': 0.6127298043347043, 'recall': 0.6047904191616766, 'f1_score': 0.6073168958472448}, 'performance': {'train_time_seconds': 0.5669608116149902, 'total_time_seconds': 5.041213274002075, 'inference_time_ms_per_sample': 0.0015747047470001403}, 'confusion_matrix': [[48, 11, 8, 4, 6], [14, 24, 7, 10, 3], [8, 9, 35, 7, 3], [2, 13, 3, 57, 2], [10, 8, 2, 2, 38]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5853658536585366, 'recall': 0.6233766233766234, 'f1': 0.6037735849056604, 'support': 77}, {'label': 'entertainment', 'precision': 0.36923076923076925, 'recall': 0.41379310344827586, 'f1': 0.3902439024390244, 'support': 58}, {'label': 'politics', 'precision': 0.6363636363636364, 'recall': 0.5645161290322581, 'f1': 0.5982905982905983, 'support': 62}, {'label': 'sport', 'precision': 0.7125, 'recall': 0.7402597402597403, 'f1': 0.7261146496815286, 'support': 77}, {'label': 'tech', 'precision': 0.7307692307692307, 'recall': 0.6333333333333333, 'f1': 0.6785714285714286, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_svd_n300_logistic', 'timestamp': '2025-10-21T12:53:21.085721', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.4189677238464355, 'features_extracted': 5000, 'reduction_time': 54.96820306777954, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9579877074406162, 'recall': 0.9580838323353293, 'f1_score': 0.9579768495760042}, 'performance': {'train_time_seconds': 0.39840102195739746, 'total_time_seconds': 57.785571813583374, 'inference_time_ms_per_sample': 0.0015896951367041308}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 56, 1, 0, 0], [2, 1, 58, 1, 0], [0, 0, 0, 77, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9342105263157895, 'recall': 0.922077922077922, 'f1': 0.9281045751633987, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9830508474576272, 'recall': 0.9666666666666667, 'f1': 0.9747899159663865, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k1000_naive_bayes', 'timestamp': '2025-10-21T12:58:39.390850', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 0.5457711219787598, 'features_extracted': 5000, 'reduction_time': 0.137986421585083, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9790419161676647, 'precision': 0.9797208779244705, 'recall': 0.9790419161676647, 'f1_score': 0.9789695970982052}, 'performance': {'train_time_seconds': 0.014998435974121094, 'total_time_seconds': 0.6987559795379639, 'inference_time_ms_per_sample': 0.005108153748655034}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 54, 2, 0, 2], [0, 0, 62, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 1.0, 'recall': 0.961038961038961, 'f1': 0.9801324503311258, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9538461538461539, 'recall': 1.0, 'f1': 0.9763779527559056, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_random_forest', 'timestamp': '2025-10-21T12:53:16.888881', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6343955993652344, 'features_extracted': 5000, 'reduction_time': 0.13685965538024902, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.958853372892966, 'recall': 0.9580838323353293, 'f1_score': 0.9582775575572604}, 'performance': {'train_time_seconds': 0.19925427436828613, 'total_time_seconds': 1.9705095291137695, 'inference_time_ms_per_sample': 0.09779016414802232}, 'confusion_matrix': [[73, 0, 2, 0, 2], [0, 56, 1, 1, 0], [3, 0, 59, 0, 0], [1, 0, 0, 76, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9125, 'recall': 0.948051948051948, 'f1': 0.9299363057324841, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.987012987012987, 'recall': 0.987012987012987, 'f1': 0.987012987012987, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_random_forest', 'timestamp': '2025-10-21T13:01:04.885850', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 2.328251361846924, 'features_extracted': 10000, 'reduction_time': 0.27485084533691406, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9678120960972296, 'recall': 0.9670658682634731, 'f1_score': 0.9672242803539094}, 'performance': {'train_time_seconds': 0.20060229301452637, 'total_time_seconds': 2.8037045001983643, 'inference_time_ms_per_sample': 0.2187290591394116}, 'confusion_matrix': [[75, 0, 1, 0, 1], [0, 56, 1, 1, 0], [2, 0, 60, 0, 0], [1, 0, 0, 75, 1], [3, 0, 0, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9259259259259259, 'recall': 0.974025974025974, 'f1': 0.9493670886075949, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9655172413793104, 'f1': 0.9824561403508771, 'support': 58}, {'label': 'politics', 'precision': 0.967741935483871, 'recall': 0.967741935483871, 'f1': 0.967741935483871, 'support': 62}, {'label': 'sport', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_svm', 'timestamp': '2025-10-21T12:53:11.601068', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.219264507293701, 'features_extracted': 5000, 'reduction_time': 0.1849198341369629, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9492687808402563, 'recall': 0.9491017964071856, 'f1_score': 0.9488098068555353}, 'performance': {'train_time_seconds': 0.23791980743408203, 'total_time_seconds': 2.642104148864746, 'inference_time_ms_per_sample': 0.006687855292223171}, 'confusion_matrix': [[71, 1, 2, 1, 2], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 2, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9322033898305084, 'recall': 0.9482758620689655, 'f1': 0.9401709401709402, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.967741935483871, 'f1': 0.9523809523809523, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k500_naive_bayes', 'timestamp': '2025-10-21T12:58:33.050571', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 0.4868159294128418, 'features_extracted': 5000, 'reduction_time': 0.13109803199768066, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9764910292311348, 'recall': 0.9760479041916168, 'f1_score': 0.9759020155011993}, 'performance': {'train_time_seconds': 0.00901341438293457, 'total_time_seconds': 0.626927375793457, 'inference_time_ms_per_sample': 0.00265900960225545}, 'confusion_matrix': [[75, 0, 1, 0, 1], [1, 53, 2, 0, 2], [0, 0, 62, 0, 0], [0, 0, 0, 77, 0], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9868421052631579, 'recall': 0.974025974025974, 'f1': 0.9803921568627451, 'support': 77}, {'label': 'entertainment', 'precision': 0.9814814814814815, 'recall': 0.9137931034482759, 'f1': 0.9464285714285714, 'support': 58}, {'label': 'politics', 'precision': 0.9538461538461539, 'recall': 1.0, 'f1': 0.9763779527559056, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9516129032258065, 'recall': 0.9833333333333333, 'f1': 0.9672131147540983, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n300_svm', 'timestamp': '2025-10-21T12:53:23.170557', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.6749145984649658, 'features_extracted': 5000, 'reduction_time': 45.877641439437866, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9700598802395209, 'precision': 0.97004884004884, 'recall': 0.9700598802395209, 'f1_score': 0.9699957911003121}, 'performance': {'train_time_seconds': 10.099037647247314, 'total_time_seconds': 56.65159368515015, 'inference_time_ms_per_sample': 0.003532735173573751}, 'confusion_matrix': [[72, 1, 3, 0, 1], [0, 57, 1, 0, 0], [2, 0, 59, 1, 0], [0, 0, 0, 77, 0], [1, 0, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.96, 'recall': 0.935064935064935, 'f1': 0.9473684210526315, 'support': 77}, {'label': 'entertainment', 'precision': 0.9827586206896551, 'recall': 0.9827586206896551, 'f1': 0.9827586206896551, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9871794871794872, 'recall': 1.0, 'f1': 0.9935483870967742, 'support': 77}, {'label': 'tech', 'precision': 0.9833333333333333, 'recall': 0.9833333333333333, 'f1': 0.9833333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n300_decision_tree', 'timestamp': '2025-10-21T12:55:05.719333', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.48880481719970703, 'features_extracted': 5000, 'reduction_time': 44.2054808139801, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.625748502994012, 'precision': 0.6361675338928134, 'recall': 0.625748502994012, 'f1_score': 0.6287380632179407}, 'performance': {'train_time_seconds': 0.7642977237701416, 'total_time_seconds': 45.45858335494995, 'inference_time_ms_per_sample': 0.002357774152013356}, 'confusion_matrix': [[46, 10, 9, 3, 9], [7, 31, 11, 6, 3], [9, 7, 36, 9, 1], [2, 11, 3, 60, 1], [6, 12, 5, 1, 36]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6571428571428571, 'recall': 0.5974025974025974, 'f1': 0.6258503401360545, 'support': 77}, {'label': 'entertainment', 'precision': 0.43661971830985913, 'recall': 0.5344827586206896, 'f1': 0.4806201550387597, 'support': 58}, {'label': 'politics', 'precision': 0.5625, 'recall': 0.5806451612903226, 'f1': 0.5714285714285714, 'support': 62}, {'label': 'sport', 'precision': 0.759493670886076, 'recall': 0.7792207792207793, 'f1': 0.7692307692307693, 'support': 77}, {'label': 'tech', 'precision': 0.72, 'recall': 0.6, 'f1': 0.6545454545454545, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_none_default_decision_tree', 'timestamp': '2025-10-21T12:53:19.013302', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 0.49593019485473633, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.7754491017964071, 'precision': 0.7838044303814433, 'recall': 0.7754491017964071, 'f1_score': 0.7769709676702614}, 'performance': {'train_time_seconds': 0.40170764923095703, 'total_time_seconds': 0.8976378440856934, 'inference_time_ms_per_sample': 0.0020494004209598384}, 'confusion_matrix': [[57, 1, 9, 5, 5], [4, 42, 5, 6, 1], [8, 2, 46, 3, 3], [5, 1, 4, 66, 1], [4, 0, 7, 1, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7307692307692307, 'recall': 0.7402597402597403, 'f1': 0.7354838709677419, 'support': 77}, {'label': 'entertainment', 'precision': 0.9130434782608695, 'recall': 0.7241379310344828, 'f1': 0.8076923076923077, 'support': 58}, {'label': 'politics', 'precision': 0.647887323943662, 'recall': 0.7419354838709677, 'f1': 0.6917293233082706, 'support': 62}, {'label': 'sport', 'precision': 0.8148148148148148, 'recall': 0.8571428571428571, 'f1': 0.8354430379746836, 'support': 77}, {'label': 'tech', 'precision': 0.8275862068965517, 'recall': 0.8, 'f1': 0.8135593220338984, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_decision_tree', 'timestamp': '2025-10-21T12:58:00.487048', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.6084392070770264, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.7694610778443114, 'precision': 0.7729690257820706, 'recall': 0.7694610778443114, 'f1_score': 0.7695580602879214}, 'performance': {'train_time_seconds': 0.7304980754852295, 'total_time_seconds': 2.338937282562256, 'inference_time_ms_per_sample': 0.0032564837061716412}, 'confusion_matrix': [[56, 3, 11, 2, 5], [5, 39, 6, 7, 1], [8, 2, 46, 2, 4], [2, 4, 3, 67, 1], [6, 0, 4, 1, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7272727272727273, 'recall': 0.7272727272727273, 'f1': 0.7272727272727273, 'support': 77}, {'label': 'entertainment', 'precision': 0.8125, 'recall': 0.6724137931034483, 'f1': 0.7358490566037735, 'support': 58}, {'label': 'politics', 'precision': 0.6571428571428571, 'recall': 0.7419354838709677, 'f1': 0.696969696969697, 'support': 62}, {'label': 'sport', 'precision': 0.8481012658227848, 'recall': 0.8701298701298701, 'f1': 0.8589743589743589, 'support': 77}, {'label': 'tech', 'precision': 0.8166666666666667, 'recall': 0.8166666666666667, 'f1': 0.8166666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k1000_random_forest', 'timestamp': '2025-10-21T12:58:40.099840', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5072946548461914, 'features_extracted': 5000, 'reduction_time': 0.13511896133422852, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9528874213598121, 'recall': 0.9520958083832335, 'f1_score': 0.9520363843469225}, 'performance': {'train_time_seconds': 0.7187511920928955, 'total_time_seconds': 1.3611648082733154, 'inference_time_ms_per_sample': 0.20461168117865833}, 'confusion_matrix': [[73, 0, 2, 0, 2], [1, 53, 0, 2, 2], [2, 0, 59, 1, 0], [0, 0, 0, 77, 0], [3, 0, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9240506329113924, 'recall': 0.948051948051948, 'f1': 0.9358974358974359, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9137931034482759, 'f1': 0.954954954954955, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9333333333333333, 'recall': 0.9333333333333333, 'f1': 0.9333333333333333, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_decision_tree', 'timestamp': '2025-10-21T13:01:07.792255', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 2.357182502746582, 'features_extracted': 10000, 'reduction_time': 0.27425432205200195, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7784431137724551, 'precision': 0.7820767640639236, 'recall': 0.7784431137724551, 'f1_score': 0.7787006522958154}, 'performance': {'train_time_seconds': 0.12883710861206055, 'total_time_seconds': 2.7602739334106445, 'inference_time_ms_per_sample': 0.003114431918024303}, 'confusion_matrix': [[59, 2, 9, 4, 3], [5, 42, 4, 5, 2], [12, 3, 42, 2, 3], [3, 2, 3, 68, 1], [8, 1, 1, 1, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6781609195402298, 'recall': 0.7662337662337663, 'f1': 0.7195121951219512, 'support': 77}, {'label': 'entertainment', 'precision': 0.84, 'recall': 0.7241379310344828, 'f1': 0.7777777777777778, 'support': 58}, {'label': 'politics', 'precision': 0.711864406779661, 'recall': 0.6774193548387096, 'f1': 0.6942148760330579, 'support': 62}, {'label': 'sport', 'precision': 0.85, 'recall': 0.8831168831168831, 'f1': 0.8662420382165605, 'support': 77}, {'label': 'tech', 'precision': 0.8448275862068966, 'recall': 0.8166666666666667, 'f1': 0.8305084745762712, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_svd_n300_logistic', 'timestamp': '2025-10-21T13:01:10.567477', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.721118688583374, 'features_extracted': 10000, 'reduction_time': 10.813473224639893, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9640718562874252, 'precision': 0.9641165228313715, 'recall': 0.9640718562874252, 'f1_score': 0.9640051880045576}, 'performance': {'train_time_seconds': 0.4311497211456299, 'total_time_seconds': 12.965741634368896, 'inference_time_ms_per_sample': 0.0016603641167372287}, 'confusion_matrix': [[73, 1, 2, 0, 1], [1, 55, 1, 1, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.948051948051948, 'recall': 0.948051948051948, 'f1': 0.948051948051948, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1': 0.9666666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n500_svm', 'timestamp': '2025-10-21T12:56:57.229311', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.068403720855713, 'features_extracted': 5000, 'reduction_time': 47.20204830169678, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.95245745977042, 'recall': 0.9520958083832335, 'f1_score': 0.9519860198586759}, 'performance': {'train_time_seconds': 19.901919841766357, 'total_time_seconds': 68.17237186431885, 'inference_time_ms_per_sample': 0.005288038425102919}, 'confusion_matrix': [[71, 1, 3, 1, 1], [0, 55, 1, 2, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [0, 2, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9594594594594594, 'recall': 0.922077922077922, 'f1': 0.9403973509933775, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9206349206349206, 'recall': 0.9354838709677419, 'f1': 0.928, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9827586206896551, 'recall': 0.95, 'f1': 0.9661016949152542, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_none_default_naive_bayes', 'timestamp': '2025-10-21T12:53:17.463038', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 0.500938892364502, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9764315665903217, 'recall': 0.9760479041916168, 'f1_score': 0.9760572736773053}, 'performance': {'train_time_seconds': 0.16298389434814453, 'total_time_seconds': 0.6639227867126465, 'inference_time_ms_per_sample': 0.01864019268287156}, 'confusion_matrix': [[74, 1, 1, 0, 1], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 1, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9866666666666667, 'recall': 0.961038961038961, 'f1': 0.9736842105263158, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9516129032258065, 'recall': 0.9833333333333333, 'f1': 0.9672131147540983, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n500_naive_bayes', 'timestamp': '2025-10-21T12:58:05.475362', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.842015266418457, 'features_extracted': 5000, 'reduction_time': 8.587058067321777, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.5329341317365269, 'precision': 0.5409022990433698, 'recall': 0.5329341317365269, 'f1_score': 0.528508189093391}, 'performance': {'train_time_seconds': 0.1042332649230957, 'total_time_seconds': 10.53330659866333, 'inference_time_ms_per_sample': 0.0036719316493965194}, 'confusion_matrix': [[30, 8, 7, 16, 16], [3, 30, 2, 19, 4], [7, 3, 31, 14, 7], [4, 6, 11, 53, 3], [7, 4, 12, 3, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.5882352941176471, 'recall': 0.38961038961038963, 'f1': 0.46875, 'support': 77}, {'label': 'entertainment', 'precision': 0.5882352941176471, 'recall': 0.5172413793103449, 'f1': 0.5504587155963303, 'support': 58}, {'label': 'politics', 'precision': 0.49206349206349204, 'recall': 0.5, 'f1': 0.496, 'support': 62}, {'label': 'sport', 'precision': 0.5047619047619047, 'recall': 0.6883116883116883, 'f1': 0.5824175824175825, 'support': 77}, {'label': 'tech', 'precision': 0.53125, 'recall': 0.5666666666666667, 'f1': 0.5483870967741935, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_none_default_random_forest', 'timestamp': '2025-10-21T12:57:58.507111', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6888337135314941, 'features_extracted': 10000, 'reduction_time': 0, 'features_after_reduction': 10000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9570552642093025, 'recall': 0.9550898203592815, 'f1_score': 0.9553410479190152}, 'performance': {'train_time_seconds': 0.2494199275970459, 'total_time_seconds': 1.93825364112854, 'inference_time_ms_per_sample': 0.09719625918451183}, 'confusion_matrix': [[74, 0, 1, 0, 2], [1, 54, 0, 2, 1], [5, 0, 57, 0, 0], [1, 0, 0, 76, 0], [2, 0, 0, 0, 58]], 'per_class_metrics': [{'label': 'business', 'precision': 0.891566265060241, 'recall': 0.961038961038961, 'f1': 0.925, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9310344827586207, 'f1': 0.9642857142857143, 'support': 58}, {'label': 'politics', 'precision': 0.9827586206896551, 'recall': 0.9193548387096774, 'f1': 0.95, 'support': 62}, {'label': 'sport', 'precision': 0.9743589743589743, 'recall': 0.987012987012987, 'f1': 0.9806451612903225, 'support': 77}, {'label': 'tech', 'precision': 0.9508196721311475, 'recall': 0.9666666666666667, 'f1': 0.9586776859504132, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_naive_bayes', 'timestamp': '2025-10-21T12:53:14.265024', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 2.4507861137390137, 'features_extracted': 5000, 'reduction_time': 0.13713860511779785, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9730538922155688, 'precision': 0.9737496602766063, 'recall': 0.9730538922155688, 'f1_score': 0.9729928141568138}, 'performance': {'train_time_seconds': 0.015705585479736328, 'total_time_seconds': 2.603630304336548, 'inference_time_ms_per_sample': 0.004504255192008561}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 54, 2, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 0.9818181818181818, 'recall': 0.9310344827586207, 'f1': 0.9557522123893806, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9523809523809523, 'recall': 1.0, 'f1': 0.975609756097561, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n500_svm', 'timestamp': '2025-10-21T12:59:15.218400', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.693120241165161, 'features_extracted': 10000, 'reduction_time': 30.339335441589355, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9553885024437342, 'recall': 0.9550898203592815, 'f1_score': 0.9550230061056472}, 'performance': {'train_time_seconds': 17.726267099380493, 'total_time_seconds': 50.75872278213501, 'inference_time_ms_per_sample': 0.00796846286979264}, 'confusion_matrix': [[73, 1, 2, 0, 1], [0, 55, 1, 2, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [0, 2, 2, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9605263157894737, 'recall': 0.948051948051948, 'f1': 0.954248366013072, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9206349206349206, 'recall': 0.9354838709677419, 'f1': 0.928, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_svd_n300_logistic', 'timestamp': '2025-10-21T12:58:43.479536', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.721653938293457, 'features_extracted': 5000, 'reduction_time': 2.8649544715881348, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9700598802395209, 'precision': 0.970683682925388, 'recall': 0.9700598802395209, 'f1_score': 0.969878180796915}, 'performance': {'train_time_seconds': 0.41942262649536133, 'total_time_seconds': 4.006031036376953, 'inference_time_ms_per_sample': 0.0017838563747748645}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 55, 1, 1, 0], [0, 0, 61, 1, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9861111111111112, 'recall': 0.922077922077922, 'f1': 0.9530201342281879, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9836065573770492, 'recall': 1.0, 'f1': 0.9917355371900827, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n300_svm', 'timestamp': '2025-10-21T12:58:09.138633', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.2377898693084717, 'features_extracted': 10000, 'reduction_time': 4.7638959884643555, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.9669744984861264, 'recall': 0.9670658682634731, 'f1_score': 0.966919993074902}, 'performance': {'train_time_seconds': 10.035152196884155, 'total_time_seconds': 17.036838054656982, 'inference_time_ms_per_sample': 0.0016432322427898112}, 'confusion_matrix': [[72, 1, 3, 0, 1], [0, 56, 1, 1, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.96, 'recall': 0.935064935064935, 'f1': 0.9473684210526315, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9836065573770492, 'recall': 1.0, 'f1': 0.9917355371900827, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n300_random_forest', 'timestamp': '2025-10-21T12:58:32.772734', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.6664080619812012, 'features_extracted': 10000, 'reduction_time': 3.880789279937744, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.8473053892215568, 'precision': 0.8557731805270882, 'recall': 0.8473053892215568, 'f1_score': 0.8471911626987415}, 'performance': {'train_time_seconds': 0.47530531883239746, 'total_time_seconds': 6.022502660751343, 'inference_time_ms_per_sample': 0.10471215505086019}, 'confusion_matrix': [[70, 1, 5, 0, 1], [5, 46, 0, 5, 2], [7, 1, 50, 4, 0], [2, 3, 0, 72, 0], [10, 3, 2, 0, 45]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7446808510638298, 'recall': 0.9090909090909091, 'f1': 0.8187134502923976, 'support': 77}, {'label': 'entertainment', 'precision': 0.8518518518518519, 'recall': 0.7931034482758621, 'f1': 0.8214285714285714, 'support': 58}, {'label': 'politics', 'precision': 0.8771929824561403, 'recall': 0.8064516129032258, 'f1': 0.8403361344537815, 'support': 62}, {'label': 'sport', 'precision': 0.8888888888888888, 'recall': 0.935064935064935, 'f1': 0.9113924050632911, 'support': 77}, {'label': 'tech', 'precision': 0.9375, 'recall': 0.75, 'f1': 0.8333333333333334, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_svd_n300_naive_bayes', 'timestamp': '2025-10-21T12:55:04.046621', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 2.166818380355835, 'features_extracted': 5000, 'reduction_time': 98.63720631599426, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.5718562874251497, 'precision': 0.5772411221513017, 'recall': 0.5718562874251497, 'f1_score': 0.5711587913179235}, 'performance': {'train_time_seconds': 0.00771784782409668, 'total_time_seconds': 100.8117425441742, 'inference_time_ms_per_sample': 0.0020101398764970062}, 'confusion_matrix': [[43, 7, 7, 7, 13], [5, 39, 2, 7, 5], [4, 8, 32, 9, 9], [2, 14, 7, 51, 3], [12, 10, 8, 4, 26]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6515151515151515, 'recall': 0.5584415584415584, 'f1': 0.6013986013986014, 'support': 77}, {'label': 'entertainment', 'precision': 0.5, 'recall': 0.6724137931034483, 'f1': 0.5735294117647058, 'support': 58}, {'label': 'politics', 'precision': 0.5714285714285714, 'recall': 0.5161290322580645, 'f1': 0.5423728813559322, 'support': 62}, {'label': 'sport', 'precision': 0.6538461538461539, 'recall': 0.6623376623376623, 'f1': 0.6580645161290323, 'support': 77}, {'label': 'tech', 'precision': 0.4642857142857143, 'recall': 0.43333333333333335, 'f1': 0.4482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_svm', 'timestamp': '2025-10-21T13:00:03.116445', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6231625080108643, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.955132880061035, 'recall': 0.9550898203592815, 'f1_score': 0.954929793129267}, 'performance': {'train_time_seconds': 0.8094727993011475, 'total_time_seconds': 2.4326353073120117, 'inference_time_ms_per_sample': 0.002163612913942622}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [1, 1, 58, 1, 1], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.96, 'recall': 0.935064935064935, 'f1': 0.9473684210526315, 'support': 77}, {'label': 'entertainment', 'precision': 0.9491525423728814, 'recall': 0.9655172413793104, 'f1': 0.9572649572649573, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9655172413793104, 'recall': 0.9333333333333333, 'f1': 0.9491525423728814, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n300_svm', 'timestamp': '2025-10-21T13:00:19.253692', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.9251790046691895, 'features_extracted': 5000, 'reduction_time': 3.343489170074463, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.9612472706571393, 'recall': 0.9610778443113772, 'f1_score': 0.9608690821855964}, 'performance': {'train_time_seconds': 9.753958225250244, 'total_time_seconds': 16.022626399993896, 'inference_time_ms_per_sample': 0.0020058569080101513}, 'confusion_matrix': [[71, 1, 3, 1, 1], [0, 55, 1, 2, 0], [3, 0, 58, 1, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9594594594594594, 'recall': 0.922077922077922, 'f1': 0.9403973509933775, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.9354838709677419, 'recall': 0.9354838709677419, 'f1': 0.9354838709677419, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9836065573770492, 'recall': 1.0, 'f1': 0.9917355371900827, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k1000_svm', 'timestamp': '2025-10-21T12:58:38.525021', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5708105564117432, 'features_extracted': 5000, 'reduction_time': 0.13814759254455566, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9493306201985031, 'recall': 0.9491017964071856, 'f1_score': 0.9486712288048192}, 'performance': {'train_time_seconds': 0.14265084266662598, 'total_time_seconds': 0.8516089916229248, 'inference_time_ms_per_sample': 0.004753381192327259}, 'confusion_matrix': [[71, 1, 2, 1, 2], [0, 55, 1, 2, 0], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [3, 3, 1, 0, 53]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9322033898305084, 'recall': 0.9482758620689655, 'f1': 0.9401709401709402, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9636363636363636, 'recall': 0.8833333333333333, 'f1': 0.9217391304347826, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n300_random_forest', 'timestamp': '2025-10-21T12:54:46.872396', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.1550064086914062, 'features_extracted': 5000, 'reduction_time': 17.32608413696289, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.8592814371257484, 'precision': 0.8662905311717382, 'recall': 0.8592814371257484, 'f1_score': 0.8575404936884088}, 'performance': {'train_time_seconds': 0.32223010063171387, 'total_time_seconds': 18.80332064628601, 'inference_time_ms_per_sample': 0.0999195133140701}, 'confusion_matrix': [[72, 1, 1, 2, 1], [4, 43, 1, 9, 1], [7, 1, 48, 5, 1], [0, 0, 2, 75, 0], [6, 4, 1, 0, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8089887640449438, 'recall': 0.935064935064935, 'f1': 0.8674698795180723, 'support': 77}, {'label': 'entertainment', 'precision': 0.8775510204081632, 'recall': 0.7413793103448276, 'f1': 0.8037383177570093, 'support': 58}, {'label': 'politics', 'precision': 0.9056603773584906, 'recall': 0.7741935483870968, 'f1': 0.8347826086956521, 'support': 62}, {'label': 'sport', 'precision': 0.8241758241758241, 'recall': 0.974025974025974, 'f1': 0.8928571428571429, 'support': 77}, {'label': 'tech', 'precision': 0.9423076923076923, 'recall': 0.8166666666666667, 'f1': 0.875, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k500_logistic', 'timestamp': '2025-10-21T13:00:41.633316', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.9386179447174072, 'features_extracted': 10000, 'reduction_time': 0.26361846923828125, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9495617956125221, 'recall': 0.9491017964071856, 'f1_score': 0.948905694821008}, 'performance': {'train_time_seconds': 1.0289056301116943, 'total_time_seconds': 3.231142044067383, 'inference_time_ms_per_sample': 0.004350068326481802}, 'confusion_matrix': [[70, 2, 3, 1, 1], [1, 56, 0, 1, 0], [1, 1, 59, 1, 0], [0, 0, 0, 77, 0], [3, 2, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9333333333333333, 'recall': 0.9090909090909091, 'f1': 0.9210526315789473, 'support': 77}, {'label': 'entertainment', 'precision': 0.9180327868852459, 'recall': 0.9655172413793104, 'f1': 0.9411764705882353, 'support': 58}, {'label': 'politics', 'precision': 0.9516129032258065, 'recall': 0.9516129032258065, 'f1': 0.9516129032258065, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9821428571428571, 'recall': 0.9166666666666666, 'f1': 0.9482758620689655, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n300_naive_bayes', 'timestamp': '2025-10-21T12:54:19.834787', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 0.5019998550415039, 'features_extracted': 5000, 'reduction_time': 26.448357105255127, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.49700598802395207, 'precision': 0.5109417528579205, 'recall': 0.49700598802395207, 'f1_score': 0.493993047782573}, 'performance': {'train_time_seconds': 0.05496716499328613, 'total_time_seconds': 27.005324125289917, 'inference_time_ms_per_sample': 0.004826191656603784}, 'confusion_matrix': [[28, 9, 9, 17, 14], [3, 28, 2, 18, 7], [6, 5, 31, 13, 7], [4, 11, 11, 47, 4], [4, 7, 13, 4, 32]], 'per_class_metrics': [{'label': 'business', 'precision': 0.6222222222222222, 'recall': 0.36363636363636365, 'f1': 0.45901639344262296, 'support': 77}, {'label': 'entertainment', 'precision': 0.4666666666666667, 'recall': 0.4827586206896552, 'f1': 0.4745762711864407, 'support': 58}, {'label': 'politics', 'precision': 0.4696969696969697, 'recall': 0.5, 'f1': 0.484375, 'support': 62}, {'label': 'sport', 'precision': 0.47474747474747475, 'recall': 0.6103896103896104, 'f1': 0.5340909090909091, 'support': 77}, {'label': 'tech', 'precision': 0.5, 'recall': 0.5333333333333333, 'f1': 0.5161290322580645, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n500_logistic', 'timestamp': '2025-10-21T13:00:54.035751', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.5639257431030273, 'features_extracted': 5000, 'reduction_time': 6.161293268203735, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9553666788698633, 'recall': 0.9550898203592815, 'f1_score': 0.9550008050524863}, 'performance': {'train_time_seconds': 0.23241949081420898, 'total_time_seconds': 7.957638502120972, 'inference_time_ms_per_sample': 0.0019323326156524842}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 55, 1, 1, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.921875, 'recall': 0.9516129032258065, 'f1': 0.9365079365079365, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_svm', 'timestamp': '2025-10-21T13:00:59.615386', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.4067094326019287, 'features_extracted': 10000, 'reduction_time': 0.30031394958496094, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9492687808402563, 'recall': 0.9491017964071856, 'f1_score': 0.9488098068555353}, 'performance': {'train_time_seconds': 0.14721441268920898, 'total_time_seconds': 2.8542377948760986, 'inference_time_ms_per_sample': 0.005160263198578429}, 'confusion_matrix': [[71, 1, 2, 1, 2], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 2, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9322033898305084, 'recall': 0.9482758620689655, 'f1': 0.9401709401709402, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.967741935483871, 'f1': 0.9523809523809523, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n500_logistic', 'timestamp': '2025-10-21T12:55:51.195698', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.1096909046173096, 'features_extracted': 5000, 'reduction_time': 55.2117440700531, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.9553666788698633, 'recall': 0.9550898203592815, 'f1_score': 0.9550008050524863}, 'performance': {'train_time_seconds': 9.637257814407349, 'total_time_seconds': 65.95869278907776, 'inference_time_ms_per_sample': 0.03356276871915349}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 55, 1, 1, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9821428571428571, 'recall': 0.9482758620689655, 'f1': 0.9649122807017544, 'support': 58}, {'label': 'politics', 'precision': 0.921875, 'recall': 0.9516129032258065, 'f1': 0.9365079365079365, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n500_naive_bayes', 'timestamp': '2025-10-21T13:00:05.997614', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.7218735218048096, 'features_extracted': 10000, 'reduction_time': 8.79366135597229, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.47305389221556887, 'precision': 0.4898371273647038, 'recall': 0.47305389221556887, 'f1_score': 0.46532977206903015}, 'performance': {'train_time_seconds': 0.06958913803100586, 'total_time_seconds': 10.585124015808105, 'inference_time_ms_per_sample': 0.0050824559377339075}, 'confusion_matrix': [[22, 18, 4, 13, 20], [3, 28, 1, 19, 7], [4, 13, 24, 10, 11], [3, 10, 10, 50, 4], [8, 9, 6, 3, 34]], 'per_class_metrics': [{'label': 'business', 'precision': 0.55, 'recall': 0.2857142857142857, 'f1': 0.37606837606837606, 'support': 77}, {'label': 'entertainment', 'precision': 0.358974358974359, 'recall': 0.4827586206896552, 'f1': 0.4117647058823529, 'support': 58}, {'label': 'politics', 'precision': 0.5333333333333333, 'recall': 0.3870967741935484, 'f1': 0.4485981308411215, 'support': 62}, {'label': 'sport', 'precision': 0.5263157894736842, 'recall': 0.6493506493506493, 'f1': 0.5813953488372093, 'support': 77}, {'label': 'tech', 'precision': 0.4473684210526316, 'recall': 0.5666666666666667, 'f1': 0.5, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k1000_logistic', 'timestamp': '2025-10-21T13:00:55.996838', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.754443645477295, 'features_extracted': 10000, 'reduction_time': 0.2762587070465088, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582480715261207, 'recall': 0.9580838323353293, 'f1_score': 0.9579495451843525}, 'performance': {'train_time_seconds': 0.5704948902130127, 'total_time_seconds': 3.6011972427368164, 'inference_time_ms_per_sample': 0.006095377984874977}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_logistic', 'timestamp': '2025-10-21T12:53:09.198361', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.6252079010009766, 'features_extracted': 5000, 'reduction_time': 0.13901495933532715, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582480715261207, 'recall': 0.9580838323353293, 'f1_score': 0.9579495451843525}, 'performance': {'train_time_seconds': 0.6220395565032959, 'total_time_seconds': 2.3862624168395996, 'inference_time_ms_per_sample': 0.006731398805172858}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 1, 60, 1, 0], [0, 0, 0, 77, 0], [3, 1, 0, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k1000_decision_tree', 'timestamp': '2025-10-21T12:58:41.545107', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.6093406677246094, 'features_extracted': 5000, 'reduction_time': 0.18863511085510254, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7994011976047904, 'precision': 0.8019461495985645, 'recall': 0.7994011976047904, 'f1_score': 0.7987767407459456}, 'performance': {'train_time_seconds': 0.12679386138916016, 'total_time_seconds': 1.924769639968872, 'inference_time_ms_per_sample': 0.002955248255929547}, 'confusion_matrix': [[62, 2, 6, 3, 4], [5, 40, 6, 5, 2], [10, 2, 45, 3, 2], [2, 3, 2, 70, 0], [7, 1, 2, 0, 50]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7209302325581395, 'recall': 0.8051948051948052, 'f1': 0.7607361963190185, 'support': 77}, {'label': 'entertainment', 'precision': 0.8333333333333334, 'recall': 0.6896551724137931, 'f1': 0.7547169811320755, 'support': 58}, {'label': 'politics', 'precision': 0.7377049180327869, 'recall': 0.7258064516129032, 'f1': 0.7317073170731707, 'support': 62}, {'label': 'sport', 'precision': 0.8641975308641975, 'recall': 0.9090909090909091, 'f1': 0.8860759493670886, 'support': 77}, {'label': 'tech', 'precision': 0.8620689655172413, 'recall': 0.8333333333333334, 'f1': 0.847457627118644, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k1000_logistic', 'timestamp': '2025-10-21T12:58:36.223984', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.747957706451416, 'features_extracted': 5000, 'reduction_time': 0.2319326400756836, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.9491017964071856, 'precision': 0.9493412900010231, 'recall': 0.9491017964071856, 'f1_score': 0.9487291399363083}, 'performance': {'train_time_seconds': 1.3057658672332764, 'total_time_seconds': 2.285656213760376, 'inference_time_ms_per_sample': 0.006331655079733112}, 'confusion_matrix': [[71, 1, 2, 1, 2], [1, 54, 1, 2, 0], [0, 0, 61, 1, 0], [0, 0, 0, 77, 0], [3, 2, 1, 0, 54]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9466666666666667, 'recall': 0.922077922077922, 'f1': 0.9342105263157895, 'support': 77}, {'label': 'entertainment', 'precision': 0.9473684210526315, 'recall': 0.9310344827586207, 'f1': 0.9391304347826087, 'support': 58}, {'label': 'politics', 'precision': 0.9384615384615385, 'recall': 0.9838709677419355, 'f1': 0.9606299212598425, 'support': 62}, {'label': 'sport', 'precision': 0.9506172839506173, 'recall': 1.0, 'f1': 0.9746835443037974, 'support': 77}, {'label': 'tech', 'precision': 0.9642857142857143, 'recall': 0.9, 'f1': 0.9310344827586207, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k500_logistic', 'timestamp': '2025-10-21T12:58:29.261013', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 1.1311838626861572, 'features_extracted': 5000, 'reduction_time': 0.1803886890411377, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9550898203592815, 'precision': 0.955096479972386, 'recall': 0.9550898203592815, 'f1_score': 0.9548787636704571}, 'performance': {'train_time_seconds': 1.2370555400848389, 'total_time_seconds': 2.548628091812134, 'inference_time_ms_per_sample': 0.02702981412053822}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 55, 1, 1, 0], [0, 0, 60, 1, 1], [0, 0, 0, 77, 0], [3, 2, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9523809523809523, 'recall': 0.967741935483871, 'f1': 0.96, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n300_random_forest', 'timestamp': '2025-10-21T13:00:42.100079', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 1.7279973030090332, 'features_extracted': 5000, 'reduction_time': 4.794756174087524, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.8562874251497006, 'precision': 0.8621242528380139, 'recall': 0.8562874251497006, 'f1_score': 0.8561982105510918}, 'performance': {'train_time_seconds': 0.31194448471069336, 'total_time_seconds': 6.834697961807251, 'inference_time_ms_per_sample': 0.10056624155558512}, 'confusion_matrix': [[71, 1, 3, 1, 1], [4, 46, 0, 7, 1], [6, 0, 51, 5, 0], [3, 4, 0, 70, 0], [5, 4, 3, 0, 48]], 'per_class_metrics': [{'label': 'business', 'precision': 0.797752808988764, 'recall': 0.922077922077922, 'f1': 0.8554216867469879, 'support': 77}, {'label': 'entertainment', 'precision': 0.8363636363636363, 'recall': 0.7931034482758621, 'f1': 0.8141592920353983, 'support': 58}, {'label': 'politics', 'precision': 0.8947368421052632, 'recall': 0.8225806451612904, 'f1': 0.8571428571428571, 'support': 62}, {'label': 'sport', 'precision': 0.8433734939759037, 'recall': 0.9090909090909091, 'f1': 0.875, 'support': 77}, {'label': 'tech', 'precision': 0.96, 'recall': 0.8, 'f1': 0.8727272727272727, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k500_naive_bayes', 'timestamp': '2025-10-21T13:00:48.561374', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.7845983505249023, 'features_extracted': 10000, 'reduction_time': 0.2703547477722168, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9820359281437125, 'precision': 0.9823089592595371, 'recall': 0.9820359281437125, 'f1_score': 0.9820616790388387}, 'performance': {'train_time_seconds': 0.009134054183959961, 'total_time_seconds': 2.064087152481079, 'inference_time_ms_per_sample': 0.0024869770347001312}, 'confusion_matrix': [[76, 0, 0, 0, 1], [1, 56, 0, 0, 1], [2, 0, 60, 0, 0], [0, 0, 0, 77, 0], [0, 1, 0, 0, 59]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9620253164556962, 'recall': 0.987012987012987, 'f1': 0.9743589743589743, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 1.0, 'recall': 0.967741935483871, 'f1': 0.9836065573770492, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9672131147540983, 'recall': 0.9833333333333333, 'f1': 0.9752066115702479, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_chi2_k500_decision_tree', 'timestamp': '2025-10-21T12:58:34.804555', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.0693485736846924, 'features_extracted': 5000, 'reduction_time': 0.1916356086730957, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.7934131736526946, 'precision': 0.7949682879010527, 'recall': 0.7934131736526946, 'f1_score': 0.7925932783075914}, 'performance': {'train_time_seconds': 0.14272379875183105, 'total_time_seconds': 1.4037079811096191, 'inference_time_ms_per_sample': 0.002999505596960376}, 'confusion_matrix': [[60, 3, 6, 3, 5], [4, 42, 4, 8, 0], [11, 2, 44, 2, 3], [2, 1, 1, 70, 3], [7, 2, 2, 0, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7142857142857143, 'recall': 0.7792207792207793, 'f1': 0.7453416149068323, 'support': 77}, {'label': 'entertainment', 'precision': 0.84, 'recall': 0.7241379310344828, 'f1': 0.7777777777777778, 'support': 58}, {'label': 'politics', 'precision': 0.7719298245614035, 'recall': 0.7096774193548387, 'f1': 0.7394957983193278, 'support': 62}, {'label': 'sport', 'precision': 0.8433734939759037, 'recall': 0.9090909090909091, 'f1': 0.875, 'support': 77}, {'label': 'tech', 'precision': 0.8166666666666667, 'recall': 0.8166666666666667, 'f1': 0.8166666666666667, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_svd_n300_random_forest', 'timestamp': '2025-10-21T12:59:49.826092', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.49426770210266113, 'features_extracted': 5000, 'reduction_time': 2.6601459980010986, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.8652694610778443, 'precision': 0.8723286151555663, 'recall': 0.8652694610778443, 'f1_score': 0.864191453582739}, 'performance': {'train_time_seconds': 0.25342226028442383, 'total_time_seconds': 3.4078359603881836, 'inference_time_ms_per_sample': 0.09766809954614696}, 'confusion_matrix': [[69, 3, 2, 1, 2], [5, 47, 0, 6, 0], [6, 2, 49, 5, 0], [0, 0, 0, 77, 0], [5, 6, 1, 1, 47]], 'per_class_metrics': [{'label': 'business', 'precision': 0.8117647058823529, 'recall': 0.8961038961038961, 'f1': 0.8518518518518519, 'support': 77}, {'label': 'entertainment', 'precision': 0.8103448275862069, 'recall': 0.8103448275862069, 'f1': 0.8103448275862069, 'support': 58}, {'label': 'politics', 'precision': 0.9423076923076923, 'recall': 0.7903225806451613, 'f1': 0.8596491228070176, 'support': 62}, {'label': 'sport', 'precision': 0.8555555555555555, 'recall': 1.0, 'f1': 0.9221556886227545, 'support': 77}, {'label': 'tech', 'precision': 0.9591836734693877, 'recall': 0.7833333333333333, 'f1': 0.8623853211009175, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_chi2_k500_svm', 'timestamp': '2025-10-21T13:00:44.887512', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 500, 'score_func': 'chi2'}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 3.15437388420105, 'features_extracted': 10000, 'reduction_time': 0.3427734375, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9520958083832335, 'precision': 0.9521095217958485, 'recall': 0.9520958083832335, 'f1_score': 0.951900443887059}, 'performance': {'train_time_seconds': 0.1607213020324707, 'total_time_seconds': 3.6578686237335205, 'inference_time_ms_per_sample': 0.0029152738833855725}, 'confusion_matrix': [[71, 1, 4, 0, 1], [1, 55, 0, 2, 0], [1, 0, 60, 0, 1], [0, 0, 0, 77, 0], [3, 2, 0, 0, 55]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9342105263157895, 'recall': 0.922077922077922, 'f1': 0.9281045751633987, 'support': 77}, {'label': 'entertainment', 'precision': 0.9482758620689655, 'recall': 0.9482758620689655, 'f1': 0.9482758620689655, 'support': 58}, {'label': 'politics', 'precision': 0.9375, 'recall': 0.967741935483871, 'f1': 0.9523809523809523, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9649122807017544, 'recall': 0.9166666666666666, 'f1': 0.9401709401709402, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_none_default_svm', 'timestamp': '2025-10-21T12:53:16.194029', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'svm', 'name': 'SVM', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 0.5605647563934326, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9580838323353293, 'precision': 0.9582955955257405, 'recall': 0.9580838323353293, 'f1_score': 0.9579734972801608}, 'performance': {'train_time_seconds': 0.6983299255371094, 'total_time_seconds': 1.258894681930542, 'inference_time_ms_per_sample': 0.0025091057052155454}, 'confusion_matrix': [[72, 1, 2, 1, 1], [0, 56, 1, 1, 0], [2, 0, 59, 1, 0], [0, 0, 0, 77, 0], [2, 1, 1, 0, 56]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1': 0.9655172413793104, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9625, 'recall': 1.0, 'f1': 0.9808917197452229, 'support': 77}, {'label': 'tech', 'precision': 0.9824561403508771, 'recall': 0.9333333333333333, 'f1': 0.9572649572649573, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_pca_n300_logistic', 'timestamp': '2025-10-21T13:00:13.542377', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 300}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.5569851398468018, 'features_extracted': 5000, 'reduction_time': 2.944516658782959, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.9670658682634731, 'precision': 0.967220084440634, 'recall': 0.9670658682634731, 'f1_score': 0.9668787539237004}, 'performance': {'train_time_seconds': 0.18973898887634277, 'total_time_seconds': 5.6912407875061035, 'inference_time_ms_per_sample': 0.0015804153716492797}, 'confusion_matrix': [[71, 1, 3, 1, 1], [1, 56, 1, 0, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9726027397260274, 'recall': 0.922077922077922, 'f1': 0.9466666666666667, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.967741935483871, 'recall': 1.0, 'f1': 0.9836065573770492, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_chi2_k1000_decision_tree', 'timestamp': '2025-10-21T12:53:18.905469', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'chi2', 'name': 'Chi¬≤', 'config': {'k': 1000, 'score_func': 'chi2'}}, 'classifier': {'type': 'decision_tree', 'name': 'Decision Tree', 'config': {'max_depth': 20, 'random_state': 42}}, 'extraction_time': 1.708139181137085, 'features_extracted': 5000, 'reduction_time': 0.20644307136535645, 'features_after_reduction': 1000, 'metrics': {'accuracy': 0.7904191616766467, 'precision': 0.7943552324279511, 'recall': 0.7904191616766467, 'f1_score': 0.7911972562416145}, 'performance': {'train_time_seconds': 0.24192237854003906, 'total_time_seconds': 2.1565046310424805, 'inference_time_ms_per_sample': 0.005604978093130146}, 'confusion_matrix': [[56, 1, 10, 4, 6], [6, 44, 3, 4, 1], [9, 2, 47, 2, 2], [3, 2, 4, 68, 0], [4, 1, 4, 2, 49]], 'per_class_metrics': [{'label': 'business', 'precision': 0.717948717948718, 'recall': 0.7272727272727273, 'f1': 0.7225806451612903, 'support': 77}, {'label': 'entertainment', 'precision': 0.88, 'recall': 0.7586206896551724, 'f1': 0.8148148148148148, 'support': 58}, {'label': 'politics', 'precision': 0.6911764705882353, 'recall': 0.7580645161290323, 'f1': 0.7230769230769231, 'support': 62}, {'label': 'sport', 'precision': 0.85, 'recall': 0.8831168831168831, 'f1': 0.8662420382165605, 'support': 77}, {'label': 'tech', 'precision': 0.8448275862068966, 'recall': 0.8166666666666667, 'f1': 0.8305084745762712, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_none_default_naive_bayes', 'timestamp': '2025-10-21T13:00:05.562148', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'none', 'name': 'None', 'config': {}}, 'classifier': {'type': 'naive_bayes', 'name': 'Naive Bayes', 'config': {}}, 'extraction_time': 1.606860876083374, 'features_extracted': 5000, 'reduction_time': 0, 'features_after_reduction': 5000, 'metrics': {'accuracy': 0.9760479041916168, 'precision': 0.9769557169444895, 'recall': 0.9760479041916168, 'f1_score': 0.9760681744843009}, 'performance': {'train_time_seconds': 0.16846847534179688, 'total_time_seconds': 1.775329351425171, 'inference_time_ms_per_sample': 0.010465433497628766}, 'confusion_matrix': [[73, 0, 2, 0, 2], [0, 55, 1, 0, 2], [1, 0, 61, 0, 0], [0, 0, 0, 77, 0], [0, 0, 0, 0, 60]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9864864864864865, 'recall': 0.948051948051948, 'f1': 0.9668874172185431, 'support': 77}, {'label': 'entertainment', 'precision': 1.0, 'recall': 0.9482758620689655, 'f1': 0.9734513274336283, 'support': 58}, {'label': 'politics', 'precision': 0.953125, 'recall': 0.9838709677419355, 'f1': 0.9682539682539683, 'support': 62}, {'label': 'sport', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'support': 77}, {'label': 'tech', 'precision': 0.9375, 'recall': 1.0, 'f1': 0.967741935483871, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n12_svd_n300_random_forest', 'timestamp': '2025-10-21T12:56:44.880040', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'svd', 'name': 'Truncated SVD', 'config': {'n_components': 300}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 2.378662109375, 'features_extracted': 5000, 'reduction_time': 55.39263296127319, 'features_after_reduction': 300, 'metrics': {'accuracy': 0.8532934131736527, 'precision': 0.8581639965505096, 'recall': 0.8532934131736527, 'f1_score': 0.8524710227087751}, 'performance': {'train_time_seconds': 0.2504997253417969, 'total_time_seconds': 58.02179479598999, 'inference_time_ms_per_sample': 0.09754532111619046}, 'confusion_matrix': [[67, 1, 3, 2, 4], [7, 46, 0, 5, 0], [4, 1, 51, 5, 1], [1, 0, 1, 75, 0], [8, 3, 3, 0, 46]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7701149425287356, 'recall': 0.8701298701298701, 'f1': 0.8170731707317073, 'support': 77}, {'label': 'entertainment', 'precision': 0.9019607843137255, 'recall': 0.7931034482758621, 'f1': 0.8440366972477065, 'support': 58}, {'label': 'politics', 'precision': 0.8793103448275862, 'recall': 0.8225806451612904, 'f1': 0.85, 'support': 62}, {'label': 'sport', 'precision': 0.8620689655172413, 'recall': 0.974025974025974, 'f1': 0.9146341463414634, 'support': 77}, {'label': 'tech', 'precision': 0.9019607843137255, 'recall': 0.7666666666666667, 'f1': 0.8288288288288288, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n500_logistic', 'timestamp': '2025-10-21T12:58:45.505091', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'logistic', 'name': 'Logistic Regression', 'config': {'max_iter': 1000, 'random_state': 42}}, 'extraction_time': 2.948129177093506, 'features_extracted': 10000, 'reduction_time': 25.3087317943573, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.9610778443113772, 'precision': 0.9611079378179738, 'recall': 0.9610778443113772, 'f1_score': 0.9610100504984803}, 'performance': {'train_time_seconds': 1.4394886493682861, 'total_time_seconds': 29.696349620819092, 'inference_time_ms_per_sample': 0.007640101952467135}, 'confusion_matrix': [[72, 1, 2, 1, 1], [1, 56, 1, 0, 0], [1, 0, 59, 1, 1], [0, 0, 0, 77, 0], [2, 0, 1, 0, 57]], 'per_class_metrics': [{'label': 'business', 'precision': 0.9473684210526315, 'recall': 0.935064935064935, 'f1': 0.9411764705882353, 'support': 77}, {'label': 'entertainment', 'precision': 0.9824561403508771, 'recall': 0.9655172413793104, 'f1': 0.9739130434782609, 'support': 58}, {'label': 'politics', 'precision': 0.9365079365079365, 'recall': 0.9516129032258065, 'f1': 0.944, 'support': 62}, {'label': 'sport', 'precision': 0.9746835443037974, 'recall': 1.0, 'f1': 0.9871794871794872, 'support': 77}, {'label': 'tech', 'precision': 0.9661016949152542, 'recall': 0.95, 'f1': 0.957983193277311, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m10000_n12_pca_n500_random_forest', 'timestamp': '2025-10-21T13:00:16.642849', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 10000, 'ngram_range': [1, 2], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 2.8174712657928467, 'features_extracted': 10000, 'reduction_time': 8.997152328491211, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.8353293413173652, 'precision': 0.8457073898333426, 'recall': 0.8353293413173652, 'f1_score': 0.834265189493075}, 'performance': {'train_time_seconds': 0.36716723442077637, 'total_time_seconds': 12.181790828704834, 'inference_time_ms_per_sample': 0.10181401304142204}, 'confusion_matrix': [[69, 0, 3, 3, 2], [4, 43, 0, 11, 0], [5, 1, 50, 6, 0], [1, 3, 0, 73, 0], [9, 4, 3, 0, 44]], 'per_class_metrics': [{'label': 'business', 'precision': 0.7840909090909091, 'recall': 0.8961038961038961, 'f1': 0.8363636363636363, 'support': 77}, {'label': 'entertainment', 'precision': 0.8431372549019608, 'recall': 0.7413793103448276, 'f1': 0.7889908256880734, 'support': 58}, {'label': 'politics', 'precision': 0.8928571428571429, 'recall': 0.8064516129032258, 'f1': 0.847457627118644, 'support': 62}, {'label': 'sport', 'precision': 0.7849462365591398, 'recall': 0.948051948051948, 'f1': 0.8588235294117647, 'support': 77}, {'label': 'tech', 'precision': 0.9565217391304348, 'recall': 0.7333333333333333, 'f1': 0.8301886792452831, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}, {'pipeline_id': 'bow_m5000_n11_pca_n500_random_forest', 'timestamp': '2025-10-21T12:58:16.024201', 'extractor': {'type': 'bow', 'name': 'Bag of Words', 'config': {'max_features': 5000, 'ngram_range': [1, 1], 'min_df': 2}}, 'reducer': {'type': 'pca', 'name': 'PCA', 'config': {'n_components': 500}}, 'classifier': {'type': 'random_forest', 'name': 'Random Forest', 'config': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}}, 'extraction_time': 0.5613861083984375, 'features_extracted': 5000, 'reduction_time': 5.172078609466553, 'features_after_reduction': 500, 'metrics': {'accuracy': 0.8143712574850299, 'precision': 0.8273532523310462, 'recall': 0.8143712574850299, 'f1_score': 0.8111639814406696}, 'performance': {'train_time_seconds': 0.3358938694000244, 'total_time_seconds': 6.069358587265015, 'inference_time_ms_per_sample': 0.10824560405251508}, 'confusion_matrix': [[72, 0, 3, 2, 0], [4, 38, 1, 14, 1], [8, 1, 44, 8, 1], [0, 2, 1, 73, 1], [8, 4, 2, 1, 45]], 'per_class_metrics': [{'label': 'business', 'precision': 0.782608695652174, 'recall': 0.935064935064935, 'f1': 0.8520710059171598, 'support': 77}, {'label': 'entertainment', 'precision': 0.8444444444444444, 'recall': 0.6551724137931034, 'f1': 0.7378640776699029, 'support': 58}, {'label': 'politics', 'precision': 0.8627450980392157, 'recall': 0.7096774193548387, 'f1': 0.7787610619469026, 'support': 62}, {'label': 'sport', 'precision': 0.7448979591836735, 'recall': 0.948051948051948, 'f1': 0.8342857142857143, 'support': 77}, {'label': 'tech', 'precision': 0.9375, 'recall': 0.75, 'f1': 0.8333333333333334, 'support': 60}], 'labels': ['business', 'entertainment', 'politics', 'sport', 'tech'], 'status': 'success'}]};
    </script>
    
    <!-- Main script -->
    <script>

// ===== GLOBAL STATE =====
let selectedExtractor = 'tfidf';
let selectedReducer = 'none';
let selectedClassifiers = ['logistic', 'svm', 'naive_bayes'];

// ===== INITIALIZATION =====
document.addEventListener('DOMContentLoaded', function() {
    initializeBuilder();
    updatePreview();
    
    // Add change listeners
    document.querySelectorAll('input[name="extractor"]').forEach(radio => {
        radio.addEventListener('change', handleExtractorChange);
    });
    
    document.querySelectorAll('input[name="reducer"]').forEach(radio => {
        radio.addEventListener('change', handleReducerChange);
    });
    
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.addEventListener('change', handleClassifierChange);
    });
});

function initializeBuilder() {
    // Set initial checked states
    document.querySelector('input[name="extractor"][value="tfidf"]').checked = true;
    document.querySelector('input[name="reducer"][value="none"]').checked = true;
    
    ['logistic', 'svm', 'naive_bayes'].forEach(clf => {
        document.querySelector(`input[name="classifier"][value="${clf}"]`).checked = true;
    });
}

// ===== EVENT HANDLERS =====
function handleExtractorChange(e) {
    selectedExtractor = e.target.value;
    updateRadioStyles('extractor');
    updatePreview();
}

function handleReducerChange(e) {
    selectedReducer = e.target.value;
    updateRadioStyles('reducer');
    updatePreview();
}

function handleClassifierChange(e) {
    if (e.target.checked) {
        selectedClassifiers.push(e.target.value);
    } else {
        selectedClassifiers = selectedClassifiers.filter(c => c !== e.target.value);
    }
    updateCheckboxStyles();
    updatePreview();
}

function updateRadioStyles(name) {
    document.querySelectorAll(`input[name="${name}"]`).forEach(radio => {
        const label = radio.closest('label');
        if (radio.checked) {
            label.classList.add('checked');
        } else {
            label.classList.remove('checked');
        }
    });
}

function updateCheckboxStyles() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        const label = checkbox.closest('label');
        if (checkbox.checked) {
            label.classList.add('checked');
        } else {
            label.classList.remove('checked');
        }
    });
}

function updatePreview() {
    const count = selectedClassifiers.length;
    const extractorName = document.querySelector(`input[name="extractor"][value="${selectedExtractor}"]`).dataset.name;
    const reducerName = document.querySelector(`input[name="reducer"][value="${selectedReducer}"]`).dataset.name;
    
    document.getElementById('preview-count').textContent = count;
    
    const list = document.getElementById('preview-list');
    list.innerHTML = '';
    
    selectedClassifiers.forEach(clf => {
        const classifierName = document.querySelector(`input[name="classifier"][value="${clf}"]`).dataset.name;
        const li = document.createElement('li');
        li.textContent = `${extractorName} ‚Üí ${reducerName} ‚Üí ${classifierName}`;
        list.appendChild(li);
    });
}

// ===== CLASSIFIER ACTIONS =====
function selectAllClassifiers() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.checked = true;
        selectedClassifiers = Array.from(document.querySelectorAll('input[name="classifier"]')).map(cb => cb.value);
    });
    updateCheckboxStyles();
    updatePreview();
}

function deselectAllClassifiers() {
    document.querySelectorAll('input[name="classifier"]').forEach(checkbox => {
        checkbox.checked = false;
    });
    selectedClassifiers = [];
    updateCheckboxStyles();
    updatePreview();
}

function selectTopClassifiers() {
    // Top 3 fastest: Naive Bayes, SVM, Logistic
    deselectAllClassifiers();
    ['naive_bayes', 'svm', 'logistic'].forEach(clf => {
        const checkbox = document.querySelector(`input[name="classifier"][value="${clf}"]`);
        if (checkbox) {
            checkbox.checked = true;
            selectedClassifiers.push(clf);
        }
    });
    updateCheckboxStyles();
    updatePreview();
}

function resetBuilder() {
    selectedExtractor = 'tfidf';
    selectedReducer = 'none';
    selectedClassifiers = ['logistic', 'svm', 'naive_bayes'];
    initializeBuilder();
    updateRadioStyles('extractor');
    updateRadioStyles('reducer');
    updateCheckboxStyles();
    updatePreview();
    
    // Hide results if shown
    document.getElementById('results-section').style.display = 'none';
}

// ===== COMPARE PIPELINES =====
function comparePipelines() {
    if (selectedClassifiers.length === 0) {
        alert('Please select at least one classifier!');
        return;
    }
    
    // Filter matching pipelines
    const matchingPipelines = allPipelinesData.all_results.filter(pipeline => {
        return pipeline.extractor.type === selectedExtractor &&
               pipeline.reducer.type === selectedReducer &&
               selectedClassifiers.includes(pipeline.classifier.type);
    });
    
    if (matchingPipelines.length === 0) {
        alert('No matching pipelines found! Try different combinations.');
        return;
    }
    
    // Show results section
    document.getElementById('results-section').style.display = 'block';
    
    // Scroll to results
    document.getElementById('results-section').scrollIntoView({ behavior: 'smooth' });
    
    // Build visualizations
    buildBestCards(matchingPipelines);
    buildComparisonTable(matchingPipelines);
    buildHeatmap(allPipelinesData.all_results);
    buildTradeoffChart(allPipelinesData.all_results);
    buildConfusionMatrices(matchingPipelines);
}

// ===== BUILD BEST CARDS =====
function buildBestCards(pipelines) {
    const bestAccuracy = pipelines.reduce((a, b) => a.metrics.accuracy > b.metrics.accuracy ? a : b);
    const fastestTrain = pipelines.reduce((a, b) => a.performance.total_time_seconds < b.performance.total_time_seconds ? a : b);
    const fastestInfer = pipelines.reduce((a, b) => a.performance.inference_time_ms_per_sample < b.performance.inference_time_ms_per_sample ? a : b);
    
    const html = `
        <div class="best-card accuracy">
            <h3>üèÜ Best Accuracy</h3>
            <div class="metric-value" style="color: #10b981;">${(bestAccuracy.metrics.accuracy * 100).toFixed(2)}%</div>
            <div class="pipeline-name">${formatPipelineName(bestAccuracy)}</div>
        </div>
        <div class="best-card speed">
            <h3>‚ö° Fastest Training</h3>
            <div class="metric-value" style="color: #f59e0b;">${fastestTrain.performance.total_time_seconds.toFixed(2)}s</div>
            <div class="pipeline-name">${formatPipelineName(fastestTrain)}</div>
        </div>
        <div class="best-card size">
            <h3>üí® Fastest Inference</h3>
            <div class="metric-value" style="color: #3b82f6;">${fastestInfer.performance.inference_time_ms_per_sample.toFixed(2)}ms</div>
            <div class="pipeline-name">${formatPipelineName(fastestInfer)}</div>
        </div>
    `;
    
    document.getElementById('best-cards').innerHTML = html;
}

function formatPipelineName(pipeline) {
    return `${pipeline.extractor.name} ‚Üí ${pipeline.reducer.name} ‚Üí ${pipeline.classifier.name}`;
}

// ===== BUILD COMPARISON TABLE =====
function buildComparisonTable(pipelines) {
    // Find best values
    const bestAcc = Math.max(...pipelines.map(p => p.metrics.accuracy));
    const bestF1 = Math.max(...pipelines.map(p => p.metrics.f1_score));
    const bestTrain = Math.min(...pipelines.map(p => p.performance.total_time_seconds));
    const bestInfer = Math.min(...pipelines.map(p => p.performance.inference_time_ms_per_sample));
    
    let rows = '';
    pipelines.forEach(p => {
        const isBestAcc = p.metrics.accuracy === bestAcc;
        const isBestF1 = p.metrics.f1_score === bestF1;
        const isBestTrain = p.performance.total_time_seconds === bestTrain;
        const isBestInfer = p.performance.inference_time_ms_per_sample === bestInfer;
        
        rows += `
            <tr>
                <td class="pipeline-cell">${formatPipelineName(p)}</td>
                <td class="${isBestAcc ? 'metric-best' : ''}">${(p.metrics.accuracy * 100).toFixed(2)}%</td>
                <td class="${isBestF1 ? 'metric-best' : ''}">${(p.metrics.f1_score * 100).toFixed(2)}%</td>
                <td class="${isBestTrain ? 'metric-best' : ''}">${p.performance.total_time_seconds.toFixed(2)}s</td>
                <td class="${isBestInfer ? 'metric-best' : ''}">${p.performance.inference_time_ms_per_sample.toFixed(3)}ms</td>
                <td>${p.features_extracted}</td>
                <td>${p.features_after_reduction}</td>
            </tr>
        `;
    });
    
    const html = `
        <table class="comparison-table">
            <thead>
                <tr>
                    <th>Pipeline</th>
                    <th>Accuracy</th>
                    <th>F1-Score</th>
                    <th>Train Time</th>
                    <th>Inference</th>
                    <th>Features (Raw)</th>
                    <th>Features (Final)</th>
                </tr>
            </thead>
            <tbody>
                ${rows}
            </tbody>
        </table>
    `;
    
    document.getElementById('comparison-table-container').innerHTML = html;
}

// ===== BUILD HEATMAP =====
function buildHeatmap(allPipelines) {
    // Group by extractor+reducer (x-axis) and classifier (y-axis)
    const classifiers = ['logistic', 'svm', 'naive_bayes', 'random_forest', 'decision_tree'];
    const pipelines_combos = [];
    
    // Get unique extractor+reducer combinations
    const combinations = {};
    allPipelines.forEach(p => {
        const combo = `${p.extractor.type}_${p.reducer.type}`;
        if (!combinations[combo]) {
            combinations[combo] = `${p.extractor.name}+${p.reducer.name}`;
        }
    });
    
    const xLabels = Object.values(combinations);
    const yLabels = classifiers.map(clf => {
        const sample = allPipelines.find(p => p.classifier.type === clf);
        return sample ? sample.classifier.name : clf;
    });
    
    // Build matrix
    const zData = [];
    classifiers.forEach(clf => {
        const row = [];
        Object.keys(combinations).forEach(combo => {
            const [ext, red] = combo.split('_');
            const pipeline = allPipelines.find(p => 
                p.extractor.type === ext && 
                p.reducer.type === red && 
                p.classifier.type === clf
            );
            row.push(pipeline ? pipeline.metrics.accuracy * 100 : null);
        });
        zData.push(row);
    });
    
    const data = [{
        z: zData,
        x: xLabels,
        y: yLabels,
        type: 'heatmap',
        colorscale: [
            [0, '#ef4444'],
            [0.85, '#f59e0b'],
            [0.90, '#fbbf24'],
            [0.95, '#a7f3d0'],
            [1, '#10b981']
        ],
        hovertemplate: '%{y}<br>%{x}<br>Accuracy: %{z:.2f}%<extra></extra>',
        colorbar: {
            title: 'Accuracy (%)',
            titleside: 'right'
        }
    }];
    
    const layout = {
        xaxis: { title: 'Feature Extraction + Reduction', tickangle: -45 },
        yaxis: { title: 'Classifier' },
        margin: { l: 150, r: 50, b: 150, t: 50 },
        height: 500
    };
    
    Plotly.newPlot('heatmap-chart', data, layout, {responsive: true});
}

// ===== BUILD TRADEOFF CHART =====
function buildTradeoffChart(allPipelines) {
    const traces = [];
    const classifiers = [...new Set(allPipelines.map(p => p.classifier.type))];
    const colors = ['#667eea', '#f59e0b', '#10b981', '#ef4444', '#3b82f6'];
    
    classifiers.forEach((clf, idx) => {
        const pipelinesForClf = allPipelines.filter(p => p.classifier.type === clf);
        
        traces.push({
            x: pipelinesForClf.map(p => p.performance.total_time_seconds),
            y: pipelinesForClf.map(p => p.metrics.accuracy * 100),
            mode: 'markers',
            type: 'scatter',
            name: pipelinesForClf[0].classifier.name,
            marker: {
                size: 12,
                color: colors[idx % colors.length]
            },
            text: pipelinesForClf.map(p => formatPipelineName(p)),
            hovertemplate: '%{text}<br>Time: %{x:.2f}s<br>Accuracy: %{y:.2f}%<extra></extra>'
        });
    });
    
    const layout = {
        xaxis: { title: 'Training Time (seconds)', type: 'log' },
        yaxis: { title: 'Accuracy (%)', range: [75, 100] },
        hovermode: 'closest',
        legend: { x: 0.7, y: 0.1 },
        height: 500
    };
    
    Plotly.newPlot('tradeoff-chart', traces, layout, {responsive: true});
}

// ===== BUILD CONFUSION MATRICES =====
function buildConfusionMatrices(pipelines) {
    const html = '<h3>üéØ Confusion Matrices (Selected Pipelines)</h3><div class="cm-grid" id="cm-grid"></div>';
    document.getElementById('confusion-matrices').innerHTML = html;
    
    const grid = document.getElementById('cm-grid');
    
    pipelines.forEach((p, idx) => {
        const div = document.createElement('div');
        div.id = `cm-${idx}`;
        grid.appendChild(div);
        
        const data = [{
            z: p.confusion_matrix,
            x: p.labels,
            y: p.labels,
            type: 'heatmap',
            colorscale: 'Blues',
            hovertemplate: 'True: %{y}<br>Pred: %{x}<br>Count: %{z}<extra></extra>'
        }];
        
        const layout = {
            title: `${formatPipelineName(p)}<br>Accuracy: ${(p.metrics.accuracy * 100).toFixed(2)}%`,
            xaxis: { title: 'Predicted', side: 'bottom' },
            yaxis: { title: 'True', autorange: 'reversed' },
            height: 400,
            margin: { l: 100, r: 50, b: 100, t: 80 }
        };
        
        Plotly.newPlot(`cm-${idx}`, data, layout, {responsive: true});
    });
}

    </script>
</body>
</html>