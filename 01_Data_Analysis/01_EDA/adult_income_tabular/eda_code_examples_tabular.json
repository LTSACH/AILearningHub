{
  "dataset_overview": {
    "title": "Dataset Overview",
    "explanation": {
      "what": "Dataset overview provides a high-level summary: number of samples, features, data types, and target distribution.",
      "why": "Understanding dataset structure is the first step in EDA. It helps identify what kind of analysis is needed and potential challenges.",
      "how": "Check for balanced/imbalanced targets, identify numerical vs categorical features, and understand dataset size for memory planning."
    },
    "plotly": "import pandas as pd\nimport plotly.graph_objects as go\n\n# Load data from GitHub\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Basic info\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Total samples: {len(df):,}\")\nprint(f\"Total features: {len(df.columns)}\")\nprint(f\"\\nFeatures: {list(df.columns)}\")\n\n# Data types\nprint(f\"\\nData types:\")\nprint(df.dtypes)\n\n# Target distribution\ntarget_dist = df['income'].value_counts()\nprint(f\"\\nTarget distribution:\")\nprint(target_dist)\n\n# Create pie chart for target\nfig = go.Figure(data=[go.Pie(\n    labels=target_dist.index,\n    values=target_dist.values,\n    hole=0.3,\n    marker=dict(colors=['#667eea', '#f093fb']),\n    textinfo='label+percent+value',\n    textfont_size=14\n)])\n\nfig.update_layout(\n    title='Income Distribution',\n    showlegend=True,\n    width=600,\n    height=400\n)\n\nfig.show()",
    "matplotlib": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Basic info\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Total samples: {len(df):,}\")\nprint(df.info())\n\n# Target distribution pie chart\ntarget_dist = df['income'].value_counts()\n\nfig, ax = plt.subplots(figsize=(8, 6))\ncolors = ['#667eea', '#f093fb']\n\nwedges, texts, autotexts = ax.pie(\n    target_dist.values,\n    labels=target_dist.index,\n    autopct='%1.1f%%',\n    colors=colors,\n    startangle=90\n)\n\nfor autotext in autotexts:\n    autotext.set_color('white')\n    autotext.set_fontweight('bold')\n\nax.set_title('Income Distribution', fontsize=16, pad=20)\nplt.tight_layout()\nplt.show()",
    "seaborn": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Summary statistics\nprint(df.describe())\nprint(f\"\\nDataset shape: {df.shape}\")\n\n# Target distribution bar plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\ntarget_dist = df['income'].value_counts()\nsns.barplot(x=target_dist.index, y=target_dist.values, \n           palette=['#667eea', '#f093fb'], ax=ax)\n\nax.set_title('Income Distribution', fontsize=16, pad=20)\nax.set_xlabel('Income Class', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\n\n# Add value labels\nfor i, v in enumerate(target_dist.values):\n    ax.text(i, v + 500, f'{v:,}', ha='center', fontweight='bold')\n\nplt.tight_layout()\nplt.show()"
  },
  "missing_values": {
    "title": "Missing Values Analysis",
    "explanation": {
      "what": "Missing values analysis identifies which features have missing data, how much is missing, and patterns in missingness.",
      "why": "Missing data can bias results and reduce statistical power. Understanding missing patterns helps choose appropriate imputation strategies.",
      "how": "Check missing percentage per feature. <5% = simple imputation, 5-30% = advanced methods, >50% = consider dropping. Look for patterns (MAR, MCAR, MNAR)."
    },
    "plotly": "import pandas as pd\nimport plotly.graph_objects as go\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Calculate missing values\nmissing_counts = df.isnull().sum()\nmissing_pct = (df.isnull().sum() / len(df) * 100)\n\n# Filter columns with missing values\nmissing_df = pd.DataFrame({\n    'column': missing_counts[missing_counts > 0].index,\n    'count': missing_counts[missing_counts > 0].values,\n    'percentage': missing_pct[missing_counts > 0].values\n}).sort_values('percentage', ascending=False)\n\nprint(\"Missing Values Summary:\")\nprint(missing_df)\n\n# Create bar chart\nfig = go.Figure(data=[go.Bar(\n    x=missing_df['column'],\n    y=missing_df['percentage'],\n    marker_color='#f093fb',\n    text=[f\"{p:.2f}%\" for p in missing_df['percentage']],\n    textposition='outside'\n)])\n\nfig.update_layout(\n    title='Missing Values by Feature (%)',\n    xaxis_title='Features',\n    yaxis_title='Missing Percentage',\n    width=800,\n    height=400\n)\n\nfig.show()\n\n# Imputation recommendations\nprint(\"\\nüí° Recommendations:\")\nfor _, row in missing_df.iterrows():\n    col, pct = row['column'], row['percentage']\n    if pct > 50:\n        print(f\"  {col}: {pct:.1f}% missing ‚Üí Consider dropping\")\n    elif pct > 5:\n        print(f\"  {col}: {pct:.1f}% missing ‚Üí Use advanced imputation (KNN, iterative)\")\n    else:\n        print(f\"  {col}: {pct:.1f}% missing ‚Üí Simple imputation (mode/median)\")",
    "matplotlib": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Calculate missing values\nmissing_counts = df.isnull().sum()\nmissing_pct = (missing_counts / len(df) * 100)\n\n# Filter and sort\nmissing_data = missing_pct[missing_pct > 0].sort_values(ascending=False)\n\n# Create bar chart\nfig, ax = plt.subplots(figsize=(10, 6))\nax.bar(missing_data.index, missing_data.values, color='#f093fb', alpha=0.7)\n\nax.set_title('Missing Values by Feature', fontsize=16, pad=20)\nax.set_xlabel('Features', fontsize=12)\nax.set_ylabel('Missing Percentage (%)', fontsize=12)\nax.grid(axis='y', alpha=0.3)\n\n# Add value labels\nfor i, (col, pct) in enumerate(missing_data.items()):\n    ax.text(i, pct + 0.2, f'{pct:.2f}%', ha='center', fontweight='bold')\n\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()\n\n# Print summary\nprint(f\"\\nTotal missing values: {missing_counts.sum():,}\")\nprint(f\"Columns with missing: {len(missing_data)}\")",
    "seaborn": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Missing values heatmap (sample of data)\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Sample rows for visualization\nsample_df = df.sample(min(1000, len(df)), random_state=42)\n\n# Create mask for missing values\nsns.heatmap(sample_df.isnull(), \n           cbar=True,\n           cmap='viridis',\n           yticklabels=False,\n           ax=ax)\n\nax.set_title('Missing Values Pattern (sample of 1000 rows)', fontsize=16, pad=20)\nax.set_xlabel('Features', fontsize=12)\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()\n\n# Missing percentage\nmissing_pct = (df.isnull().sum() / len(df) * 100).sort_values(ascending=False)\nprint(\"\\nMissing Percentage:\")\nprint(missing_pct[missing_pct > 0])"
  },
  "numerical_distributions": {
    "title": "Numerical Feature Distributions",
    "explanation": {
      "what": "Distribution analysis shows how numerical values are spread: normal, skewed, bimodal, etc. Includes histograms, KDE plots, and box plots.",
      "why": "Understanding distributions helps choose preprocessing (scaling, transformation), detect outliers, and select appropriate models.",
      "how": "Look for shape (normal, skewed), outliers (box plot whiskers), and range. Right-skewed data may need log transformation. Outliers may need capping or removal."
    },
    "plotly": "import pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Select a numerical feature\nfeature = 'age'  # Change to: age, education_num, capital_gain, hours_per_week\n\n# Create histogram with KDE\nfig = go.Figure()\n\nfig.add_trace(go.Histogram(\n    x=df[feature],\n    nbinsx=30,\n    name='Distribution',\n    marker_color='#667eea',\n    opacity=0.7\n))\n\nfig.update_layout(\n    title=f'{feature.replace(\"_\", \" \").title()} Distribution',\n    xaxis_title=feature.replace('_', ' ').title(),\n    yaxis_title='Count',\n    width=800,\n    height=400,\n    showlegend=True\n)\n\nfig.show()\n\n# Statistics\nprint(f\"\\n{feature} Statistics:\")\nprint(f\"  Mean: {df[feature].mean():.2f}\")\nprint(f\"  Median: {df[feature].median():.2f}\")\nprint(f\"  Std: {df[feature].std():.2f}\")\nprint(f\"  Min: {df[feature].min()}\")\nprint(f\"  Max: {df[feature].max()}\")\n\n# Box plot for outliers\nfig2 = go.Figure()\n\nfig2.add_trace(go.Box(\n    y=df[feature],\n    name=feature,\n    marker_color='#764ba2',\n    boxmean='sd'  # Show mean and std\n))\n\nfig2.update_layout(\n    title=f'{feature.replace(\"_\", \" \").title()} - Box Plot (Outlier Detection)',\n    yaxis_title=feature.replace('_', ' ').title(),\n    width=600,\n    height=500\n)\n\nfig2.show()",
    "matplotlib": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Analyze all numerical features\nnumerical_cols = ['age', 'fnlwgt', 'education_num', 'capital_gain', \n                  'capital_loss', 'hours_per_week']\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\nfig.suptitle('Numerical Features Distribution', fontsize=16, y=0.995)\n\nfor idx, col in enumerate(numerical_cols):\n    ax = axes[idx // 3, idx % 3]\n    \n    # Histogram\n    ax.hist(df[col].dropna(), bins=30, color='#667eea', alpha=0.7, edgecolor='black')\n    ax.set_title(col.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n    ax.set_xlabel(col.replace('_', ' ').title())\n    ax.set_ylabel('Frequency')\n    ax.grid(axis='y', alpha=0.3)\n    \n    # Add mean line\n    mean_val = df[col].mean()\n    ax.axvline(mean_val, color='red', linestyle='--', \n              linewidth=2, label=f'Mean: {mean_val:.1f}')\n    ax.legend(fontsize=8)\n\nplt.tight_layout()\nplt.show()\n\n# Print statistics\nprint(\"\\nNumerical Features Statistics:\")\nprint(df[numerical_cols].describe())",
    "seaborn": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Select numerical features\nnumerical_cols = ['age', 'education_num', 'capital_gain', 'hours_per_week']\n\n# Create distribution plots with KDE\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfig.suptitle('Numerical Features Distribution with KDE', fontsize=16)\n\nfor idx, col in enumerate(numerical_cols):\n    ax = axes[idx // 2, idx % 2]\n    \n    sns.histplot(data=df, x=col, kde=True, color='#667eea', ax=ax)\n    ax.set_title(col.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n    ax.set_xlabel(col.replace('_', ' ').title())\n    ax.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Box plots for outlier detection\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfig.suptitle('Box Plots - Outlier Detection', fontsize=16)\n\nfor idx, col in enumerate(numerical_cols):\n    ax = axes[idx // 2, idx % 2]\n    \n    sns.boxplot(y=df[col], color='#764ba2', ax=ax)\n    ax.set_title(col.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n    ax.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  "categorical_distributions": {
    "title": "Categorical Feature Distributions",
    "explanation": {
      "what": "Categorical distribution shows frequency of each category value. Reveals cardinality (number of unique values) and class balance.",
      "why": "High cardinality (many unique values) requires different encoding strategies. Imbalanced categories may need special handling.",
      "how": "Check unique value counts. Low cardinality (<10) ‚Üí One-Hot Encoding. High cardinality (>50) ‚Üí Target Encoding or Frequency Encoding. Rare categories (<1%) may need grouping."
    },
    "plotly": "import pandas as pd\nimport plotly.graph_objects as go\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Select a categorical feature\nfeature = 'workclass'  # Change to: education, marital_status, occupation, etc.\n\n# Get value counts\nvalue_counts = df[feature].value_counts()\n\n# Create bar chart\nfig = go.Figure(data=[go.Bar(\n    x=value_counts.index,\n    y=value_counts.values,\n    marker_color='#4facfe',\n    text=value_counts.values,\n    textposition='outside'\n)])\n\nfig.update_layout(\n    title=f'{feature.replace(\"_\", \" \").title()} Distribution',\n    xaxis_title=feature.replace('_', ' ').title(),\n    yaxis_title='Count',\n    width=900,\n    height=500,\n    xaxis={'tickangle': 45}\n)\n\nfig.show()\n\n# Print statistics\nprint(f\"\\n{feature} Statistics:\")\nprint(f\"  Unique values: {df[feature].nunique()}\")\nprint(f\"  Missing: {df[feature].isnull().sum()} ({df[feature].isnull().sum()/len(df)*100:.2f}%)\")\nprint(f\"\\nTop categories:\")\nfor cat, count in value_counts.head(10).items():\n    print(f\"  {cat}: {count:,} ({count/len(df)*100:.2f}%)\")",
    "matplotlib": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Analyze all categorical features\ncategorical_cols = ['workclass', 'education', 'marital_status', 'occupation']\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\nfig.suptitle('Categorical Features Distribution', fontsize=16, y=0.995)\n\nfor idx, col in enumerate(categorical_cols):\n    ax = axes[idx // 2, idx % 2]\n    \n    value_counts = df[col].value_counts().head(10)\n    \n    ax.barh(value_counts.index, value_counts.values, color='#4facfe', alpha=0.7)\n    ax.set_title(col.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n    ax.set_xlabel('Count')\n    ax.invert_yaxis()\n    ax.grid(axis='x', alpha=0.3)\n    \n    # Add unique count\n    ax.text(0.02, 0.98, f'Unique: {df[col].nunique()}', \n           transform=ax.transAxes, va='top', fontsize=9,\n           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\nplt.tight_layout()\nplt.show()",
    "seaborn": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Select feature\nfeature = 'education'  # Change to other categorical features\n\n# Get top 15 categories\nvalue_counts = df[feature].value_counts().head(15)\n\n# Create bar plot\nfig, ax = plt.subplots(figsize=(10, 8))\n\nsns.barplot(y=value_counts.index, x=value_counts.values, \n           color='#4facfe', ax=ax)\n\nax.set_title(f'{feature.replace(\"_\", \" \").title()} Distribution', \n            fontsize=14, fontweight='bold')\nax.set_xlabel('Count', fontsize=12)\nax.set_ylabel(feature.replace('_', ' ').title(), fontsize=12)\nax.grid(axis='x', alpha=0.3)\n\n# Add percentages\ntotal = value_counts.sum()\nfor i, v in enumerate(value_counts.values):\n    ax.text(v + 50, i, f'{v:,} ({v/total*100:.1f}%)', \n           va='center', fontsize=9)\n\nplt.tight_layout()\nplt.show()\n\n# Cardinality info\nprint(f\"\\nCardinality: {df[feature].nunique()} unique values\")\nprint(f\"Missing: {df[feature].isnull().sum()} ({df[feature].isnull().sum()/len(df)*100:.2f}%)\")"
  },
  "target_distribution": {
    "title": "Target Variable Analysis",
    "explanation": {
      "what": "Target distribution shows class balance and target characteristics. Critical for understanding what you're predicting.",
      "why": "Imbalanced targets require special handling: class weights, resampling (SMOTE, undersampling), or different evaluation metrics (F1, ROC-AUC instead of accuracy).",
      "how": "Check class ratio. Balanced = 40:60 to 50:50. Imbalanced = >2:1 ratio. Highly imbalanced = >10:1. Use stratified sampling and appropriate metrics."
    },
    "plotly": "import pandas as pd\nimport plotly.graph_objects as go\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Target distribution\ntarget_counts = df['income'].value_counts()\n\n# Create pie chart\nfig = go.Figure(data=[go.Pie(\n    labels=target_counts.index,\n    values=target_counts.values,\n    hole=0.35,\n    marker=dict(colors=['#667eea', '#f093fb']),\n    textinfo='label+percent+value',\n    textfont_size=14\n)])\n\nfig.update_layout(\n    title='Income Distribution (Target Variable)',\n    showlegend=True,\n    width=600,\n    height=400\n)\n\nfig.show()\n\n# Print statistics\nprint(\"Target Distribution:\")\nfor label, count in target_counts.items():\n    pct = count / len(df) * 100\n    print(f\"  {label}: {count:,} ({pct:.2f}%)\")\n\n# Imbalance ratio\nmajority = target_counts.max()\nminority = target_counts.min()\nratio = majority / minority\nprint(f\"\\nImbalance Ratio: {ratio:.2f}:1\")\nif ratio > 2:\n    print(\"‚ö†Ô∏è Dataset is imbalanced - consider using class weights or resampling\")\nelse:\n    print(\"‚úÖ Dataset is relatively balanced\")",
    "matplotlib": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Target distribution\ntarget_counts = df['income'].value_counts()\n\n# Create figure with 2 subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# Pie chart\ncolors = ['#667eea', '#f093fb']\nax1.pie(target_counts.values, labels=target_counts.index, autopct='%1.1f%%',\n       colors=colors, startangle=90)\nax1.set_title('Income Distribution (Pie Chart)', fontsize=14, fontweight='bold')\n\n# Bar chart\nax2.bar(target_counts.index, target_counts.values, color=colors, alpha=0.7)\nax2.set_title('Income Distribution (Bar Chart)', fontsize=14, fontweight='bold')\nax2.set_ylabel('Count')\nax2.grid(axis='y', alpha=0.3)\n\n# Add value labels\nfor i, (label, count) in enumerate(target_counts.items()):\n    ax2.text(i, count + 500, f'{count:,}', ha='center', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Print imbalance ratio\nratio = target_counts.max() / target_counts.min()\nprint(f\"\\nImbalance Ratio: {ratio:.2f}:1\")",
    "seaborn": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Target distribution\ntarget_counts = df['income'].value_counts()\n\n# Count plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\nsns.countplot(data=df, x='income', palette=['#667eea', '#f093fb'], ax=ax)\n\nax.set_title('Income Distribution', fontsize=16, fontweight='bold', pad=20)\nax.set_xlabel('Income Class', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nax.grid(axis='y', alpha=0.3)\n\n# Add percentage labels\ntotal = len(df)\nfor i, p in enumerate(ax.patches):\n    height = p.get_height()\n    pct = height / total * 100\n    ax.text(p.get_x() + p.get_width()/2., height + 500,\n           f'{int(height):,}\\n({pct:.1f}%)',\n           ha='center', fontweight='bold')\n\nplt.tight_layout()\nplt.show()"
  },
  "correlation_analysis": {
    "title": "Correlation Analysis",
    "explanation": {
      "what": "Correlation measures linear relationships between numerical features. Values range from -1 (perfect negative) to +1 (perfect positive).",
      "why": "High correlations indicate redundancy (multicollinearity). One feature may be sufficient, reducing model complexity and preventing overfitting.",
      "how": "Heatmap shows all pairwise correlations. |r| > 0.7 = high correlation (consider removing one). |r| < 0.3 = weak/no correlation. Use for feature selection."
    },
    "plotly": "import pandas as pd\nimport plotly.graph_objects as go\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Select numerical features\nnumerical_cols = ['age', 'fnlwgt', 'education_num', 'capital_gain', \n                  'capital_loss', 'hours_per_week']\n\n# Compute correlation matrix\ncorr_matrix = df[numerical_cols].corr()\n\n# Create heatmap\nfig = go.Figure(data=go.Heatmap(\n    z=corr_matrix.values,\n    x=corr_matrix.columns,\n    y=corr_matrix.columns,\n    colorscale='RdBu_r',\n    zmid=0,\n    text=corr_matrix.values,\n    texttemplate='%{text:.2f}',\n    textfont={\"size\": 10},\n    colorbar=dict(title=\"Correlation\")\n))\n\nfig.update_layout(\n    title='Correlation Matrix - Numerical Features',\n    width=700,\n    height=600,\n    xaxis={'tickangle': 45}\n)\n\nfig.show()\n\n# Print high correlations\nprint(\"\\nHigh Correlations (|r| > 0.5):\")\nfor i in range(len(numerical_cols)):\n    for j in range(i+1, len(numerical_cols)):\n        corr = corr_matrix.iloc[i, j]\n        if abs(corr) > 0.5:\n            print(f\"  {numerical_cols[i]} ‚Üî {numerical_cols[j]}: r = {corr:.3f}\")",
    "matplotlib": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Numerical features\nnumerical_cols = ['age', 'fnlwgt', 'education_num', 'capital_gain', \n                  'capital_loss', 'hours_per_week']\n\n# Correlation matrix\ncorr_matrix = df[numerical_cols].corr()\n\n# Create heatmap\nfig, ax = plt.subplots(figsize=(10, 8))\nim = ax.imshow(corr_matrix, cmap='RdBu_r', aspect='auto', vmin=-1, vmax=1)\n\n# Set ticks and labels\nax.set_xticks(np.arange(len(numerical_cols)))\nax.set_yticks(np.arange(len(numerical_cols)))\nax.set_xticklabels(numerical_cols)\nax.set_yticklabels(numerical_cols)\n\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n\n# Add colorbar\ncbar = plt.colorbar(im, ax=ax)\ncbar.set_label('Correlation Coefficient', rotation=270, labelpad=20)\n\n# Add correlation values\nfor i in range(len(numerical_cols)):\n    for j in range(len(numerical_cols)):\n        text = ax.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n                      ha=\"center\", va=\"center\",\n                      color=\"white\" if abs(corr_matrix.iloc[i, j]) > 0.5 else \"black\",\n                      fontsize=9, fontweight='bold')\n\nax.set_title('Correlation Matrix', fontsize=16, pad=20)\nplt.tight_layout()\nplt.show()",
    "seaborn": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Numerical features\nnumerical_cols = ['age', 'fnlwgt', 'education_num', 'capital_gain', \n                  'capital_loss', 'hours_per_week']\n\n# Correlation matrix\ncorr_matrix = df[numerical_cols].corr()\n\n# Create heatmap with seaborn\nfig, ax = plt.subplots(figsize=(10, 8))\n\nsns.heatmap(corr_matrix,\n           annot=True,\n           fmt='.2f',\n           cmap='RdBu_r',\n           center=0,\n           square=True,\n           linewidths=0.5,\n           cbar_kws={'label': 'Correlation Coefficient'},\n           ax=ax)\n\nax.set_title('Correlation Matrix - Numerical Features', fontsize=16, pad=20)\nplt.tight_layout()\nplt.show()\n\n# Pair plot (select top features)\ntop_features = ['age', 'education_num', 'hours_per_week']\nsns.pairplot(df[top_features + ['income']], hue='income', \n            palette={'<=50K': '#667eea', '>50K': '#f093fb'},\n            diag_kind='kde', plot_kws={'alpha': 0.6})\nplt.suptitle('Pair Plot - Selected Features', y=1.01)\nplt.show()"
  },
  "outlier_detection": {
    "title": "Outlier Detection",
    "explanation": {
      "what": "Outliers are data points that significantly differ from other observations. Can be measurement errors, data entry mistakes, or rare but valid extreme values that actually occur in the real world.",
      "why": "Outliers can severely skew statistics (mean, std), bias model training, and lead to poor predictions on normal data. Identifying them helps decide appropriate action: keep (if valid), remove (if errors), or cap (winsorize) to reduce impact.",
      "how": "<div class='outlier-methods'><div class='method-box'><strong>üìê IQR Method (Interquartile Range):</strong><div class='formula'>Lower Bound = Q1 - 1.5 √ó IQR</div><div class='formula'>Upper Bound = Q3 + 1.5 √ó IQR</div><div class='formula'>IQR = Q3 - Q1</div><p>Values <strong>outside [Lower, Upper]</strong> are outliers. Standard box plot method.</p></div><div class='method-box'><strong>üìä Z-Score Method:</strong><div class='formula'>z = (x - Œº) / œÉ</div><p>If <strong>|z| > 3</strong>, value is outlier (>3 std from mean). Assumes normal distribution.</p></div><div class='method-box'><strong>‚ö†Ô∏è Important:</strong> Always <strong>investigate</strong> outliers before removing! They may contain valuable insights (e.g., high earners in income data).</div></div>"
    },
    "plotly": "import pandas as pd\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Select features with potential outliers\nfeatures = ['age', 'capital_gain', 'hours_per_week']\n\n# Create box plots\nfig = make_subplots(\n    rows=1, cols=3,\n    subplot_titles=[f.replace('_', ' ').title() for f in features]\n)\n\ncolors = ['#667eea', '#f093fb', '#43e97b']\n\nfor idx, (feature, color) in enumerate(zip(features, colors), 1):\n    fig.add_trace(\n        go.Box(y=df[feature], name=feature, marker_color=color, boxmean='sd'),\n        row=1, col=idx\n    )\n\nfig.update_layout(\n    title_text='Outlier Detection - Box Plots',\n    showlegend=False,\n    height=400,\n    width=1200\n)\n\nfig.show()\n\n# IQR method for one feature\nfeature = 'capital_gain'\nQ1 = df[feature].quantile(0.25)\nQ3 = df[feature].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\noutliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n\nprint(f\"\\n{feature} - IQR Outlier Detection:\")\nprint(f\"  Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\nprint(f\"  Bounds: [{lower_bound:.2f}, {upper_bound:.2f}]\")\nprint(f\"  Outliers: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)\")\nprint(f\"  Outlier range: [{outliers[feature].min():.2f}, {outliers[feature].max():.2f}]\")",
    "matplotlib": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Create box plots for all numerical features\nnumerical_cols = ['age', 'education_num', 'capital_gain', \n                  'capital_loss', 'hours_per_week']\n\nfig, axes = plt.subplots(1, 5, figsize=(16, 5))\nfig.suptitle('Outlier Detection - Box Plots', fontsize=16, y=1.02)\n\ncolors = ['#667eea', '#764ba2', '#f093fb', '#4facfe', '#43e97b']\n\nfor idx, (col, color) in enumerate(zip(numerical_cols, colors)):\n    ax = axes[idx]\n    \n    bp = ax.boxplot(df[col].dropna(), vert=True, patch_artist=True,\n                    boxprops=dict(facecolor=color, alpha=0.7),\n                    medianprops=dict(color='red', linewidth=2))\n    \n    ax.set_title(col.replace('_', ' ').title(), fontsize=11, fontweight='bold')\n    ax.set_ylabel('Value')\n    ax.grid(axis='y', alpha=0.3)\n    \n    # Add outlier count\n    Q1, Q3 = df[col].quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    outliers = df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)]\n    \n    ax.text(0.5, 0.98, f'Outliers: {len(outliers)} ({len(outliers)/len(df)*100:.1f}%)',\n           transform=ax.transAxes, ha='center', va='top', fontsize=8,\n           bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n\nplt.tight_layout()\nplt.show()",
    "seaborn": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Numerical features\nnumerical_cols = ['age', 'education_num', 'capital_gain', 'hours_per_week']\n\n# Box plots\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfig.suptitle('Outlier Detection Using Box Plots', fontsize=16)\n\nfor idx, col in enumerate(numerical_cols):\n    ax = axes[idx // 2, idx % 2]\n    \n    sns.boxplot(y=df[col], color='#667eea', ax=ax)\n    ax.set_title(col.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n    ax.grid(axis='y', alpha=0.3)\n    \n    # Calculate outliers\n    Q1, Q3 = df[col].quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    outliers = len(df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)])\n    \n    ax.text(0.02, 0.98, f'Outliers: {outliers}',\n           transform=ax.transAxes, va='top',\n           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n\nplt.tight_layout()\nplt.show()\n\n# Violin plot (shows distribution + outliers)\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.violinplot(data=df[numerical_cols], palette='muted', ax=ax)\nax.set_title('Feature Distributions with Outliers (Violin Plot)', fontsize=14, fontweight='bold')\nax.set_ylabel('Value')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()"
  },
  "target_vs_features": {
    "title": "Target vs Features Analysis",
    "explanation": {
      "what": "Analyze how target variable relates to each feature. Shows which features strongly correlate with the target.",
      "why": "Features with strong target relationship are good predictors. Weak relationship features may not add value to models.",
      "how": "For categorical: compare target distribution across categories. For numerical: compare mean/median by target class. Large differences = strong predictor."
    },
    "plotly": "import pandas as pd\nimport plotly.graph_objects as go\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Analyze income by categorical feature\nfeature = 'education'  # Change to: sex, marital_status, occupation, etc.\n\n# Cross-tabulation (percentage)\ncrosstab = pd.crosstab(df[feature], df['income'], normalize='index') * 100\n\n# Sort by >50K percentage\ncrosstab = crosstab.sort_values('>50K', ascending=False)\n\n# Create grouped bar chart\nfig = go.Figure()\n\nfig.add_trace(go.Bar(\n    name='<=50K',\n    x=crosstab.index,\n    y=crosstab['<=50K'],\n    marker_color='#667eea'\n))\n\nfig.add_trace(go.Bar(\n    name='>50K',\n    x=crosstab.index,\n    y=crosstab['>50K'],\n    marker_color='#f093fb'\n))\n\nfig.update_layout(\n    title=f'Income Distribution by {feature.replace(\"_\", \" \").title()}',\n    xaxis_title=feature.replace('_', ' ').title(),\n    yaxis_title='Percentage (%)',\n    barmode='stack',\n    width=1000,\n    height=500,\n    xaxis={'tickangle': 45}\n)\n\nfig.show()\n\n# Print insights\nprint(f\"\\n{feature} with highest >50K rate:\")\nprint(crosstab.nlargest(5, '>50K'))",
    "matplotlib": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Analyze top categorical features\nfeatures = ['sex', 'education', 'marital_status']\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nfig.suptitle('Income Distribution by Categorical Features', fontsize=16)\n\nfor idx, feature in enumerate(features):\n    ax = axes[idx]\n    \n    # Cross-tabulation (counts)\n    crosstab = pd.crosstab(df[feature], df['income'])\n    \n    # Stacked bar chart\n    crosstab.plot(kind='bar', stacked=True, color=['#667eea', '#f093fb'],\n                 alpha=0.8, ax=ax)\n    \n    ax.set_title(feature.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n    ax.set_xlabel('')\n    ax.set_ylabel('Count')\n    ax.legend(title='Income', fontsize=9)\n    ax.grid(axis='y', alpha=0.3)\n    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n\nplt.tight_layout()\nplt.show()",
    "seaborn": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load data\nurl = 'https://raw.githubusercontent.com/LTSACH/AILearningHub/main/datasets/adult-income/data/adult_train.csv'\ndf = pd.read_csv(url)\n\n# Select feature\nfeature = 'marital_status'  # Change to other features\n\n# Count plot grouped by income\nfig, ax = plt.subplots(figsize=(12, 6))\n\nsns.countplot(data=df, x=feature, hue='income',\n             palette={'<=50K': '#667eea', '>50K': '#f093fb'},\n             ax=ax)\n\nax.set_title(f'Income Distribution by {feature.replace(\"_\", \" \").title()}',\n            fontsize=14, fontweight='bold')\nax.set_xlabel(feature.replace('_', ' ').title(), fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nax.legend(title='Income', fontsize=10)\nax.grid(axis='y', alpha=0.3)\n\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()\n\n# Percentage breakdown\ncrosstab = pd.crosstab(df[feature], df['income'], normalize='index') * 100\nprint(f\"\\n{feature} - Income Distribution (%):\")\nprint(crosstab.round(2))"
  }
}